from python import Python, PythonObject
from sys.param_env import env_get_int, env_get_string

# Helper function to retrieve and convert float parameters
fn get_float_param(name: String, default: String) -> Float64:
    let raw_value = env_get_string[name, default]()
    match Float64.parse(raw_value):
        .Some(value) -> value
        .None -> 
            # Handle parsing error by using the default value
            print("Warning: Unable to parse float for parameter '" + name + "'. Using default value: " + default)
            Float64.parse(default).unwrap()

# Function to retrieve compile-time parameters using param_env
fn get_parameters() raises -> PythonObject:
    # Retrieve compile-time parameters with default values
    var params = Python.import_module("builtins").dict()

    params["max_epochs"] = env_get_int["max_epochs", 100]()
    params["batch_size"] = env_get_int["batch_size", 16]()
    params["use_gpu"] = env_get_int["use_gpu", 0]() != 0  # Convert int to bool
    params["grokfast_type"] = env_get_string["grokfast_type", "ema"]()
    params["learning_rate"] = get_float_param("learning_rate", "1e-4")
    params["num_workers"] = env_get_int["num_workers", 4]()
    params["fast_dev_run"] = env_get_int["fast_dev_run", 0]() != 0
    params["optuna_study_name"] = env_get_string["optuna_study_name", ""]()
    params["optuna_storage"] = env_get_string["optuna_storage", "sqlite:///optuna_results.db"]()
    params["prefetch_factor"] = env_get_int["prefetch_factor", 2]()
    params["no_persistent_workers"] = env_get_int["no_persistent_workers", 0]() != 0
    params["grokfast_alpha"] = get_float_param("grokfast_alpha", "0.98")
    params["grokfast_lamb"] = get_float_param("grokfast_lamb", "2.0")
    params["grokfast_window_size"] = env_get_int["grokfast_window_size", 100]()
    params["no_logging"] = env_get_int["no_logging", 0]() != 0
    params["no_checkpointing"] = env_get_int["no_checkpointing", 0]() != 0
    params["no_progress_bar"] = env_get_int["no_progress_bar", 0]() != 0
    params["model_checkpoint"] = env_get_string["model_checkpoint", ""]()
    params["project"] = env_get_string["project", "gpt2-arc"]()
    params["val_check_interval"] = get_float_param("val_check_interval", "0.01")
    params["enable_symbol_freq"] = env_get_int["enable_symbol_freq", 0]() != 0
    params["results_dir"] = env_get_string["results_dir", "./results"]()
    params["run_name"] = env_get_string["run_name", "default_run"]()
    params["use_synthetic_data"] = env_get_int["use_synthetic_data", 0]() != 0
    params["train_split"] = get_float_param("train_split", "0.8")
    params["val_split"] = get_float_param("val_split", "0.1")
    params["test_split"] = get_float_param("test_split", "0.1")
    params["matmul_precision"] = env_get_string["matmul_precision", "medium"]()
    params["synthetic_data_path"] = env_get_string["synthetic_data_path", ""]()
    params["log_level"] = env_get_string["log_level", "INFO"]()
    params["use_optuna"] = env_get_int["use_optuna", 0]() != 0
    params["accelerator"] = env_get_string["accelerator", "gpu"]()
    params["profiler_dirpath"] = env_get_string["profiler_dirpath", "./profiler_logs"]()
    params["profiler_filename"] = env_get_string["profiler_filename", "profile"]()
    params["include_pad_in_accuracy"] = env_get_int["include_pad_in_accuracy", 1]() != 0

    return params

# Function to validate mamba_ratio
def validate_mamba_ratio(value: Float64) -> Float64:
    if value < 0.0 or value > 1.0:
        raise Error("mamba_ratio must be between 0.0 and 1.0")
    return value


# Define ConfigSavingModelCheckpoint using Python interop
def create_config_saving_model_checkpoint(config: PythonObject, trial_num: String = "NA", task_id: String = "NA", iter_num: String = "NA") -> PythonObject:
    var ModelCheckpoint = Python.import_module("pytorch_lightning.callbacks").ModelCheckpoint
    var datetime_module = Python.import_module("datetime")
    
    struct ConfigSavingModelCheckpoint(ModelCheckpoint):
        def __init__(self, config, trial_num="NA", task_id="NA", iter_num="NA", *args, **kwargs):
            super().__init__(*args, **kwargs)
            self.config = config
            self.trial_num = trial_num
            self.task_id = task_id
            self.iter_num = iter_num
            self.timestamp = datetime_module.datetime.now().strftime("%Y%m%dT%H%M%S")
        
        def on_save_checkpoint(self, trainer, pl_module, checkpoint):
            checkpoint["model_config"] = self.config.model.__dict__
            checkpoint["trial_num"] = self.trial_num
            checkpoint["task_id"] = self.task_id
            checkpoint["iter_num"] = self.iter_num
            checkpoint["timestamp"] = self.timestamp
            super().on_save_checkpoint(trainer, pl_module, checkpoint)
        
        def format_checkpoint_name(self, metrics):
            return self.filename.format(
                trial_num=self.trial_num,
                task_id=self.task_id,
                iter_num=self.iter_num,
                val_loss=metrics.get("val_loss", 0.0),
                epoch=metrics.get("epoch", 0),
                timestamp=self.timestamp
            )
    
    return ConfigSavingModelCheckpoint(config, trial_num, task_id, iter_num)

# Define ModelConfigSaver using Python interop
def create_model_config_saver(config: PythonObject) -> PythonObject:
    var Callback = Python.import_module("pytorch_lightning.callbacks").Callback
    
    class ModelConfigSaver(Callback):
        def __init__(self, config):
            super().__init__()
            self.config = config
        
        def on_save_checkpoint(self, trainer, pl_module, checkpoint):
            checkpoint["model_config"] = self.config.model.__dict__
    
    return ModelConfigSaver(config)

# Prepare validation or test data
def prepare_val_or_test_data(eval_set: PythonObject, args: PythonObject, is_validation: Bool = True) -> List[Dict[String, Any]]:
    var set_type = "validation" if is_validation else "test"
    var logger = Python.import_module("logging").getLogger("train")
    logger.debug("Preparing " + set_type + " data from arckit evaluation set")
    
    var samples: List[Dict[String, Any]] = []
    for task in eval_set.tasks:
        if is_validation:
            examples = task.train
        else:
            examples = task.test
        for ex in examples:
            var sample = {"input": ex[0], "output": ex[1], "task_id": task.id}
            samples.append(sample)
    
    logger.debug("Prepared " + String(len(samples)) + " samples for " + set_type + " dataset")
    return samples

# Load dataset
def load_dataset(args: PythonObject, config: PythonObject, dataset_type: String = "train", all_synthetic_data: Optional[PythonObject] = None) -> PythonObject:
    var logger = Python.import_module("logging").getLogger("train")
    logger.debug("load_dataset called with dataset_type='" + dataset_type + "', args.use_synthetic_data=" + String(args.use_synthetic_data))
    
    if dataset_type.lower() == "train":
        if args.use_synthetic_data:
            dataset = all_synthetic_data["train_dataset"]
        else:
            var arckit = Python.import_module("arckit")
            dataset = Python.import_module("gpt2_arc.src.data.arc_dataset").ARCDataset(
                data_source=arckit.load_data()[0],
                is_test=False,
                max_samples=args.max_train_samples,
                num_symbols=config.training.num_symbols,
                pad_symbol_idx=config.training.pad_symbol_idx,
                symbol_freq=config.training.symbol_freq if args.enable_symbol_freq else None
            )
    else:
        var arckit = Python.import_module("arckit")
        var eval_set = arckit.load_data()[1]
        var data_source = prepare_val_or_test_data(eval_set, args, is_validation=(dataset_type.lower() == "val"))
        dataset = Python.import_module("gpt2_arc.src.data.arc_dataset").ARCDataset(
            data_source=data_source,
            is_test=(dataset_type.lower() == "test"),
            num_symbols=config.training.num_symbols,
            pad_symbol_idx=config.training.pad_symbol_idx,
            symbol_freq=config.training.symbol_freq if args.enable_symbol_freq else None
        )
    
    if len(dataset) == 0:
        logger.error("No samples loaded for " + dataset_type + " dataset. Please check your data source.")
        raise Error("No samples loaded for " + dataset_type + " dataset.")
    
    logger.debug(dataset_type.capitalize() + " dataset loaded with " + String(len(dataset)) + " samples")
    return dataset

# Load and split synthetic data
def load_and_split_synthetic_data(args: PythonObject, config: PythonObject) -> PythonObject:
    var logger = Python.import_module("logging").getLogger("train")
    logger.debug("Entering load_and_split_synthetic_data function")
    
    synthetic_dataset = Python.import_module("gpt2_arc.src.data.arc_dataset").ARCDataset(
        data_source=args.synthetic_data_path,
        is_test=False,
        max_samples=args.max_train_samples,
        num_symbols=config.training.num_symbols,
        pad_symbol_idx=config.training.pad_symbol_idx,
        symbol_freq=config.training.symbol_freq if args.enable_symbol_freq else None
    )
    
    var total_samples = len(synthetic_dataset)
    logger.debug("Total synthetic samples loaded: " + String(total_samples))
    assert total_samples > 0, "No synthetic samples were loaded. Please check your synthetic data files."
    
    return {"train_dataset": synthetic_dataset}

# Train model
def train_model(args: PythonObject) -> None:
    # Import necessary Python modules directly within the function
    var argparse = Python.import_module("argparse")
    var logging = Python.import_module("logging")
    var os = Python.import_module("os")
    var sys = Python.import_module("sys")
    var torch = Python.import_module("torch")
    var numpy = Python.import_module("numpy")
    var pytorch_lightning = Python.import_module("pytorch_lightning")
    var optuna = Python.import_module("optuna")
    var arckit = Python.import_module("arckit")
    var concurrent_futures = Python.import_module("concurrent.futures")
    var random = Python.import_module("random")
    var tqdm = Python.import_module("tqdm")
    var datetime_module = Python.import_module("datetime")
    
    var logger = logging.getLogger("train")
    logger.debug("Initializing PyTorch Lightning Trainer")
    
    if args.use_synthetic_data and not args.synthetic_data_path:
        raise Error("--synthetic_data_path must be provided when using synthetic data.")
    
    var total_split = args.train_split + args.val_split + args.test_split
    if not (abs(total_split - 1.0) < 1e-6):
        raise Error("Train, validation, and test splits must sum to 1.0")
    
    torch.set_float32_matmul_precision(args.matmul_precision)
    logger.info("Set float32 matmul precision to: " + args.matmul_precision)
    logger.debug("Command line arguments: " + String(args))
    
    # Initialize profiler if needed
    if args.use_profiler:
        var ProfilerActivity = Python.import_module("torch.profiler").ProfilerActivity
        profiler = Python.import_module("lightning.pytorch.profilers").PyTorchProfiler(
            dirpath=args.profiler_dirpath,
            filename=args.profiler_filename,
            activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],
            record_shapes=True,
            with_stack=True
        )
    else:
        profiler = None
    
    logger.setLevel(Python.evaluate("logging.DEBUG"))
    logger.info("Starting main function")
    logger.debug("Initializing PyTorch Lightning Trainer")
    logger.debug("Command line arguments: " + String(args))
    
    var trainer = None  # Initialize trainer to None
    
    try:
        if args.use_optuna:
            logger.info("Loading best hyperparameters from Optuna study")
            var study_name = args.optuna_study_name
            
            if study_name is None:
                var study_summaries = optuna.get_all_study_summaries(storage=args.optuna_storage)
                var study_names = [summary.study_name for summary in study_summaries]
                
                if len(study_names) == 1:
                    study_name = study_names[0]
                    logger.info("Automatically selected the only available study: " + study_name)
                elif len(study_names) == 0:
                    logger.error("No studies found in the specified Optuna storage.")
                    sys.exit(1)
                else:
                    logger.error("Multiple studies found in the specified Optuna storage. Please specify the study name using --optuna-study-name.")
                    sys.exit(1)
            
            try:
                var study = optuna.load_study(study_name=study_name, storage=args.optuna_storage)
            except KeyError:
                var study = optuna.create_study(study_name=study_name, storage=args.optuna_storage)
            
            var best_params = study.best_params
            logger.debug("Loaded best parameters: " + String(best_params))
            
            var n_head_exp = best_params["n_head_exp"]
            var n_head = 2 ** n_head_exp
            var n_embd_multiplier = best_params["n_embd_multiplier"]
            var n_embd = n_head * n_embd_multiplier
            n_embd = 2 ** Python.evaluate("int(np.log2(n_embd))")
            
            var ModelConfig = Python.import_module("gpt2_arc.src.config").ModelConfig
            var TrainingConfig = Python.import_module("gpt2_arc.src.config").TrainingConfig
            
            var model_config = ModelConfig(
                n_embd=n_embd,
                n_head=n_head,
                n_layer=best_params["n_layer"],
                dropout=best_params["dropout"],
                num_workers=args.num_workers if args.num_workers is not None else Python.import_module("multiprocessing").cpu_count(),
                prefetch_factor=args.prefetch_factor,
                persistent_workers=not args.no_persistent_workers,
                pin_memory=not args.no_pin_memory,
            )
            
            var training_config = TrainingConfig(
                batch_size=best_params["batch_size"],
                learning_rate=best_params["learning_rate"],
                max_epochs=args.max_epochs,
                use_gpu=args.use_gpu,
                log_level=args.log_level,
                use_synthetic_data=args.use_synthetic_data,
                synthetic_data_path=args.synthetic_data_path,
                include_pad_in_loss=args.include_pad_in_loss,
                include_pad_in_accuracy=args.include_pad_in_accuracy,
                num_workers=args.num_workers,
                prefetch_factor=args.prefetch_factor,
                persistent_workers=not args.no_persistent_workers,
                pin_memory=args.pin_memory,
                use_grokfast=args.use_grokfast,
                grokfast_type=args.grokfast_type,
                grokfast_alpha=args.grokfast_alpha,
                grokfast_lamb=args.grokfast_lamb,
                grokfast_window_size=args.grokfast_window_size,
            )
        else:
            logger.info("Using provided or default hyperparameters")
            var ModelConfig = Python.import_module("gpt2_arc.src.config").ModelConfig
            var TrainingConfig = Python.import_module("gpt2_arc.src.config").TrainingConfig
            
            var model_config = ModelConfig(
                n_embd=args.n_embd,
                n_head=args.n_head,
                n_layer=args.n_layer,
                dropout=args.dropout,
                mamba_ratio=args.mamba_ratio,
                d_state=args.d_state,
                d_conv=args.d_conv,
                mamba_depth=args.mamba_depth,
                mamba_expand=args.mamba_expand,
            )
            
            var training_config = TrainingConfig(
                batch_size=args.batch_size,
                learning_rate=args.learning_rate,
                max_epochs=args.max_epochs,
                use_gpu=args.use_gpu,
                log_level=args.log_level,
                use_synthetic_data=args.use_synthetic_data,
                synthetic_data_path=args.synthetic_data_path,
                use_grokfast=args.use_grokfast,
                grokfast_type=args.grokfast_type,
                grokfast_alpha=args.grokfast_alpha,
                grokfast_lamb=args.grokfast_lamb,
                grokfast_window_size=args.grokfast_window_size,
                include_pad_in_loss=args.include_pad_in_loss,
                include_pad_in_accuracy=args.include_pad_in_accuracy,
                num_workers=args.num_workers,
                prefetch_factor=args.prefetch_factor,
                persistent_workers=not args.no_persistent_workers,
                pin_memory=args.pin_memory,
            )
        
        var Config = Python.import_module("gpt2_arc.src.config").Config
        var config = Config(model=model_config, training=training_config)
        logger.debug("Configuration: " + String(config))
        
        if args.use_synthetic_data:
            var all_synthetic_data = load_and_split_synthetic_data(args, config)
        else:
            var all_synthetic_data = None
        
        logger.info("Loading datasets sequentially to avoid memory allocation issues")
        
        try:
            var train_data = load_dataset(args, config, dataset_type="train", all_synthetic_data=all_synthetic_data)
            var val_data = load_dataset(args, config, dataset_type="val")
            var test_data = load_dataset(args, config, dataset_type="test")
        except Error as e:
            logger.error("Error loading datasets: " + String(e))
            raise
        
        logger.info("Training dataset source: " + ("synthetic data" if args.use_synthetic_data else "official ARC data"))
        logger.info("Validation dataset source: official ARC data")
        logger.info("Test dataset source: official ARC data")
        
        logger.debug("Number of training samples: " + String(len(train_data)))
        logger.debug("Number of validation samples: " + String(len(val_data)))
        logger.debug("Number of test samples: " + String(len(test_data)))
        
        if args.enable_symbol_freq:
            logger.debug("Calculating symbol frequencies as it is enabled.")
            if args.use_synthetic_data:
                logger.debug("Calculating symbol frequencies for synthetic training set")
                var symbol_freq = train_data.get_symbol_frequencies()
            else:
                logger.debug("Calculating symbol frequencies for ARC training set")
                var symbol_freq = train_data.get_symbol_frequencies()
            
            var symbol_freq_dict = {}
            for (i, freq) in symbol_freq.enumerate():
                symbol_freq_dict[i] = Float64(freq)
            var pad_symbol_idx = config.training.pad_symbol_idx
            symbol_freq_dict.pop(pad_symbol_idx, None)
            logger.debug("Removed pad_symbol_idx (" + String(pad_symbol_idx) + ") from symbol_freq_dict. New length: " + String(len(symbol_freq_dict)))
            
            assert(len(symbol_freq_dict) == config.training.num_classes - 1, "Length of symbol_freq_dict (" + String(len(symbol_freq_dict)) + ") does not match num_classes minus padding (" + String(config.training.num_classes - 1) + ").")
            
            var balance_symbols = True
            var balancing_method = "weighting"
        else:
            var symbol_freq_dict = {}
            logger.debug("Symbol frequency calculation is disabled. Using empty symbol_freq_dict.")
            var balance_symbols = False
            var balancing_method = "none"
        
        var TrainingConfigUpdated = Python.import_module("gpt2_arc.src.config").TrainingConfig
        training_config = TrainingConfigUpdated(
            batch_size=training_config.batch_size,
            learning_rate=training_config.learning_rate,
            max_epochs=training_config.max_epochs,
            use_gpu=training_config.use_gpu,
            log_level=training_config.log_level,
            use_synthetic_data=training_config.use_synthetic_data,
            synthetic_data_path=training_config.synthetic_data_path,
            include_pad_in_loss=training_config.include_pad_in_loss,
            include_pad_in_accuracy=training_config.include_pad_in_accuracy,
            symbol_freq=symbol_freq_dict,
            balance_symbols=balance_symbols,
            balancing_method=balancing_method,
            num_workers=training_config.num_workers,
            prefetch_factor=training_config.prefetch_factor,
            persistent_workers=training_config.persistent_workers,
            pin_memory=training_config.pin_memory,
            use_grokfast=training_config.use_grokfast,
            grokfast_type=training_config.grokfast_type,
            grokfast_alpha=training_config.grokfast_alpha,
            grokfast_lamb=training_config.grokfast_lamb,
            grokfast_window_size=training_config.grokfast_window_size
        )
        
        config = Config(model=model_config, training=training_config)
        
        # Calculate symbol frequencies if enabled
        if args.enable_symbol_freq:
            if args.use_synthetic_data:
                logger.debug("Calculating symbol frequencies for synthetic training set")
                var train_symbol_freq = train_data.get_symbol_frequencies()
            else:
                logger.debug("Calculating symbol frequencies for ARC training set")
                var train_symbol_freq = train_data.get_symbol_frequencies()
        else:
            var train_symbol_freq = {}
        
        var num_classes = config.training.num_classes
        logger.info("Number of classes set to: " + String(num_classes))
        logger.info("Creating DataLoader instances")
        
        # Ensure test_data is not None
        assert(test_data is not None, "Test dataset is None after loading.")
        
        # Initialize model
        logger.info("Initializing model")
        var GPT2ARC = Python.import_module("gpt2_arc.src.models.gpt2").GPT2ARC
        var model = GPT2ARC(
            config=config,
            num_classes=config.training.num_classes,
            symbol_freq=symbol_freq_dict,
            pad_symbol_idx=config.training.pad_symbol_idx
        )
        logger.debug("Model initialized with config: " + String(model_config))
        
        # Calculate Mamba and Transformer layers
        var mamba_layers = Int(config.model.n_layer * config.model.mamba_ratio)
        var transformer_layers = config.model.n_layer - mamba_layers
        logger.info("Number of Mamba layers: " + String(mamba_layers))
        logger.info("Number of Transformer layers: " + String(transformer_layers))
        
        # Validate layers
        if mamba_layers < 0 or transformer_layers < 0:
            logger.error("Calculation of mamba_layers or transformer_layers resulted in negative numbers.")
            raise Error("Invalid layer count: mamba_layers and transformer_layers must be non-negative.")
        
        if mamba_layers + transformer_layers != config.model.n_layer:
            logger.error("The sum of mamba_layers and transformer_layers does not match n_layer.")
            raise Error("Inconsistency in layer count: verify that mamba_ratio is set correctly.")
        
        # Load the checkpoint if specified
        if args.model_checkpoint:
            logger.info("Loading model from checkpoint: " + args.model_checkpoint)
            var checkpoint = torch.load(args.model_checkpoint)
            if "model_config" in checkpoint and "training_config" in checkpoint:
                var ModelConfig = Python.import_module("gpt2_arc.src.config").ModelConfig
                var TrainingConfig = Python.import_module("gpt2_arc.src.config").TrainingConfig
                var model_config = ModelConfig(**checkpoint["model_config"])
                var training_config = TrainingConfig(**checkpoint["training_config"])
                config = Config(model=model_config, training=training_config)
                var num_classes = config.training.num_classes
                var symbol_freq_dict = config.training.symbol_freq
                model = GPT2ARC(config=config, num_classes=num_classes, symbol_freq=symbol_freq_dict, pad_symbol_idx=config.training.pad_symbol_idx)
                logger.debug("Loaded TrainingConfig with num_classes=" + String(num_classes) + " from checkpoint")
            else:
                logger.error("Checkpoint missing 'model_config' or 'training_config'.")
                raise KeyError("Checkpoint must contain 'model_config' and 'training_config'.")
            model.load_state_dict(checkpoint["state_dict"])
        
        # Log dataset source information
        if args.use_synthetic_data:
            logger.info("Using synthetic data for training, validation, and testing.")
        else:
            logger.info("Using official ARC datasets for training, validation, and testing.")
        
        var ResultsCollector = Python.import_module("gpt2_arc.src.utils.results_collector").ResultsCollector
        var results_collector = ResultsCollector(config)
        
        # Initialize experiment tracker
        var ExperimentTracker = Python.import_module("gpt2_arc.src.utils.experiment_tracker").ExperimentTracker
        var tracker = ExperimentTracker(config, project=args.project)
        
        logger.info("Initializing ARCTrainer")
        var ARCTrainer = Python.import_module("gpt2_arc.src.training.trainer").ARCTrainer
        var trainer_py = ARCTrainer(
            model=model,
            train_dataset=train_data,
            val_dataset=val_data,
            config=config,
            args=args,
            results_collector=results_collector,
            test_dataset=test_data
        )
        trainer_py.log_hyperparameters()
        
        # Determine accelerator parameters based on the --accelerator argument
        if args.accelerator == "tpu":
            var accelerator = "tpu"
            var devices = "xla:1"  # Use 'xla:8' for TPU v3-8 pods
            var strategy = "tpu_spawn"  # Recommended strategy for TPU
        elif args.accelerator == "gpu":
            if torch.cuda.is_available():
                var accelerator = "gpu"
                var devices = 1
            else:
                var accelerator = "cpu"
                var devices = 1
            var strategy = "auto"
        else:
            var accelerator = "cpu"
            var devices = 1
            var strategy = "auto"
        
        # Initialize callbacks list
        var callbacks: List[PythonObject] = []
        
        # Initialize GrokfastCallback if enabled
        if config.training.use_grokfast:
            var GrokfastCallback = Python.import_module("gpt2_arc.src.utils").GrokfastCallback
            var grokfast_callback = GrokfastCallback(
                filter_type=config.training.grokfast_type,
                alpha=config.training.grokfast_alpha,
                lamb=config.training.grokfast_lamb,
                window_size=(config.training.grokfast_window_size if config.training.grokfast_type == "ma" else 100),
                warmup=True,
                trigger=False
            )
            callbacks.append(grokfast_callback)
            logger.info("GrokfastCallback added to the training callbacks.")
        else:
            logger.info("Grokfast is disabled; no callback added.")
        
        # Add the standard ModelCheckpoint callback
        if not args.no_checkpointing:
            var ModelCheckpoint = Python.import_module("pytorch_lightning.callbacks").ModelCheckpoint
            var checkpoint_filename = ("resume-" if args.model_checkpoint else "") + "checkpoint-step_{step}-val_loss_{val_loss:.4f}"
            var checkpoint_callback = ModelCheckpoint(
                dirpath="checkpoints",
                filename=checkpoint_filename,
                save_top_k=3,
                monitor="val_loss",
                mode="min"
            )
            callbacks.append(checkpoint_callback)
            
            # Instantiate and add the ModelConfigSaver callback
            var ModelConfigSaver = create_model_config_saver(config)
            callbacks.append(ModelConfigSaver)
            logger.info("ModelConfigSaver callback added to the training callbacks.")
        
        logger.info("Setting up PyTorch Lightning trainer")
        
        # Define trial_num, task_id, and iter_num
        var trial_num = 0  # Initialize to 0 or another appropriate default
        var task_id = "default_task"  # Replace with dynamic task identification if necessary
        var iter_num = 1  # Initialize to 1; increment as needed within your training loop
        
        # Initialize TensorBoard logger if logging is enabled
        if not args.no_logging:
            var TensorBoardLogger = Python.import_module("pytorch_lightning.loggers").TensorBoardLogger
            var tb_logger = TensorBoardLogger(
                save_dir="runs",
                name="experiment_" + String(results_collector.experiment_id)
            )
            logger.debug("TensorBoard logger initialized. Log dir: " + tb_logger.log_dir)
        else:
            var tb_logger = Python.None
            logger.debug("Logging is disabled")
        
        # Initialize PyTorch Lightning Trainer
        var pl_trainer = pytorch_lightning.Trainer(
            max_epochs=config.training.max_epochs,
            logger=(tb_logger if not args.no_logging else Python.None),
            callbacks=(callbacks if len(callbacks) > 0 else Python.None),
            enable_checkpointing=not args.no_checkpointing,
            enable_progress_bar=not args.no_progress_bar,
            fast_dev_run=args.fast_dev_run,
            gradient_clip_val=1.0,
            precision=16,
            accelerator=accelerator,
            devices=devices,
            strategy=strategy,
            profiler=profiler,
            val_check_interval=args.val_check_interval
        )
        
        if not args.no_logging:
            trainer_py.results_collector.set_tensorboard_log_path(tb_logger.log_dir)
            logger.debug("TensorBoard log path set in results collector: " + tb_logger.log_dir)
        
        # Log initial memory usage
        if args.use_gpu and torch.cuda.is_available():
            var memory_allocated = torch.cuda.memory_allocated()
            var memory_reserved = torch.cuda.memory_reserved()
            logger.info("Initial CUDA memory allocated: " + String(memory_allocated) + " bytes")
            logger.info("Initial CUDA memory reserved: " + String(memory_reserved) + " bytes")
        
        logger.info("Starting model training")
        logger.debug("Training parameters: batch_size=" + String(config.training.batch_size) + ", learning_rate=" + String(config.training.learning_rate) + ", max_epochs=" + String(config.training.max_epochs))
        
        # Train the model
        logger.info("Starting model training")
        pl_trainer.fit(trainer_py)
        
        # Log memory usage after training
        if args.use_gpu and torch.cuda.is_available():
            var memory_allocated = torch.cuda.memory_allocated()
            var memory_reserved = torch.cuda.memory_reserved()
            logger.info("CUDA memory allocated after training: " + String(memory_allocated) + " bytes")
            logger.info("CUDA memory reserved after training: " + String(memory_reserved) + " bytes")
        
        logger.info("Model training completed successfully.")
        
        # Define DataLoader for test data
        var DataLoader = Python.import_module("torch.utils.data").DataLoader
        var test_loader = DataLoader(
            test_data,
            batch_size=config.training.batch_size,
            shuffle=False,
            num_workers=config.training.num_workers,
            pin_memory=config.training.pin_memory
        )
        
        # After training, run test
        logger.info("Starting model evaluation on test dataset.")
        logger.info("Running model evaluation")
        logger.debug("Preparing to run Trainer.test()")
        var test_results = pl_trainer.test(model=trainer_py, dataloaders=test_loader)
        
        if test_results:
            var sum_test_loss = 0.0
            var sum_test_accuracy = 0.0
            var sum_test_diff_accuracy = 0.0
            for result in test_results:
                sum_test_loss += result["avg_test_loss"]
                sum_test_accuracy += result["avg_test_accuracy"]
                sum_test_diff_accuracy += result["avg_test_diff_accuracy"]
            
            var avg_test_loss = sum_test_loss / Float64(len(test_results))
            var avg_test_accuracy = sum_test_accuracy / Float64(len(test_results))
            var avg_test_diff_accuracy = sum_test_diff_accuracy / Float64(len(test_results))
            
            logger.info("Test results - Loss: " + String(avg_test_loss) + ", Accuracy: " + String(avg_test_accuracy) + ", Diff Accuracy: " + String(avg_test_diff_accuracy))
            
            var results = {
                "avg_test_loss": avg_test_loss,
                "avg_test_accuracy": avg_test_accuracy,
                "avg_test_diff_accuracy": avg_test_diff_accuracy
            }
            
            # Add task-specific results
            for result in test_results:
                for key, value in result.items():
                    if key.endswith("_test_accuracy") or key.endswith("_test_diff_accuracy"):
                        results[key] = value
            
            trainer_py.results_collector.set_test_results(results)
            
        trainer_py.results_collector.set_final_metrics({
            "best_val_loss": trainer_py.best_val_loss,
            "best_epoch": trainer_py.best_epoch,
            "final_test_loss": avg_test_loss,
            "final_test_accuracy": avg_test_accuracy,
            "final_test_diff_accuracy": avg_test_diff_accuracy
        })
        
        # Save the final model with configuration
        logger.info("Saving final model with configuration")
        var model_path = "final_model_" + String(trainer_py.results_collector.experiment_id) + ".pth"
        var os_module = Python.import_module("os")
        os_module.makedirs("checkpoints", exist_ok=True)
        torch.save({
            "state_dict": trainer_py.model.state_dict(),
            "model_config": trainer_py.config.model.__dict__,
            "training_config": trainer_py.config.training.__dict__,
            "pad_symbol_idx": trainer_py.config.training.pad_symbol_idx,
            "symbol_freq": trainer_py.config.training.symbol_freq
        }, model_path)
        trainer_py.results_collector.set_checkpoint_path(model_path)
        logger.debug("Model and configuration saved to: " + model_path)
        
        # Save results
        logger.info("Saving experiment results")
        os_module.makedirs("results", exist_ok=True)
        var results_path = "results/experiment_" + String(trainer_py.results_collector.experiment_id) + ".json"
        trainer_py.results_collector.save_to_json(results_path)
        logger.debug("Results saved to: " + results_path)
    
    except Error as e:
        if "CUDA out of memory" in str(e):
            logger.error("CUDA out of memory error occurred.")
            logger.error("Consider reducing the batch size or model complexity.")
            raise Error("CUDA out of memory error occurred.")
        else:
            logger.error("A runtime error occurred: " + String(e))
            raise Error("A runtime error occurred: " + String(e))
    except Exception as e:
        logger.error("An unexpected error occurred: " + String(e))
        sys.exit(1)  # Exit the program after logging the error
    finally:
        if "tracker" in locals():
            tracker.finish()
    
    if trainer_py is not None:
        pass  # Proceed with any additional logic if needed
    else:
        logger.error("Trainer was not initialized. Exiting the training loop.")

# Main function
# Main function
fn main() raises -> None:
    # Retrieve compile-time parameters
    var args = get_parameters()
    
    try:
        train_model(args)
    except PythonObject as e:
        print("Error during training:", String(e))

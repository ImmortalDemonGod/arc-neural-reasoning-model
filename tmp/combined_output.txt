<?xml version='1.0' encoding='utf-8'?>
<source type="local_directory" path="/Volumes/Totallynotaharddrive/arc-neural-reasoning-model/gpt2_arc"><file name="benchmark.py">import torch._dynamo import csv import uuid datetime import datetime import os import torch torch.utils.data import dataloader import arckit gpt2_arc.src.data.arc_dataset import arcdataset gpt2_arc.src.models.gpt2 import gpt2arc gpt2_arc.src.config import modelconfig import time torch.amp import autocast import psutil import logging import argparse import statistics import numpy np scipy import stats # set logging logging.basicconfig(level=logging.info) logger = logging.getlogger(__name__) # dynamically adjustable baseline values cpu, gpu, mps baselines = { 'cpu': {'total_time': 1.6391, 'grids_per_second': 199.27}, 'cuda': {'total_time': 0.0481, 'grids_per_second': 13774.98}, 'mps': {'total_time': 0.0481, 'grids_per_second': 13774.98} # updated baselines mps } def benchmark_model(model, dataset, batch_size=1, num_batches=1, num_runs=1, device_type='cpu', precision='medium'): print(f"starting benchmark_model parameters: batch_size={batch_size}, num_batches={num_batches}, num_runs={num_runs}, device_type={device_type}, precision={precision}") run_id = str(uuid.uuid4()) current_time = datetime.now().strftime("%y-%m-%d %h:%m:%s") practical_threshold = 20.0 # define threshold practical significance total_time_runs = [] grids_per_second_runs = [] cpu_usages = [] memory_usages = [] run_results = [] # initialize run_results store run's data gpu_usages = [] # initialize gpu_usages store gpu utilization data # select device based argument (including support mps) device = torch.device("cuda" device_type == "cuda" torch.cuda.is_available() else "mps" device_type == "mps" torch.backends.mps.is_available() else "cpu") model = model.to(device) torch._dynamo.config.suppress_errors = true device.type == "cpu": compiled_model = model # use model directly cpu else: try: device.type != "mps": compiled_model = torch.compile(model, mode="reduce-overhead", fullgraph=true) else: compiled_model = model # use model directly mps except importerror e: logger.warning(f"compilation failed error: {e}. falling back eager execution.") compiled_model = model run range(num_runs): print(f"starting run {run + 1}/{num_runs}") dataloader = dataloader(dataset, batch_size=batch_size, collate_fn=arcdataset.collate_fn) total_time = 0.0 total_grids = 0 i, (inputs, outputs) enumerate(dataloader): print(f"processing batch {i + 1}/{num_batches}") &gt;= num_batches: break # create dummy attention mask (all ones) attention_mask = torch.ones(inputs.size(0), inputs.size(2) * inputs.size(3), dtype=torch.float32) inputs, attention_mask = inputs.to(device), attention_mask.to(device) # log system load system state processing batch cpu_percent = psutil.cpu_percent(interval=none) memory_info = psutil.virtual_memory() cpu_usages.append(cpu_percent) memory_usages.append(memory_info.percent) device.type == 'cuda': gpu_utilization = torch.cuda.utilization(device.index) gpu_usages.append(gpu_utilization) logger.info(f"run {run+1}, batch {i+1}: cpu usage: {cpu_percent}%, memory usage: {memory_info.percent}%, gpu utilization: {gpu_utilization}%") else: logger.info(f"run {run+1}, batch {i+1}: cpu usage: {cpu_percent}%, memory usage: {memory_info.percent}%") # measure time taken process batch start_time = time.time() torch.cuda.is_available(): torch.cuda.synchronize() torch.no_grad(): device.type == 'cuda': autocast(device_type=device.type, dtype=torch.float16): compiled_model(inputs, attention_mask) else: compiled_model(inputs, attention_mask) torch.cuda.is_available(): torch.cuda.synchronize() end_time = time.time() batch_time = end_time - start_time print(f"batch time: {batch_time}") batch_time &lt;= 0: print(f"warning: invalid batch time: {batch_time}. skipping batch.") continue total_time += batch_time total_grids += len(inputs) print(f"run {run + 1} completed. total time: {total_time}, total grids: {total_grids}") # average metrics run grids_per_second = total_grids / total_time logger.info(f"run {run+1}: total time: {total_time:.4f} seconds, grids per second: {grids_per_second:.2f}") # store results run run_results.append({ 'run_id': run_id, 'datetime': current_time, 'run': run + 1, 'total_time': total_time, 'grids_per_second': grids_per_second, 'cpu_usage': np.mean(cpu_usages), 'memory_usage': np.mean(memory_usages), 'gpu_usage': np.mean(gpu_usages) gpu_usages else none, 'batch_size': batch_size, 'num_batches': num_batches, 'device': device.type, 'n_embd': model.config.n_embd, 'n_head': model.config.n_head, 'n_layer': model.config.n_layer, 'precision': precision # add precision }) total_time_runs.append(total_time) grids_per_second_runs.append(grids_per_second) total_time &lt;= 0 total_grids &lt;= 0: print(f"error: invalid total time ({total_time}) total grids ({total_grids}). check benchmark implementation.") return 0, 0 # return sensible defaults instead negative values avg_total_time = np.mean(total_time_runs) avg_grids_per_second = np.mean(grids_per_second_runs) std_total_time = np.std(total_time_runs, ddof=1) std_grids_per_second = np.std(grids_per_second_runs, ddof=1) # perform statistical analysis (confidence intervals, effect size, etc.) confidence_level = 0.95 z_score = stats.norm.ppf((1 + confidence_level) / 2) ci_total_time = z_score * (std_total_time / np.sqrt(num_runs)) ci_grids_per_second = z_score * (std_grids_per_second / np.sqrt(num_runs)) effect_size_time = (avg_total_time - baselines[device.type]['total_time']) / std_total_time effect_size_grids = (avg_grids_per_second - baselines[device.type]['grids_per_second']) / std_grids_per_second # calculate improvements regressions based averages time_improvement = baselines[device.type]['total_time'] - avg_total_time time_improvement_percent = (time_improvement / baselines[device.type]['total_time']) * 100 time_regression = avg_total_time - baselines[device.type]['total_time'] time_regression_percent = (time_regression / baselines[device.type]['total_time']) * 100 grids_per_second_improvement = avg_grids_per_second - baselines[device.type]['grids_per_second'] grids_per_second_improvement_percent = (grids_per_second_improvement / baselines[device.type]['grids_per_second']) * 100 grids_per_second_regression = baselines[device.type]['grids_per_second'] - avg_grids_per_second grids_per_second_regression_percent = (grids_per_second_regression / baselines[device.type]['grids_per_second']) * 100 # determine improvement improvement_time = avg_total_time &lt; baselines[device.type]['total_time'] improvement_grids = avg_grids_per_second &gt; baselines[device.type]['grids_per_second'] # log improvements regressions based averages avg_total_time &lt; baselines[device.type]['total_time']: logger.info(f"improvement average total time: -{time_improvement:.4f} seconds ({time_improvement_percent:.2f}%)") else: logger.info(f"regression average total time: +{time_regression:.4f} seconds ({time_regression_percent:.2f}%)") avg_grids_per_second &gt; baselines[device.type]['grids_per_second']: logger.info(f"improvement average grids per second: +{grids_per_second_improvement:.2f} ({grids_per_second_improvement_percent:.2f}%)") else: logger.info(f"regression average grids per second: -{grids_per_second_regression:.2f} ({grids_per_second_regression_percent:.2f}%)") # update practical significance checks practical_significance_time = time_improvement_percent &gt;= practical_threshold practical_significance_grids = grids_per_second_improvement_percent &gt;= practical_threshold # log practical significance improvement_time: practical_significance_time: logger.info("the improvement average total time practically significant.") else: logger.info("the improvement average total time practically significant.") else: practical_significance_time: logger.info("the regression average total time practically significant.") else: logger.info("the regression average total time practically significant.") improvement_grids: practical_significance_grids: logger.info("the improvement average grids per second practically significant.") else: logger.info("the improvement average grids per second practically significant.") else: practical_significance_grids: logger.info("the regression average grids per second practically significant.") else: logger.info("the regression average grids per second practically significant.") # perform one-sample t-test t_stat_time, p_value_time = stats.ttest_1samp(total_time_runs, baselines[device.type]['total_time']) t_stat_grids, p_value_grids = stats.ttest_1samp(grids_per_second_runs, baselines[device.type]['grids_per_second']) logger.info(f"t-test total time: t-statistic = {t_stat_time:.4f}, p-value = {p_value_time:.4f}") logger.info(f"t-test grids per second: t-statistic = {t_stat_grids:.4f}, p-value = {p_value_grids:.4f}") # log results including confidence intervals logger.info(f"run summary:") logger.info(f" avg total time: {avg_total_time:.4f}s (ci 95%: {ci_total_time:.4f}s)") logger.info(f" avg grids per second: {avg_grids_per_second:.2f} (ci 95%: {ci_grids_per_second:.2f})") logger.info(f" effect size (total time): {effect_size_time:.4f}, effect size (grids per second): {effect_size_grids:.4f}") # determine improvement improvement_time = avg_total_time &lt; baselines[device.type]['total_time'] improvement_grids = avg_grids_per_second &gt; baselines[device.type]['grids_per_second'] csv_file_path = 'benchmark_results.csv' file_exists = os.path.isfile(csv_file_path) open(csv_file_path, 'a', newline='') csvfile: fieldnames = [ 'run_id', 'datetime', 'run', 'total_time', 'grids_per_second', 'cpu_usage', 'memory_usage', 'batch_size', 'num_batches', 'device', 'n_embd', 'n_head', 'n_layer', 'gpu_usage', 'precision' ] writer = csv.dictwriter(csvfile, fieldnames=fieldnames) file_exists: writer.writeheader() result run_results: writer.writerow(result) # write statistical summary csv stats_csv_file_path = 'benchmark_statistics.csv' stats_file_exists = os.path.isfile(stats_csv_file_path) open(stats_csv_file_path, 'a', newline='') csvfile: fieldnames = [ 'run_id', 'datetime', 'avg_total_time', 'std_total_time', 'ci_total_time', 'avg_grids_per_second', 'std_grids_per_second', 'ci_grids_per_second', 'effect_size_time', 'effect_size_grids', 'percent_change_time', 'percent_change_grids', 't_stat_time', 'p_value_time', 't_stat_grids', 'p_value_grids', 'improvement_time', 'improvement_grids', 'practical_significance_time', 'practical_significance_grids', 'precision' ] writer = csv.dictwriter(csvfile, fieldnames=fieldnames) stats_file_exists: writer.writeheader() writer.writerow({ 'run_id': run_id, 'datetime': current_time, 'avg_total_time': avg_total_time, 'std_total_time': std_total_time, 'ci_total_time': ci_total_time, 'avg_grids_per_second': avg_grids_per_second, 'std_grids_per_second': std_grids_per_second, 'ci_grids_per_second': ci_grids_per_second, 'effect_size_time': effect_size_time, 'effect_size_grids': effect_size_grids, 'percent_change_time': time_improvement_percent improvement_time else time_regression_percent, 'percent_change_grids': grids_per_second_improvement_percent improvement_grids else grids_per_second_regression_percent, 't_stat_time': t_stat_time, 'p_value_time': p_value_time, 't_stat_grids': t_stat_grids, 'p_value_grids': p_value_grids, 'improvement_time': improvement_time, 'improvement_grids': improvement_grids, 'practical_significance_time': practical_significance_time, 'practical_significance_grids': practical_significance_grids, 'precision': precision # add precision }) print(f"benchmark completed. final results - avg_time: {avg_total_time}, avg_grids: {avg_grids_per_second}") return avg_total_time, avg_grids_per_second def main(args): print(f"starting main function args: {args}") # set float32 matmul precision torch.set_float32_matmul_precision(args.precision) train_set, _ = arckit.load_data() full_dataset = arcdataset(train_set, is_test=false) # create model configuration model_config = modelconfig(n_embd=args.n_embd, n_head=args.n_head, n_layer=args.n_layer) model = gpt2arc(model_config) # run benchmark different configurations run_num range(args.num_full_runs): logger.info(f"starting full benchmark run {run_num + 1}/{args.num_full_runs}") avg_time, avg_grids = benchmark_model( model, full_dataset, batch_size=args.batch_size, num_batches=args.num_batches, num_runs=args.num_runs, device_type=args.device, precision=args.precision ) logger.info(f"full run {run_num + 1} - avg time: {avg_time:.4f}s, avg grids per second: {avg_grids:.2f}") __name__ == "__main__": parser = argparse.argumentparser(description="benchmark gpt2arc model.") parser.add_argument('--num-runs', type=int, default=20, help='number runs configuration') parser.add_argument('--num-full-runs', type=int, default=1, help='number full configurations run') parser.add_argument('--batch-size', type=int, default=32, help='batch size run') parser.add_argument('--num-batches', type=int, default=10, help='number batches per run') parser.add_argument('--n-embd', type=int, default=64, help='number embeddings model') parser.add_argument('--n-head', type=int, default=2, help='number attention heads') parser.add_argument('--n-layer', type=int, default=1, help='number layers') parser.add_argument('--device', choices=['cpu', 'cuda', 'mps'], default='cpu', help='device run benchmark (cpu, cuda, mps)') parser.add_argument('--precision', choices=['highest', 'high', 'medium'], default='highest', help='precision level float32 matrix multiplications') args = parser.parse_args() main(args)</file><file name="README.md"># gpt-2 arc neural reasoning model project implements neural reasoning model based gpt-2 architecture solve tasks abstraction reasoning corpus (arc) challenge. ## features - **data handling**: utilizes custom `arcdataset` class handling preprocessing arc data. - **model architecture**: implements `gpt2arc` model leveraging pre-trained gpt-2 architecture. - **training**: includes `train.py` script training model using pytorch lightning, support logging checkpointing. - **testing**: comprehensive test suite using `pytest` ensure model data integrity. ## installation clone repository install required packages: ```bash git clone https://github.com/yourusername/arc-neural-reasoning-model.git cd arc-neural-reasoning-model pip install -e . ``` development, install extra dependencies: ```bash pip install -e ".[dev]" ``` ## usage ### training model train model, use following command: ``` python src/train.py --train_data path/to/train_data --val_data path/to/val_data --batch_size 32 --learning_rate 1e-4 --max_epochs 10 --use_gpu ``` adjust parameters needed. trained model checkpoints saved `checkpoints` directory. ### evaluating model evaluate trained model test set, use following command: ``` python src/evaluate.py --test_data path/to/test_data --model_checkpoint path/to/model_checkpoint.ckpt --batch_size 32 ``` output evaluation metrics model test dataset. ## running tests run tests, use following command: ``` pytest -v ``` run tests display results, including test coverage. ## contributing [add contribution guidelines here] ## license project licensed mit license - see [license](license) file details.</file><file name="requirements.txt">aider-chat torch&gt;=2.0.0 transformers&gt;=4.0.0 pytorch-lightning&gt;=2.0.0 numpy&gt;=1.20.0 pytest&gt;=6.0 pytest-cov&gt;=2.0 black&gt;=20.8b1 isort&gt;=5.0 flake8&gt;=3.9 ruff scipy psutil ultralytics-thop mypy pynvml tox tensorboard arckit urllib3&gt;=1.26.0 chardet&gt;=5.0.0</file><file name="setup.py">setuptools import setup setup()</file><file name=".pytest_cache/README.md"># pytest cache directory # directory contains data pytest's cache plugin, provides `--lf` `--ff` options, well `cache` fixture. **do not** commit version control. see [the docs](https://docs.pytest.org/en/stable/how-to/cache.html) information.</file><file name="src/__init__.py"># file allows src directory recognized package.</file><file name="src/config.py"># gpt2_arc/src/config.py dataclasses import dataclass @dataclass class modelconfig: n_embd: int = 768 n_head: int = 12 n_layer: int = 12 dropout: float = 0.1 @dataclass class trainingconfig: batch_size: int = 32 learning_rate: float = 1e-4 max_epochs: int = 10 use_gpu: bool = true dataclasses import field @dataclass class config: model: modelconfig = field(default_factory=modelconfig) training: trainingconfig = field(default_factory=trainingconfig)</file><file name="src/evaluate.py">import argparse import pytorch_lightning pl import torch src.data.arc_dataset import arcdataset src.models.gpt2 import gpt2arc src.config import config src.training.trainer import arctrainer def evaluate(model, test_dataset, batch_size=32): trainer = arctrainer(model, none, test_dataset, config=config()) pl_trainer = pl.trainer(accelerator='gpu' torch.cuda.is_available() else 'cpu') results = pl_trainer.test(trainer) return results[0] def main(args): # load test data test_data = arcdataset(args.test_data) # load trained model model = gpt2arc(config().model) model.load_state_dict(torch.load(args.model_checkpoint)) model.eval() # evaluate model results = evaluate(model, test_data, args.batch_size) print("evaluation results:") metric, value results.items(): print(f"{metric}: {value}") __name__ == "__main__": parser = argparse.argumentparser( description="evaluate arc neural reasoning model" ) parser.add_argument( "--test_data", type=str, required=true, help="path test data" ) parser.add_argument( "--model_checkpoint", type=str, required=true, help="path model checkpoint", ) parser.add_argument( "--batch_size", type=int, default=32, help="batch size evaluation" ) args = parser.parse_args() main(args)</file><file name="src/data/__init__.py" /><file name="src/data/arc_dataset.py"># gp2_arc/src/data/arc_dataset.py import os import json import random typing import union, list, dict, tuple import numpy np import torch import torch.nn.functional f torch.utils.data import dataset import logging try: arckit.data import taskset except importerror: taskset = none logger = logging.getlogger(__name__) logger.setlevel(logging.error) # set error default # create handler writes stderr handler = logging.streamhandler() handler.setlevel(logging.error) # create formatting logs formatter = logging.formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s') handler.setformatter(formatter) # add handler logger logger.addhandler(handler) # function set debug mode def set_debug_mode(debug=false): debug: logger.setlevel(logging.debug) handler.setlevel(logging.debug) else: logger.setlevel(logging.error) handler.setlevel(logging.error) class arcdataset(dataset): def __init__( self, data_source: union[str, list[dict], 'taskset', tuple[union[list, 'taskset'], str]], is_test: bool = false, num_symbols: int = 10, test_split: float = 0.2, debug=false, ): logger.debug(f"arcdataset.__init__ called data_source: {data_source}") self.debug_attr = "test" # simple attribute testing set_debug_mode(debug) # set debug mode based parameter logger.debug(f"initializing arcdataset data_source type: {type(data_source)}") isinstance(data_source, str): logger.debug(f"data source path: {data_source}") os.path.isdir(data_source): logger.debug("processing synthetic data directory") self.data = self._process_synthetic_data(data_source) elif os.path.isfile(data_source): logger.debug("processing json data file") open(data_source, 'r') f: raw_data = json.load(f) self.data = self._process_json_data(raw_data) else: raise filenotfounderror(f"data source file directory found: {data_source}") elif isinstance(data_source, list): logger.debug("processing list data") self.data = self._process_list_data(data_source) elif isinstance(data_source, tuple): logger.debug("processing combined data") self.data = self._combine_data(*data_source) elif taskset none isinstance(data_source, taskset): logger.debug("processing arckit data") self.data = self._process_arckit_data(data_source) else: logger.error(f"invalid data_source type: {type(data_source)}") raise valueerror("data source must either file path, list tasks, taskset") logger.debug(f"number tasks: {len(self.data)}") logger.debug(f"first task structure: {self.data[0].keys()}") logger.debug(f"first train sample structure: {self.data[0]['train'][0].keys()}") logger.debug(f"first train input shape: {np.array(self.data[0]['train'][0]['input']).shape}") self.is_test = is_test self.num_symbols = num_symbols self.test_split = test_split logger.debug(f"test_split set to: {self.test_split}") self.test_split = test_split self.samples = [] taskset none isinstance(data_source, taskset): task data_source.tasks: self.samples.extend(task.train) self.samples.extend(task.test) isinstance(data_source, str): os.path.isdir(data_source): self.data = self._process_synthetic_data(data_source) elif os.path.isfile(data_source): open(data_source, 'r') f: raw_data = json.load(f) self.data = self._process_json_data(raw_data) else: raise filenotfounderror(f"data source file directory found: {data_source}") elif isinstance(data_source, list): self.data = self._process_list_data(data_source) elif isinstance(data_source, tuple): self.data = self._combine_data(*data_source) elif taskset none isinstance(data_source, taskset): self.data = self._process_arckit_data(data_source) else: logger.error(f"invalid data_source type: {type(data_source)}") raise valueerror("data source must either file path, list tasks, taskset") print(f"number train samples: {sum(len(task['train']) task self.data)}") print(f"number test samples: {sum(len(task['test']) task self.data)}") self.max_grid_size = self._compute_max_grid_size() self._validate_data() def _process_json_data(self, raw_data: list[dict]) -&gt; list[dict]: processed_data = [] task raw_data: logger.debug(f"processing task: {task}") processed_task = { "train": [ {"input": np.array(example["input"]), "output": np.array(example["output"])} example task["train"] ], "test": [ {"input": np.array(example["input"]), "output": np.array(example["output"])} example task["test"] ] } processed_data.append(processed_task) # flatten data structure flattened_data = [] task processed_data: flattened_data.extend(task['train']) flattened_data.extend(task['test']) return flattened_data def _validate_data(self): task self.data: split ["train", "test"]: split task: sample task[split]: ("input" sample "output" sample): raise valueerror(f"each sample must contain 'input' 'output'. task: {task.get('id', 'unknown')}") print("data validation passed.") def _compute_max_grid_size(self): max_h, max_w = 0, 0 task self.data: split ['train', 'test']: sample task[split]: isinstance(sample['input'], torch.tensor): sample['input'].dim() == 3: h, w = sample['input'].shape[1], sample['input'].shape[2] elif sample['input'].dim() == 2: h, w = sample['input'].shape else: raise valueerror(f"unexpected tensor dimensions: {sample['input'].dim()}") elif isinstance(sample['input'], np.ndarray): h, w = sample['input'].shape elif isinstance(sample['input'], list): h, w = len(sample['input']), len(sample['input'][0]) else: raise typeerror(f"unexpected input type: {type(sample['input'])}") max_h = max(max_h, h) max_w = max(max_w, w) logger.debug(f"computed max grid size: ({max_h}, {max_w})") return (max_h, max_w) def _combine_data(self, official_data, synthetic_data_path): official_processed = self._process_arckit_data(official_data) taskset none isinstance(official_data, taskset) else official_data synthetic_processed = self._process_synthetic_data(synthetic_data_path) return official_processed + synthetic_processed def _process_synthetic_data(self, directory: str) -&gt; list[dict]: processed_data = [] filename os.listdir(directory): filename.endswith('.json'): open(os.path.join(directory, filename), 'r') f: task_data = json.load(f) processed_data.append(self._process_single_task(task_data)) return processed_data def _process_single_task(self, task_data: union[dict, list]) -&gt; dict: logger.debug(f"inside _process_single_task, test_split is: {self.test_split}") isinstance(task_data, dict): train_examples = task_data.get("train", []) test_examples = task_data.get("test", []) elif isinstance(task_data, list): split_idx = int(len(task_data) * (1 - self.test_split)) train_examples = task_data[:split_idx] test_examples = task_data[split_idx:] else: raise valueerror("task data must either dictionary list") return { "train": [self._preprocess_grid(example) example train_examples], "test": [self._preprocess_grid(example) example test_examples] } def _process_arckit_data(self, taskset: 'taskset') -&gt; list[dict]: processed_data = [] logger.debug(f"processing taskset {len(taskset.tasks)} tasks") task taskset.tasks: logger.debug(f"processing task: {task.id}") logger.debug(f"train samples: {len(task.train)}, test samples: {len(task.test)}") processed_task = { "id": task.id, "train": [ {"input": np.array(ex[0]), "output": np.array(ex[1])} ex task.train ], "test": [ {"input": np.array(ex[0]), "output": np.array(ex[1])} ex task.test ] } processed_data.append(processed_task) logger.debug(f"processed task {task.id}: train samples: {len(processed_task['train'])}, test samples: {len(processed_task['test'])}") logger.debug(f"processed {len(processed_data)} tasks") return processed_data def __len__(self) -&gt; int: self.is_test: total_samples = sum(len(task['test']) task self.data) else: total_samples = sum(len(task['train']) task self.data) logger.debug(f"total samples dataset: {total_samples}") return total_samples def __getitem__(self, idx: int) -&gt; tuple[torch.tensor, torch.tensor]: idx &lt; 0 idx &gt;= len(self): raise indexerror(f"index {idx} range (total samples: {len(self)})") current_idx = 0 task self.data: split = 'test' self.is_test else 'train' idx &lt; current_idx + len(task[split]): sample = task[split][idx - current_idx] input_grid = self._preprocess_grid(sample["input"]) output_grid = self._preprocess_grid(sample["output"]) logger.debug(f"__getitem__ input dtype: {input_grid.dtype}, output dtype: {output_grid.dtype}") return input_grid, output_grid current_idx += len(task[split]) raise runtimeerror("unexpected error __getitem__") def _validate_data(self): task self.data: split ["train", "test"]: split task: continue idx, sample enumerate(task[split]): "input" sample "output" sample: raise valueerror(f"sample {idx} task {split} set missing 'input' 'output' key") input_data = sample["input"] output_data = sample["output"] (isinstance(input_data, (list, np.ndarray)) isinstance(output_data, (list, np.ndarray))): raise valueerror(f"sample {idx} task {split} set 'input' 'output' must list numpy array") isinstance(input_data, list): input_data = np.array(input_data) isinstance(output_data, list): output_data = np.array(output_data) input_data.ndim != 2 output_data.ndim != 2: raise valueerror(f"sample {idx} task {split} set 'input' 'output' must 2d lists") np.any(input_data &gt;= self.num_symbols) np.any(output_data &gt;= self.num_symbols): raise valueerror(f"sample {idx} task {split} set contains invalid symbols (&gt;= {self.num_symbols})") def _compute_grid_size_stats(self): max_height, max_width = 0, 0 task self.data: split ["train", "test"]: sample task[split]: max_height = max(max_height, sample["input"].shape[0], sample["output"].shape[0]) max_width = max(max_width, sample["input"].shape[1], sample["output"].shape[1]) self.max_grid_size = (max_height, max_width) def _compute_symbol_frequencies(self): symbol_counts = np.zeros(self.num_symbols, dtype=int) task self.data: split ["train", "test"]: sample task[split]: symbol_counts += np.bincount(sample["input"].flatten(), minlength=self.num_symbols) symbol_counts += np.bincount(sample["output"].flatten(), minlength=self.num_symbols) return symbol_counts / symbol_counts.sum() def _preprocess_grid(self, grid: union[dict, np.ndarray]) -&gt; torch.tensor: isinstance(grid, dict): input_grid = np.array(grid['input']) logger.debug(f"original grid shape: {input_grid.shape}") logger.debug(f"original grid content:\n{input_grid}") elif isinstance(grid, np.ndarray): input_grid = grid logger.debug(f"original grid shape: {input_grid.shape}") logger.debug(f"original grid content:\n{input_grid}") else: raise valueerror(f"unexpected grid type: {type(grid)}") # pad grid 30x30 padded_grid = self._pad_grid(input_grid, height=30, width=30) # convert tensor add channel dimension grid_tensor = torch.tensor(padded_grid, dtype=torch.float32).unsqueeze(0) logger.debug(f"preprocessed grid shape: {grid_tensor.shape}") logger.debug(f"preprocessed grid content:\n{grid_tensor}") return grid_tensor def _scale_grid(self, grid: np.ndarray, height: int, width: int) -&gt; np.ndarray: return grid # scaling, preserve original size def _pad_grid(self, grid: np.ndarray, height: int, width: int) -&gt; np.ndarray: h, w = grid.shape pad_h = (height - h) // 2 pad_w = (width - w) // 2 return np.pad(grid, ((pad_h, height - h - pad_h), (pad_w, width - w - pad_w)), mode='constant') def _process_list_data(self, data_source: list[dict]) -&gt; list[dict]: processed_data = [] item data_source: processed_item = { "train": [{"input": np.array(item["input"]), "output": np.array(item["output"])}], "test": [] } processed_data.append(processed_item) return processed_data @staticmethod def collate_fn(batch): # method used dataloader prepare batches inputs, outputs = zip(*batch) # find max dimensions batch max_h = max(i.size(1) inputs) max_w = max(i.size(2) inputs) # pad inputs outputs max size batch padded_inputs = torch.stack([f.pad(i, (0, max_w - i.size(2), 0, max_h - i.size(1))) inputs]) padded_outputs = torch.stack([f.pad(o, (0, max_w - o.size(2), 0, max_h - o.size(1))) outputs]) return padded_inputs, padded_outputs</file><file name="src/gpt2_arc.egg-info/dependency_links.txt" /><file name="src/gpt2_arc.egg-info/requires.txt">torch numpy pytest pytorch-lightning [dev] pytest-cov black flake8</file><file name="src/gpt2_arc.egg-info/SOURCES.txt">license readme.md pyproject.toml setup.cfg gpt2_arc/src/data/__init__.py gpt2_arc/src/data/arc_dataset.py gpt2_arc/src/gpt2_arc.egg-info/pkg-info gpt2_arc/src/gpt2_arc.egg-info/sources.txt gpt2_arc/src/gpt2_arc.egg-info/dependency_links.txt gpt2_arc/src/gpt2_arc.egg-info/requires.txt gpt2_arc/src/gpt2_arc.egg-info/top_level.txt gpt2_arc/src/models/__init__.py gpt2_arc/src/models/gpt2.py gpt2_arc/src/training/__init__.py gpt2_arc/src/training/trainer.py gpt2_arc/src/utils/__init__.py gpt2_arc/src/utils/helpers.py</file><file name="src/gpt2_arc.egg-info/top_level.txt">data models training utils</file><file name="src/models/__init__.py" /><file name="src/models/gpt2.py"># gpt2_arc/src/models/gpt2.py import logging import torch import torch.nn.functional f torch import nn import torch.nn.init init logging.basicconfig(level=logging.debug) logger = logging.getlogger(__name__) class attention(nn.module): def __init__(self, n_embd, n_head): super().__init__() self.n_head = n_head self.n_embd = n_embd self.key = nn.linear(n_embd, n_embd) self.query = nn.linear(n_embd, n_embd) self.value = nn.linear(n_embd, n_embd) self.proj = nn.linear(n_embd, n_embd) logger.debug(f"initialized attention n_embd={n_embd}, n_head={n_head}") def forward(self, x, mask=none): b, t, c = x.size() torch._dynamo.is_compiling(): logger.debug(f"attention input shape: {x.shape}") k = self.key(x).view(b, t, self.n_head, c // self.n_head).transpose(1, 2) q = self.query(x).view(b, t, self.n_head, c // self.n_head).transpose(1, 2) v = self.value(x).view(b, t, self.n_head, c // self.n_head).transpose(1, 2) att = (q @ k.transpose(-2, -1)) * (1.0 / torch.sqrt(torch.tensor(k.size(-1), dtype=torch.float32))) mask none: att = att.masked_fill(mask[:, none, none, :] == 0, float("-inf")) att = f.softmax(att, dim=-1) = att @ v = y.transpose(1, 2).contiguous().view(b, t, c) output = self.proj(y) torch._dynamo.is_compiling(): logger.debug(f"attention output shape: {output.shape}") return output class feedforward(nn.module): def __init__(self, n_embd): super().__init__() self.net = nn.sequential( nn.linear(n_embd, 4 * n_embd), nn.relu(), nn.linear(4 * n_embd, n_embd) ) logger.debug(f"initialized feedforward n_embd={n_embd}") def forward(self, x): torch._dynamo.is_compiling(): logger.debug(f"feedforward input shape: {x.shape}") output = self.net(x) torch._dynamo.is_compiling(): logger.debug(f"feedforward output shape: {output.shape}") return output class transformerblock(nn.module): def __init__(self, n_embd, n_head): super().__init__() self.attention = attention(n_embd, n_head) self.feed_forward = feedforward(n_embd) self.ln1 = nn.layernorm(n_embd) self.ln2 = nn.layernorm(n_embd) logger.debug( f"initialized transformerblock n_embd={n_embd}, n_head={n_head}" ) def forward(self, x, mask=none): torch._dynamo.is_compiling(): logger.debug(f"transformerblock input shape: {x.shape}") x = x + self.attention(self.ln1(x), mask) x = x + self.feed_forward(self.ln2(x)) torch._dynamo.is_compiling(): logger.debug(f"transformerblock output shape: {x.shape}") return x dataclasses import dataclass src.config import modelconfig @dataclass class modelconfig: n_embd: int = 768 n_head: int = 12 n_layer: int = 12 dropout: float = 0.1 class gpt2arc(nn.module): def __init__(self, config: modelconfig): super().__init__() self.config = config # replace token embedding convolutional layer self.conv1 = nn.conv2d(in_channels=1, out_channels=self.config.n_embd, kernel_size=3, padding=1).to(torch.float32) self.blocks = nn.modulelist( [ transformerblock(self.config.n_embd, self.config.n_head) _ range(self.config.n_layer) ] ) self.ln_f = nn.layernorm(self.config.n_embd) # initialize weights self.apply(self._init_weights) def _init_weights(self, module): isinstance(module, nn.conv2d): # calculate fan_in conv2d fan_in = module.in_channels * module.kernel_size[0] * module.kernel_size[1] std = 1.0 / fan_in**0.5 init.normal_(module.weight, mean=0.0, std=std) module.bias none: init.zeros_(module.bias) elif isinstance(module, nn.linear): fan_in = module.in_features std = 1.0 / fan_in**0.5 init.normal_(module.weight, mean=0.0, std=std) module.bias none: init.zeros_(module.bias) # initialization nn.layernorm, using default def forward(self, input_ids, attention_mask=none): torch._dynamo.is_compiling(): logger.debug(f"gpt2arc input shape: {input_ids.shape}, dtype: {input_ids.dtype}") # check input_ids already correct shape input_ids.dim() == 4: x = input_ids.float() else: # reshape input_ids [batch_size, 1, height, width] batch_size = input_ids.size(0) seq_length = input_ids.size(1) height = width = int(seq_length ** 0.5) x = input_ids.float().view(batch_size, 1, height, width) x = self.conv1(x) b, c, h, w = x.size() x = x.view(b, c, h * w) # flatten spatial dimensions x = x.permute(0, 2, 1) # rearrange (batch_size, sequence_length, channels) block self.blocks: x = block(x, attention_mask) x = self.ln_f(x) return x</file><file name="src/training/__init__.py" /><file name="src/training/train.py"># gpt2_arc/src/training/train.py import argparse import pytorch_lightning pl import torch pytorch_lightning.callbacks import modelcheckpoint pytorch_lightning.loggers import tensorboardlogger src.data.arc_dataset import arcdataset src.models.gpt2 import gpt2arc src.config import config, modelconfig, trainingconfig src.training.trainer import arctrainer def main(args): # load data train_data = arcdataset(args.train_data) val_data = arcdataset(args.val_data) print("data loaded successfully") print("initializing model new configuration") model_config = modelconfig(n_embd=96, n_head=3, n_layer=1) model = gpt2arc(config=model_config) print("initializing trainer new configuration") config = config(model=model_config, training=trainingconfig(batch_size=args.batch_size, learning_rate=args.learning_rate, max_epochs=args.max_epochs)) trainer = arctrainer( model=model, train_dataset=train_data, val_dataset=val_data, config=config ) # create pytorch lightning trainer logger = false args.no_logging else tensorboardlogger("tb_logs", name="arc_model") callbacks = [] args.no_checkpointing: checkpoint_callback = modelcheckpoint( dirpath="checkpoints", filename="arc_model-{epoch:02d}-{val_loss:.2f}", save_top_k=3, monitor="val_loss", mode="min", ) callbacks.append(checkpoint_callback) torch.utils.data import dataloader train_loader = dataloader(train_data, batch_size=args.batch_size, num_workers=7) val_loader = dataloader(val_data, batch_size=args.batch_size, num_workers=7) pl_trainer = pl.trainer( max_epochs=config.training.max_epochs, logger=logger, callbacks=callbacks callbacks else none, enable_checkpointing=not args.no_checkpointing, enable_progress_bar=not args.no_progress_bar, gradient_clip_val=1.0, accelerator='gpu' args.use_gpu torch.cuda.is_available() else 'cpu' ) # train model pl_trainer.fit(trainer) __name__ == "__main__": parser = argparse.argumentparser(description="train arc neural reasoning model") parser.add_argument( "--train_data", type=str, required=true, help="path training data" ) parser.add_argument( "--val_data", type=str, required=true, help="path validation data" ) parser.add_argument( "--batch_size", type=int, default=32, help="batch size training" ) parser.add_argument( "--learning_rate", type=float, default=1e-4, help="learning rate" ) parser.add_argument( "--max_epochs", type=int, default=10, help="maximum number epochs" ) parser.add_argument( "--use_gpu", action="store_true", help="use gpu training available" ) parser.add_argument( "--no_logging", action="store_true", help="disable logging" ) parser.add_argument( "--no_checkpointing", action="store_true", help="disable checkpointing" ) parser.add_argument( "--no_progress_bar", action="store_true", help="disable progress bar" ) args = parser.parse_args() main(args)</file><file name="src/training/trainer.py"># gpt2_arc/src/training/trainer.py import pytorch_lightning pl import torch import logging torch import nn, optim import time typing import src.config import config torch.utils.data import dataloader logger = logging.getlogger(__name__) class arctrainer(pl.lightningmodule): def __init__(self, model, train_dataset, val_dataset, config: config): super().__init__() self.model = model self.train_dataset = train_dataset self.val_dataset = val_dataset self.config = config self.batch_size = config.training.batch_size self.lr = config.training.learning_rate self.train_losses = [] self.logged_metrics = {} def training_step(self, batch, batch_idx): start_time = time.time() isinstance(batch, tuple): input_ids, attention_mask, labels = batch elif isinstance(batch, dict): input_ids = batch["input_ids"] attention_mask = batch["attention_mask"] labels = batch["labels"].long() else: raise valueerror("batch must either tuple dictionary") # ensure tensors float32 input_ids = input_ids.to(torch.float32) attention_mask = attention_mask.to(torch.float32) outputs = self(input_ids, attention_mask) loss = self.compute_loss(outputs, labels) self.log("train_loss", loss) self.train_losses.append(loss.item()) end_time = time.time() batch_time = end_time - start_time logger.info(f"batch {batch_idx} training time: {batch_time:.4f} seconds") return loss def validation_step(self, batch, batch_idx): isinstance(batch, tuple): input_ids, attention_mask, labels = batch elif isinstance(batch, dict): input_ids = batch["input_ids"] attention_mask = batch["attention_mask"] labels = batch["labels"] else: raise valueerror("batch must either tuple dictionary") outputs = self(input_ids, attention_mask) loss = self.compute_loss(outputs, labels) self.log("val_loss", loss) self.logged_metrics["val_loss"] = loss.item() def test_step(self, batch, batch_idx): input_ids, attention_mask, labels = batch outputs = self(input_ids, attention_mask) loss = self.compute_loss(outputs, labels) b, t, c = outputs.size() # define b c outputs = outputs.view(b, -1, c) predictions = torch.argmax(outputs, dim=-1) labels = labels.view(b, -1) accuracy = (predictions == labels).float().mean() self.log('test_accuracy', accuracy) self.log('test_loss', loss) # log test loss return {"test_accuracy": accuracy} def configure_optimizers(self): return torch.optim.adamw(self.parameters(), lr=self.lr) def train_dataloader(self): return dataloader(self.train_dataset, batch_size=self.batch_size, shuffle=true, num_workers=7) def val_dataloader(self): return dataloader(self.val_dataset, batch_size=self.batch_size, num_workers=7) def test_dataloader(self): return dataloader(self.val_dataset, batch_size=self.batch_size, num_workers=7) def compute_loss(self, outputs, labels): return nn.crossentropyloss()( outputs.view(-1, outputs.size(-1)), labels.view(-1) ) def forward(self, input_ids, attention_mask=none): return self.model(input_ids, attention_mask)</file><file name="src/utils/__init__.py" /><file name="src/utils/helpers.py" /><file name="tests/__init__.py" /><file name="tests/test_arc_dataset.py"># gpt2_arc/tests/test_arc_dataset.py import os import numpy np import pytest import torch import random import logging src.data.arc_dataset import arcdataset, set_debug_mode # set logging tests logger = logging.getlogger(__name__) logger.setlevel(logging.error) @pytest.fixture(scope="module") def debug_mode(): set_debug_mode(true) yield set_debug_mode(false) unittest.mock import mock arckit.data import taskset @pytest.fixture def sample_data(): return [ {"input": [[1, 0], [0, 1]], "output": [[0, 1], [1, 0]]}, {"input": [[0, 1], [1, 0]], "output": [[1, 0], [0, 1]]}, ] @pytest.fixture def mock_taskset(): mock_task = mock() mock_task.id = "mock_task_1" mock_task.train = [ (np.array([[1, 0], [0, 1]]), np.array([[0, 1], [1, 0]])), (np.array([[0, 1], [1, 0]]), np.array([[1, 0], [0, 1]])) ] mock_task.test = [ (np.array([[1, 1], [0, 0]]), np.array([[0, 0], [1, 1]])) ] mock_taskset = mock(spec=taskset) mock_taskset.tasks = [mock_task] return mock_taskset def test_arc_dataset_initialization(sample_data, debug_mode): dataset = arcdataset(sample_data, debug=true) logger.debug(f"dataset length: {len(dataset)}, expected: {len(sample_data)}") assert len(dataset) == len(sample_data), "dataset length mismatch" input_grid, output_grid = dataset[0] logger.debug(f"input grid shape: {input_grid.shape}, expected: (1, 30, 30)") logger.debug(f"output grid shape: {output_grid.shape}, expected: (1, 30, 30)") assert isinstance(input_grid, torch.tensor), "input torch.tensor" assert isinstance(output_grid, torch.tensor), "output torch.tensor" # update shape check match new preprocessing logic assert input_grid.shape == (1, 30, 30), "input grid shape (1, 30, 30)" assert output_grid.shape == (1, 30, 30), "output grid shape (1, 30, 30)" # verify original data preserved center padded grid center_input = input_grid[0, 14:16, 14:16] center_output = output_grid[0, 14:16, 14:16] logger.debug(f"center input:\n{center_input}") logger.debug(f"center output:\n{center_output}") assert torch.allclose(center_input, torch.tensor([[1., 0.], [0., 1.]])), "input data preserved correctly" assert torch.allclose(center_output, torch.tensor([[0., 1.], [1., 0.]])), "output data preserved correctly" dataset = arcdataset(sample_data) assert len(dataset) == 2, "dataset 2 samples" input_grid, output_grid = dataset[0] assert isinstance(input_grid, torch.tensor), "input torch.tensor" assert isinstance(output_grid, torch.tensor), "output torch.tensor" # update shape check match new preprocessing logic assert input_grid.shape == (1, 30, 30), "input grid shape (1, 30, 30)" assert output_grid.shape == (1, 30, 30), "output grid shape (1, 30, 30)" # verify original data preserved center padded grid center_input = input_grid[0, 14:16, 14:16] center_output = output_grid[0, 14:16, 14:16] assert torch.allclose(center_input, torch.tensor([[1., 0.], [0., 1.]])), "input data preserved correctly" assert torch.allclose(center_output, torch.tensor([[0., 1.], [1., 0.]])), "output data preserved correctly" #skip @pytest.mark.skip(reason="skipping test synthetic data test problematic") def test_arc_dataset_synthetic_data(debug_mode): synthetic_data_path = "/volumes/totallynotaharddrive/arc-neural-reasoning-model/syntheticarc/tasks" assert os.path.isdir(synthetic_data_path), f"directory exist: {synthetic_data_path}" train_dataset = arcdataset(synthetic_data_path, is_test=false, debug=true) test_dataset = arcdataset(synthetic_data_path, is_test=true, debug=true) assert len(train_dataset) &gt; 0, "synthetic train dataset empty" assert len(test_dataset) &gt; 0, "synthetic test dataset empty" logger.debug(f"loaded {len(train_dataset.data)} synthetic tasks") logger.debug(f"total train dataset length: {len(train_dataset)}") logger.debug(f"total test dataset length: {len(test_dataset)}") total_train = sum(len(task['train']) task train_dataset.data) total_test = sum(len(task['test']) task test_dataset.data) logger.debug(f"total train samples: {total_train}") logger.debug(f"total test samples: {total_test}") i, task enumerate(train_dataset.data): print(f"task {i} - train samples: {len(task['train'])}, test samples: {len(task['test'])}") assert len(train_dataset) == total_train, f"train dataset length ({len(train_dataset)}) match total train samples ({total_train})" assert len(test_dataset) == total_test, f"test dataset length ({len(test_dataset)}) match total test samples ({total_test})" len(train_dataset) == 0: pytest.skip("train dataset empty; skipping random sample tests.") print(f"train dataset size: {len(train_dataset)}") print(f"test dataset size: {len(test_dataset)}") len(train_dataset) &lt; 3: pytest.skip("not enough data train dataset random sampling tests.") # test random samples train dataset range(3): idx = random.choice(range(len(train_dataset))) try: print(f"\ntrain sample {i + 1}:") print(f"generated index: {idx}") input_grid, output_grid = train_dataset[idx] print(f"input grid shape: {input_grid.shape}") print(f"output grid shape: {output_grid.shape}") except indexerror e: print(f"error: attempted access index {idx} range. train dataset size {len(train_dataset)}.") pytest.fail(f"generated index {idx} range train dataset size {len(train_dataset)}: {str(e)}") # verify grid sizes max_h, max_w = train_dataset.max_grid_size assert max_h &gt; 0 max_w &gt; 0, "grid size positive" print(f"maximum grid size: {train_dataset.max_grid_size}") # verify access train test splits assert len(train_dataset.data) &gt; 0, "dataset contain least one task" assert 'train' train_dataset.data[0], "each task 'train' split" assert 'test' train_dataset.data[0], "each task 'test' split" print(f"train dataset length: {len(train_dataset)}") print(f"test dataset length: {len(test_dataset)}") def test_arc_dataset_getitem(sample_data): dataset = arcdataset(sample_data) input_grid, output_grid = dataset[0] assert isinstance(input_grid, torch.tensor), "input torch.tensor" assert isinstance(output_grid, torch.tensor), "output torch.tensor" assert input_grid.shape == (1, 30, 30), "input grid shape (1, 30, 30)" assert output_grid.shape == (1, 30, 30), "output grid shape (1, 30, 30)" # check original data preserved center center_input = input_grid[0, 14:16, 14:16] center_output = output_grid[0, 14:16, 14:16] assert torch.allclose(center_input, torch.tensor([[1., 0.], [0., 1.]])), "input data preserved correctly" assert torch.allclose(center_output, torch.tensor([[0., 1.], [1., 0.]])), "output data preserved correctly" def test_arc_dataset_len(sample_data): print("debugging: entering test_arc_dataset_len") print(f"debugging: sample_data = {sample_data}") dataset = arcdataset(sample_data) print(f"debugging: len(dataset) = {len(dataset)}, len(sample_data) = {len(sample_data)}") assert len(dataset) == len(sample_data), "dataset length match input data length" print("debugging: exiting test_arc_dataset_len") def test_arc_dataset_invalid_data(sample_data): invalid_data = [{"input": [1, 0], "output": [[0, 1], [1, 0]]}] pytest.raises(valueerror): arcdataset(invalid_data) invalid_data = [{"input": [[1, 0], [0, 1]], "output": "not list"}] pytest.raises(valueerror): arcdataset(invalid_data) def test_arc_dataset_preprocess_grid(sample_data): dataset = arcdataset(sample_data, num_symbols=10) input_grid, output_grid = dataset[0] print(f"input grid shape: {input_grid.shape}") print(f"output grid shape: {output_grid.shape}") print(f"input grid content:\n{input_grid}") print(f"output grid content:\n{output_grid}") # check grids indeed 3d assert input_grid.ndim == 3, f"expected 3d input grid, got {input_grid.ndim}d" assert output_grid.ndim == 3, f"expected 3d output grid, got {output_grid.ndim}d" # check shape (1, 30, 30) assert input_grid.shape == (1, 30, 30), f"preprocessed grid shape (1, 30, 30), got {input_grid.shape}" assert output_grid.shape == (1, 30, 30), f"preprocessed grid shape (1, 30, 30), got {output_grid.shape}" # check original data preserved center expected_input = torch.zeros((1, 30, 30)) expected_input[0, 14:16, 14:16] = torch.tensor([[1., 0.], [0., 1.]]) expected_output = torch.zeros((1, 30, 30)) expected_output[0, 14:16, 14:16] = torch.tensor([[0., 1.], [1., 0.]]) print(f"expected input:\n{expected_input}") print(f"expected output:\n{expected_output}") assert torch.allclose(input_grid, expected_input), "input grid data mismatch" assert torch.allclose(output_grid, expected_output), "output grid data mismatch" @pytest.fixture def mock_taskset(): mock_task = mock() mock_task.id = "mock_task_1" mock_task.train = [ (np.array([[1, 0], [0, 1]]), np.array([[0, 1], [1, 0]])), (np.array([[0, 1], [1, 0]]), np.array([[1, 0], [0, 1]])) ] mock_task.test = [ (np.array([[1, 1], [0, 0]]), np.array([[0, 0], [1, 1]])) ] mock_taskset = mock(spec=taskset) mock_taskset.tasks = [mock_task] return mock_taskset #skip @pytest.mark.skip(reason="skipping test problematic") def test_arc_dataset_taskset_initialization(mock_taskset): import logging logging.basicconfig(level=logging.debug) logger = logging.getlogger(__name__) logger.debug(f"mock taskset: {mock_taskset}") logger.debug(f"mock taskset attributes: {dir(mock_taskset)}") print(f"mock task train data: {mock_taskset.tasks[0].train}") print(f"mock task test data: {mock_taskset.tasks[0].test}") dataset = arcdataset(mock_taskset) logger.debug(f"dataset length: {len(dataset)}") print(f"dataset length: {len(dataset)}, expected: 3") assert len(dataset) == 3, "dataset 3 samples (2 train + 1 test)" input_grid, output_grid = dataset[0] print(f"input grid shape: {input_grid.shape}, expected: (1, 30, 30)") print(f"output grid shape: {output_grid.shape}, expected: (1, 30, 30)") assert isinstance(input_grid, torch.tensor), "input torch.tensor" assert isinstance(output_grid, torch.tensor), "output torch.tensor" assert input_grid.shape == (1, 30, 30), "input grid shape (1, 30, 30)" assert output_grid.shape == (1, 30, 30), "output grid shape (1, 30, 30)" # check original data preserved center center_input = input_grid[0, 14:16, 14:16] center_output = output_grid[0, 14:16, 14:16] print(f"center input: {center_input}") print(f"center output: {center_output}") assert torch.allclose(center_input, torch.tensor([[1., 0.], [0., 1.]])), "input data preserved correctly" assert torch.allclose(center_output, torch.tensor([[0., 1.], [1., 0.]])), "output data preserved correctly" import logging logging.basicconfig(level=logging.debug) logger = logging.getlogger(__name__) logger.debug(f"mock taskset: {mock_taskset}") logger.debug(f"mock taskset attributes: {dir(mock_taskset)}") dataset = arcdataset(mock_taskset) logger.debug(f"dataset length: {len(dataset)}") assert len(dataset) == 3, "dataset 3 samples (2 train + 1 test)" input_grid, output_grid = dataset[0] assert isinstance(input_grid, torch.tensor), "input torch.tensor" assert isinstance(output_grid, torch.tensor), "output torch.tensor" assert input_grid.shape == (1, 30, 30), "input grid shape (1, 30, 30)" assert output_grid.shape == (1, 30, 30), "output grid shape (1, 30, 30)" # check original data preserved center center_input = input_grid[0, 14:16, 14:16] center_output = output_grid[0, 14:16, 14:16] assert torch.allclose(center_input, torch.tensor([[1., 0.], [0., 1.]])), "input data preserved correctly" assert torch.allclose(center_output, torch.tensor([[0., 1.], [1., 0.]])), "output data preserved correctly" torch.utils.data import dataloader def test_arc_dataset_collate_fn(sample_data): logger.debug("starting test_arc_dataset_collate_fn") dataset = arcdataset(sample_data) dataloader = dataloader(dataset, batch_size=2, collate_fn=arcdataset.collate_fn) batch = next(iter(dataloader)) input_batch, output_batch = batch logger.debug(f"collated batch shapes - inputs: {input_batch.shape}, outputs: {output_batch.shape}") assert input_batch.shape == (2, 1, 30, 30), "batched input shape (2, 1, 30, 30)" assert output_batch.shape == (2, 1, 30, 30), "batched output shape (2, 1, 30, 30)" logger.debug("completed test_arc_dataset_collate_fn") def test_arc_dataset_variable_size_grids(sample_data): logger.debug("starting test_arc_dataset_variable_size_grids") variable_data = sample_data + [{"input": [[1, 0, 2], [0, 2, 1], [2, 1, 0]], "output": [[2, 1, 0], [1, 0, 2], [0, 2, 1]]}] dataset = arcdataset(variable_data) # check first sample (2x2) input_grid_1, output_grid_1 = dataset[0] assert input_grid_1.shape == (1, 30, 30), "first sample shape (1, 30, 30)" assert output_grid_1.shape == (1, 30, 30), "first sample shape (1, 30, 30)" # check center first sample (2x2) center_input_1 = input_grid_1[0, 14:16, 14:16] center_output_1 = output_grid_1[0, 14:16, 14:16] assert torch.allclose(center_input_1, torch.tensor([[1., 0.], [0., 1.]])), "first sample input data preserved correctly" assert torch.allclose(center_output_1, torch.tensor([[0., 1.], [1., 0.]])), "first sample output data preserved correctly" # check third sample (3x3) input_grid_2, output_grid_2 = dataset[2] assert input_grid_2.shape == (1, 30, 30), "third sample shape (1, 30, 30)" assert output_grid_2.shape == (1, 30, 30), "third sample shape (1, 30, 30)" # check center third sample (3x3) center_input_2 = input_grid_2[0, 13:16, 13:16] center_output_2 = output_grid_2[0, 13:16, 13:16] assert torch.allclose(center_input_2, torch.tensor([[1., 0., 2.], [0., 2., 1.], [2., 1., 0.]])), f"third sample input data preserved correctly. got:\n{center_input_2}" assert torch.allclose(center_output_2, torch.tensor([[2., 1., 0.], [1., 0., 2.], [0., 2., 1.]])), f"third sample output data preserved correctly. got:\n{center_output_2}" logger.debug("completed test_arc_dataset_variable_size_grids")</file><file name="tests/test_end_to_end.py"># gpt2_arc/tests/test_end_to_end.py import pytest import torch import numpy np src.data.arc_dataset import arcdataset src.models.gpt2 import gpt2arc src.training.trainer import arctrainer src.config import config, modelconfig, trainingconfig import pytorch_lightning pl import time import logging import os thop import profile, clever_format # import thop pytest import approx # set logging logging.basicconfig(level=logging.debug) logger = logging.getlogger(__name__) @pytest.fixture def arc_data_path(): # adjust path location arc dataset json file return "/volumes/totallynotaharddrive/arc-neural-reasoning-model/syntheticarc/tasks/1c786137.json" import arckit def test_end_to_end(): logger.debug("starting end-to-end test") try: # load data using arckit logger.debug("loading data using arckit") train_set, eval_set = arckit.load_data() # create datasets using arcdataset logger.debug("creating train validation datasets") full_dataset = arcdataset(train_set, is_test=false) # use smaller subset dataset subset_size = int(0.1 * len(full_dataset)) # use 10% dataset train_dataset, _ = torch.utils.data.random_split(full_dataset, [subset_size, len(full_dataset) - subset_size]) val_dataset, _ = torch.utils.data.random_split(full_dataset, [subset_size, len(full_dataset) - subset_size]) logger.debug(f"train dataset size: {len(train_dataset)}, validation dataset size: {len(val_dataset)}") # create custom collate function handle data format def collate_fn(batch): inputs = [item[0].to(torch.float32) item batch] # convert float32 outputs = [item[1].to(torch.float32) item batch] # convert float32 logger.debug(f"batch input dtypes stack: {[item[0].dtype item batch]}") logger.debug(f"batch output dtypes stack: {[item[1].dtype item batch]}") # inputs outputs already tensors, need stack input_stack = torch.stack(inputs) output_stack = torch.stack(outputs) # log data types stacking logger.debug(f"collate function input_stack dtype: {input_stack.dtype}") logger.debug(f"collate function output_stack dtype: {output_stack.dtype}") # create dummy attention mask (all ones) attention_mask = torch.ones(input_stack.size(0), input_stack.size(2) * input_stack.size(3), dtype=torch.float32) logger.debug(f"collate function attention_mask dtype: {attention_mask.dtype}") return input_stack, attention_mask, output_stack logger.debug(f"batch output dtypes stack: {[item[1].dtype item batch]}") # inputs outputs already tensors, need stack input_stack = torch.stack(inputs) output_stack = torch.stack(outputs) # create dummy attention mask (all ones) attention_mask = torch.ones(input_stack.size(0), input_stack.size(2) * input_stack.size(3), dtype=torch.float32) logger.debug(f"collate function input dtype: {input_stack.dtype}") return input_stack, attention_mask, output_stack # initialize model logger.debug("initializing model") model_config = modelconfig(n_embd=64, n_head=2, n_layer=1) # use smaller model configuration model = gpt2arc(model_config).to(torch.float32) logger.debug(f"model initialized config: {model_config}") # # thop profiling - commented due typeerror mps tensors # logger.debug("profiling model thop") # dummy_input = torch.randn(1, 1, 28, 28, dtype=torch.float32) # example input shape # macs, params = profile(model, inputs=(dummy_input,)) # macs, params = clever_format([macs, params], "%.3f") # logger.info(f"macs: {macs}, parameters: {params}") # initialize trainer logger.debug("initializing trainer") config = config(model=model_config, training=trainingconfig(batch_size=32, learning_rate=1e-4, max_epochs=2)) # reduce epochs 2 trainer = arctrainer(model, train_dataset, val_dataset, config) trainer.train_dataloader = lambda: torch.utils.data.dataloader(train_dataset, batch_size=config.training.batch_size, collate_fn=collate_fn) trainer.val_dataloader = lambda: torch.utils.data.dataloader(val_dataset, batch_size=config.training.batch_size, collate_fn=collate_fn) trainer.test_dataloader = lambda: torch.utils.data.dataloader(val_dataset, batch_size=config.training.batch_size, collate_fn=collate_fn) logger.debug(f"trainer initialized config: {config}") # create pytorch lightning trainer logger.debug("creating pytorch lightning trainer") # measure training time start_time = time.time() pl_trainer = pl.trainer( max_epochs=config.training.max_epochs, logger=false, enable_checkpointing=false, enable_progress_bar=false ) logger.debug("pytorch lightning trainer created") # evaluate model training get initial accuracy logger.info("evaluating model training") initial_val_results = pl_trainer.test(trainer, verbose=false) initial_accuracy = initial_val_results[0]['test_accuracy'] initial_loss = initial_val_results[0]['test_loss'] logger.info(f"initial validation accuracy: {initial_accuracy}, initial loss: {initial_loss}") print(f"initial validation accuracy: {initial_accuracy}, initial loss: {initial_loss}") logger.debug("starting model training") pl_trainer.fit(trainer) end_time = time.time() training_time = end_time - start_time logger.info(f"total training time: {training_time:.2f} seconds") logger.debug("model training completed") # check loss decreased train_losses = trainer.train_losses logger.info(f"training losses: {train_losses}") assert train_losses[-1] &lt; train_losses[0], f"training loss decrease. initial loss: {train_losses[0]}, final loss: {train_losses[-1]}" # check final loss lower initial loss assert train_losses[-1] &lt; train_losses[0], "final training loss lower initial loss" # check average loss per epoch decreases epoch_losses = [sum(train_losses[i:i+33])/33 range(0, len(train_losses), 33)] assert all(epoch_losses[i] &gt; epoch_losses[i+1] range(len(epoch_losses)-1)), "average training loss per epoch consistently decrease" # evaluate model training logger.debug("evaluating model training") final_val_results = pl_trainer.test(trainer, verbose=false) final_accuracy = final_val_results[0]['test_accuracy'] final_loss = final_val_results[0]['test_loss'] logger.info(f"final validation accuracy: {final_accuracy}, final loss: {final_loss}") print(f"final validation accuracy: {final_accuracy}, final loss: {final_loss}") # check validation accuracy improved assert final_accuracy &gt; initial_accuracy, f"validation accuracy improve. initial accuracy: {initial_accuracy}, final accuracy: {final_accuracy}" logger.info(f"final training loss: {train_losses[-1]:.4f}") logger.info(f"validation accuracy: {final_accuracy:.4f}") # check model parameters total_params = sum(p.numel() p model.parameters()) trainable_params = sum(p.numel() p model.parameters() p.requires_grad) assert total_params &gt; 0, "model parameters" assert trainable_params &gt; 0, "model trainable parameters" assert trainable_params == total_params, "not parameters trainable" logger.debug(f"total parameters: {total_params}") logger.debug(f"trainable parameters: {trainable_params}") logger.debug("end-to-end test completed successfully") except exception e: logger.error(f"end-to-end test failed error: {str(e)}") raise</file><file name="tests/test_gpt2.py"># gpt2_arc/tests/test_gpt2.py import logging import pytest import torch src.config import modelconfig src.models.gpt2 import gpt2arc, attention, feedforward, transformerblock logging.basicconfig(level=logging.debug) logger = logging.getlogger(__name__) @pytest.fixture def model(): config = modelconfig() return gpt2arc(config) def test_gpt2arc_initialization(model): assert isinstance(model, gpt2arc) assert hasattr(model, "conv1") # check conv1 instead token_embedding assert hasattr(model, "blocks") assert hasattr(model, "ln_f") assert hasattr(model, "config") def test_gpt2arc_forward_pass(model): batch_size = 2 height = 30 width = 30 input_ids = torch.randn(batch_size, 1, height, width) # simulate image-like input attention_mask = torch.ones((batch_size, height * width)) output = model(input_ids, attention_mask) assert isinstance(output, torch.tensor) assert output.shape == (batch_size, height * width, model.config.n_embd) logger.debug(f"output shape: {output.shape}") def test_gpt2arc_output_values(model): logger.debug("testing gpt2arc output values") batch_size = 1 channels = 1 height = 30 width = 30 input_ids = torch.randn(batch_size, channels, height, width) # simulate image-like input attention_mask = torch.ones((batch_size, height * width)) output = model(input_ids, attention_mask) assert torch.isnan(output).any(), "output contains nan values" def test_gpt2arc_forward_pass(model): batch_size = 2 channels = 1 height = 30 width = 30 input_ids = torch.randn(batch_size, channels, height, width) # simulate image-like input attention_mask = torch.ones((batch_size, height * width)) output_with_mask = model(input_ids, attention_mask) output_without_mask = model(input_ids) logger.debug( f"difference outputs: {(output_with_mask - output_without_mask).abs().mean()}" ) def test_attention_module(): logger.debug("testing attention module") attention = attention(n_embd=768, n_head=12) x = torch.randn(2, 10, 768) output = attention(x) assert output.shape == x.shape logger.debug(f"attention input shape: {x.shape}, output shape: {output.shape}") def test_feedforward_module(): logger.debug("testing feedforward module") ff = feedforward(n_embd=768) x = torch.randn(2, 10, 768) output = ff(x) assert output.shape == x.shape logger.debug(f"feedforward input shape: {x.shape}, output shape: {output.shape}") def test_transformer_block(): logger.debug("testing transformerblock") block = transformerblock(n_embd=768, n_head=12) x = torch.randn(2, 10, 768) output = block(x) assert output.shape == x.shape logger.debug( f"transformerblock input shape: {x.shape}, output shape: {output.shape}" )</file><file name="tests/test_train.py"># gpt2_arc/tests/test_train.py import os import sys sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "../../"))) import os import sys import pytest import logging logger = logging.getlogger(__name__) def set_logging_level(level=logging.error): logger = logging.getlogger() logger.setlevel(level) # add project root pythonpath sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "../../"))) import argparse unittest.mock import any, magicmock, patch import pytorch_lightning pl import torch gpt2_arc.src.data.arc_dataset import arcdataset gpt2_arc.src.models.gpt2 import gpt2arc gpt2_arc.src.training.train import main gpt2_arc.src.training.trainer import arctrainer @pytest.fixture def mock_args(): args = argparse.namespace() args.train_data = "mock_train_data.json" args.val_data = "mock_val_data.json" args.batch_size = 32 args.learning_rate = 1e-4 args.max_epochs = 10 args.use_gpu = false args.no_logging = false args.no_checkpointing = false args.no_progress_bar = false return args @pytest.fixture def mock_dataset(): dataset = magicmock(spec=arcdataset) dataset.data = [{"input": "mock input", "output": "mock output"}] dataset.__len__.return_value = 100 return dataset src.config import config, modelconfig, trainingconfig @pytest.fixture def model(): config = config(model=modelconfig(), training=trainingconfig()) return gpt2arc(config.model) @pytest.fixture def trainer(): model_config = modelconfig(n_embd=64, n_head=2, n_layer=1) config = config(model=model_config, training=trainingconfig(batch_size=32, learning_rate=1e-4, max_epochs=2)) model = gpt2arc(config.model) return arctrainer(model, none, none, config) @pytest.fixture def mock_pl_trainer(): return magicmock(spec=pl.trainer) # existing gpt2arc model tests def test_gpt2arc_initialization(model): assert isinstance(model, gpt2arc) assert hasattr(model, "conv1") # check conv1 instead token_embedding assert hasattr(model, "blocks") assert hasattr(model, "ln_f") assert hasattr(model, "config") def test_gpt2arc_forward_pass(model): batch_size = 2 height = width = 30 seq_length = height * width input_ids = torch.randint(0, 2, (batch_size, seq_length)) attention_mask = torch.ones((batch_size, seq_length)) output_with_mask = model(input_ids, attention_mask) output_without_mask = model(input_ids) assert isinstance(output_with_mask, torch.tensor) assert output_with_mask.shape == (batch_size, seq_length, model.config.n_embd) assert isinstance(output_without_mask, torch.tensor) assert output_without_mask.shape == (batch_size, seq_length, model.config.n_embd) logger.debug(f"difference outputs: {(output_with_mask - output_without_mask).abs().mean()}") def test_gpt2arc_output_values(model): logger.debug("testing gpt2arc output values") batch_size = 1 height = width = 30 seq_length = height * width input_ids = torch.randint(0, 2, (batch_size, seq_length)) attention_mask = torch.ones((batch_size, seq_length)) output = model(input_ids, attention_mask) assert torch.isnan(output).any(), "output contains nan values" assert torch.isinf(output).any(), "output contains infinity values" def test_gpt2arc_attention_mask(model): batch_size = 2 channels = 1 height = 30 width = 30 input_ids = torch.randint(0, 2, (batch_size, channels, height, width)) attention_mask = torch.zeros((batch_size, height * width)) attention_mask[:, :450] = 1 # attend first half pixels output_with_mask = model(input_ids, attention_mask) output_without_mask = model(input_ids) assert torch.allclose(output_with_mask, output_without_mask), "attention mask affect output" # new tests train.py def test_logging(mock_args, mock_dataset, model, mock_pl_trainer): print("entering test_logging") patch( "gpt2_arc.src.training.train.arcdataset", return_value=mock_dataset ), patch("gpt2_arc.src.training.train.gpt2arc", return_value=model), patch( "gpt2_arc.src.training.train.arctrainer", return_value=trainer ), patch( "gpt2_arc.src.training.train.pl.trainer", return_value=mock_pl_trainer ), patch("gpt2_arc.src.training.train.tensorboardlogger") mock_logger, patch( "gpt2_arc.src.training.train.modelcheckpoint" ) mock_checkpoint: main(mock_args) mock_logger.assert_called_once_with("tb_logs", name="arc_model") mock_checkpoint.assert_called_once_with( dirpath="checkpoints", filename="arc_model-{epoch:02d}-{val_loss:.2f}", save_top_k=3, monitor="val_loss", mode="min", ) def test_fit_call(mock_args, mock_dataset, model, mock_pl_trainer): print("entering test_fit_call") patch( "gpt2_arc.src.training.train.arcdataset", return_value=mock_dataset ), patch("gpt2_arc.src.training.train.gpt2arc", return_value=model), patch( "gpt2_arc.src.training.train.arctrainer", return_value=trainer ), patch( "gpt2_arc.src.training.train.pl.trainer", return_value=mock_pl_trainer ), patch("gpt2_arc.src.training.train.tensorboardlogger"), patch( "gpt2_arc.src.training.train.modelcheckpoint" ): main(mock_args) mock_pl_trainer.fit.assert_called_once_with(trainer) def test_data_loading(mock_args): patch( "gpt2_arc.src.data.arc_dataset.arcdataset.__init__", return_value=none ) mock_init: arcdataset(mock_args.train_data) mock_init.assert_called_once_with(mock_args.train_data) def test_trainer_initialization(model, mock_dataset): config = config(model=modelconfig(), training=trainingconfig()) trainer = arctrainer( model=model, train_dataset=mock_dataset, val_dataset=mock_dataset, config=config ) assert isinstance(trainer, arctrainer) assert trainer.model == model assert trainer.train_dataset == mock_dataset assert trainer.val_dataset == mock_dataset assert trainer.batch_size == 32 assert trainer.lr == 1e-4 @pytest.mark.parametrize("batch_size", [1, 1000000]) def test_batch_size_extremes(mock_args, batch_size): model_config = modelconfig(n_embd=96, n_head=3, n_layer=1) config = config(model=model_config, training=trainingconfig(batch_size=batch_size, learning_rate=5e-4, max_epochs=10)) mock_args.batch_size = batch_size mock_args.no_logging = true mock_args.no_checkpointing = true mock_args.no_progress_bar = true mock_args.use_gpu = false patch("gpt2_arc.src.training.train.arcdataset"), patch( "gpt2_arc.src.training.train.gpt2arc" ), patch("gpt2_arc.src.training.train.arctrainer"), patch( "gpt2_arc.src.training.train.pl.trainer" ) mock_trainer: main(mock_args) mock_trainer.assert_called_with( max_epochs=config.training.max_epochs, logger=false, callbacks=none, enable_checkpointing=false, enable_progress_bar=false, gradient_clip_val=1.0, accelerator='cpu' ) @pytest.mark.parametrize("learning_rate", [1e-10, 1000]) def test_learning_rate_extremes(mock_args, learning_rate): set_logging_level(logging.warning) # suppress info debug messages mock_args.learning_rate = learning_rate patch("gpt2_arc.src.training.train.arcdataset"), patch( "gpt2_arc.src.training.train.gpt2arc" ), patch("gpt2_arc.src.training.train.arctrainer"), patch( "gpt2_arc.src.training.train.pl.trainer" ): main(mock_args) # raise exception def test_non_existent_train_data(mock_args): mock_args.train_data = "non_existent_path.json" pytest.raises(filenotfounderror): main(mock_args) def test_gpu_not_available(mock_args): mock_args.use_gpu = true mock_args.no_logging = false mock_args.no_checkpointing = false mock_args.no_progress_bar = false patch("torch.cuda.is_available", return_value=false), patch( "gpt2_arc.src.training.train.arcdataset" ), patch("gpt2_arc.src.training.train.gpt2arc"), patch( "gpt2_arc.src.training.train.arctrainer" ), patch("gpt2_arc.src.training.train.pl.trainer") mock_trainer: main(mock_args) mock_trainer.assert_called_with( max_epochs=mock_args.max_epochs, logger=any, callbacks=any, enable_checkpointing=true, enable_progress_bar=true, gradient_clip_val=1.0, accelerator='cpu' ) hypothesis import healthcheck, given, settings hypothesis import strategies st @settings(suppress_health_check=[healthcheck.function_scoped_fixture]) @given(batch_size=st.integers(min_value=1, max_value=1024)) def test_valid_batch_sizes(mock_args, batch_size): mock_args.batch_size = batch_size patch("gpt2_arc.src.training.train.arcdataset"), patch( "gpt2_arc.src.training.train.gpt2arc" ), patch("gpt2_arc.src.training.train.arctrainer"), patch( "gpt2_arc.src.training.train.pl.trainer" ): main(mock_args) # raise exception @settings(suppress_health_check=[healthcheck.function_scoped_fixture]) @given( learning_rate=st.floats( min_value=1e-6, max_value=1.0, allow_nan=false, allow_infinity=false ) ) def test_valid_learning_rates(mock_args, learning_rate): mock_args.learning_rate = learning_rate patch("gpt2_arc.src.training.train.arcdataset"), patch( "gpt2_arc.src.training.train.gpt2arc" ), patch("gpt2_arc.src.training.train.arctrainer"), patch( "gpt2_arc.src.training.train.pl.trainer" ): main(mock_args) # raise exception def test_end_to_end_training(mock_args, tmp_path): model_config = modelconfig(n_embd=96, n_head=3, n_layer=1) config = config(model=model_config, training=trainingconfig(batch_size=32, learning_rate=5e-4, max_epochs=2)) checkpoint_dir = tmp_path / "checkpoints" checkpoint_dir.mkdir() mock_args.checkpoint_dir = str(checkpoint_dir) patch("gpt2_arc.src.training.train.arcdataset"), patch( "gpt2_arc.src.training.train.gpt2arc" ), patch("gpt2_arc.src.training.train.arctrainer"), patch( "gpt2_arc.src.training.train.pl.trainer" ) mock_trainer, patch( "gpt2_arc.src.training.train.modelcheckpoint" ) mock_checkpoint: main(mock_args) mock_trainer.return_value.fit.assert_called_once() mock_checkpoint.assert_called_once() def test_tensorboard_logging(mock_args, tmp_path): log_dir = tmp_path / "tb_logs" log_dir.mkdir() patch("gpt2_arc.src.training.train.arcdataset"), patch( "gpt2_arc.src.training.train.gpt2arc" ), patch("gpt2_arc.src.training.train.arctrainer"), patch( "gpt2_arc.src.training.train.pl.trainer" ), patch("gpt2_arc.src.training.train.tensorboardlogger") mock_logger: main(mock_args) mock_logger.assert_called_once_with("tb_logs", name="arc_model") # additional test gpt2arc model training context def test_arctrainer_forward_pass(trainer): batch_size = 2 seq_length = 900 # 30x30 grid input_ids = torch.randint(0, 2, (batch_size, seq_length)) attention_mask = torch.ones((batch_size, seq_length)) output = trainer(input_ids, attention_mask) assert isinstance(output, torch.tensor) assert output.shape == (batch_size, seq_length, trainer.model.config.n_embd) def test_arctrainer_training_step(trainer): batch_size = 2 height = width = 30 # 30x30 grid seq_length = height * width vocab_size = 10 # use small vocab size testing batch = { "input_ids": torch.randint(0, vocab_size, (batch_size, seq_length)).long(), "attention_mask": torch.ones((batch_size, seq_length)).float(), "labels": torch.randint(0, vocab_size, (batch_size, seq_length), dtype=torch.long), } loss = trainer.training_step(batch, 0) assert isinstance(loss, torch.tensor) assert loss.shape == torch.size([]) # loss scalar assert torch.isnan(loss).any(), "loss contains nan values" assert torch.isinf(loss).any(), "loss contains infinity values" @pytest.mark.parametrize("batch_format", ["tuple", "dict"]) def test_arctrainer_batch_format(trainer, batch_format): batch_size = 2 height = width = 30 # 30x30 grid seq_length = height * width vocab_size = 10 # use small vocab size testing batch_format == "tuple": batch = ( torch.randint(0, vocab_size, (batch_size, seq_length)).long(), torch.ones((batch_size, seq_length)).float(), torch.randint(0, vocab_size, (batch_size, seq_length)).long(), ) else: batch = { "input_ids": torch.randint(0, vocab_size, (batch_size, seq_length)).long(), "attention_mask": torch.ones((batch_size, seq_length)).float(), "labels": torch.randint(0, vocab_size, (batch_size, seq_length)).long(), } loss = trainer.training_step(batch, 0) assert isinstance(loss, torch.tensor) assert loss.shape == torch.size([]) # loss scalar assert torch.isnan(loss).any(), "loss contains nan values" assert torch.isinf(loss).any(), "loss contains infinity values"</file><file name="tests/test_trainer.py"># gpt2_arc/tests/test_trainer.py import pytest import torch src.config import config, modelconfig, trainingconfig src.data.arc_dataset import arcdataset src.models.gpt2 import gpt2arc src.training.trainer import arctrainer @pytest.fixture def sample_data(): return [ {"input": [[1, 0], [0, 1]], "output": [[0, 1], [1, 0]]}, {"input": [[0, 1], [1, 0]], "output": [[1, 0], [0, 1]]}, ] @pytest.fixture def model(): config = modelconfig() return gpt2arc(config) @pytest.fixture def trainer(model, sample_data): config = config(model=modelconfig(), training=trainingconfig()) train_dataset = arcdataset(sample_data) val_dataset = arcdataset(sample_data) return arctrainer(model, train_dataset, val_dataset, config) def test_arctrainer_initialization(trainer): assert isinstance(trainer, arctrainer) assert hasattr(trainer, "model") assert hasattr(trainer, "train_dataset") assert hasattr(trainer, "val_dataset") def test_arctrainer_forward_pass(trainer): batch_size = 2 seq_length = 900 # 30x30 grid input_ids = torch.randint(0, 2, (batch_size, seq_length)) attention_mask = torch.ones((batch_size, seq_length)) output = trainer(input_ids, attention_mask) assert isinstance(output, torch.tensor) assert output.shape == (batch_size, seq_length, trainer.model.config.n_embd) @pytest.mark.parametrize("batch_format", ["tuple", "dict"]) def test_arctrainer_training_step(trainer, batch_format): batch_size = 2 seq_length = 900 # 30x30 grid vocab_size = 10 # use small vocab size testing batch_format == "tuple": batch = ( torch.randint(0, vocab_size, (batch_size, seq_length)).long(), torch.ones((batch_size, seq_length)).float(), torch.randint(0, vocab_size, (batch_size, seq_length)).long(), ) else: batch = { "input_ids": torch.randint(0, vocab_size, (batch_size, seq_length)).long(), "attention_mask": torch.ones((batch_size, seq_length)).float(), "labels": torch.randint(0, vocab_size, (batch_size, seq_length)).long(), } loss = trainer.training_step(batch, 0) assert isinstance(loss, torch.tensor) assert loss.shape == torch.size([]) assert torch.isnan(loss).any(), "loss contains nan values" assert torch.isinf(loss).any(), "loss contains infinity values" @pytest.mark.parametrize("batch_format", ["tuple", "dict"]) def test_arctrainer_validation_step(trainer, batch_format): batch_size = 2 seq_length = 900 # 30x30 grid vocab_size = 10 # use small vocab size testing batch_format == "tuple": batch = ( torch.randint(0, vocab_size, (batch_size, seq_length)).long(), torch.ones((batch_size, seq_length)).float(), torch.randint(0, vocab_size, (batch_size, seq_length)).long(), ) else: batch = { "input_ids": torch.randint(0, vocab_size, (batch_size, seq_length)).long(), "attention_mask": torch.ones((batch_size, seq_length)).float(), "labels": torch.randint(0, vocab_size, (batch_size, seq_length)).long(), } trainer.validation_step(batch, 0) # check val_loss logged assert "val_loss" trainer.logged_metrics def test_arctrainer_configure_optimizers(trainer): optimizer = trainer.configure_optimizers() assert isinstance(optimizer, torch.optim.adamw) # use torch.optim.adamw def test_arctrainer_train_dataloader(trainer): dataloader = trainer.train_dataloader() assert isinstance(dataloader, torch.utils.data.dataloader) assert len(dataloader.dataset) == len(trainer.train_dataset) def test_arctrainer_val_dataloader(trainer): dataloader = trainer.val_dataloader() assert isinstance(dataloader, torch.utils.data.dataloader) assert len(dataloader.dataset) == len(trainer.val_dataset)</file></source>============================= test session starts ==============================
platform darwin -- Python 3.12.5, pytest-8.3.2, pluggy-1.5.0
rootdir: /Volumes/Totallynotaharddrive/arc-neural-reasoning-model
configfile: pyproject.toml
plugins: anyio-4.4.0, hypothesis-6.111.2, cov-5.0.0, profiling-1.7.0
collected 47 items

tests/test_arc_dataset.py::test_arc_dataset_initialization 2024-09-10 12:51:54,763 - src.data.arc_dataset - DEBUG - ARCDataset.__init__ called with data_source: [{'input': [[1, 0], [0, 1]], 'output': [[0, 1], [1, 0]]}, {'input': [[0, 1], [1, 0]], 'output': [[1, 0], [0, 1]]}]
2024-09-10 12:51:54,763 - src.data.arc_dataset - DEBUG - Initializing ARCDataset with data_source type: <class 'list'>
2024-09-10 12:51:54,763 - src.data.arc_dataset - DEBUG - Processing list data
2024-09-10 12:51:54,763 - src.data.arc_dataset - DEBUG - Number of tasks: 2
2024-09-10 12:51:54,763 - src.data.arc_dataset - DEBUG - First task structure: dict_keys(['train', 'test'])
2024-09-10 12:51:54,763 - src.data.arc_dataset - DEBUG - First train sample structure: dict_keys(['input', 'output'])
2024-09-10 12:51:54,763 - src.data.arc_dataset - DEBUG - First train input shape: (2, 2)
2024-09-10 12:51:54,763 - src.data.arc_dataset - DEBUG - test_split set to: 0.2
2024-09-10 12:51:54,763 - src.data.arc_dataset - DEBUG - Computed max grid size: (2, 2)
2024-09-10 12:51:54,763 - src.data.arc_dataset - DEBUG - Total samples in dataset: 2
2024-09-10 12:51:54,763 - src.data.arc_dataset - DEBUG - Total samples in dataset: 2
2024-09-10 12:51:54,763 - src.data.arc_dataset - DEBUG - Total samples in dataset: 2
2024-09-10 12:51:54,763 - src.data.arc_dataset - DEBUG - Original grid shape: (2, 2)
2024-09-10 12:51:54,782 - src.data.arc_dataset - DEBUG - Original grid content:
[[1 0]
 [0 1]]
2024-09-10 12:51:55,100 - src.data.arc_dataset - DEBUG - Preprocessed grid shape: torch.Size([1, 30, 30])
2024-09-10 12:51:55,473 - src.data.arc_dataset - DEBUG - Preprocessed grid content:
tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])
2024-09-10 12:51:55,473 - src.data.arc_dataset - DEBUG - Original grid shape: (2, 2)
2024-09-10 12:51:55,473 - src.data.arc_dataset - DEBUG - Original grid content:
[[0 1]
 [1 0]]
2024-09-10 12:51:55,473 - src.data.arc_dataset - DEBUG - Preprocessed grid shape: torch.Size([1, 30, 30])
2024-09-10 12:51:55,474 - src.data.arc_dataset - DEBUG - Preprocessed grid content:
tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])
2024-09-10 12:51:55,474 - src.data.arc_dataset - DEBUG - __getitem__ input dtype: torch.float32, output dtype: torch.float32
2024-09-10 12:51:55,530 - src.data.arc_dataset - DEBUG - ARCDataset.__init__ called with data_source: [{'input': [[1, 0], [0, 1]], 'output': [[0, 1], [1, 0]]}, {'input': [[0, 1], [1, 0]], 'output': [[1, 0], [0, 1]]}]
Number of train samples: 2
Number of test samples: 0
Number of train samples: 2
Number of test samples: 0
PASSED
tests/test_arc_dataset.py::test_arc_dataset_synthetic_data SKIPPED (...)
tests/test_arc_dataset.py::test_arc_dataset_getitem Number of train samples: 2
Number of test samples: 0
PASSED
tests/test_arc_dataset.py::test_arc_dataset_len Debugging: Entering test_arc_dataset_len
Debugging: sample_data = [{'input': [[1, 0], [0, 1]], 'output': [[0, 1], [1, 0]]}, {'input': [[0, 1], [1, 0]], 'output': [[1, 0], [0, 1]]}]
Number of train samples: 2
Number of test samples: 0
Debugging: len(dataset) = 2, len(sample_data) = 2
Debugging: Exiting test_arc_dataset_len
PASSED
tests/test_arc_dataset.py::test_arc_dataset_invalid_data Number of train samples: 1
Number of test samples: 0
Number of train samples: 1
Number of test samples: 0
PASSED
tests/test_arc_dataset.py::test_arc_dataset_preprocess_grid Number of train samples: 2
Number of test samples: 0
Input grid shape: torch.Size([1, 30, 30])
Output grid shape: torch.Size([1, 30, 30])
Input grid content:
tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])
Output grid content:
tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])
Expected input:
tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])
Expected output:
tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])
PASSED
tests/test_arc_dataset.py::test_arc_dataset_taskset_initialization SKIPPED
tests/test_arc_dataset.py::test_arc_dataset_collate_fn Number of train samples: 2
Number of test samples: 0
PASSED
tests/test_arc_dataset.py::test_arc_dataset_variable_size_grids Number of train samples: 3
Number of test samples: 0
PASSED
tests/test_end_to_end.py::test_end_to_end Number of train samples: 1302
Number of test samples: 416
Initial validation accuracy: 0.008444445207715034, Initial loss: 4.562187194824219
Final validation accuracy: 0.8517009019851685, Final loss: 1.0906503200531006
PASSED
tests/test_gpt2.py::test_gpt2arc_initialization PASSED
tests/test_gpt2.py::test_gpt2arc_forward_pass PASSED
tests/test_gpt2.py::test_gpt2arc_output_values PASSED
tests/test_gpt2.py::test_attention_module PASSED
tests/test_gpt2.py::test_feedforward_module PASSED
tests/test_gpt2.py::test_transformer_block PASSED
tests/test_train.py::test_gpt2arc_initialization PASSED
tests/test_train.py::test_gpt2arc_forward_pass PASSED
tests/test_train.py::test_gpt2arc_output_values PASSED
tests/test_train.py::test_gpt2arc_attention_mask PASSED
tests/test_train.py::test_logging Entering test_logging
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
PASSED
tests/test_train.py::test_fit_call Entering test_fit_call
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
PASSED
tests/test_train.py::test_data_loading PASSED
tests/test_train.py::test_trainer_initialization PASSED
tests/test_train.py::test_batch_size_extremes[1] Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
PASSED
tests/test_train.py::test_batch_size_extremes[1000000] Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
PASSED
tests/test_train.py::test_learning_rate_extremes[1e-10] Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
PASSED
tests/test_train.py::test_learning_rate_extremes[1000] Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
PASSED
tests/test_train.py::test_non_existent_train_data PASSED
tests/test_train.py::test_gpu_not_available Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
PASSED
tests/test_train.py::test_valid_batch_sizes Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
PASSED
tests/test_train.py::test_valid_learning_rates Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
PASSED
tests/test_train.py::test_end_to_end_training Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
PASSED
tests/test_train.py::test_tensorboard_logging Data loaded successfully
Initializing model with new configuration
Initializing trainer with new configuration
PASSED
tests/test_train.py::test_arctrainer_forward_pass PASSED
tests/test_train.py::test_arctrainer_training_step PASSED
tests/test_train.py::test_arctrainer_batch_format[tuple] PASSED
tests/test_train.py::test_arctrainer_batch_format[dict] PASSED
tests/test_trainer.py::test_arctrainer_initialization Number of train samples: 2
Number of test samples: 0
Number of train samples: 2
Number of test samples: 0
PASSED
tests/test_trainer.py::test_arctrainer_forward_pass Number of train samples: 2
Number of test samples: 0
Number of train samples: 2
Number of test samples: 0
PASSED
tests/test_trainer.py::test_arctrainer_training_step[tuple] Number of train samples: 2
Number of test samples: 0
Number of train samples: 2
Number of test samples: 0
PASSED
tests/test_trainer.py::test_arctrainer_training_step[dict] Number of train samples: 2
Number of test samples: 0
Number of train samples: 2
Number of test samples: 0
PASSED
tests/test_trainer.py::test_arctrainer_validation_step[tuple] Number of train samples: 2
Number of test samples: 0
Number of train samples: 2
Number of test samples: 0
PASSED
tests/test_trainer.py::test_arctrainer_validation_step[dict] Number of train samples: 2
Number of test samples: 0
Number of train samples: 2
Number of test samples: 0
PASSED
tests/test_trainer.py::test_arctrainer_configure_optimizers Number of train samples: 2
Number of test samples: 0
Number of train samples: 2
Number of test samples: 0
PASSED
tests/test_trainer.py::test_arctrainer_train_dataloader Number of train samples: 2
Number of test samples: 0
Number of train samples: 2
Number of test samples: 0
PASSED
tests/test_trainer.py::test_arctrainer_val_dataloader Number of train samples: 2
Number of test samples: 0
Number of train samples: 2
Number of test samples: 0
PASSED

=============================== warnings summary ===============================
gpt2_arc/tests/test_end_to_end.py::test_end_to_end
  /Volumes/Totallynotaharddrive/arc-neural-reasoning-model/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.

gpt2_arc/tests/test_end_to_end.py::test_end_to_end
  /Volumes/Totallynotaharddrive/arc-neural-reasoning-model/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.

gpt2_arc/tests/test_end_to_end.py::test_end_to_end
  /Volumes/Totallynotaharddrive/arc-neural-reasoning-model/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.

gpt2_arc/tests/test_train.py::test_arctrainer_training_step
gpt2_arc/tests/test_train.py::test_arctrainer_batch_format[tuple]
gpt2_arc/tests/test_train.py::test_arctrainer_batch_format[dict]
gpt2_arc/tests/test_trainer.py::test_arctrainer_training_step[tuple]
gpt2_arc/tests/test_trainer.py::test_arctrainer_training_step[dict]
gpt2_arc/tests/test_trainer.py::test_arctrainer_validation_step[tuple]
gpt2_arc/tests/test_trainer.py::test_arctrainer_validation_step[dict]
  /Volumes/Totallynotaharddrive/arc-neural-reasoning-model/.venv/lib/python3.12/site-packages/pytorch_lightning/core/module.py:445: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html

---------- coverage: platform darwin, python 3.12.5-final-0 ----------
Name                    Stmts   Miss  Cover   Missing
-----------------------------------------------------
src/training/train.py      42     12    71%   66-97
-----------------------------------------------------
TOTAL                      42     12    71%

=========================== short test summary info ============================
SKIPPED [1] tests/test_arc_dataset.py:92: Skipping test for synthetic data because test is problematic
SKIPPED [1] tests/test_arc_dataset.py:234: Skipping because test is problematic
============ 45 passed, 2 skipped, 10 warnings in 63.56s (0:01:03) =============

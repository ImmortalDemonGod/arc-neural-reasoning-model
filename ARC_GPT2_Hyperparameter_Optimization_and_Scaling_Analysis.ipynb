{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8-QMJgz1LmwE",
      "metadata": {
        "id": "8-QMJgz1LmwE"
      },
      "outputs": [],
      "source": [
        "#Required: https://youtu.be/IDxrMbXPVTA?si=PHfGry-HQj__3Xne\n",
        "# https://ngrok.com/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0L9IwEdxzd-H",
      "metadata": {
        "id": "0L9IwEdxzd-H"
      },
      "source": [
        "# STUFF YOU CHANGE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6okItopOumX_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6okItopOumX_",
        "outputId": "44391386-b0da-4dee-e405-e4fb2f621a4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parent Directory: /content/drive/MyDrive/ArcGPT/\n",
            "ARC Model Directory: /content/arc-neural-reasoning-model/\n",
            "Manual parameters validated successfully\n",
            "Current Configuration:\n",
            "Parent Directory: /content/drive/MyDrive/ArcGPT/\n",
            "Use Best Parameters: True\n",
            "Manual Parameters: {'n_embd': 4, 'n_head': 4, 'n_layer': 5, 'batch_size': 15, 'learning_rate': 0.005936106784234055, 'max_epochs': 50}\n",
            "Number of Optuna Trials: 100\n",
            "Hyperparameter Ranges:\n",
            "  n_embd: 64 to 4096\n",
            "  n_head: 2 to 16\n",
            "  n_layer: 2 to 16\n",
            "  batch_size: 1 to 40\n",
            "  learning_rate: 0.0001 to 0.1\n",
            "  max_epochs: 15 to 40\n",
            "\n",
            "GPU Available: False\n"
          ]
        }
      ],
      "source": [
        "# ========== User-Defined Parameters (Top of Notebook) ==========\n",
        "\n",
        "dev_mode = True  # Set to True for development mode (Miguel's coding machine)\n",
        "\n",
        "\n",
        "# Replace with your actual authtoken\n",
        "ngrok_auth_token = \"2NCEuxuUBMj6zsdTokQHkYJ4AZz_3E7e2pyW87otgFg3UdSC3\"\n",
        "\n",
        "# 1. Base directory for storing date-based experiment result folders.\n",
        "import os\n",
        "\n",
        "# Define the base directory for the arc-neural-reasoning-model\n",
        "arc_model_dir = \"/content/arc-neural-reasoning-model/\"\n",
        "parent_dir = \"/content/drive/MyDrive/ArcGPT/\"\n",
        "#parent_dir = \"/content/\"\n",
        "print(f\"Parent Directory: {parent_dir}\")\n",
        "print(f\"ARC Model Directory: {arc_model_dir}\")\n",
        "\n",
        "# 2. Boolean flag to choose between best hyperparameters from previous experiments (True) or manual parameters (False).\n",
        "use_best_params = True  # Set to False to use manual parameters\n",
        "perform_hyperparameter_tuning = True  # Set to True to perform hyperparameter tuning\n",
        "\n",
        "# 3. Dictionary of manually set hyperparameters used when use_best_params is False.\n",
        "#    Includes model architecture and training settings.\n",
        "manual_params = {\n",
        "    \"n_embd\": 4,     # Embedding dimension\n",
        "    \"n_head\": 4,       # Number of attention heads\n",
        "    \"n_layer\": 5,     # Number of transformer layers\n",
        "    \"batch_size\": 15,  # Batch size for training\n",
        "    \"learning_rate\": 0.005936106784234055,  # Learning rate\n",
        "    \"max_epochs\": 50   # Maximum number of epochs for training\n",
        "}\n",
        "\n",
        "# Hyperparameter tuning search space settings\n",
        "# 4. Number of Optuna trials for hyperparameter tuning.\n",
        "#    More trials can lead to better optimization but increase computation time.\n",
        "n_trials = 100\n",
        "\n",
        "# 5. Range for embedding dimension in hyperparameter search space.\n",
        "n_embd_min, n_embd_max = 64, 4096\n",
        "\n",
        "# 6. Range for number of attention heads in transformer model during tuning.\n",
        "n_head_min, n_head_max = 2, 16\n",
        "\n",
        "# 7. Range for number of transformer layers in model architecture during optimization.\n",
        "n_layer_min, n_layer_max = 2, 16\n",
        "\n",
        "# 8. Range of batch sizes to explore. Larger batches can speed up training but may require more memory.\n",
        "batch_size_min, batch_size_max = 1, 40\n",
        "\n",
        "# 9. Range for learning rate in hyperparameter search space. Crucial for model convergence and performance.\n",
        "learning_rate_min, learning_rate_max = 1e-4, 1e-1\n",
        "\n",
        "# 10. Range for number of training epochs to consider during hyperparameter optimization.\n",
        "max_epochs_min, max_epochs_max = 15, 40\n",
        "\n",
        "# 11. Range for n_head exponent in hyperparameter search space.\n",
        "n_head_exp_min, n_head_exp_max = 1, 10\n",
        "\n",
        "# 12. Range for n_embd multiplier in hyperparameter search space.\n",
        "n_embd_multiplier_min, n_embd_multiplier_max = 4, 256\n",
        "\n",
        "# These parameters allow flexible experimentation with different model configurations and training settings,\n",
        "# enabling comprehensive exploration of the hyperparameter space for optimal model performance.\n",
        "\n",
        "# Validate manual parameters\n",
        "def validate_manual_params(params):\n",
        "    assert params[\"n_embd\"] % params[\"n_head\"] == 0, f\"n_embd ({params['n_embd']}) must be divisible by n_head ({params['n_head']})\"\n",
        "    assert params[\"n_embd\"] >= params[\"n_head\"], f\"n_embd ({params['n_embd']}) must be greater than or equal to n_head ({params['n_head']})\"\n",
        "    assert params[\"n_layer\"] > 0, f\"n_layer ({params['n_layer']}) must be positive\"\n",
        "    print(\"Manual parameters validated successfully\")\n",
        "\n",
        "\n",
        "# Validate the manual parameters\n",
        "validate_manual_params(manual_params)\n",
        "\n",
        "# Print configurations for verification\n",
        "print(\"Current Configuration:\")\n",
        "print(f\"Parent Directory: {parent_dir}\")\n",
        "print(f\"Use Best Parameters: {use_best_params}\")\n",
        "print(f\"Manual Parameters: {manual_params}\")\n",
        "print(f\"Number of Optuna Trials: {n_trials}\")\n",
        "print(\"Hyperparameter Ranges:\")\n",
        "print(f\"  n_embd: {n_embd_min} to {n_embd_max}\")\n",
        "print(f\"  n_head: {n_head_min} to {n_head_max}\")\n",
        "print(f\"  n_layer: {n_layer_min} to {n_layer_max}\")\n",
        "print(f\"  batch_size: {batch_size_min} to {batch_size_max}\")\n",
        "print(f\"  learning_rate: {learning_rate_min} to {learning_rate_max}\")\n",
        "print(f\"  max_epochs: {max_epochs_min} to {max_epochs_max}\")\n",
        "\n",
        "# Save configuration\n",
        "import json\n",
        "\n",
        "def save_config(config, filename=\"config.json\"):\n",
        "    full_path = os.path.join(parent_dir, filename)\n",
        "    os.makedirs(parent_dir, exist_ok=True)\n",
        "    with open(full_path, 'w') as f:\n",
        "        json.dump(config, f, indent=4)\n",
        "\n",
        "config = {\n",
        "    \"parent_dir\": parent_dir,\n",
        "    \"use_best_params\": use_best_params,\n",
        "    \"manual_params\": manual_params,\n",
        "    \"tuning\": {\n",
        "        \"n_trials\": n_trials,\n",
        "        \"n_embd\": (n_embd_min, n_embd_max),\n",
        "        \"n_head\": (n_head_min, n_head_max),\n",
        "        \"n_layer\": (n_layer_min, n_layer_max),\n",
        "        \"batch_size\": (batch_size_min, batch_size_max),\n",
        "        \"learning_rate\": (learning_rate_min, learning_rate_max),\n",
        "        \"max_epochs\": (max_epochs_min, max_epochs_max)\n",
        "    }\n",
        "}\n",
        "\n",
        "# Check GPU availability\n",
        "import torch\n",
        "print(\"\\nGPU Available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU Name:\", torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2-qicsswzi-S",
      "metadata": {
        "id": "2-qicsswzi-S"
      },
      "source": [
        "# CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DgxlLFBTg8Kt",
      "metadata": {
        "id": "DgxlLFBTg8Kt"
      },
      "source": [
        "### 1. Set up the Colab environment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "u8k0Yxzd4RCb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "u8k0Yxzd4RCb",
        "outputId": "e77118cc-921d-4b4d-f4b4-8fb0a72aabda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Development mode is enabled. Using Miguel's coding machine.\n",
            "[Errno 2] No such file or directory: '/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/'\n",
            "/workspaces/arc-neural-reasoning-model\n",
            "Configuration saved to config.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/codespace/.local/lib/python3.12/site-packages/IPython/core/magics/osm.py:393: UserWarning: This is now an optional IPython functionality, using bookmarks requires you to install the `pickleshare` library.\n",
            "  bkms = self.shell.db.get('bookmarks', {})\n"
          ]
        }
      ],
      "source": [
        "if dev_mode != True:\n",
        "    print(\"Setting up Colab environment...\")\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "        save_config(config)\n",
        "        print(f\"Configuration saved to config.json\")\n",
        "\n",
        "    #general error\n",
        "    except:\n",
        "        print(\"Google Colab not detected. Skipping drive mount.\")\n",
        "\n",
        "    %cd /content/\n",
        "    !rm -rf /content/arc-neural-reasoning-model/\n",
        "    !git clone https://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@github.com/ImmortalDemonGod/arc-neural-reasoning-model.git\n",
        "    !pip install -r /content/arc-neural-reasoning-model/gpt2_arc/requirements.txt\n",
        "    !pip install optuna\n",
        "    !pip install torchsummary\n",
        "    !pip install jupyterlab jupyterlab-optuna\n",
        "    # Install the required packages\n",
        "    !pip install optuna-dashboard pyngrok\n",
        "    #!ngrok config add-authtoken 2NCEuxuUBMj6zsdTokQHkYJ4AZz_3E7e2pyW87otgFg3UdSC3\n",
        "    !pip install tensorboard\n",
        "    !pip install watchdog\n",
        "    !pip install numpy\n",
        "    !pip install --upgrade jax jaxlib torch pytorch_lightning\n",
        "    #!pip uninstall tensorflow -y\n",
        "    #!find . -type d -name \"__pycache__\" -exec rm -r {} +\n",
        "    !rm -rf /tmp/libtpu_lockfile\n",
        "    !rm -rf /content/arc-neural-reasoning-model/arc_sat_solver\n",
        "    !rm -rf /content/arc-neural-reasoning-model/benchmark_results\n",
        "    !rm -rf /content/arc-neural-reasoning-model/checkpoints\n",
        "    !rm -rf /content/arc-neural-reasoning-model/tmp\n",
        "    %cd /content/arc-neural-reasoning-model/\n",
        "    !pip install -e .\n",
        "else:\n",
        "    print(\"Development mode is enabled. Using Miguel's coding machine.\")\n",
        "    arc_model_dir = \"/workspaces/arc-neural-reasoning-model/\"\n",
        "    parent_dir = \"/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/\"\n",
        "    %cd /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/\n",
        "    save_config(config)\n",
        "    print(f\"Configuration saved to config.json\")\n",
        "\n",
        "# Setup ngrok for remote access (ensure you have your authtoken configured)\n",
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(ngrok_auth_token)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Iz4dsrstg8Ku",
      "metadata": {
        "id": "Iz4dsrstg8Ku"
      },
      "source": [
        "### 2. Run hyperparameter tuning (in the background) click the **links** to see the dashboards:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6zIQhT9m9_wv",
      "metadata": {
        "id": "6zIQhT9m9_wv"
      },
      "source": [
        "make sure to set the directory in your drive to save the files in"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "DVIRPnKcPV92",
      "metadata": {
        "id": "DVIRPnKcPV92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/codespace/.local/lib/python3.12/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
            "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Get the current date in YYYYMMDD format\n",
        "current_date = datetime.now().strftime('%Y%m%d')\n",
        "\n",
        "\n",
        "# Create a folder named after the current date\n",
        "date_folder = os.path.join(parent_dir, current_date)\n",
        "if not os.path.exists(date_folder):\n",
        "    os.makedirs(date_folder)\n",
        "\n",
        "# Change into the newly created folder\n",
        "%cd {date_folder}\n",
        "\n",
        "# Now all your operations will save to /content/YYYYMMDD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sV0auRJ4OojK",
      "metadata": {
        "id": "sV0auRJ4OojK"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import os\n",
        "import time\n",
        "from pyngrok import ngrok\n",
        "from datetime import datetime\n",
        "import sys\n",
        "\n",
        "# Install TensorBoard if not already installed\n",
        "!pip install tensorboard\n",
        "\n",
        "# Function to kill processes by name\n",
        "def kill_process_by_name(process_name):\n",
        "    try:\n",
        "        # Find and kill the process using pkill (Linux/Unix/Mac) or taskkill (Windows)\n",
        "        if os.name == \"posix\":  # For Unix-based systems\n",
        "            subprocess.run([\"pkill\", \"-f\", process_name], check=True)\n",
        "        elif os.name == \"nt\":  # For Windows systems\n",
        "            subprocess.run([\"taskkill\", \"/IM\", process_name, \"/F\"], check=True)\n",
        "        print(f\"Successfully terminated any running {process_name} processes.\")\n",
        "    except subprocess.CalledProcessError:\n",
        "        print(f\"No {process_name} processes were found running.\")\n",
        "\n",
        "# Kill existing Optuna, TensorBoard, and ngrok processes\n",
        "kill_process_by_name(\"tensorboard\")\n",
        "kill_process_by_name(\"ngrok\")\n",
        "kill_process_by_name(\"optuna-dashboard\")\n",
        "\n",
        "# Start ngrok tunnel for TensorBoard\n",
        "print(\"Setting up ngrok tunnel for TensorBoard...\")\n",
        "public_url_tb = ngrok.connect(6006)\n",
        "print(f\"TensorBoard ngrok tunnel is accessible at: {public_url_tb}\")\n",
        "\n",
        "# Start ngrok tunnel for Optuna dashboard\n",
        "print(\"Setting up ngrok tunnel for Optuna dashboard...\")\n",
        "public_url_optuna = ngrok.connect(8081)\n",
        "print(f\"Optuna dashboard ngrok tunnel is accessible at: {public_url_optuna}\")\n",
        "\n",
        "# Define the log directory\n",
        "log_dir = os.path.join(date_folder, \"runs\")\n",
        "os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "# Now run TensorBoard in the background using Python module execution\n",
        "# Use 'tensorboard.main' to correctly invoke TensorBoard\n",
        "tensorboard_command = [\n",
        "    sys.executable, \"-m\", \"tensorboard.main\", \"--logdir\", log_dir, \"--port\", \"6006\"\n",
        "]\n",
        "print(\"Starting TensorBoard...\")\n",
        "subprocess.Popen(tensorboard_command)  # Run TensorBoard without blocking\n",
        "\n",
        "# Wait for TensorBoard to start\n",
        "time.sleep(10)\n",
        "\n",
        "print(\"\\nAll processes launched successfully. You can access them via ngrok URLs:\")\n",
        "print(f\"📊 TensorBoard: {public_url_tb}\")\n",
        "print(f\"📈 Optuna Dashboard: {public_url_optuna}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wV89eu4FipY8",
      "metadata": {
        "id": "wV89eu4FipY8"
      },
      "outputs": [],
      "source": [
        "if perform_hyperparameter_tuning:\n",
        "    print(\"Searching for best hyperparameters...\")\n",
        "    # Run the optimization command in a separate subprocess (so it's non-blocking too, if desired)\n",
        "    print(\"Starting hyperparameter tuning...\")\n",
        "    optimize_command = [\n",
        "        \"python\", os.path.join(arc_model_dir, \"gpt2_arc/src/optimize_hyperparameters.py\"),\n",
        "        \"--n_trials\", str(n_trials),\n",
        "        \"--storage\", f\"sqlite:///{date_folder}/optuna_results.db\",\n",
        "        \"--n_jobs\", \"1\",  # Use all available cores\n",
        "        \"--n_embd_min\", str(n_embd_min), \"--n_embd_max\", str(n_embd_max),\n",
        "        \"--n_head_min\", str(n_head_min), \"--n_head_max\", str(n_head_max),\n",
        "        \"--n_layer_min\", str(n_layer_min), \"--n_layer_max\", str(n_layer_max),\n",
        "        \"--batch_size_min\", str(batch_size_min), \"--batch_size_max\", str(batch_size_max),\n",
        "        \"--learning_rate_min\", str(learning_rate_min), \"--learning_rate_max\", str(learning_rate_max),\n",
        "        \"--max_epochs_min\", str(max_epochs_min), \"--max_epochs_max\", str(max_epochs_max),\n",
        "        \"--n_head_exp_min\", str(n_head_exp_min), \"--n_head_exp_max\", str(n_head_exp_max),\n",
        "        \"--n_embd_multiplier_min\", str(n_embd_multiplier_min), \"--n_embd_multiplier_max\",\n",
        "    str(n_embd_multiplier_max)\n",
        "    ]\n",
        "    subprocess.Popen(optimize_command)\n",
        "\n",
        "    # Start the Optuna dashboard after the optimization begins\n",
        "    print(\"Starting Optuna dashboard...\")\n",
        "    optuna_command = [\n",
        "        \"optuna-dashboard\", \"--port\", \"8081\", f\"sqlite:///{date_folder}/optuna_results.db\"\n",
        "    ]\n",
        "    subprocess.Popen(optuna_command)\n",
        "\n",
        "    print(\"All processes launched successfully. You can access them via ngrok URLs.\")\n",
        "else:\n",
        "    print(\"Hyperparameter tuning not performed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gb75DkIFg8Kw",
      "metadata": {
        "id": "gb75DkIFg8Kw"
      },
      "source": [
        "### 3. Get the best hyperparameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "fda44504",
      "metadata": {
        "id": "fda44504"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Storage Name: sqlite:////workspaces/arc-neural-reasoning-model/optuna_results.db\n",
            "Study Name: gpt2_arc_optimization\n",
            "Available studies in the database:\n",
            "- gpt2_arc_optimization\n",
            "Best hyperparameters:\n",
            "{\n",
            "  \"n_head_exp\": 2,\n",
            "  \"n_embd_multiplier\": 91,\n",
            "  \"n_layer\": 2,\n",
            "  \"batch_size\": 21,\n",
            "  \"learning_rate\": 0.0044446551952796705,\n",
            "  \"max_epochs\": 5\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "import numpy as np\n",
        "\n",
        "# Set Optuna storage and study details\n",
        "#storage_name = f\"sqlite:///{date_folder}/optuna_results.db\"\n",
        "storage_name = \"sqlite:////workspaces/arc-neural-reasoning-model/optuna_results.db\"\n",
        "study_name = \"gpt2_arc_optimization\"\n",
        "print(f\"Storage Name: {storage_name}\")\n",
        "print(f\"Study Name: {study_name}\")\n",
        "\n",
        "if use_best_params:\n",
        "    try:\n",
        "        # List all study names in the database\n",
        "        study_summaries = optuna.study.get_all_study_summaries(storage=storage_name)\n",
        "        print(\"Available studies in the database:\")\n",
        "        for study_summary in study_summaries:\n",
        "            print(f\"- {study_summary.study_name}\")\n",
        "\n",
        "        # Load the specified study\n",
        "        study = optuna.load_study(study_name=study_name, storage=storage_name)\n",
        "        best_params = study.best_params\n",
        "        print(\"Best hyperparameters:\")\n",
        "        print(json.dumps(best_params, indent=2))\n",
        "\n",
        "        # Save the best parameters to a JSON file\n",
        "        with open(f\"{date_folder}/best_hyperparameters.json\", \"w\") as f:\n",
        "            json.dump(best_params, f)\n",
        "\n",
        "    except KeyError as e:\n",
        "        print(\"Error: The specified study does not exist in the database. Please ensure that the study name and storage path are correct.\")\n",
        "        print(f\"Details: {str(e)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5062c297",
      "metadata": {
        "id": "5062c297"
      },
      "source": [
        "### 4. Setup Evaluation of the trained model in the background:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "0pwrd3HMBnhW",
      "metadata": {
        "id": "0pwrd3HMBnhW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "arc_model_dir is set to: /workspaces/arc-neural-reasoning-model/\n",
            "Watching for new models in directory: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "No previously evaluated models found. Starting fresh.\n",
            "Background checkpoint observer started.\n",
            "Watching for new checkpoints and final models in all subdirectories...\n",
            "This script will continue running in the background.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: []\n",
            "Current models: set()\n",
            "New models to evaluate: set()\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: []\n",
            "Current models: set()\n",
            "New models to evaluate: set()\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: []\n",
            "Current models: set()\n",
            "New models to evaluate: set()\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: []\n",
            "Current models: set()\n",
            "New models to evaluate: set()\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: []\n",
            "Current models: set()\n",
            "New models to evaluate: set()\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: []\n",
            "Current models: set()\n",
            "New models to evaluate: set()\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: []\n",
            "Current models: set()\n",
            "New models to evaluate: set()\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: []\n",
            "Current models: set()\n",
            "New models to evaluate: set()\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: []\n",
            "Current models: set()\n",
            "New models to evaluate: set()\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: []\n",
            "Current models: set()\n",
            "New models to evaluate: set()\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: []\n",
            "Current models: set()\n",
            "New models to evaluate: set()\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: []\n",
            "Current models: set()\n",
            "New models to evaluate: set()\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: []\n",
            "Current models: set()\n",
            "New models to evaluate: set()\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: []\n",
            "Current models: set()\n",
            "New models to evaluate: set()\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: []\n",
            "Current models: set()\n",
            "New models to evaluate: set()\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: []\n",
            "Current models: set()\n",
            "New models to evaluate: set()\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: []\n",
            "Current models: set()\n",
            "New models to evaluate: set()\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: []\n",
            "Current models: set()\n",
            "New models to evaluate: set()\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: []\n",
            "Current models: set()\n",
            "New models to evaluate: set()\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: []\n",
            "Current models: set()\n",
            "New models to evaluate: set()\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: []\n",
            "Current models: set()\n",
            "New models to evaluate: set()\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: []\n",
            "Current models: set()\n",
            "New models to evaluate: set()\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: []\n",
            "Current models: set()\n",
            "New models to evaluate: set()\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: []\n",
            "Current models: set()\n",
            "New models to evaluate: set()\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: []\n",
            "Current models: set()\n",
            "New models to evaluate: set()\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: []\n",
            "Current models: set()\n",
            "New models to evaluate: set()\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: []\n",
            "Current models: set()\n",
            "New models to evaluate: set()\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: []\n",
            "Current models: set()\n",
            "New models to evaluate: set()\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: []\n",
            "Current models: set()\n",
            "New models to evaluate: set()\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: []\n",
            "Current models: set()\n",
            "New models to evaluate: set()\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: []\n",
            "Current models: set()\n",
            "New models to evaluate: set()\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: []\n",
            "Current models: set()\n",
            "New models to evaluate: set()\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: []\n",
            "Current models: set()\n",
            "New models to evaluate: set()\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: []\n",
            "Current models: set()\n",
            "New models to evaluate: set()\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: []\n",
            "Current models: set()\n",
            "New models to evaluate: set()\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: []\n",
            "Current models: set()\n",
            "New models to evaluate: set()\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: ['/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt']\n",
            "Current models: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "New models to evaluate: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "Evaluating model: arc_model-epoch=00-val_loss=0.37.ckpt with command: python /workspaces/arc-neural-reasoning-model/gpt2_arc/src/evaluate.py --model_checkpoint /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt --batch_size 32 --output_dir evaluation_results --wandb_project arc-evaluation --wandb_run_name scaling-test-evaluation-epoch00-val_loss0.37\n",
            "Successfully evaluated model: arc_model-epoch=00-val_loss=0.37.ckpt\n",
            "Evaluation Output:\n",
            "DEBUG: Attempting to generate model summary\n",
            "DEBUG: Model summary generated successfully\n",
            "DEBUG: Model summary:\n",
            "   | Name                        | Type             | Params | Mode\n",
            "-------------------------------------------------------------------------\n",
            "0  | conv1                       | Conv2d           | 2.6 K  | eval\n",
            "1  | blocks                      | ModuleList       | 1.6 M  | eval\n",
            "2  | blocks.0                    | TransformerBlock | 789 K  | eval\n",
            "3  | blocks.0.attention          | Attention        | 263 K  | eval\n",
            "4  | blocks.0.attention.key      | Linear           | 65.8 K | eval\n",
            "5  | blocks.0.attention.query    | Linear           | 65.8 K | eval\n",
            "6  | blocks.0.attention.value    | Linear           | 65.8 K | eval\n",
            "7  | blocks.0.attention.proj     | Linear           | 65.8 K | eval\n",
            "8  | blocks.0.feed_forward       | FeedForward      | 525 K  | eval\n",
            "9  | blocks.0.feed_forward.net   | Sequential       | 525 K  | eval\n",
            "10 | blocks.0.feed_forward.net.0 | Linear           | 263 K  | eval\n",
            "11 | blocks.0.feed_forward.net.1 | ReLU             | 0      | eval\n",
            "12 | blocks.0.feed_forward.net.2 | Linear           | 262 K  | eval\n",
            "13 | blocks.0.ln1                | LayerNorm        | 512    | eval\n",
            "14 | blocks.0.ln2                | LayerNorm        | 512    | eval\n",
            "15 | blocks.1                    | TransformerBlock | 789 K  | eval\n",
            "16 | blocks.1.attention          | Attention        | 263 K  | eval\n",
            "17 | blocks.1.attention.key      | Linear           | 65.8 K | eval\n",
            "18 | blocks.1.attention.query    | Linear           | 65.8 K | eval\n",
            "19 | blocks.1.attention.value    | Linear           | 65.8 K | eval\n",
            "20 | blocks.1.attention.proj     | Linear           | 65.8 K | eval\n",
            "21 | blocks.1.feed_forward       | FeedForward      | 525 K  | eval\n",
            "22 | blocks.1.feed_forward.net   | Sequential       | 525 K  | eval\n",
            "23 | blocks.1.feed_forward.net.0 | Linear           | 263 K  | eval\n",
            "24 | blocks.1.feed_forward.net.1 | ReLU             | 0      | eval\n",
            "25 | blocks.1.feed_forward.net.2 | Linear           | 262 K  | eval\n",
            "26 | blocks.1.ln1                | LayerNorm        | 512    | eval\n",
            "27 | blocks.1.ln2                | LayerNorm        | 512    | eval\n",
            "28 | ln_f                        | LayerNorm        | 512    | eval\n",
            "29 | fc_out                      | Linear           | 2.6 K  | eval\n",
            "-------------------------------------------------------------------------\n",
            "1.6 M     Trainable params\n",
            "0         Non-trainable params\n",
            "1.6 M     Total params\n",
            "6.341     Total estimated model params size (MB)\n",
            "0         Modules in train mode\n",
            "30        Modules in eval mode\n",
            "DEBUG: Sanitized model_name: arc_model-epoch_00-val_loss_0\n",
            "DEBUG: Model name contains only valid characters.\n",
            "DEBUG: Initialized self.results['train'] as <class 'dict'>\n",
            "\n",
            "Testing: |          | 0/? [00:00<?, ?it/s]\n",
            "Testing:   0%|          | 0/43 [00:00<?, ?it/s]\n",
            "Testing DataLoader 0:   0%|          | 0/43 [00:00<?, ?it/s]DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9666666388511658\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 35\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.14285714285714285\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9844444394111633\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.3\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9733333587646484\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 29\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.1724137931034483\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9655555486679077\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 37\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.16216216216216217\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 22\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.2727272727272727\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9722222089767456\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.945555567741394\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8822222352027893\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 56\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9177777767181396\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 32\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9833333492279053\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 33\n",
            "Correctly predicted different pixels: 18\n",
            "Calculated accuracy: 0.5454545454545454\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 42\n",
            "Correctly predicted different pixels: 22\n",
            "Calculated accuracy: 0.5238095238095238\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 39\n",
            "Correctly predicted different pixels: 19\n",
            "Calculated accuracy: 0.48717948717948717\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6611111164093018\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 247\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6922222375869751\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 208\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6166666746139526\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 285\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.800000011920929\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 39\n",
            "Correctly predicted different pixels: 26\n",
            "Calculated accuracy: 0.6666666666666666\n",
            "DEBUG: compute_accuracy - Accuracy: 0.75\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 52\n",
            "Correctly predicted different pixels: 32\n",
            "Calculated accuracy: 0.6153846153846154\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8399999737739563\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 43\n",
            "Correctly predicted different pixels: 30\n",
            "Calculated accuracy: 0.6976744186046512\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 25\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.2\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 3\n",
            "Calculated accuracy: 0.14285714285714285\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.16666666666666666\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9544444680213928\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 31\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9677777886390686\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 19\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 2\n",
            "Calculated accuracy: 0.09523809523809523\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 28\n",
            "Correctly predicted different pixels: 2\n",
            "Calculated accuracy: 0.07142857142857142\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9399999976158142\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 55\n",
            "Correctly predicted different pixels: 2\n",
            "Calculated accuracy: 0.03636363636363636\n",
            "DEBUG: compute_accuracy - Accuracy: 0.47777777910232544\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 897\n",
            "Correctly predicted different pixels: 429\n",
            "Calculated accuracy: 0.4782608695652174\n",
            "DEBUG: compute_accuracy - Accuracy: 0.4333333373069763\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 896\n",
            "Correctly predicted different pixels: 390\n",
            "Calculated accuracy: 0.43526785714285715\n",
            "DEBUG: compute_accuracy - Accuracy: 0.2988888919353485\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 896\n",
            "Correctly predicted different pixels: 269\n",
            "Calculated accuracy: 0.3002232142857143\n",
            "DEBUG: compute_accuracy - Accuracy: 0.29555556178092957\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 895\n",
            "Correctly predicted different pixels: 266\n",
            "Calculated accuracy: 0.29720670391061454\n",
            "\n",
            "Testing DataLoader 0:   2%|▏         | 1/43 [00:05<03:53,  0.18it/s]DEBUG: compute_accuracy - Accuracy: 0.652222216129303\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 77\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8622221946716309\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8488888740539551\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 22\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9677777886390686\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 536\n",
            "Correctly predicted different pixels: 509\n",
            "Calculated accuracy: 0.9496268656716418\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9666666388511658\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 477\n",
            "Correctly predicted different pixels: 447\n",
            "Calculated accuracy: 0.9371069182389937\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9188888669013977\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 536\n",
            "Correctly predicted different pixels: 463\n",
            "Calculated accuracy: 0.8638059701492538\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9655555486679077\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 31\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9366666674613953\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 57\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9388889074325562\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 55\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9166666865348816\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 75\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 4\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 1\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 52\n",
            "Correctly predicted different pixels: 35\n",
            "Calculated accuracy: 0.6730769230769231\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9788888692855835\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 60\n",
            "Correctly predicted different pixels: 41\n",
            "Calculated accuracy: 0.6833333333333333\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 64\n",
            "Correctly predicted different pixels: 44\n",
            "Calculated accuracy: 0.6875\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9722222089767456\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 23\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 13\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9466666579246521\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 44\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9466666579246521\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 41\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9466666579246521\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 47\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 33\n",
            "Correctly predicted different pixels: 25\n",
            "Calculated accuracy: 0.7575757575757576\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 29\n",
            "Correctly predicted different pixels: 23\n",
            "Calculated accuracy: 0.7931034482758621\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 30\n",
            "Correctly predicted different pixels: 21\n",
            "Calculated accuracy: 0.7\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 27\n",
            "Correctly predicted different pixels: 20\n",
            "Calculated accuracy: 0.7407407407407407\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8833333253860474\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 67\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9344444274902344\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.898888885974884\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 58\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9711111187934875\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 23\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9744444489479065\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9744444489479065\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "\n",
            "Testing DataLoader 0:   5%|▍         | 2/43 [00:10<03:29,  0.20it/s]DEBUG: compute_accuracy - Accuracy: 0.894444465637207\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 92\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8799999952316284\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 104\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.894444465637207\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 92\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.894444465637207\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 92\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.949999988079071\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9333333373069763\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 54\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 4\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 4\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9877777695655823\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 4\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 5\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9666666388511658\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9833333492279053\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 27\n",
            "Correctly predicted different pixels: 9\n",
            "Calculated accuracy: 0.3333333333333333\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 7\n",
            "Calculated accuracy: 0.2916666666666667\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 19\n",
            "Correctly predicted different pixels: 7\n",
            "Calculated accuracy: 0.3684210526315789\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 13\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.38461538461538464\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9711111187934875\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9544444680213928\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9711111187934875\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 11\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 3\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 37\n",
            "Correctly predicted different pixels: 26\n",
            "Calculated accuracy: 0.7027027027027027\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 68\n",
            "Correctly predicted different pixels: 48\n",
            "Calculated accuracy: 0.7058823529411765\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9844444394111633\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 51\n",
            "Correctly predicted different pixels: 37\n",
            "Calculated accuracy: 0.7254901960784313\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8766666650772095\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 84\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8755555748939514\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 86\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8255555629730225\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 124\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9200000166893005\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9333333373069763\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.902222216129303\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 52\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8122222423553467\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 104\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "\n",
            "Testing DataLoader 0:   7%|▋         | 3/43 [00:13<02:59,  0.22it/s]DEBUG: compute_accuracy - Accuracy: 0.8655555844306946\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 69\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8266666531562805\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8411111235618591\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8888888955116272\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 7\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8955555558204651\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.653333306312561\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6222222447395325\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.601111114025116\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9511111378669739\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9399999976158142\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 22\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9355555772781372\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 9\n",
            "Calculated accuracy: 0.25\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 9\n",
            "Calculated accuracy: 0.25\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 9\n",
            "Calculated accuracy: 0.25\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8022222518920898\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 54\n",
            "Correctly predicted different pixels: 27\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7811111211776733\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 111\n",
            "Correctly predicted different pixels: 52\n",
            "Calculated accuracy: 0.46846846846846846\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9211111068725586\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9577777981758118\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 19\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9733333587646484\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 5\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 27\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 27\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 27\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 27\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9144444465637207\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9511111378669739\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 5\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9377777576446533\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8122222423553467\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 96\n",
            "Correctly predicted different pixels: 51\n",
            "Calculated accuracy: 0.53125\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8644444346427917\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 55\n",
            "Correctly predicted different pixels: 32\n",
            "Calculated accuracy: 0.5818181818181818\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8799999952316284\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 49\n",
            "Correctly predicted different pixels: 30\n",
            "Calculated accuracy: 0.6122448979591837\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9766666889190674\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 44\n",
            "Correctly predicted different pixels: 23\n",
            "Calculated accuracy: 0.5227272727272727\n",
            "\n",
            "Testing DataLoader 0:   9%|▉         | 4/43 [00:16<02:38,  0.25it/s]DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 46\n",
            "Correctly predicted different pixels: 24\n",
            "Calculated accuracy: 0.5217391304347826\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9766666889190674\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 42\n",
            "Correctly predicted different pixels: 21\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9744444489479065\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 44\n",
            "Correctly predicted different pixels: 21\n",
            "Calculated accuracy: 0.4772727272727273\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 54\n",
            "Correctly predicted different pixels: 27\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9733333587646484\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 32\n",
            "Correctly predicted different pixels: 16\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9788888692855835\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 38\n",
            "Correctly predicted different pixels: 19\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9733333587646484\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 63\n",
            "Correctly predicted different pixels: 40\n",
            "Calculated accuracy: 0.6349206349206349\n",
            "DEBUG: compute_accuracy - Accuracy: 0.996666669845581\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 129\n",
            "Correctly predicted different pixels: 127\n",
            "Calculated accuracy: 0.9844961240310077\n",
            "DEBUG: compute_accuracy - Accuracy: 0.948888897895813\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 108\n",
            "Correctly predicted different pixels: 62\n",
            "Calculated accuracy: 0.5740740740740741\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9988889098167419\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 51\n",
            "Correctly predicted different pixels: 50\n",
            "Calculated accuracy: 0.9803921568627451\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9977777600288391\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 52\n",
            "Correctly predicted different pixels: 50\n",
            "Calculated accuracy: 0.9615384615384616\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9988889098167419\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 86\n",
            "Correctly predicted different pixels: 85\n",
            "Calculated accuracy: 0.9883720930232558\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9988889098167419\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 78\n",
            "Correctly predicted different pixels: 77\n",
            "Calculated accuracy: 0.9871794871794872\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9988889098167419\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 4\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9844444394111633\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 120\n",
            "Correctly predicted different pixels: 106\n",
            "Calculated accuracy: 0.8833333333333333\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9711111187934875\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 231\n",
            "Correctly predicted different pixels: 206\n",
            "Calculated accuracy: 0.8917748917748918\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 167\n",
            "Correctly predicted different pixels: 161\n",
            "Calculated accuracy: 0.9640718562874252\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9744444489479065\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 4\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9677777886390686\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9566666483879089\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 15\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8888888955116272\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 43\n",
            "Correctly predicted different pixels: 2\n",
            "Calculated accuracy: 0.046511627906976744\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8655555844306946\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 67\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.05970149253731343\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8266666531562805\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 75\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.08\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 27\n",
            "Correctly predicted different pixels: 17\n",
            "Calculated accuracy: 0.6296296296296297\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 54\n",
            "Correctly predicted different pixels: 34\n",
            "Calculated accuracy: 0.6296296296296297\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 19\n",
            "Calculated accuracy: 0.5277777777777778\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9566666483879089\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 7\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9666666388511658\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 10\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9377777576446533\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 22\n",
            "Correctly predicted different pixels: 11\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9555555582046509\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 32\n",
            "Correctly predicted different pixels: 16\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.3055555522441864\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 81\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "\n",
            "Testing DataLoader 0:  12%|█▏        | 5/43 [00:18<02:23,  0.26it/s]DEBUG: compute_accuracy - Accuracy: 0.3055555522441864\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 80\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.3055555522441864\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 52\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9477777481079102\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 38\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9622222185134888\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 25\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9288889169692993\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 55\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8922222256660461\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 43\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9288889169692993\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 28\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9766666889190674\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 3\n",
            "Correctly predicted different pixels: 3\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9666666388511658\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 5\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9611111283302307\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 5\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.4122222363948822\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 66\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.4122222363948822\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 50\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.4144444465637207\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 62\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 187\n",
            "Correctly predicted different pixels: 179\n",
            "Calculated accuracy: 0.9572192513368984\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 152\n",
            "Correctly predicted different pixels: 139\n",
            "Calculated accuracy: 0.9144736842105263\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 84\n",
            "Correctly predicted different pixels: 78\n",
            "Calculated accuracy: 0.9285714285714286\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.047619047619047616\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9466666579246521\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 199\n",
            "Correctly predicted different pixels: 162\n",
            "Calculated accuracy: 0.8140703517587939\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9399999976158142\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 214\n",
            "Correctly predicted different pixels: 186\n",
            "Calculated accuracy: 0.8691588785046729\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9288889169692993\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 72\n",
            "Correctly predicted different pixels: 35\n",
            "Calculated accuracy: 0.4861111111111111\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9655555486679077\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 22\n",
            "Correctly predicted different pixels: 11\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9688888788223267\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 10\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9066666960716248\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 52\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9266666769981384\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 35\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9255555272102356\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 31\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9244444370269775\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 66\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9233333468437195\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 67\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9577777981758118\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 15\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9311110973358154\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "\n",
            "Testing DataLoader 0:  14%|█▍        | 6/43 [00:21<02:13,  0.28it/s]DEBUG: compute_accuracy - Accuracy: 0.9344444274902344\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 26\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.949999988079071\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.1599999964237213\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 145\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.20555555820465088\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 87\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8677777647972107\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 5\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8422222137451172\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7099999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 242\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6644444465637207\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 270\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6255555748939514\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 311\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9644444584846497\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 1\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9544444680213928\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9711111187934875\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 4\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9555555582046509\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9744444489479065\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 2\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9333333373069763\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 69\n",
            "Correctly predicted different pixels: 12\n",
            "Calculated accuracy: 0.17391304347826086\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9688888788223267\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 33\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.18181818181818182\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9644444584846497\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 34\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.14705882352941177\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9377777576446533\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 62\n",
            "Correctly predicted different pixels: 10\n",
            "Calculated accuracy: 0.16129032258064516\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 77\n",
            "Correctly predicted different pixels: 71\n",
            "Calculated accuracy: 0.922077922077922\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 84\n",
            "Correctly predicted different pixels: 74\n",
            "Calculated accuracy: 0.8809523809523809\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9877777695655823\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 105\n",
            "Correctly predicted different pixels: 94\n",
            "Calculated accuracy: 0.8952380952380953\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 1\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 1\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9677777886390686\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 1\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 9\n",
            "Calculated accuracy: 0.25\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 27\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 45\n",
            "Correctly predicted different pixels: 9\n",
            "Calculated accuracy: 0.2\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 51\n",
            "Correctly predicted different pixels: 37\n",
            "Calculated accuracy: 0.7254901960784313\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 49\n",
            "Correctly predicted different pixels: 34\n",
            "Calculated accuracy: 0.6938775510204082\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9844444394111633\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 52\n",
            "Correctly predicted different pixels: 39\n",
            "Calculated accuracy: 0.75\n",
            "\n",
            "Testing DataLoader 0:  16%|█▋        | 7/43 [00:24<02:05,  0.29it/s]DEBUG: compute_accuracy - Accuracy: 0.9844444394111633\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 46\n",
            "Correctly predicted different pixels: 33\n",
            "Calculated accuracy: 0.717391304347826\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 43\n",
            "Correctly predicted different pixels: 28\n",
            "Calculated accuracy: 0.6511627906976745\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9844444394111633\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 48\n",
            "Correctly predicted different pixels: 36\n",
            "Calculated accuracy: 0.75\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9044444561004639\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 13\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9300000071525574\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 7\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8899999856948853\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 13\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9611111283302307\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 30\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9622222185134888\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 28\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9622222185134888\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 28\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 5\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 11\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9666666388511658\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 15\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9744444489479065\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9722222089767456\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9655555486679077\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9311110973358154\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 235\n",
            "Correctly predicted different pixels: 189\n",
            "Calculated accuracy: 0.8042553191489362\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 326\n",
            "Correctly predicted different pixels: 269\n",
            "Calculated accuracy: 0.8251533742331288\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9088888764381409\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 208\n",
            "Correctly predicted different pixels: 148\n",
            "Calculated accuracy: 0.7115384615384616\n",
            "DEBUG: compute_accuracy - Accuracy: 0.897777795791626\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 200\n",
            "Correctly predicted different pixels: 138\n",
            "Calculated accuracy: 0.69\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9788888692855835\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.1\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9877777695655823\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.16666666666666666\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 7\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.14285714285714285\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9544444680213928\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 352\n",
            "Correctly predicted different pixels: 311\n",
            "Calculated accuracy: 0.8835227272727273\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9622222185134888\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 422\n",
            "Correctly predicted different pixels: 388\n",
            "Calculated accuracy: 0.919431279620853\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 276\n",
            "Correctly predicted different pixels: 263\n",
            "Calculated accuracy: 0.9528985507246377\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 25\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 34\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 34\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 221\n",
            "Correctly predicted different pixels: 201\n",
            "Calculated accuracy: 0.9095022624434389\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9788888692855835\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 251\n",
            "Correctly predicted different pixels: 238\n",
            "Calculated accuracy: 0.9482071713147411\n",
            "\n",
            "Testing DataLoader 0:  19%|█▊        | 8/43 [00:27<01:58,  0.29it/s]DEBUG: compute_accuracy - Accuracy: 0.9744444489479065\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 255\n",
            "Correctly predicted different pixels: 232\n",
            "Calculated accuracy: 0.9098039215686274\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6277777552604675\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 64\n",
            "Correctly predicted different pixels: 61\n",
            "Calculated accuracy: 0.953125\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6266666650772095\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 62\n",
            "Correctly predicted different pixels: 60\n",
            "Calculated accuracy: 0.967741935483871\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6288889050483704\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 61\n",
            "Correctly predicted different pixels: 61\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9300000071525574\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 22\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9344444274902344\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9277777671813965\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 30\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9944444298744202\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 15\n",
            "Calculated accuracy: 0.75\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 19\n",
            "Correctly predicted different pixels: 12\n",
            "Calculated accuracy: 0.631578947368421\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 12\n",
            "Calculated accuracy: 0.6666666666666666\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 11\n",
            "Calculated accuracy: 0.6111111111111112\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 11\n",
            "Calculated accuracy: 0.6111111111111112\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 7\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9288889169692993\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 60\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.945555567741394\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9555555582046509\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9766666889190674\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9277777671813965\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 65\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9733333587646484\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 12\n",
            "Calculated accuracy: 0.3333333333333333\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9833333492279053\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.25\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9844444394111633\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 7\n",
            "Calculated accuracy: 0.3333333333333333\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 10\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8500000238418579\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 120\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8577777743339539\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 112\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9200000166893005\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 48\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8600000143051147\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 78\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8644444346427917\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 78\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 29\n",
            "Correctly predicted different pixels: 19\n",
            "Calculated accuracy: 0.6551724137931034\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 25\n",
            "Correctly predicted different pixels: 16\n",
            "Calculated accuracy: 0.64\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 28\n",
            "Correctly predicted different pixels: 18\n",
            "Calculated accuracy: 0.6428571428571429\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 31\n",
            "Correctly predicted different pixels: 18\n",
            "Calculated accuracy: 0.5806451612903226\n",
            "\n",
            "Testing DataLoader 0:  21%|██        | 9/43 [00:29<01:52,  0.30it/s]DEBUG: compute_accuracy - Accuracy: 0.996666669845581\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 51\n",
            "Correctly predicted different pixels: 48\n",
            "Calculated accuracy: 0.9411764705882353\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 59\n",
            "Correctly predicted different pixels: 49\n",
            "Calculated accuracy: 0.8305084745762712\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 97\n",
            "Correctly predicted different pixels: 83\n",
            "Calculated accuracy: 0.8556701030927835\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9733333587646484\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 118\n",
            "Correctly predicted different pixels: 100\n",
            "Calculated accuracy: 0.847457627118644\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 108\n",
            "Correctly predicted different pixels: 100\n",
            "Calculated accuracy: 0.9259259259259259\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9733333587646484\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 140\n",
            "Correctly predicted different pixels: 116\n",
            "Calculated accuracy: 0.8285714285714286\n",
            "DEBUG: compute_accuracy - Accuracy: 0.894444465637207\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 95\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8666666746139526\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 120\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8755555748939514\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 112\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8888888955116272\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 97\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8888888955116272\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 97\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8533333539962769\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 76\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.945555567741394\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9288889169692993\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 48\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8122222423553467\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 120\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9722222089767456\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9977777600288391\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 27\n",
            "Correctly predicted different pixels: 25\n",
            "Calculated accuracy: 0.9259259259259259\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9988889098167419\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 13\n",
            "Calculated accuracy: 0.9285714285714286\n",
            "DEBUG: compute_accuracy - Accuracy: 0.996666669845581\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 17\n",
            "Calculated accuracy: 0.85\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9977777600288391\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 13\n",
            "Correctly predicted different pixels: 11\n",
            "Calculated accuracy: 0.8461538461538461\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9988889098167419\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 13\n",
            "Correctly predicted different pixels: 12\n",
            "Calculated accuracy: 0.9230769230769231\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9833333492279053\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 38\n",
            "Correctly predicted different pixels: 23\n",
            "Calculated accuracy: 0.6052631578947368\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9766666889190674\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 45\n",
            "Correctly predicted different pixels: 26\n",
            "Calculated accuracy: 0.5777777777777777\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 44\n",
            "Correctly predicted different pixels: 26\n",
            "Calculated accuracy: 0.5909090909090909\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9788888692855835\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 50\n",
            "Correctly predicted different pixels: 32\n",
            "Calculated accuracy: 0.64\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 25\n",
            "Calculated accuracy: 0.625\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 46\n",
            "Correctly predicted different pixels: 28\n",
            "Calculated accuracy: 0.6086956521739131\n",
            "DEBUG: compute_accuracy - Accuracy: 0.596666693687439\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 75\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6155555844306946\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 77\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7022222280502319\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 30\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9722222089767456\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 34\n",
            "Correctly predicted different pixels: 9\n",
            "Calculated accuracy: 0.2647058823529412\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 46\n",
            "Correctly predicted different pixels: 10\n",
            "Calculated accuracy: 0.21739130434782608\n",
            "\n",
            "Testing DataLoader 0:  23%|██▎       | 10/43 [00:32<01:47,  0.31it/s]DEBUG: compute_accuracy - Accuracy: 0.9288889169692993\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 73\n",
            "Correctly predicted different pixels: 10\n",
            "Calculated accuracy: 0.136986301369863\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9355555772781372\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 56\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9744444489479065\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 22\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6544444561004639\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 77\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6100000143051147\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 70\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6166666746139526\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 102\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8533333539962769\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 175\n",
            "Correctly predicted different pixels: 90\n",
            "Calculated accuracy: 0.5142857142857142\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9144444465637207\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 116\n",
            "Correctly predicted different pixels: 41\n",
            "Calculated accuracy: 0.35344827586206895\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9200000166893005\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 122\n",
            "Correctly predicted different pixels: 66\n",
            "Calculated accuracy: 0.5409836065573771\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 10\n",
            "Calculated accuracy: 0.5882352941176471\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 10\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9788888692855835\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 25\n",
            "Correctly predicted different pixels: 13\n",
            "Calculated accuracy: 0.52\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9944444298744202\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 2\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8822222352027893\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 5\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8244444727897644\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 7\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7488889098167419\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8077777624130249\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9366666674613953\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 3\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8911111354827881\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8911111354827881\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 3\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7866666913032532\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8399999737739563\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8266666531562805\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 84\n",
            "Correctly predicted different pixels: 67\n",
            "Calculated accuracy: 0.7976190476190477\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9722222089767456\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 37\n",
            "Correctly predicted different pixels: 28\n",
            "Calculated accuracy: 0.7567567567567568\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9722222089767456\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 37\n",
            "Correctly predicted different pixels: 28\n",
            "Calculated accuracy: 0.7567567567567568\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 27\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9333333373069763\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 58\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9422222375869751\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 50\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "\n",
            "Testing DataLoader 0:  26%|██▌       | 11/43 [00:35<01:42,  0.31it/s]DEBUG: compute_accuracy - Accuracy: 0.9233333468437195\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 66\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8122222423553467\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 166\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8122222423553467\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 163\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8122222423553467\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 162\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.1088888868689537\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 39\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.02564102564102564\n",
            "DEBUG: compute_accuracy - Accuracy: 0.08666666597127914\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 45\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.08888888888888889\n",
            "DEBUG: compute_accuracy - Accuracy: 0.15000000596046448\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 95\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.08421052631578947\n",
            "DEBUG: compute_accuracy - Accuracy: 0.20777778327465057\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 115\n",
            "Correctly predicted different pixels: 26\n",
            "Calculated accuracy: 0.22608695652173913\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9733333587646484\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 23\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.043478260869565216\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 2\n",
            "Calculated accuracy: 0.2\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9555555582046509\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 42\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.09523809523809523\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 19\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.3157894736842105\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9944444298744202\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 11\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.5454545454545454\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.35294117647058826\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 23\n",
            "Correctly predicted different pixels: 7\n",
            "Calculated accuracy: 0.30434782608695654\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 28\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.2857142857142857\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.4444444444444444\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 27\n",
            "Correctly predicted different pixels: 9\n",
            "Calculated accuracy: 0.3333333333333333\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 9\n",
            "Calculated accuracy: 0.25\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 9\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 9\n",
            "Calculated accuracy: 0.25\n",
            "DEBUG: compute_accuracy - Accuracy: 0.12888889014720917\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 123\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.12888889014720917\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 82\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.12888889014720917\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 99\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 29\n",
            "Correctly predicted different pixels: 14\n",
            "Calculated accuracy: 0.4827586206896552\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9766666889190674\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 34\n",
            "Correctly predicted different pixels: 17\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 18\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9711111187934875\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 47\n",
            "Correctly predicted different pixels: 21\n",
            "Calculated accuracy: 0.44680851063829785\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8666666746139526\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 44\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.022727272727272728\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8500000238418579\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 66\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.09090909090909091\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8700000047683716\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 68\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "\n",
            "Testing DataLoader 0:  28%|██▊       | 12/43 [00:37<01:37,  0.32it/s]DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 53\n",
            "Correctly predicted different pixels: 40\n",
            "Calculated accuracy: 0.7547169811320755\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 46\n",
            "Correctly predicted different pixels: 34\n",
            "Calculated accuracy: 0.7391304347826086\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 42\n",
            "Correctly predicted different pixels: 30\n",
            "Calculated accuracy: 0.7142857142857143\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 41\n",
            "Correctly predicted different pixels: 32\n",
            "Calculated accuracy: 0.7804878048780488\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 5\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 5\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.75\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 54\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.75\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 28\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7522222399711609\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 48\n",
            "Correctly predicted different pixels: 2\n",
            "Calculated accuracy: 0.041666666666666664\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9766666889190674\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9711111187934875\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 13\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9511111378669739\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7822222113609314\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 48\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8122222423553467\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 44\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6211110949516296\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 15\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.5233333110809326\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7333333492279053\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 15\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 89\n",
            "Correctly predicted different pixels: 77\n",
            "Calculated accuracy: 0.8651685393258427\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9977777600288391\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 15\n",
            "Calculated accuracy: 0.8823529411764706\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9977777600288391\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 27\n",
            "Correctly predicted different pixels: 25\n",
            "Calculated accuracy: 0.9259259259259259\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 43\n",
            "Correctly predicted different pixels: 38\n",
            "Calculated accuracy: 0.8837209302325582\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 49\n",
            "Correctly predicted different pixels: 44\n",
            "Calculated accuracy: 0.8979591836734694\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 32\n",
            "Correctly predicted different pixels: 16\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 34\n",
            "Correctly predicted different pixels: 17\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 28\n",
            "Correctly predicted different pixels: 11\n",
            "Calculated accuracy: 0.39285714285714285\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9844444394111633\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 29\n",
            "Correctly predicted different pixels: 15\n",
            "Calculated accuracy: 0.5172413793103449\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9288889169692993\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 64\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6088888645172119\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 400\n",
            "Correctly predicted different pixels: 48\n",
            "Calculated accuracy: 0.12\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 81\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 30\n",
            "Correctly predicted different pixels: 14\n",
            "Calculated accuracy: 0.4666666666666667\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 30\n",
            "Correctly predicted different pixels: 15\n",
            "Calculated accuracy: 0.5\n",
            "\n",
            "Testing DataLoader 0:  30%|███       | 13/43 [00:40<01:33,  0.32it/s]DEBUG: compute_accuracy - Accuracy: 0.9711111187934875\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 46\n",
            "Correctly predicted different pixels: 20\n",
            "Calculated accuracy: 0.43478260869565216\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8544444441795349\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 5\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.804444432258606\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7911111116409302\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.757777750492096\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9388889074325562\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9277777671813965\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 31\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8899999856948853\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 51\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 31\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9300000071525574\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 56\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 190\n",
            "Correctly predicted different pixels: 180\n",
            "Calculated accuracy: 0.9473684210526315\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 100\n",
            "Correctly predicted different pixels: 96\n",
            "Calculated accuracy: 0.96\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9944444298744202\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 140\n",
            "Correctly predicted different pixels: 135\n",
            "Calculated accuracy: 0.9642857142857143\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9233333468437195\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 193\n",
            "Correctly predicted different pixels: 126\n",
            "Calculated accuracy: 0.6528497409326425\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7022222280502319\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 184\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7988888621330261\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 130\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6399999856948853\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 228\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.897777795791626\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.902222216129303\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 25\n",
            "Correctly predicted different pixels: 25\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 15\n",
            "Correctly predicted different pixels: 15\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9166666865348816\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 35\n",
            "Correctly predicted different pixels: 35\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 7\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9722222089767456\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 5\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 2\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7555555701255798\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 113\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7733333110809326\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 103\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 4\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9077777862548828\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8799999952316284\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 5\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.800000011920929\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 22\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7333333492279053\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "\n",
            "Testing DataLoader 0:  33%|███▎      | 14/43 [00:43<01:29,  0.32it/s]DEBUG: compute_accuracy - Accuracy: 0.8888888955116272\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 15\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8888888955116272\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8888888955116272\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 7\n",
            "Calculated accuracy: 0.4375\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.47058823529411764\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 15\n",
            "Correctly predicted different pixels: 7\n",
            "Calculated accuracy: 0.4666666666666667\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8577777743339539\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 100\n",
            "Correctly predicted different pixels: 64\n",
            "Calculated accuracy: 0.64\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8500000238418579\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 89\n",
            "Correctly predicted different pixels: 46\n",
            "Calculated accuracy: 0.5168539325842697\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9399999976158142\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 65\n",
            "Correctly predicted different pixels: 42\n",
            "Calculated accuracy: 0.6461538461538462\n",
            "DEBUG: compute_accuracy - Accuracy: 0.948888897895813\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.945555567741394\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 11\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 67\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9211111068725586\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 61\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9200000166893005\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 63\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 31\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 30\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9611111283302307\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 30\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 31\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8622221946716309\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 66\n",
            "Correctly predicted different pixels: 3\n",
            "Calculated accuracy: 0.045454545454545456\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7766666412353516\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 88\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.045454545454545456\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9744444489479065\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9766666889190674\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9200000166893005\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 32\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8933333158493042\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 48\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.898888885974884\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 22\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.22727272727272727\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9277777671813965\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 3\n",
            "Calculated accuracy: 0.25\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8888888955116272\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 106\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.07547169811320754\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 3\n",
            "Calculated accuracy: 0.16666666666666666\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9288889169692993\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 64\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.0625\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 90\n",
            "Correctly predicted different pixels: 9\n",
            "Calculated accuracy: 0.1\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8888888955116272\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 100\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.05\n",
            "\n",
            "Testing DataLoader 0:  35%|███▍      | 15/43 [00:46<01:26,  0.33it/s]DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 34\n",
            "Correctly predicted different pixels: 16\n",
            "Calculated accuracy: 0.47058823529411764\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9788888692855835\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 38\n",
            "Correctly predicted different pixels: 19\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 20\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 16\n",
            "Calculated accuracy: 0.4444444444444444\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 38\n",
            "Correctly predicted different pixels: 18\n",
            "Calculated accuracy: 0.47368421052631576\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 26\n",
            "Correctly predicted different pixels: 13\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.47058823529411764\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 9\n",
            "Calculated accuracy: 0.25\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 11\n",
            "Correctly predicted different pixels: 3\n",
            "Calculated accuracy: 0.2727272727272727\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9833333492279053\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.2857142857142857\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9833333492279053\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.2857142857142857\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 5\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 7\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9644444584846497\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.05555555555555555\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 13\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9511111378669739\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 11\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9355555772781372\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9233333468437195\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 27\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9666666388511658\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9466666579246521\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9544444680213928\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 30\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7955555319786072\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 184\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7599999904632568\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 216\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.95333331823349\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9577777981758118\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8855555653572083\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 493\n",
            "Correctly predicted different pixels: 390\n",
            "Calculated accuracy: 0.7910750507099391\n",
            "\n",
            "Testing DataLoader 0:  37%|███▋      | 16/43 [00:48<01:22,  0.33it/s]DEBUG: compute_accuracy - Accuracy: 0.9988889098167419\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 344\n",
            "Correctly predicted different pixels: 343\n",
            "Calculated accuracy: 0.997093023255814\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9988889098167419\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 336\n",
            "Correctly predicted different pixels: 335\n",
            "Calculated accuracy: 0.9970238095238095\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 9\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 32\n",
            "Correctly predicted different pixels: 16\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 28\n",
            "Correctly predicted different pixels: 18\n",
            "Calculated accuracy: 0.6428571428571429\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 32\n",
            "Correctly predicted different pixels: 26\n",
            "Calculated accuracy: 0.8125\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9944444298744202\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 29\n",
            "Correctly predicted different pixels: 24\n",
            "Calculated accuracy: 0.8275862068965517\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 31\n",
            "Correctly predicted different pixels: 23\n",
            "Calculated accuracy: 0.7419354838709677\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9833333492279053\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 25\n",
            "Correctly predicted different pixels: 10\n",
            "Calculated accuracy: 0.4\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9733333587646484\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 249\n",
            "Correctly predicted different pixels: 232\n",
            "Calculated accuracy: 0.9317269076305221\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9766666889190674\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 248\n",
            "Correctly predicted different pixels: 235\n",
            "Calculated accuracy: 0.9475806451612904\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9588888883590698\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 254\n",
            "Correctly predicted different pixels: 219\n",
            "Calculated accuracy: 0.8622047244094488\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9833333492279053\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9766666889190674\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 10\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9877777695655823\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 4\n",
            "Correctly predicted different pixels: 2\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9666666388511658\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 12\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9944444298744202\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 3\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9177777767181396\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 58\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9288889169692993\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 48\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.855555534362793\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 114\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 80\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.05\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8611111044883728\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 123\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.008130081300813009\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 83\n",
            "Correctly predicted different pixels: 9\n",
            "Calculated accuracy: 0.10843373493975904\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9588888883590698\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 22\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9688888788223267\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "\n",
            "Testing DataLoader 0:  40%|███▉      | 17/43 [00:51<01:18,  0.33it/s]DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9844444394111633\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 13\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9733333587646484\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 46\n",
            "Correctly predicted different pixels: 27\n",
            "Calculated accuracy: 0.5869565217391305\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9788888692855835\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 42\n",
            "Correctly predicted different pixels: 24\n",
            "Calculated accuracy: 0.5714285714285714\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9744444489479065\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 45\n",
            "Correctly predicted different pixels: 25\n",
            "Calculated accuracy: 0.5555555555555556\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 43\n",
            "Correctly predicted different pixels: 25\n",
            "Calculated accuracy: 0.5813953488372093\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9766666889190674\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 47\n",
            "Correctly predicted different pixels: 28\n",
            "Calculated accuracy: 0.5957446808510638\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 23\n",
            "Correctly predicted different pixels: 11\n",
            "Calculated accuracy: 0.4782608695652174\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 19\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.42105263157894735\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9833333492279053\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 19\n",
            "Correctly predicted different pixels: 9\n",
            "Calculated accuracy: 0.47368421052631576\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 11\n",
            "Calculated accuracy: 0.4583333333333333\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 11\n",
            "Calculated accuracy: 0.55\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9944444298744202\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 19\n",
            "Correctly predicted different pixels: 14\n",
            "Calculated accuracy: 0.7368421052631579\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 15\n",
            "Correctly predicted different pixels: 11\n",
            "Calculated accuracy: 0.7333333333333333\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 2\n",
            "Calculated accuracy: 0.25\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 2\n",
            "Calculated accuracy: 0.2222222222222222\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 3\n",
            "Calculated accuracy: 0.3333333333333333\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9944444298744202\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.4444444444444444\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9944444298744202\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.4444444444444444\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 3\n",
            "Calculated accuracy: 0.3333333333333333\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9944444298744202\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.4444444444444444\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9444444179534912\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 52\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.09615384615384616\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9466666579246521\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 56\n",
            "Correctly predicted different pixels: 10\n",
            "Calculated accuracy: 0.17857142857142858\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 11\n",
            "Correctly predicted different pixels: 3\n",
            "Calculated accuracy: 0.2727272727272727\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 13\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.3076923076923077\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 433\n",
            "Correctly predicted different pixels: 429\n",
            "Calculated accuracy: 0.9907621247113164\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9722222089767456\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 709\n",
            "Correctly predicted different pixels: 704\n",
            "Calculated accuracy: 0.9929478138222849\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 97\n",
            "Correctly predicted different pixels: 94\n",
            "Calculated accuracy: 0.9690721649484536\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "\n",
            "Testing DataLoader 0:  42%|████▏     | 18/43 [00:54<01:15,  0.33it/s]DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 7\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9311110973358154\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 34\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9211111068725586\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 33\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.898888885974884\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 43\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 3\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 4\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 7\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9877777695655823\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 4\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 3\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9788888692855835\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 37\n",
            "Correctly predicted different pixels: 32\n",
            "Calculated accuracy: 0.8648648648648649\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9877777695655823\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 42\n",
            "Correctly predicted different pixels: 33\n",
            "Calculated accuracy: 0.7857142857142857\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 36\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.16666666666666666\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 2\n",
            "Calculated accuracy: 0.2222222222222222\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.29411764705882354\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 2\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 57\n",
            "Correctly predicted different pixels: 48\n",
            "Calculated accuracy: 0.8421052631578947\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 68\n",
            "Correctly predicted different pixels: 60\n",
            "Calculated accuracy: 0.8823529411764706\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9844444394111633\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 65\n",
            "Correctly predicted different pixels: 51\n",
            "Calculated accuracy: 0.7846153846153846\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7522222399711609\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 184\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9333333373069763\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 41\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9066666960716248\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 80\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9066666960716248\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 80\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6222222447395325\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 336\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 3\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 15\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9766666889190674\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9744444489479065\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "\n",
            "Testing DataLoader 0:  44%|████▍     | 19/43 [00:56<01:11,  0.34it/s]DEBUG: compute_accuracy - Accuracy: 0.9322222471237183\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 21\n",
            "Calculated accuracy: 0.525\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9222221970558167\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 55\n",
            "Correctly predicted different pixels: 20\n",
            "Calculated accuracy: 0.36363636363636365\n",
            "DEBUG: compute_accuracy - Accuracy: 0.948888897895813\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 37\n",
            "Correctly predicted different pixels: 19\n",
            "Calculated accuracy: 0.5135135135135135\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8322222232818604\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7644444704055786\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 4\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8155555725097656\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 3\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9288889169692993\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 62\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9288889169692993\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 60\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9288889169692993\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 59\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9288889169692993\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 61\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9288889169692993\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 60\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8100000023841858\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 103\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.949999988079071\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 31\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9877777695655823\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 7\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9177777767181396\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 45\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9788888692855835\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9722222089767456\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 176\n",
            "Correctly predicted different pixels: 159\n",
            "Calculated accuracy: 0.9034090909090909\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9833333492279053\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 157\n",
            "Correctly predicted different pixels: 146\n",
            "Calculated accuracy: 0.9299363057324841\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 227\n",
            "Correctly predicted different pixels: 219\n",
            "Calculated accuracy: 0.9647577092511013\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9733333587646484\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 41\n",
            "Correctly predicted different pixels: 26\n",
            "Calculated accuracy: 0.6341463414634146\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9611111283302307\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 163\n",
            "Correctly predicted different pixels: 131\n",
            "Calculated accuracy: 0.803680981595092\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8888888955116272\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 56\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8888888955116272\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 56\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8888888955116272\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 48\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 218\n",
            "Correctly predicted different pixels: 208\n",
            "Calculated accuracy: 0.9541284403669725\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8866666555404663\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 217\n",
            "Correctly predicted different pixels: 115\n",
            "Calculated accuracy: 0.5299539170506913\n",
            "DEBUG: compute_accuracy - Accuracy: 0.846666693687439\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 227\n",
            "Correctly predicted different pixels: 90\n",
            "Calculated accuracy: 0.3964757709251101\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9788888692855835\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 83\n",
            "Correctly predicted different pixels: 64\n",
            "Calculated accuracy: 0.7710843373493976\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9744444489479065\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 97\n",
            "Correctly predicted different pixels: 74\n",
            "Calculated accuracy: 0.7628865979381443\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 96\n",
            "Correctly predicted different pixels: 76\n",
            "Calculated accuracy: 0.7916666666666666\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7955555319786072\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 60\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "\n",
            "Testing DataLoader 0:  47%|████▋     | 20/43 [00:59<01:08,  0.34it/s]DEBUG: compute_accuracy - Accuracy: 0.7888888716697693\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 78\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9133333563804626\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 32\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8822222352027893\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 44\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8766666650772095\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 59\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7944444417953491\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 90\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9122222065925598\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9088888764381409\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8788889050483704\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9244444370269775\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9077777862548828\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 30\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9077777862548828\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 28\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9733333587646484\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9688888788223267\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 4\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 123\n",
            "Correctly predicted different pixels: 117\n",
            "Calculated accuracy: 0.9512195121951219\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9944444298744202\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 126\n",
            "Correctly predicted different pixels: 121\n",
            "Calculated accuracy: 0.9603174603174603\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 145\n",
            "Correctly predicted different pixels: 138\n",
            "Calculated accuracy: 0.9517241379310345\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9733333587646484\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 26\n",
            "Correctly predicted different pixels: 2\n",
            "Calculated accuracy: 0.07692307692307693\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9555555582046509\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 43\n",
            "Correctly predicted different pixels: 3\n",
            "Calculated accuracy: 0.06976744186046512\n",
            "DEBUG: compute_accuracy - Accuracy: 0.948888897895813\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 28\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9344444274902344\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 15\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8888888955116272\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 39\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8888888955116272\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 37\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8888888955116272\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 43\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8888888955116272\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 46\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9433333277702332\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 7\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 1\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 2\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9399999976158142\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "\n",
            "Testing DataLoader 0:  49%|████▉     | 21/43 [01:01<01:04,  0.34it/s]DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 16\n",
            "Calculated accuracy: 0.8\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 22\n",
            "Correctly predicted different pixels: 18\n",
            "Calculated accuracy: 0.8181818181818182\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 20\n",
            "Calculated accuracy: 0.8333333333333334\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 22\n",
            "Correctly predicted different pixels: 18\n",
            "Calculated accuracy: 0.8181818181818182\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8777777552604675\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 7\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8722222447395325\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 7\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8755555748939514\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8744444251060486\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 13\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9466666579246521\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9422222375869751\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9788888692855835\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 11\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9277777671813965\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 60\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9422222375869751\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 48\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9566666483879089\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9444444179534912\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9333333373069763\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 23\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8733333349227905\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 48\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8222222328186035\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 45\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8899999856948853\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 72\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9733333587646484\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9188888669013977\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 15\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8811110854148865\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 15\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.847777783870697\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 19\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.5988888740539551\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 144\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.4122222363948822\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 121\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.3055555522441864\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 324\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.945555567741394\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 48\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.948888897895813\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 47\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.02127659574468085\n",
            "DEBUG: compute_accuracy - Accuracy: 0.949999988079071\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 46\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.021739130434782608\n",
            "DEBUG: compute_accuracy - Accuracy: 0.949999988079071\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 46\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.021739130434782608\n",
            "DEBUG: compute_accuracy - Accuracy: 0.949999988079071\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 46\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.021739130434782608\n",
            "\n",
            "Testing DataLoader 0:  51%|█████     | 22/43 [01:04<01:01,  0.34it/s]DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 17\n",
            "Calculated accuracy: 0.8095238095238095\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9944444298744202\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 26\n",
            "Correctly predicted different pixels: 21\n",
            "Calculated accuracy: 0.8076923076923077\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 18\n",
            "Calculated accuracy: 0.75\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 22\n",
            "Correctly predicted different pixels: 18\n",
            "Calculated accuracy: 0.8181818181818182\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9977777600288391\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 16\n",
            "Calculated accuracy: 0.8888888888888888\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9944444298744202\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 20\n",
            "Calculated accuracy: 0.8333333333333334\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 29\n",
            "Correctly predicted different pixels: 20\n",
            "Calculated accuracy: 0.6896551724137931\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9466666579246521\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 55\n",
            "Correctly predicted different pixels: 42\n",
            "Calculated accuracy: 0.7636363636363637\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8822222352027893\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 83\n",
            "Correctly predicted different pixels: 56\n",
            "Calculated accuracy: 0.6746987951807228\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8155555725097656\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 154\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8399999737739563\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 144\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8266666531562805\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 120\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8233333230018616\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 147\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9722222089767456\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 29\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.13793103448275862\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.23809523809523808\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 15\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.4\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 18\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9733333587646484\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 48\n",
            "Correctly predicted different pixels: 24\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9833333492279053\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 12\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9677777886390686\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9477777481079102\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9944444298744202\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7155555486679077\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7155555486679077\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7155555486679077\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7155555486679077\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 26\n",
            "Correctly predicted different pixels: 22\n",
            "Calculated accuracy: 0.8461538461538461\n",
            "DEBUG: compute_accuracy - Accuracy: 0.996666669845581\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 17\n",
            "Calculated accuracy: 0.85\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 31\n",
            "Correctly predicted different pixels: 27\n",
            "Calculated accuracy: 0.8709677419354839\n",
            "\n",
            "Testing DataLoader 0:  53%|█████▎    | 23/43 [01:07<00:58,  0.34it/s]DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 26\n",
            "Correctly predicted different pixels: 22\n",
            "Calculated accuracy: 0.8461538461538461\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 26\n",
            "Correctly predicted different pixels: 22\n",
            "Calculated accuracy: 0.8461538461538461\n",
            "DEBUG: compute_accuracy - Accuracy: 0.996666669845581\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 29\n",
            "Correctly predicted different pixels: 26\n",
            "Calculated accuracy: 0.896551724137931\n",
            "DEBUG: compute_accuracy - Accuracy: 0.996666669845581\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 30\n",
            "Correctly predicted different pixels: 27\n",
            "Calculated accuracy: 0.9\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9644444584846497\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 31\n",
            "Correctly predicted different pixels: 19\n",
            "Calculated accuracy: 0.6129032258064516\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9622222185134888\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 29\n",
            "Correctly predicted different pixels: 19\n",
            "Calculated accuracy: 0.6551724137931034\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9666666388511658\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 33\n",
            "Correctly predicted different pixels: 19\n",
            "Calculated accuracy: 0.5757575757575758\n",
            "DEBUG: compute_accuracy - Accuracy: 0.3655555546283722\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 58\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.36000001430511475\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.36000001430511475\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 96\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.36000001430511475\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 35\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6200000047683716\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 48\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7322221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 32\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6511111259460449\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 46\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9233333468437195\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 48\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8899999856948853\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 78\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9333333373069763\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 74\n",
            "Correctly predicted different pixels: 30\n",
            "Calculated accuracy: 0.40540540540540543\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9133333563804626\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 95\n",
            "Correctly predicted different pixels: 39\n",
            "Calculated accuracy: 0.4105263157894737\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9355555772781372\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.35294117647058826\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9333333373069763\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 19\n",
            "Correctly predicted different pixels: 7\n",
            "Calculated accuracy: 0.3684210526315789\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9511111378669739\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 19\n",
            "Correctly predicted different pixels: 9\n",
            "Calculated accuracy: 0.47368421052631576\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8999999761581421\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 144\n",
            "Correctly predicted different pixels: 71\n",
            "Calculated accuracy: 0.4930555555555556\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 130\n",
            "Correctly predicted different pixels: 63\n",
            "Calculated accuracy: 0.4846153846153846\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8666666746139526\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 189\n",
            "Correctly predicted different pixels: 90\n",
            "Calculated accuracy: 0.47619047619047616\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9577777981758118\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9577777981758118\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9577777981758118\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9266666769981384\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 28\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.21428571428571427\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9555555582046509\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 32\n",
            "Correctly predicted different pixels: 12\n",
            "Calculated accuracy: 0.375\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9211111068725586\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 14\n",
            "Calculated accuracy: 0.5833333333333334\n",
            "DEBUG: compute_accuracy - Accuracy: 0.903333306312561\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 61\n",
            "Correctly predicted different pixels: 47\n",
            "Calculated accuracy: 0.7704918032786885\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7599999904632568\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 73\n",
            "Correctly predicted different pixels: 27\n",
            "Calculated accuracy: 0.3698630136986301\n",
            "\n",
            "Testing DataLoader 0:  56%|█████▌    | 24/43 [01:10<00:55,  0.34it/s]DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9844444394111633\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9477777481079102\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 31\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9266666769981384\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9111111164093018\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 38\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9544444680213928\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 28\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8066666722297668\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 44\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7900000214576721\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 57\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.800000011920929\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 48\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6688888669013977\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 38\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8266666531562805\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 39\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.0\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 82\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.0\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 114\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.0\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 93\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.0011111111380159855\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 84\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9877777695655823\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 11\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 11\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9577777981758118\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9066666960716248\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 49\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8844444155693054\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 64\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 42\n",
            "Correctly predicted different pixels: 32\n",
            "Calculated accuracy: 0.7619047619047619\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9877777695655823\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 44\n",
            "Correctly predicted different pixels: 33\n",
            "Calculated accuracy: 0.75\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 45\n",
            "Correctly predicted different pixels: 36\n",
            "Calculated accuracy: 0.8\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9644444584846497\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9688888788223267\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9644444584846497\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9555555582046509\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 64\n",
            "Correctly predicted different pixels: 24\n",
            "Calculated accuracy: 0.375\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9744444489479065\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 41\n",
            "Correctly predicted different pixels: 18\n",
            "Calculated accuracy: 0.43902439024390244\n",
            "\n",
            "Testing DataLoader 0:  58%|█████▊    | 25/43 [01:13<00:52,  0.34it/s]DEBUG: compute_accuracy - Accuracy: 0.9711111187934875\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 54\n",
            "Correctly predicted different pixels: 28\n",
            "Calculated accuracy: 0.5185185185185185\n",
            "DEBUG: compute_accuracy - Accuracy: 0.75\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 34\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8411111235618591\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 32\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8144444227218628\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 42\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8533333539962769\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 30\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9733333587646484\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 2\n",
            "Calculated accuracy: 0.14285714285714285\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.35294117647058826\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9844444394111633\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.4166666666666667\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9844444394111633\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.4166666666666667\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.35294117647058826\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9688888788223267\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9377777576446533\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.95333331823349\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 30\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9244444370269775\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 42\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 3\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 4\n",
            "Correctly predicted different pixels: 2\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9611111283302307\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7888888716697693\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 23\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7688888907432556\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7400000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9200000166893005\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 32\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7733333110809326\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 132\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8811110854148865\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 74\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8388888835906982\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 101\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8399999737739563\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8399999737739563\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 25\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8399999737739563\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.79666668176651\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 64\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7233333587646484\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 96\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9333333373069763\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 26\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7155555486679077\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 4\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "\n",
            "Testing DataLoader 0:  60%|██████    | 26/43 [01:15<00:49,  0.34it/s]DEBUG: compute_accuracy - Accuracy: 0.644444465637207\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8399999737739563\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 2\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9200000166893005\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8622221946716309\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 80\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7322221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 177\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9577777981758118\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 19\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9566666483879089\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7599999904632568\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 49\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.5477777719497681\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 63\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6822222471237183\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 99\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 72\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 33\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8399999737739563\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 139\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 31\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 72\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9688888788223267\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 74\n",
            "Correctly predicted different pixels: 46\n",
            "Calculated accuracy: 0.6216216216216216\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9688888788223267\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 74\n",
            "Correctly predicted different pixels: 49\n",
            "Calculated accuracy: 0.6621621621621622\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9555555582046509\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 120\n",
            "Correctly predicted different pixels: 80\n",
            "Calculated accuracy: 0.6666666666666666\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 22\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9744444489479065\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 23\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9766666889190674\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9722222089767456\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 27\n",
            "Correctly predicted different pixels: 27\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 44\n",
            "Correctly predicted different pixels: 44\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 47\n",
            "Correctly predicted different pixels: 47\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 4\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9633333086967468\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9300000071525574\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "\n",
            "Testing DataLoader 0:  63%|██████▎   | 27/43 [01:18<00:46,  0.34it/s]DEBUG: compute_accuracy - Accuracy: 0.9333333373069763\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 7\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9333333373069763\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9255555272102356\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.2844444513320923\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 202\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.3611111044883728\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 171\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6666666865348816\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 76\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9833333492279053\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 121\n",
            "Correctly predicted different pixels: 106\n",
            "Calculated accuracy: 0.8760330578512396\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 71\n",
            "Correctly predicted different pixels: 65\n",
            "Calculated accuracy: 0.9154929577464789\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9877777695655823\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 50\n",
            "Correctly predicted different pixels: 47\n",
            "Calculated accuracy: 0.94\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 122\n",
            "Correctly predicted different pixels: 106\n",
            "Calculated accuracy: 0.8688524590163934\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 91\n",
            "Correctly predicted different pixels: 82\n",
            "Calculated accuracy: 0.9010989010989011\n",
            "DEBUG: compute_accuracy - Accuracy: 0.945555567741394\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.949999988079071\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9666666388511658\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 54\n",
            "Correctly predicted different pixels: 27\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.95333331823349\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 71\n",
            "Correctly predicted different pixels: 32\n",
            "Calculated accuracy: 0.4507042253521127\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9388889074325562\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 97\n",
            "Correctly predicted different pixels: 47\n",
            "Calculated accuracy: 0.4845360824742268\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9266666769981384\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 28\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.897777795791626\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 46\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 7\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 15\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9611111283302307\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 42\n",
            "Correctly predicted different pixels: 7\n",
            "Calculated accuracy: 0.16666666666666666\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9766666889190674\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9333333373069763\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 62\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.0967741935483871\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7866666913032532\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 208\n",
            "Correctly predicted different pixels: 16\n",
            "Calculated accuracy: 0.07692307692307693\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "\n",
            "Testing DataLoader 0:  65%|██████▌   | 28/43 [01:21<00:43,  0.34it/s]DEBUG: compute_accuracy - Accuracy: 0.9666666388511658\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 4\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 254\n",
            "Correctly predicted different pixels: 240\n",
            "Calculated accuracy: 0.9448818897637795\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9766666889190674\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 251\n",
            "Correctly predicted different pixels: 235\n",
            "Calculated accuracy: 0.9362549800796812\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 316\n",
            "Correctly predicted different pixels: 297\n",
            "Calculated accuracy: 0.939873417721519\n",
            "DEBUG: compute_accuracy - Accuracy: 0.0\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 100\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.0\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 117\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.0\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 34\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.0\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 59\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 34\n",
            "Calculated accuracy: 0.85\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 39\n",
            "Correctly predicted different pixels: 33\n",
            "Calculated accuracy: 0.8461538461538461\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 39\n",
            "Correctly predicted different pixels: 34\n",
            "Calculated accuracy: 0.8717948717948718\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 56\n",
            "Correctly predicted different pixels: 40\n",
            "Calculated accuracy: 0.7142857142857143\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 41\n",
            "Correctly predicted different pixels: 30\n",
            "Calculated accuracy: 0.7317073170731707\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9766666889190674\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 52\n",
            "Correctly predicted different pixels: 31\n",
            "Calculated accuracy: 0.5961538461538461\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9688888788223267\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 69\n",
            "Correctly predicted different pixels: 43\n",
            "Calculated accuracy: 0.6231884057971014\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9644444584846497\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 80\n",
            "Correctly predicted different pixels: 48\n",
            "Calculated accuracy: 0.6\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9788888692855835\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 52\n",
            "Correctly predicted different pixels: 33\n",
            "Calculated accuracy: 0.6346153846153846\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 11\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9788888692855835\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 11\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9766666889190674\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9666666388511658\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9399999976158142\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 25\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9844444394111633\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 10\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 7\n",
            "Calculated accuracy: 0.4375\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7688888907432556\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 100\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7688888907432556\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 79\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7744444608688354\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 94\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "\n",
            "Testing DataLoader 0:  67%|██████▋   | 29/43 [01:24<00:40,  0.35it/s]DEBUG: compute_accuracy - Accuracy: 0.8922222256660461\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 93\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9422222375869751\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 49\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9066666960716248\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 81\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9666666388511658\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 57\n",
            "Correctly predicted different pixels: 28\n",
            "Calculated accuracy: 0.49122807017543857\n",
            "DEBUG: compute_accuracy - Accuracy: 0.95333331823349\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 77\n",
            "Correctly predicted different pixels: 37\n",
            "Calculated accuracy: 0.4805194805194805\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9666666388511658\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 50\n",
            "Correctly predicted different pixels: 22\n",
            "Calculated accuracy: 0.44\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9666666388511658\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 56\n",
            "Correctly predicted different pixels: 26\n",
            "Calculated accuracy: 0.4642857142857143\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 71\n",
            "Correctly predicted different pixels: 62\n",
            "Calculated accuracy: 0.8732394366197183\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 34\n",
            "Correctly predicted different pixels: 29\n",
            "Calculated accuracy: 0.8529411764705882\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 34\n",
            "Calculated accuracy: 0.85\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 12\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.4444444444444444\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 22\n",
            "Correctly predicted different pixels: 11\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.699999988079071\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 32\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.4699999988079071\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.75\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 30\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 48\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 48\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 48\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9622222185134888\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 19\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9177777767181396\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 54\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9844444394111633\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9722222089767456\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9722222089767456\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 19\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.851111114025116\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 44\n",
            "Correctly predicted different pixels: 20\n",
            "Calculated accuracy: 0.45454545454545453\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8266666531562805\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 52\n",
            "Correctly predicted different pixels: 18\n",
            "Calculated accuracy: 0.34615384615384615\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8533333539962769\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 44\n",
            "Correctly predicted different pixels: 16\n",
            "Calculated accuracy: 0.36363636363636365\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9377777576446533\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 24\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9288889169692993\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 21\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8822222352027893\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 36\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9655555486679077\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 23\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.2608695652173913\n",
            "\n",
            "Testing DataLoader 0:  70%|██████▉   | 30/43 [01:26<00:37,  0.35it/s]DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 3\n",
            "Calculated accuracy: 0.16666666666666666\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9366666674613953\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 48\n",
            "Correctly predicted different pixels: 9\n",
            "Calculated accuracy: 0.1875\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9266666769981384\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 5\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9122222065925598\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9177777767181396\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 26\n",
            "Correctly predicted different pixels: 12\n",
            "Calculated accuracy: 0.46153846153846156\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 23\n",
            "Correctly predicted different pixels: 16\n",
            "Calculated accuracy: 0.6956521739130435\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 26\n",
            "Correctly predicted different pixels: 12\n",
            "Calculated accuracy: 0.46153846153846156\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 22\n",
            "Correctly predicted different pixels: 10\n",
            "Calculated accuracy: 0.45454545454545453\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 19\n",
            "Correctly predicted different pixels: 11\n",
            "Calculated accuracy: 0.5789473684210527\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 11\n",
            "Calculated accuracy: 0.6470588235294118\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 23\n",
            "Correctly predicted different pixels: 11\n",
            "Calculated accuracy: 0.4782608695652174\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9111111164093018\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 64\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9111111164093018\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 64\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9111111164093018\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 64\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9111111164093018\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 64\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8822222352027893\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9366666674613953\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9399999976158142\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9322222471237183\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 26\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9166666865348816\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 42\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9144444465637207\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.996666669845581\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 15\n",
            "Correctly predicted different pixels: 12\n",
            "Calculated accuracy: 0.8\n",
            "DEBUG: compute_accuracy - Accuracy: 0.996666669845581\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 15\n",
            "Correctly predicted different pixels: 12\n",
            "Calculated accuracy: 0.8\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9977777600288391\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 10\n",
            "Calculated accuracy: 0.8333333333333334\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.3333333333333333\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 9\n",
            "Calculated accuracy: 0.42857142857142855\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 13\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.38461538461538464\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 271\n",
            "Correctly predicted different pixels: 263\n",
            "Calculated accuracy: 0.9704797047970479\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 305\n",
            "Correctly predicted different pixels: 297\n",
            "Calculated accuracy: 0.9737704918032787\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 15\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "\n",
            "Testing DataLoader 0:  72%|███████▏  | 31/43 [01:29<00:34,  0.35it/s]DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9944444298744202\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 4\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.996666669845581\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 2\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.996666669845581\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 2\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9944444298744202\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 4\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9577777981758118\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 39\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.02564102564102564\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.125\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.07142857142857142\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 252\n",
            "Correctly predicted different pixels: 243\n",
            "Calculated accuracy: 0.9642857142857143\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 211\n",
            "Correctly predicted different pixels: 205\n",
            "Calculated accuracy: 0.9715639810426541\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 296\n",
            "Correctly predicted different pixels: 292\n",
            "Calculated accuracy: 0.9864864864864865\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9155555367469788\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9144444465637207\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9133333563804626\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 72\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 72\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 72\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9111111164093018\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 70\n",
            "Correctly predicted different pixels: 2\n",
            "Calculated accuracy: 0.02857142857142857\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8844444155693054\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 82\n",
            "Correctly predicted different pixels: 2\n",
            "Calculated accuracy: 0.024390243902439025\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8933333158493042\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 78\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.07692307692307693\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 77\n",
            "Correctly predicted different pixels: 56\n",
            "Calculated accuracy: 0.7272727272727273\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9622222185134888\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 94\n",
            "Correctly predicted different pixels: 61\n",
            "Calculated accuracy: 0.648936170212766\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9288889169692993\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 84\n",
            "Correctly predicted different pixels: 34\n",
            "Calculated accuracy: 0.40476190476190477\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 113\n",
            "Correctly predicted different pixels: 39\n",
            "Calculated accuracy: 0.34513274336283184\n",
            "DEBUG: compute_accuracy - Accuracy: 0.1899999976158142\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 79\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.1899999976158142\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 84\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.1899999976158142\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 60\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8311111330986023\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 47\n",
            "Correctly predicted different pixels: 14\n",
            "Calculated accuracy: 0.2978723404255319\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8377777934074402\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 60\n",
            "Correctly predicted different pixels: 28\n",
            "Calculated accuracy: 0.4666666666666667\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8922222256660461\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 46\n",
            "Correctly predicted different pixels: 27\n",
            "Calculated accuracy: 0.5869565217391305\n",
            "\n",
            "Testing DataLoader 0:  74%|███████▍  | 32/43 [01:31<00:31,  0.35it/s]DEBUG: compute_accuracy - Accuracy: 0.9788888692855835\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9766666889190674\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 13\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9644444584846497\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9277777671813965\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 38\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9466666579246521\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 27\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9355555772781372\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 33\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.996666669845581\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 22\n",
            "Calculated accuracy: 0.9166666666666666\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9944444298744202\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 29\n",
            "Correctly predicted different pixels: 25\n",
            "Calculated accuracy: 0.8620689655172413\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 35\n",
            "Correctly predicted different pixels: 31\n",
            "Calculated accuracy: 0.8857142857142857\n",
            "DEBUG: compute_accuracy - Accuracy: 0.949999988079071\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 44\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9433333277702332\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 50\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.846666693687439\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 135\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9300000071525574\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 62\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8911111354827881\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 84\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9399999976158142\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.3333333333333333\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.3333333333333333\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.3333333333333333\n",
            "DEBUG: compute_accuracy - Accuracy: 0.0\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 68\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.0\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 92\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.0\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 46\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9622222185134888\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 11\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9399999976158142\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 48\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 11\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.09090909090909091\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9511111378669739\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8577777743339539\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 128\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.03125\n",
            "\n",
            "Testing DataLoader 0:  77%|███████▋  | 33/43 [01:34<00:28,  0.35it/s]DEBUG: compute_accuracy - Accuracy: 0.8577777743339539\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 128\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.03125\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 20\n",
            "Calculated accuracy: 0.8333333333333334\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 22\n",
            "Correctly predicted different pixels: 18\n",
            "Calculated accuracy: 0.8181818181818182\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 32\n",
            "Correctly predicted different pixels: 26\n",
            "Calculated accuracy: 0.8125\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9844444394111633\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9711111187934875\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9788888692855835\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 50\n",
            "Correctly predicted different pixels: 34\n",
            "Calculated accuracy: 0.68\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9744444489479065\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 52\n",
            "Correctly predicted different pixels: 39\n",
            "Calculated accuracy: 0.75\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 32\n",
            "Correctly predicted different pixels: 25\n",
            "Calculated accuracy: 0.78125\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9744444489479065\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 69\n",
            "Correctly predicted different pixels: 46\n",
            "Calculated accuracy: 0.6666666666666666\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9522222280502319\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 23\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9366666674613953\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9222221970558167\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 28\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9399999976158142\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 33\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9288889169692993\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 42\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9288889169692993\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 42\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9877777695655823\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 10\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9877777695655823\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9877777695655823\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 7\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 28\n",
            "Correctly predicted different pixels: 16\n",
            "Calculated accuracy: 0.5714285714285714\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 35\n",
            "Correctly predicted different pixels: 17\n",
            "Calculated accuracy: 0.4857142857142857\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 34\n",
            "Correctly predicted different pixels: 16\n",
            "Calculated accuracy: 0.47058823529411764\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9766666889190674\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 38\n",
            "Correctly predicted different pixels: 17\n",
            "Calculated accuracy: 0.4473684210526316\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 67\n",
            "Correctly predicted different pixels: 32\n",
            "Calculated accuracy: 0.47761194029850745\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 20\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9655555486679077\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 55\n",
            "Correctly predicted different pixels: 25\n",
            "Calculated accuracy: 0.45454545454545453\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9566666483879089\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 7\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9466666579246521\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.2857142857142857\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9622222185134888\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "\n",
            "Testing DataLoader 0:  79%|███████▉  | 34/43 [01:37<00:25,  0.35it/s]DEBUG: compute_accuracy - Accuracy: 0.8733333349227905\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 103\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8788889050483704\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 101\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9522222280502319\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9311110973358154\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 32\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9200000166893005\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 31\n",
            "Correctly predicted different pixels: 23\n",
            "Calculated accuracy: 0.7419354838709677\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 35\n",
            "Correctly predicted different pixels: 25\n",
            "Calculated accuracy: 0.7142857142857143\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 35\n",
            "Correctly predicted different pixels: 25\n",
            "Calculated accuracy: 0.7142857142857143\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8688889145851135\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 23\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8933333158493042\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 26\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 28\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 78\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8399999737739563\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 141\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 0\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 0\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 29\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 30\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 183\n",
            "Correctly predicted different pixels: 161\n",
            "Calculated accuracy: 0.8797814207650273\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 101\n",
            "Correctly predicted different pixels: 94\n",
            "Calculated accuracy: 0.9306930693069307\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 153\n",
            "Correctly predicted different pixels: 139\n",
            "Calculated accuracy: 0.9084967320261438\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 58\n",
            "Correctly predicted different pixels: 48\n",
            "Calculated accuracy: 0.8275862068965517\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 70\n",
            "Correctly predicted different pixels: 53\n",
            "Calculated accuracy: 0.7571428571428571\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 54\n",
            "Correctly predicted different pixels: 45\n",
            "Calculated accuracy: 0.8333333333333334\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 34\n",
            "Correctly predicted different pixels: 27\n",
            "Calculated accuracy: 0.7941176470588235\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9977777600288391\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.8\n",
            "DEBUG: compute_accuracy - Accuracy: 0.996666669845581\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 11\n",
            "Calculated accuracy: 0.7857142857142857\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 14\n",
            "Calculated accuracy: 0.7777777777777778\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 16\n",
            "Calculated accuracy: 0.8\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 19\n",
            "Correctly predicted different pixels: 15\n",
            "Calculated accuracy: 0.7894736842105263\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9944444298744202\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 22\n",
            "Correctly predicted different pixels: 17\n",
            "Calculated accuracy: 0.7727272727272727\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9466666579246521\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 30\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 0\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 1.0\n",
            "\n",
            "Testing DataLoader 0:  81%|████████▏ | 35/43 [01:39<00:22,  0.35it/s]DEBUG: compute_accuracy - Accuracy: 0.8688889145851135\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 69\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.846666693687439\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 72\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8377777934074402\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 67\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8411111235618591\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 75\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8455555438995361\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 28\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9688888788223267\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9677777886390686\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7344444394111633\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 227\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9188888669013977\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 69\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8588888645172119\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 119\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 46\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9422222375869751\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 26\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9144444465637207\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 38\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9133333563804626\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 39\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9833333492279053\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 7\n",
            "Calculated accuracy: 0.4117647058823529\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 7\n",
            "Calculated accuracy: 0.3333333333333333\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9844444394111633\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 7\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 7\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.2244444489479065\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 888\n",
            "Correctly predicted different pixels: 201\n",
            "Calculated accuracy: 0.22635135135135134\n",
            "DEBUG: compute_accuracy - Accuracy: 0.4300000071525574\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 896\n",
            "Correctly predicted different pixels: 387\n",
            "Calculated accuracy: 0.43191964285714285\n",
            "DEBUG: compute_accuracy - Accuracy: 0.1922222226858139\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 881\n",
            "Correctly predicted different pixels: 171\n",
            "Calculated accuracy: 0.19409761634506242\n",
            "DEBUG: compute_accuracy - Accuracy: 0.15777777135372162\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 897\n",
            "Correctly predicted different pixels: 140\n",
            "Calculated accuracy: 0.15607580824972128\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9288889169692993\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 20\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9444444179534912\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 12\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9744444489479065\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 3\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8266666531562805\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8388888835906982\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8288888931274414\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.5714285714285714\n",
            "\n",
            "Testing DataLoader 0:  84%|████████▎ | 36/43 [01:42<00:19,  0.35it/s]DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 13\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.38461538461538464\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 13\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.46153846153846156\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.6\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 194\n",
            "Correctly predicted different pixels: 191\n",
            "Calculated accuracy: 0.9845360824742269\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 167\n",
            "Correctly predicted different pixels: 162\n",
            "Calculated accuracy: 0.9700598802395209\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 209\n",
            "Correctly predicted different pixels: 204\n",
            "Calculated accuracy: 0.9760765550239234\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 223\n",
            "Correctly predicted different pixels: 203\n",
            "Calculated accuracy: 0.9103139013452914\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9666666388511658\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 12\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9788888692855835\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 7\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9877777695655823\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 4\n",
            "Correctly predicted different pixels: 2\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8911111354827881\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8799999952316284\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8888888955116272\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9466666579246521\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 53\n",
            "Correctly predicted different pixels: 13\n",
            "Calculated accuracy: 0.24528301886792453\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9411110877990723\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 74\n",
            "Correctly predicted different pixels: 22\n",
            "Calculated accuracy: 0.2972972972972973\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.2222222222222222\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9944444298744202\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 12\n",
            "Calculated accuracy: 0.7058823529411765\n",
            "DEBUG: compute_accuracy - Accuracy: 0.996666669845581\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 17\n",
            "Calculated accuracy: 0.85\n",
            "DEBUG: compute_accuracy - Accuracy: 0.996666669845581\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 19\n",
            "Correctly predicted different pixels: 16\n",
            "Calculated accuracy: 0.8421052631578947\n",
            "DEBUG: compute_accuracy - Accuracy: 0.996666669845581\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 18\n",
            "Calculated accuracy: 0.8571428571428571\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9466666579246521\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 43\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9466666579246521\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 43\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9366666674613953\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 52\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9466666579246521\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 48\n",
            "Correctly predicted different pixels: 24\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9288889169692993\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 88\n",
            "Correctly predicted different pixels: 44\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9333333373069763\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 80\n",
            "Correctly predicted different pixels: 40\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8166666626930237\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 216\n",
            "Correctly predicted different pixels: 59\n",
            "Calculated accuracy: 0.27314814814814814\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8188889026641846\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 216\n",
            "Correctly predicted different pixels: 60\n",
            "Calculated accuracy: 0.2777777777777778\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 216\n",
            "Correctly predicted different pixels: 216\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 5\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 7\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "\n",
            "Testing DataLoader 0:  86%|████████▌ | 37/43 [01:45<00:17,  0.35it/s]DEBUG: compute_accuracy - Accuracy: 0.9833333492279053\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 11\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 5\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9333333373069763\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 59\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9388889074325562\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 45\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9644444584846497\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.800000011920929\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 157\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9511111378669739\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 34\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8777777552604675\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 96\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9722222089767456\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9722222089767456\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9722222089767456\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9333333373069763\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 533\n",
            "Correctly predicted different pixels: 477\n",
            "Calculated accuracy: 0.8949343339587242\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9333333373069763\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 561\n",
            "Correctly predicted different pixels: 504\n",
            "Calculated accuracy: 0.8983957219251337\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9622222185134888\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 543\n",
            "Correctly predicted different pixels: 512\n",
            "Calculated accuracy: 0.9429097605893186\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9733333587646484\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 546\n",
            "Correctly predicted different pixels: 528\n",
            "Calculated accuracy: 0.967032967032967\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9522222280502319\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 531\n",
            "Correctly predicted different pixels: 491\n",
            "Calculated accuracy: 0.9246704331450094\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8633333444595337\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 32\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8866666555404663\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 26\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9111111164093018\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9344444274902344\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9399999976158142\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 19\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9555555582046509\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9877777695655823\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 13\n",
            "Calculated accuracy: 0.5416666666666666\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9877777695655823\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 11\n",
            "Calculated accuracy: 0.55\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9877777695655823\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 13\n",
            "Calculated accuracy: 0.5416666666666666\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9577777981758118\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 32\n",
            "Correctly predicted different pixels: 16\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9611111283302307\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 7\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9833333492279053\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6933333277702332\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 77\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.5688889026641846\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 62\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.5922222137451172\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 171\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "\n",
            "Testing DataLoader 0:  88%|████████▊ | 38/43 [01:47<00:14,  0.35it/s]DEBUG: compute_accuracy - Accuracy: 0.9555555582046509\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 37\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9733333587646484\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9644444584846497\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 29\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 52\n",
            "Correctly predicted different pixels: 44\n",
            "Calculated accuracy: 0.8461538461538461\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9833333492279053\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 33\n",
            "Correctly predicted different pixels: 24\n",
            "Calculated accuracy: 0.7272727272727273\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 9\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9766666889190674\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 59\n",
            "Correctly predicted different pixels: 40\n",
            "Calculated accuracy: 0.6779661016949152\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8888888955116272\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 86\n",
            "Correctly predicted different pixels: 10\n",
            "Calculated accuracy: 0.11627906976744186\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 44\n",
            "Correctly predicted different pixels: 14\n",
            "Calculated accuracy: 0.3181818181818182\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 15\n",
            "Correctly predicted different pixels: 10\n",
            "Calculated accuracy: 0.6666666666666666\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 14\n",
            "Calculated accuracy: 0.6666666666666666\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9877777695655823\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 27\n",
            "Calculated accuracy: 0.75\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 24\n",
            "Calculated accuracy: 0.6666666666666666\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9833333492279053\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 56\n",
            "Correctly predicted different pixels: 42\n",
            "Calculated accuracy: 0.75\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 11\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 1.0\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 46\n",
            "Correctly predicted different pixels: 46\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 1.0\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 4\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 1.0\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 16\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 1.0\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 38\n",
            "Correctly predicted different pixels: 38\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7311111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8566666841506958\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 4\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8411111235618591\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.46222221851348877\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 56\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.46222221851348877\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 56\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.46222221851348877\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 65\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 53\n",
            "Correctly predicted different pixels: 37\n",
            "Calculated accuracy: 0.6981132075471698\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 62\n",
            "Correctly predicted different pixels: 45\n",
            "Calculated accuracy: 0.7258064516129032\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9744444489479065\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 66\n",
            "Correctly predicted different pixels: 45\n",
            "Calculated accuracy: 0.6818181818181818\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 59\n",
            "Correctly predicted different pixels: 44\n",
            "Calculated accuracy: 0.7457627118644068\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9766666889190674\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 69\n",
            "Correctly predicted different pixels: 50\n",
            "Calculated accuracy: 0.7246376811594203\n",
            "\n",
            "Testing DataLoader 0:  91%|█████████ | 39/43 [01:50<00:11,  0.35it/s]DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 66\n",
            "Correctly predicted different pixels: 47\n",
            "Calculated accuracy: 0.7121212121212122\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.2\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.1\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9588888883590698\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 15\n",
            "Calculated accuracy: 0.375\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9444444179534912\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 75\n",
            "Correctly predicted different pixels: 32\n",
            "Calculated accuracy: 0.4266666666666667\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9633333086967468\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 60\n",
            "Correctly predicted different pixels: 27\n",
            "Calculated accuracy: 0.45\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 19\n",
            "Calculated accuracy: 0.5277777777777778\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9066666960716248\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 53\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.945555567741394\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.897777795791626\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 47\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8622221946716309\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 78\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.01282051282051282\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8222222328186035\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 92\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8700000047683716\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 67\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7688888907432556\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 88\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.3888888955116272\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 65\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.3888888955116272\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 60\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.3888888955116272\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 41\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9733333587646484\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 60\n",
            "Correctly predicted different pixels: 38\n",
            "Calculated accuracy: 0.6333333333333333\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9711111187934875\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 59\n",
            "Correctly predicted different pixels: 37\n",
            "Calculated accuracy: 0.6271186440677966\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9733333587646484\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 55\n",
            "Correctly predicted different pixels: 39\n",
            "Calculated accuracy: 0.7090909090909091\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9744444489479065\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 53\n",
            "Correctly predicted different pixels: 36\n",
            "Calculated accuracy: 0.6792452830188679\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9766666889190674\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 51\n",
            "Correctly predicted different pixels: 32\n",
            "Calculated accuracy: 0.6274509803921569\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9688888788223267\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 56\n",
            "Correctly predicted different pixels: 34\n",
            "Calculated accuracy: 0.6071428571428571\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 7\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.5714285714285714\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 11\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.36363636363636365\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.4444444444444444\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 7\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.5714285714285714\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 15\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.5333333333333333\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.5714285714285714\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.5714285714285714\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 9\n",
            "Calculated accuracy: 0.5625\n",
            "\n",
            "Testing DataLoader 0:  93%|█████████▎| 40/43 [01:52<00:08,  0.35it/s]DEBUG: compute_accuracy - Accuracy: 0.9944444298744202\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 15\n",
            "Correctly predicted different pixels: 10\n",
            "Calculated accuracy: 0.6666666666666666\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.6666666666666666\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 19\n",
            "Correctly predicted different pixels: 2\n",
            "Calculated accuracy: 0.10526315789473684\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9688888788223267\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 23\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.043478260869565216\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 19\n",
            "Correctly predicted different pixels: 2\n",
            "Calculated accuracy: 0.10526315789473684\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.2\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.07142857142857142\n",
            "DEBUG: compute_accuracy - Accuracy: 0.95333331823349\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.95333331823349\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9711111187934875\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 27\n",
            "Correctly predicted different pixels: 2\n",
            "Calculated accuracy: 0.07407407407407407\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 5\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 2\n",
            "Calculated accuracy: 0.1111111111111111\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8722222447395325\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 25\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8833333253860474\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 30\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8455555438995361\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 37\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8766666650772095\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 38\n",
            "Correctly predicted different pixels: 16\n",
            "Calculated accuracy: 0.42105263157894735\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8933333158493042\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 32\n",
            "Correctly predicted different pixels: 14\n",
            "Calculated accuracy: 0.4375\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8933333158493042\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 54\n",
            "Correctly predicted different pixels: 34\n",
            "Calculated accuracy: 0.6296296296296297\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7288888692855835\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 80\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6777777671813965\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 79\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7277777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 56\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 30\n",
            "Correctly predicted different pixels: 13\n",
            "Calculated accuracy: 0.43333333333333335\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9722222089767456\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 44\n",
            "Correctly predicted different pixels: 19\n",
            "Calculated accuracy: 0.4318181818181818\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 23\n",
            "Correctly predicted different pixels: 11\n",
            "Calculated accuracy: 0.4782608695652174\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 574\n",
            "Correctly predicted different pixels: 567\n",
            "Calculated accuracy: 0.9878048780487805\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8322222232818604\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 572\n",
            "Correctly predicted different pixels: 425\n",
            "Calculated accuracy: 0.743006993006993\n",
            "\n",
            "Testing DataLoader 0:  95%|█████████▌| 41/43 [01:55<00:05,  0.36it/s]DEBUG: compute_accuracy - Accuracy: 0.9244444370269775\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 571\n",
            "Correctly predicted different pixels: 507\n",
            "Calculated accuracy: 0.8879159369527145\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9355555772781372\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 569\n",
            "Correctly predicted different pixels: 518\n",
            "Calculated accuracy: 0.9103690685413005\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9355555772781372\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 572\n",
            "Correctly predicted different pixels: 518\n",
            "Calculated accuracy: 0.9055944055944056\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 7\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 7\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 31\n",
            "Calculated accuracy: 0.775\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 44\n",
            "Correctly predicted different pixels: 37\n",
            "Calculated accuracy: 0.8409090909090909\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 32\n",
            "Calculated accuracy: 0.8\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 13\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.38461538461538464\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 33\n",
            "Correctly predicted different pixels: 13\n",
            "Calculated accuracy: 0.3939393939393939\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9844444394111633\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 30\n",
            "Correctly predicted different pixels: 16\n",
            "Calculated accuracy: 0.5333333333333333\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6833333373069763\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 51\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8399999737739563\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 23\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 23\n",
            "Correctly predicted different pixels: 12\n",
            "Calculated accuracy: 0.5217391304347826\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 19\n",
            "Correctly predicted different pixels: 11\n",
            "Calculated accuracy: 0.5789473684210527\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 15\n",
            "Calculated accuracy: 0.7142857142857143\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8233333230018616\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 140\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9466666579246521\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 33\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.898888885974884\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 72\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9688888788223267\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 19\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8999999761581421\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 43\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9355555772781372\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 29\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9433333277702332\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 26\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.1388888955116272\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.027777777777777776\n",
            "DEBUG: compute_accuracy - Accuracy: 0.13777777552604675\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 72\n",
            "Correctly predicted different pixels: 7\n",
            "Calculated accuracy: 0.09722222222222222\n",
            "DEBUG: compute_accuracy - Accuracy: 0.15777777135372162\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 51\n",
            "Correctly predicted different pixels: 13\n",
            "Calculated accuracy: 0.2549019607843137\n",
            "DEBUG: compute_accuracy - Accuracy: 0.1966666728258133\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 31\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.16129032258064516\n",
            "DEBUG: compute_accuracy - Accuracy: 0.95333331823349\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9377777576446533\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 52\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.058823529411764705\n",
            "\n",
            "Testing DataLoader 0:  98%|█████████▊| 42/43 [01:57<00:02,  0.36it/s]DEBUG: compute_accuracy - Accuracy: 0.9644444584846497\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 34\n",
            "Correctly predicted different pixels: 2\n",
            "Calculated accuracy: 0.058823529411764705\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.1111111111111111\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 13\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.07692307692307693\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.047619047619047616\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.058823529411764705\n",
            "DEBUG: compute_accuracy - Accuracy: 0.46222221851348877\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 11\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.36000001430511475\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8999999761581421\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 82\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.95333331823349\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 39\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8833333253860474\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 95\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9577777981758118\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 33\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9622222185134888\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 29\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9311110973358154\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 32\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9122222065925598\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9433333277702332\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 27\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9544444680213928\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 32\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9711111187934875\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9444444179534912\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 48\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "\n",
            "Testing DataLoader 0: 100%|██████████| 43/43 [01:59<00:00,  0.36it/s]DEBUG: Test epoch end - Avg loss: 0.3664872646331787, Avg accuracy: 0.9048286856023982, Avg diff accuracy: 0.26922056889637347\n",
            "\n",
            "Testing DataLoader 0: 100%|██████████| 43/43 [01:59<00:00,  0.36it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m        Test metric        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       DataLoader 0        \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m  00576224_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9599999785423279     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m00576224_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  009d5c81_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9744443893432617     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m009d5c81_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.21003207564353943    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  00dbd492_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.929444432258606     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m00dbd492_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  03560426_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9796295762062073     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m03560426_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.5188145637512207     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  05a7bcf2_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6566666960716248     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m05a7bcf2_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  0607ce86_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7966666221618652     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m0607ce86_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6599085927009583     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  0692e18c_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9785184860229492     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m0692e18c_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.16984127461910248    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  070dd51e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9611111283302307     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m070dd51e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  08573cc6_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.962592601776123     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m08573cc6_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.06767676770687103    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  0934a4d8_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.37638890743255615    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m0934a4d8_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.37773966789245605    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  09c534e7_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7877777218818665     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m09c534e7_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  0a1d4ef5_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9511110782623291     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m0a1d4ef5_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9168465733528137     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  0a2355a6_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9394444823265076     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m0a2355a6_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  0b17323b_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9938889145851135     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m0b17323b_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  0bb8deee_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9788889288902283     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m0bb8deee_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6813034415245056     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  0becf7df_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9744444489479065     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m0becf7df_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  0c786b71_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9466666579246521     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m0c786b71_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  0c9aba6e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9916666746139526     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m0c9aba6e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.747855007648468     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  0d87d2a6_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9055555462837219     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m0d87d2a6_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  0e671a1a_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9724999666213989     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m0e671a1a_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  0f63c0b9_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8908333778381348     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m0f63c0b9_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  103eff5b_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9416666626930237     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m103eff5b_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  11e1fe23_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.992222249507904     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m11e1fe23_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  12422b43_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9788888692855835     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m12422b43_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  12997ef3_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9844444394111633     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m12997ef3_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.3445091247558594     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  12eac192_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9725000262260437     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m12eac192_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  136b0064_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9822222590446472     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m136b0064_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.711358368396759     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  13713586_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.859259307384491     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m13713586_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  137f0df0_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9185185432434082     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m137f0df0_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  140c817e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8625926375389099     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m140c817e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  14754a24_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8630555272102356     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m14754a24_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  15113be4_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6255555748939514     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m15113be4_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  15663ba9_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9422222971916199     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m15663ba9_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  15696249_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9700000286102295     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m15696249_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m          0.1875           \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  16b78196_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7916666865348816     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m16b78196_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.4842342138290405     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  17b80ad2_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9611111283302307     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m17b80ad2_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  17cae0c1_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9700000286102295     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m17cae0c1_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  18419cfa_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9344444274902344     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m18419cfa_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  184a9768_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8522222638130188     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m184a9768_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.575104296207428     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  195ba7dc_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9758332967758179     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m195ba7dc_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.5054347515106201     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  1990f7a8_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9740740656852722     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m1990f7a8_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.5            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  19bb5feb_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9729630351066589     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m19bb5feb_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7311635613441467     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  1a2e2828_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9986666440963745     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m1a2e2828_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9834964871406555     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  1a6449f1_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9829629063606262     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m1a6449f1_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9130600094795227     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  1acc24af_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.964722216129303     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m1acc24af_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  1c02dbbe_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.860370397567749     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m1c02dbbe_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.06207104027271271    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  1c0d0a4b_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9825925827026367     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m1c0d0a4b_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.595678985118866     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  1c56ad9f_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9541666507720947     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m1c56ad9f_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.5            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  1d0a4b61_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.3055555522441864     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m1d0a4b61_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  1d398264_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9462962746620178     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m1d398264_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  1da012fc_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9105556011199951     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m1da012fc_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  1e81d6f9_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9681481719017029     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m1e81d6f9_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            1.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  1e97544e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.41296300292015076    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m1e97544e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  2037f2c7_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9900000095367432     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m2037f2c7_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9334214329719543     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  2072aba6_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9807407259941101     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m2072aba6_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.01587301678955555    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  20818e16_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9385185241699219     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m20818e16_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.723113477230072     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  20981f0e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9681481719017029     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m20981f0e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.5            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  212895b5_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9196296334266663     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m212895b5_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  21f83797_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9238889217376709     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m21f83797_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  22a4bbc2_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9433333277702332     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m22a4bbc2_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  25094a63_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.1827777773141861     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m25094a63_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  2546ccf6_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8550000190734863     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m2546ccf6_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  256b0a75_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6666666865348816     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m256b0a75_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  2685904e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.965925931930542     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m2685904e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  2697da3f_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9511110782623291     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m2697da3f_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.16602009534835815    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  2753e76c_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9900000095367432     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m2753e76c_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.899422824382782     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  27a77e38_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9807407259941101     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m27a77e38_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  27f8ce4f_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9650000333786011     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m27f8ce4f_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.11249999701976776    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  281123b4_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9829630255699158     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m281123b4_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7146536707878113     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  292dd178_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9081481099128723     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m292dd178_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  29700607_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9618518948554993     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m29700607_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  2a5f8217_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9774073958396912     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m2a5f8217_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  2b01abd0_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.970740795135498     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m2b01abd0_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  2c0b0aff_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9119444489479065     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m2c0b0aff_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7577368021011353     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  2c737e39_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9840741157531738     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m2c737e39_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.13650794327259064    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  2f0c5170_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9674074053764343     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m2f0c5170_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9186174869537354     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  310f3251_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9700000882148743     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m310f3251_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  3194b014_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9770370125770569     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m3194b014_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9225044250488281     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  319f2597_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6277777552604675     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m319f2597_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9736223220825195     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  31adaf00_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9307407736778259     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m31adaf00_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  31d5ba1a_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9928889274597168     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m31d5ba1a_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6540936231613159     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  32e9702f_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9548148512840271     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m32e9702f_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  332efdb3_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9533333778381348     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m332efdb3_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  3391f8c0_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9824999570846558     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m3391f8c0_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.3541666865348816     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  33b52de3_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8538888692855835     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m33b52de3_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  3490cc26_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9061111211776733     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m3490cc26_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  34b99a2b_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9883333444595337     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m34b99a2b_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.629668653011322     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  351d6448_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9927777647972107     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m351d6448_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8858424425125122     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  358ba94e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9744444489479065     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m358ba94e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8644062280654907     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  37d3e8b2_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8788889050483704     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m37d3e8b2_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  3979b1a8_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8888888955116272     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m3979b1a8_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  3a301edc_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9024444818496704     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m3a301edc_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  3b4c2228_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9979999661445618     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m3b4c2228_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8947456479072571     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  3d31c5b3_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9794444441795349     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m3d31c5b3_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6079409122467041     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  3ed85e70_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6381481885910034     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m3ed85e70_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  3ee1011a_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9537037014961243     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m3ee1011a_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.20636117458343506    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  3f23242b_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9550000429153442     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m3f23242b_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  40f6cd08_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6270370483398438     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m40f6cd08_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  414297c0_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8959259390830994     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m414297c0_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.4695725440979004     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  423a55dc_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9855555295944214     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m423a55dc_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.5216470956802368     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  42918530_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.815833330154419     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m42918530_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  42a15761_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9062963128089905     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m42a15761_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.5            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  4364c1c4_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8177778124809265     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m4364c1c4_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  456873bc_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9514815211296082     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m456873bc_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7703775763511658     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  45737921_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9733333587646484     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m45737921_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  45bbe264_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.932962954044342     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m45bbe264_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  477d2879_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8122222423553467     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m477d2879_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  47996f11_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.13833333551883698    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m47996f11_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.10620684921741486    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  48131b3c_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9733333587646484     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m48131b3c_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.11290545016527176    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  4852f2fa_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9853333234786987     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m4852f2fa_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.36084944009780884    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  48f8583b_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9798148274421692     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m48f8583b_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.29629629850387573    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  4aab4007_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.12888889014720917    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m4aab4007_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  4acc7107_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9758333563804626     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m4acc7107_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.4823917746543884     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  4b6b68e5_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8622221946716309     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m4b6b68e5_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.03787878900766373    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  4c177718_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9872222542762756     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m4c177718_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7471552491188049     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  4cd1b7b2_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9822222590446472     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m4cd1b7b2_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  4e45f183_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7507407665252686     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m4e45f183_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.013888888992369175    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  4e469f39_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9662962555885315     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m4e469f39_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  4f537728_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7972222566604614     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m4f537728_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  4ff4c9da_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6259259581565857     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m4ff4c9da_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  505fff84_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9913333654403687     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m505fff84_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8910254240036011     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  506d28a5_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9822221994400024     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m506d28a5_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.47752460837364197    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  50a16a69_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8159258961677551     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m50a16a69_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.03999999910593033    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  50aad11f_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9785184860229492     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m50aad11f_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.4671497642993927     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  50f325b5_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.801944375038147     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m50f325b5_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  516b51b7_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9188888669013977     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m516b51b7_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  5207a7b5_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9559259414672852     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m5207a7b5_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  5289ad53_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9755555391311646     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m5289ad53_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8811259269714355     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  52fd389e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7137036323547363     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m52fd389e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  54db823b_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9066666960716248     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m54db823b_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            1.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  55059096_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9744443893432617     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m55059096_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  551d5bf1_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7644444704055786     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m551d5bf1_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  55783887_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8462222218513489     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m55783887_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.10000000149011612    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  575b1a71_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8888888955116272     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m575b1a71_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  5783df64_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9900000095367432     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m5783df64_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.45825162529945374    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  5833af48_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8825926184654236     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m5833af48_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6010026335716248     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  58743b76_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9472222328186035     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m58743b76_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  58e15b12_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9170370697975159     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m58e15b12_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  59341089_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.960277795791626     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m59341089_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  5a5a2103_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8194444179534912     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m5a5a2103_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.04545454680919647    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  5af49b42_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9737036824226379     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m5af49b42_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  5b526a93_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.90666663646698      \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m5b526a93_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  5b692c0f_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9133332967758179     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m5b692c0f_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.23863637447357178    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  5b6cbef5_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9197778701782227     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m5b6cbef5_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.09092767536640167    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  5d2a5c43_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9784444570541382     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m5d2a5c43_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.47774338722229004    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  5ffb2104_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.987407386302948     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m5ffb2104_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.4901960790157318     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  604001fa_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9819444417953491     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m604001fa_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.2735389471054077     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  60a26a3e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9718518257141113     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m60a26a3e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  60c09cac_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9822221994400024     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m60c09cac_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.02777777798473835    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  626c0bcc_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9825925827026367     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m626c0bcc_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  62ab2642_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.93666672706604      \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m62ab2642_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  62b74c02_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9559259414672852     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m62b74c02_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  639f5a19_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7777777910232544     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m639f5a19_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  642248e4_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9570370316505432     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m642248e4_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  642d658d_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9611111283302307     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m642d658d_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9283973574638367     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  64a7c07e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9892592430114746     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m64a7c07e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.5            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  66e6c45b_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.995555579662323     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m66e6c45b_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.5            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  66f2d22f_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.991944432258606     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m66f2d22f_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7562196850776672     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  67636eac_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9862963557243347     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m67636eac_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.46666666865348816    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  67b4a34d_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9696295857429504     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m67b4a34d_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9138374328613281     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  67c52801_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9786111116409302     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m67c52801_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.5            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  68b67ca3_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9944444298744202     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m68b67ca3_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.5            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  692cd3b6_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9007408022880554     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m692cd3b6_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  695367ec_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8937036991119385     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m695367ec_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.05552127584815025    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  696d4842_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.962592601776123     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m696d4842_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  69889d6e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.980555534362793     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m69889d6e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  6a11f6da_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.975777804851532     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m6a11f6da_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.5782161355018616     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  6ad5bdfd_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9814814925193787     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m6ad5bdfd_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.45766592025756836    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  6df30ad6_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.991777777671814     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m6df30ad6_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.5457017421722412     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  6ea4a07e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9937036633491516     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m6ea4a07e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.37037038803100586    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  6f473927_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9677777886390686     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m6f473927_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.21378621459007263    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  7039b2d7_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9840741157531738     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m7039b2d7_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9842607378959656     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  705a3229_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9844444394111633     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m705a3229_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  712bf12e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9170370101928711     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m712bf12e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  72207abc_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9925925731658936     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m72207abc_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  72a961c9_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9844444990158081     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m72a961c9_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  73182012_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9881481528282166     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m73182012_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8835263848304749     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  73c3b0d8_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9869444370269775     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m73c3b0d8_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.2957516312599182     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  73ccf9c2_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9881481528282166     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m73ccf9c2_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8363578915596008     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  759f3fd3_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8427777886390686     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m759f3fd3_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  762cd429_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8118519186973572     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m762cd429_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  770cc55f_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9769444465637207     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m770cc55f_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  782b5218_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9344444274902344     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m782b5218_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.4673832952976227     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  79369cc6_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8040741086006165     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m79369cc6_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  7953d61e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9288889169692993     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m7953d61e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  79fb03f4_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.93833327293396      \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m79fb03f4_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  7bb29440_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9735555648803711     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m7bb29440_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8471860885620117     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  7c8af763_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8888888955116272     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m7c8af763_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  7c9b52a0_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9074074625968933     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m7c9b52a0_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6268526911735535     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  7d18a6fb_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9770370125770569     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m7d18a6fb_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7752125263214111     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  7d1f7ee8_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8325925469398499     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m7d1f7ee8_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  7d419a02_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.851111114025116     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m7d419a02_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  7e02026e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9000000357627869     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m7e02026e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  7ee1c6ea_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9133333563804626     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m7ee1c6ea_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  817e6c09_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9760000109672546     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m817e6c09_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  81c0276b_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9933333396911621     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m81c0276b_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9544203281402588     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  833dafe3_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9644444584846497     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m833dafe3_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.07334525883197784    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  845d6e51_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9477777481079102     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m845d6e51_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  84db8fc4_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8888888955116272     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m84db8fc4_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  84f2aca1_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9650000333786011     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m84f2aca1_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  8597cfd7_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.995555579662323     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m8597cfd7_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8174242377281189     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  85b81ff1_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.875           \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m85b81ff1_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.5            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  85fa5666_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9622222185134888     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m85fa5666_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  8719f442_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9422221779823303     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m8719f442_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  88207623_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9388889074325562     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m88207623_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  891232d6_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8897222280502319     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m891232d6_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  896d5239_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8825926184654236     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m896d5239_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  8a371977_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.43888890743255615    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m8a371977_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  8b28cd80_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.948888897895813     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m8b28cd80_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.017298799008131027    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  8ba14f53_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9938888549804688     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m8ba14f53_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8179367184638977     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  8cb8642d_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9296296238899231     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m8cb8642d_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7093300819396973     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  8dae5dfc_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8263888359069824     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m8dae5dfc_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  8e2edd66_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9814814925193787     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m8e2edd66_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.2586754262447357     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  8ee62060_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9788889288902283     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m8ee62060_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.5            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  8fbca751_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9659258723258972     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m8fbca751_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  90347967_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9933333396911621     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m90347967_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.5            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  903d1b4a_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7155555486679077     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m903d1b4a_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  9110e3c5_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9960317611694336     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m9110e3c5_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8651400804519653     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  917bccba_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9644444584846497     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m917bccba_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6146110892295837     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  929ab4e9_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.3613888919353485     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m929ab4e9_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  92e50de0_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6677777767181396     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m92e50de0_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  9356391f_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.90666663646698      \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m9356391f_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  93b4f4b3_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9233333468437195     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m93b4f4b3_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.40796583890914917    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  93c31fbe_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9399999976158142     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m93c31fbe_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.3983488082885742     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  94133066_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8922222256660461     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m94133066_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.48462045192718506    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  94414823_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9577777981758118     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m94414823_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  94be5b80_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9411110877990723     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m94be5b80_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.2946428656578064     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  95a58926_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8614814877510071     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m95a58926_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.5745627284049988     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  963f59bc_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9786111116409302     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m963f59bc_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  96a8c0cd_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9350000023841858     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m96a8c0cd_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  97239e3d_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7988889217376709     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m97239e3d_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  9772c176_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7477777600288391     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m9772c176_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  981571dc_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.00027777778450399637   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m981571dc_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  992798f6_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9863889217376709     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m992798f6_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  99306f82_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9162963032722473     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m99306f82_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  9a4bb226_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9888889193534851     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m9a4bb226_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7706348896026611     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  9b2a60aa_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.965925931930542     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m9b2a60aa_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  9b365c51_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      0.9670370221138      \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m9b365c51_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.444180965423584     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  9b4c17c4_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8147222995758057     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m9b4c17c4_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  9bebae7a_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9786666631698608     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m9bebae7a_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.33641454577445984    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  9c1e755f_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9461110830307007     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m9c1e755f_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  9c56f360_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9737036824226379     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m9c56f360_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.5            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  9caba7c3_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7659258842468262     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m9caba7c3_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  9ddd00f0_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9533333778381348     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m9ddd00f0_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  9def23fe_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8311111330986023     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m9def23fe_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  9f27f097_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8399999737739563     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m9f27f097_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  a04b2602_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8177778124809265     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36ma04b2602_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  a096bf4d_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7333333492279053     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36ma096bf4d_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  a3f84088_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8686110973358154     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36ma3f84088_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  a406ac07_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.958148181438446     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36ma406ac07_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  a57f2f04_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6633333563804626     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36ma57f2f04_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  a59b95c0_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9160000085830688     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36ma59b95c0_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  a680ac02_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9644444584846497     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36ma680ac02_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6501501202583313     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  a8610ef7_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9766666889190674     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36ma8610ef7_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  a934301b_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9674074053764343     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36ma934301b_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            1.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  aa18de87_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9791666269302368     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36maa18de87_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  aa300dc3_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.930555522441864     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36maa300dc3_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  aa4ec2a5_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.43740740418434143    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36maa4ec2a5_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  aab50785_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9871110916137695     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36maab50785_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9002954363822937     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  ac0c5833_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9518518447875977     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mac0c5833_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  ac2e8ecf_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9529629349708557     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mac2e8ecf_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.4784134328365326     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  ac3e2b04_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9386110901832581     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mac3e2b04_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  ac605cbb_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9875926375389099     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mac605cbb_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  ad7e01d0_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9144444465637207     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mad7e01d0_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.08509097993373871    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  ae58858e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9783333539962769     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mae58858e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  aee291af_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9762962460517883     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36maee291af_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9403367638587952     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  af22c60d_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36maf22c60d_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  af24b4cc_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9929630160331726     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36maf24b4cc_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8559829592704773     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m     avg_test_accuracy     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.904828667640686     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  avg_test_diff_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.2692205607891083     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m       avg_test_loss       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.3664872646331787     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  b0722778_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9844444394111633     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mb0722778_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7229965329170227     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  b0f4d537_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9722222089767456     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mb0f4d537_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6134893894195557     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  b15fca0b_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9675555229187012     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mb15fca0b_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  b1fc8b8e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9851110577583313     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mb1fc8b8e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.48750001192092896    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  b20f7c8b_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7707407474517822     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mb20f7c8b_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  b457fec5_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9137037396430969     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mb457fec5_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  b4a43f3b_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9633333086967468     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mb4a43f3b_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.46900829672813416    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  b7999b51_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9900000095367432     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mb7999b51_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8587267994880676     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  b7cb93ac_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9866666793823242     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mb7cb93ac_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.4814814627170563     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  b7f8a4d8_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6399999856948853     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mb7f8a4d8_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  b7fb29bc_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9100000262260437     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mb7fb29bc_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  b942fd60_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9666666984558105     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mb942fd60_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  b9630600_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8437037467956543     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mb9630600_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.3881119191646576     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  ba9d41b8_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9162963032722473     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mba9d41b8_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            1.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  baf41dbf_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9592592716217041     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mbaf41dbf_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.20501208305358887    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  bb52a14b_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9188888669013977     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mbb52a14b_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  bbb1b8b6_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9852380156517029     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mbbb1b8b6_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.5396488308906555     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  bc4146bd_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9111111164093018     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mbc4146bd_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  bcb3040b_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9196296334266663     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mbcb3040b_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  bd14c3bf_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9211111068725586     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mbd14c3bf_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  be03b35f_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9970369935035706     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mbe03b35f_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8111111521720886     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  bf32578f_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9881481528282166     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mbf32578f_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.3821733891963959     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  bf699163_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9900000095367432     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mbf699163_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9721251130104065     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  bf89d739_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9780555367469788     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mbf89d739_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  c074846d_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9948889017105103     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mc074846d_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  c1990cce_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9785184860229492     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mc1990cce_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.07402319461107254    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  c3202e5a_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9929630160331726     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mc3202e5a_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9741120338439941     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  c35c1b4c_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9144444465637207     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mc35c1b4c_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  c48954c1_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9100000262260437     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mc48954c1_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  c62e2108_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8962963223457336     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mc62e2108_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.04329491779208183    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  c64f1187_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9688888788223267     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mc64f1187_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6881044507026672     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  c658a4bd_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9194444417953491     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mc658a4bd_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.37494730949401855    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  c663677b_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.1899999976158142     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mc663677b_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  c6e1b8da_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8537037372589111     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mc6e1b8da_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.45049849152565      \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  c7d4e6ad_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9777777791023254     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mc7d4e6ad_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  c87289bb_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9436111450195312     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mc87289bb_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  c8b7cc0f_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.995555579662323     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mc8b7cc0f_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8881499767303467     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  c92b942c_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9175000190734863     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mc92b942c_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  c97c0139_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9155555963516235     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mc97c0139_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  ca8de6ea_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9900000095367432     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mca8de6ea_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.3333333432674408     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  ca8f78db_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mca8f78db_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  cad67732_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9740740656852722     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mcad67732_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  cb227835_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9792592525482178     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mcb227835_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  ccd554ac_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9307406544685364     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mccd554ac_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.02556818164885044    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  cd3c21df_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9948148727416992     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mcd3c21df_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8213383555412292     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  ce039d91_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9774999618530273     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mce039d91_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  ce8d95cc_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9802777767181396     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mce8d95cc_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7194792032241821     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  cf133acc_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9370369911193848     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mcf133acc_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  cfb2ce5a_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9325925707817078     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mcfb2ce5a_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  d017b73f_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9883332848548889     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36md017b73f_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.5            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  d19f7514_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9808333516120911     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36md19f7514_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.4937748610973358     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  d282b262_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9677777290344238     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36md282b262_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.4773857891559601     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  d2acf2cb_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9551851749420166     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36md2acf2cb_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.095238097012043     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  d304284e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8761111497879028     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36md304284e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  d37a1ef5_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9344444274902344     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36md37a1ef5_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  d47aa2ff_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9896295666694641     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36md47aa2ff_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7235023379325867     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  d492a647_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8811111450195312     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36md492a647_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  d4b1c2b1_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9442857503890991     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36md4b1c2b1_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.2857142984867096     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  d4c90558_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9829629063606262     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36md4c90558_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9063237309455872     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  d56f2372_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9866666793823242     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36md56f2372_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8060207962989807     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  d5c634a2_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9953967928886414     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36md5c634a2_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7885443568229675     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  d931c21c_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9108333587646484     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36md931c21c_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.25            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  d94c3b52_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8414815068244934     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36md94c3b52_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  da2b0fe3_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9707407355308533     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mda2b0fe3_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  da515329_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8374074101448059     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mda515329_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  dc2aa30b_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9100000262260437     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mdc2aa30b_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  dc2e9a9d_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9233333468437195     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mdc2e9a9d_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  dd2401ed_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9811111092567444     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mdd2401ed_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.43627452850341797    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  de493100_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.25111111998558044    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mde493100_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.2521111071109772     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  df8cc377_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9492592811584473     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mdf8cc377_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.5            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e0fb7511_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8314814567565918     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me0fb7511_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e133d23d_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9926666021347046     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me133d23d_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.5035164952278137     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e1baa8a4_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9894444942474365     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me1baa8a4_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9602466225624084     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e1d2900e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9777777194976807     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me1d2900e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.5            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e2092e0c_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8866667151451111     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me2092e0c_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e21a174a_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9562962651252747     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me21a174a_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.254934161901474     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e345f17b_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9961110949516296     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me345f17b_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8137826919555664     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e4075551_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9433333277702332     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me4075551_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e41c6fd3_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.936296284198761     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me41c6fd3_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.5            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e57337a4_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8762962818145752     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me57337a4_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.5169753432273865     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e5790162_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.988444447517395     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me5790162_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e5c44e8f_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9455555081367493     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me5c44e8f_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e619ca6e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8762962818145752     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me619ca6e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e633a9e5_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9722221493721008     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me633a9e5_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e66aafb8_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9508889317512512     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me66aafb8_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9255886077880859     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e681b708_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8870370388031006     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me681b708_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e69241bd_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9433333277702332     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me69241bd_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e6de6e8f_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9877777695655823     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me6de6e8f_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.5444445013999939     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e74e1818_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9674074053764343     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me74e1818_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.5            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e760a62e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.618148148059845     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me760a62e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e7639916_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9644444584846497     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me7639916_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e78887d1_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9794444441795349     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me78887d1_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6878482103347778     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e7a25a18_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9244444370269775     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me7a25a18_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.2172304391860962     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e7b06bea_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9871110916137695     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me7b06bea_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7000000476837158     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e7dd8335_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9785184860229492     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me7dd8335_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e872b94a_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            1.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me872b94a_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            1.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e88171ec_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8096296787261963     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me88171ec_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e95e3d8e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.46222221851348877    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me95e3d8e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e99362f0_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.978518545627594     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me99362f0_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7147099375724792     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e9ac8c9e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9792592525482178     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me9ac8c9e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.2666666805744171     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e9b4f6fc_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9619444012641907     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me9b4f6fc_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.44486111402511597    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e9bb6954_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9030555486679077     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me9bb6954_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0032051282469183207   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e9c9d9a1_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8203703761100769     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me9c9d9a1_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  ea959feb_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.3888889253139496     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mea959feb_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  ea9794b1_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9729629158973694     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mea9794b1_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.647230327129364     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  ecaa0ec1_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9894444346427917     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mecaa0ec1_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.48773449659347534    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  ed74f2f2_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9935185313224792     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36med74f2f2_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.5953373312950134     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  ed98d772_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9777777791023254     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36med98d772_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.10508663952350616    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  ef26cbf6_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.95333331823349      \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mef26cbf6_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  f0afb749_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9822222590446472     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mf0afb749_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.061728399246931076    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  f0df5ff0_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8670370578765869     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mf0df5ff0_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  f21745ec_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8877778053283691     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mf21745ec_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.4960607588291168     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  f3b10344_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.711481511592865     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mf3b10344_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  f3cdc58f_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9785184860229492     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mf3cdc58f_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.44780412316322327    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  f3e62deb_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9911110997200012     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mf3e62deb_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.5            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  f4081712_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9235555529594421     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mf4081712_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8869382739067078     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  f45f5ca7_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9918518662452698     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mf45f5ca7_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.5            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  f5aa3634_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9911110997200012     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mf5aa3634_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8053030371665955     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  f5c89df1_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9829629063606262     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mf5c89df1_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.437296062707901     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  f823c43c_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7616666555404663     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mf823c43c_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  f83cb3f6_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9807407259941101     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mf83cb3f6_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6049907803535461     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  f8be4b64_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9094444513320923     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mf8be4b64_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  f9a67cb5_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9262962937355042     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mf9a67cb5_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  f9d67f8b_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.15777777135372162    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mf9d67f8b_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.13529807329177856    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  fafd9572_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9700000286102295     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mfafd9572_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  fb791726_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.961017370223999     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mfb791726_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.03614457696676254    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  fc754716_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9844443798065186     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mfc754716_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.07361919432878494    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  fd096ab6_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.41111111640930176    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mfd096ab6_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  fd4b2b02_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9122222065925598     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mfd4b2b02_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  fe9372f3_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9600000977516174     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mfe9372f3_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  fea12743_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9288887977600098     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mfea12743_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  ff72ca3e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9647221565246582     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mff72ca3e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "└─────────────────────────────┴─────────────────────────────┘\n",
            "DEBUG: Logged metrics - Avg test loss: 0.3664872646331787, Avg test accuracy: 0.904828667640686, Avg diff accuracy: 0.2692205607891083\n",
            "DEBUG: Computed complete task accuracy: 0.2344139650872818\n",
            "test_loss: 0.3664872646331787\n",
            "test_accuracy: 0.904828667640686\n",
            "test_diff_accuracy: 0.2692205607891083\n",
            "complete_task_accuracy: 0.2344139650872818\n",
            "DEBUG: Creating wandb Artifact with name: arc_model-epoch_00-val_loss_0\n",
            "DEBUG: Artifact created and logged successfully.\n",
            "\n",
            "Evaluation Errors/Warnings:\n",
            "2024-09-28 23:17:21.343716: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-09-28 23:17:21.348020: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-09-28 23:17:21.362719: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-09-28 23:17:21.387396: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-09-28 23:17:21.394702: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-09-28 23:17:21.412235: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "DEBUG:tensorflow:Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n",
            "2024-09-28 23:17:23.851225: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DEBUG:h5py._conv:Creating converter from 7 to 5\n",
            "DEBUG:h5py._conv:Creating converter from 5 to 7\n",
            "DEBUG:h5py._conv:Creating converter from 7 to 5\n",
            "DEBUG:h5py._conv:Creating converter from 5 to 7\n",
            "DEBUG:git.util:Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'No such file or directory')\n",
            "DEBUG:git.cmd:Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/workspaces/arc-neural-reasoning-model, stdin=None, shell=False, universal_newlines=False)\n",
            "DEBUG:git.cmd:Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/workspaces/arc-neural-reasoning-model, stdin=None, shell=False, universal_newlines=False)\n",
            "wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
            "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/11\" 200 None\n",
            "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/11\" 200 None\n",
            "wandb: Currently logged in as: military-ingram (arc-abolition). Use `wandb login --relogin` to force relogin\n",
            "DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/workspaces/arc-neural-reasoning-model, stdin=<valid stream>, shell=False, universal_newlines=False)\n",
            "wandb: Tracking run with wandb version 0.18.1\n",
            "wandb: Run data is saved locally in /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/wandb/run-20240928_231726-q0tv1k44\n",
            "wandb: Run `wandb offline` to turn off syncing.\n",
            "wandb: Syncing run scaling-test-evaluation-epoch00-val_loss0.37\n",
            "wandb: ⭐️ View project at https://wandb.ai/arc-abolition/arc-evaluation\n",
            "wandb: 🚀 View run at https://wandb.ai/arc-abolition/arc-evaluation/runs/q0tv1k44\n",
            "/workspaces/arc-neural-reasoning-model/gpt2_arc/src/evaluate.py:118: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(args.model_checkpoint, map_location='cpu')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Initialized Attention with n_embd=256, n_head=4\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Initialized FeedForward with n_embd=256\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Initialized TransformerBlock with n_embd=256, n_head=4\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Initialized Attention with n_embd=256, n_head=4\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Initialized FeedForward with n_embd=256\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Initialized TransformerBlock with n_embd=256, n_head=4\n",
            "INFO:__main__:Model moved to device: cpu\n",
            "INFO:__main__:Defined input_size for summary: (1, 1, 100)\n",
            "DEBUG:__main__:Sanitized model_name: arc_model-epoch_00-val_loss_0\n",
            "DEBUG:__main__:Model name contains only valid characters.\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "DEBUG:fsspec.local:open file: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/lightning_logs/version_0/hparams.yaml\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[9, 9, 2,  ..., 4, 3, 2],\n",
            "          [7, 9, 3,  ..., 4, 5, 3],\n",
            "          [3, 2, 9,  ..., 7, 9, 9],\n",
            "          ...,\n",
            "          [7, 7, 9,  ..., 9, 3, 9],\n",
            "          [2, 3, 7,  ..., 5, 9, 7],\n",
            "          [3, 2, 9,  ..., 7, 9, 9]]],\n",
            "\n",
            "\n",
            "        [[[3, 5, 3,  ..., 6, 3, 3],\n",
            "          [5, 3, 3,  ..., 6, 3, 3],\n",
            "          [1, 1, 3,  ..., 5, 5, 3],\n",
            "          ...,\n",
            "          [6, 9, 9,  ..., 3, 9, 9],\n",
            "          [1, 1, 5,  ..., 4, 3, 5],\n",
            "          [1, 1, 3,  ..., 5, 5, 3]]],\n",
            "\n",
            "\n",
            "        [[[1, 9, 4,  ..., 9, 4, 4],\n",
            "          [7, 1, 4,  ..., 9, 4, 4],\n",
            "          [2, 7, 1,  ..., 2, 9, 1],\n",
            "          ...,\n",
            "          [9, 6, 7,  ..., 1, 2, 7],\n",
            "          [7, 2, 7,  ..., 7, 1, 7],\n",
            "          [2, 7, 1,  ..., 2, 9, 1]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('00576224', '00576224', '009d5c81', '009d5c81', '009d5c81', '009d5c81', '009d5c81', '00dbd492', '00dbd492', '00dbd492', '00dbd492', '03560426', '03560426', '03560426', '05a7bcf2', '05a7bcf2', '05a7bcf2', '0607ce86', '0607ce86', '0607ce86', '0692e18c', '0692e18c', '0692e18c', '070dd51e', '070dd51e', '08573cc6', '08573cc6', '08573cc6', '0934a4d8', '0934a4d8', '0934a4d8', '0934a4d8')], batch_idx: 0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('00576224', '00576224', '009d5c81', '009d5c81', '009d5c81', '009d5c81', '009d5c81', '00dbd492', '00dbd492', '00dbd492', '00dbd492', '03560426', '03560426', '03560426', '05a7bcf2', '05a7bcf2', '05a7bcf2', '0607ce86', '0607ce86', '0607ce86', '0692e18c', '0692e18c', '0692e18c', '070dd51e', '070dd51e', '08573cc6', '08573cc6', '08573cc6', '0934a4d8', '0934a4d8', '0934a4d8', '0934a4d8')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.14285714285714285\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.1724137931034483\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.16216216216216217\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.2727272727272727\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5454545454545454\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5238095238095238\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.48717948717948717\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6666666666666666\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6153846153846154\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6976744186046512\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.2\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.14285714285714285\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.16666666666666666\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.09523809523809523\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.07142857142857142\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.03636363636363636\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4782608695652174\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.43526785714285715\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.3002232142857143\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.29720670391061454\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.5816769003868103, Avg accuracy: 0.845625001937151, Avg diff accuracy: 0.21280757454400098\n",
            "/usr/local/python/3.12.1/lib/python3.12/site-packages/pytorch_lightning/utilities/data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 32. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.5816769003868103, avg_accuracy=0.845625001937151, diff_accuracy=0.21280757454400098\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.5816769003868103, 'task_ids': ('00576224', '00576224', '009d5c81', '009d5c81', '009d5c81', '009d5c81', '009d5c81', '00dbd492', '00dbd492', '00dbd492', '00dbd492', '03560426', '03560426', '03560426', '05a7bcf2', '05a7bcf2', '05a7bcf2', '0607ce86', '0607ce86', '0607ce86', '0692e18c', '0692e18c', '0692e18c', '070dd51e', '070dd51e', '08573cc6', '08573cc6', '08573cc6', '0934a4d8', '0934a4d8', '0934a4d8', '0934a4d8'), 'test_accuracy': 0.845625001937151, 'test_diff_accuracy': 0.21280757454400098, '00576224_test_accuracy': 0.9599999785423279, '00576224_test_diff_accuracy': 0.0, '009d5c81_test_accuracy': 0.9822221994400024, '009d5c81_test_diff_accuracy': 0.2727272727272727, '00dbd492_test_accuracy': 0.9177777767181396, '00dbd492_test_diff_accuracy': 0.0, '03560426_test_accuracy': 0.9777777791023254, '03560426_test_diff_accuracy': 0.48717948717948717, '05a7bcf2_test_accuracy': 0.6166666746139526, '05a7bcf2_test_diff_accuracy': 0.0, '0607ce86_test_accuracy': 0.8399999737739563, '0607ce86_test_diff_accuracy': 0.6976744186046512, '0692e18c_test_accuracy': 0.9777777791023254, '0692e18c_test_diff_accuracy': 0.16666666666666666, '070dd51e_test_accuracy': 0.9677777886390686, '070dd51e_test_diff_accuracy': 0.0, '08573cc6_test_accuracy': 0.9399999976158142, '08573cc6_test_diff_accuracy': 0.03636363636363636, '0934a4d8_test_accuracy': 0.29555556178092957, '0934a4d8_test_diff_accuracy': 0.29720670391061454}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.5816769003868103, 'task_ids': ('00576224', '00576224', '009d5c81', '009d5c81', '009d5c81', '009d5c81', '009d5c81', '00dbd492', '00dbd492', '00dbd492', '00dbd492', '03560426', '03560426', '03560426', '05a7bcf2', '05a7bcf2', '05a7bcf2', '0607ce86', '0607ce86', '0607ce86', '0692e18c', '0692e18c', '0692e18c', '070dd51e', '070dd51e', '08573cc6', '08573cc6', '08573cc6', '0934a4d8', '0934a4d8', '0934a4d8', '0934a4d8'), 'test_accuracy': 0.845625001937151, 'test_diff_accuracy': 0.21280757454400098, '00576224_test_accuracy': 0.9599999785423279, '00576224_test_diff_accuracy': 0.0, '009d5c81_test_accuracy': 0.9822221994400024, '009d5c81_test_diff_accuracy': 0.2727272727272727, '00dbd492_test_accuracy': 0.9177777767181396, '00dbd492_test_diff_accuracy': 0.0, '03560426_test_accuracy': 0.9777777791023254, '03560426_test_diff_accuracy': 0.48717948717948717, '05a7bcf2_test_accuracy': 0.6166666746139526, '05a7bcf2_test_diff_accuracy': 0.0, '0607ce86_test_accuracy': 0.8399999737739563, '0607ce86_test_diff_accuracy': 0.6976744186046512, '0692e18c_test_accuracy': 0.9777777791023254, '0692e18c_test_diff_accuracy': 0.16666666666666666, '070dd51e_test_accuracy': 0.9677777886390686, '070dd51e_test_diff_accuracy': 0.0, '08573cc6_test_accuracy': 0.9399999976158142, '08573cc6_test_diff_accuracy': 0.03636363636363636, '0934a4d8_test_accuracy': 0.29555556178092957, '0934a4d8_test_diff_accuracy': 0.29720670391061454}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('09c534e7', '09c534e7', '09c534e7', '0a1d4ef5', '0a1d4ef5', '0a1d4ef5', '0a2355a6', '0a2355a6', '0a2355a6', '0a2355a6', '0b17323b', '0b17323b', '0bb8deee', '0bb8deee', '0bb8deee', '0becf7df', '0becf7df', '0becf7df', '0c786b71', '0c786b71', '0c786b71', '0c9aba6e', '0c9aba6e', '0c9aba6e', '0c9aba6e', '0d87d2a6', '0d87d2a6', '0d87d2a6', '0e671a1a', '0e671a1a', '0e671a1a', '0e671a1a')], batch_idx: 1\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('09c534e7', '09c534e7', '09c534e7', '0a1d4ef5', '0a1d4ef5', '0a1d4ef5', '0a2355a6', '0a2355a6', '0a2355a6', '0a2355a6', '0b17323b', '0b17323b', '0bb8deee', '0bb8deee', '0bb8deee', '0becf7df', '0becf7df', '0becf7df', '0c786b71', '0c786b71', '0c786b71', '0c9aba6e', '0c9aba6e', '0c9aba6e', '0c9aba6e', '0d87d2a6', '0d87d2a6', '0d87d2a6', '0e671a1a', '0e671a1a', '0e671a1a', '0e671a1a')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9496268656716418\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9371069182389937\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8638059701492538\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6730769230769231\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6833333333333333\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6875\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7575757575757576\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7931034482758621\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7407407407407407\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.23821046948432922, Avg accuracy: 0.9448611121624708, Avg diff accuracy: 0.2433084361582033\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.23821046948432922, avg_accuracy=0.9448611121624708, diff_accuracy=0.2433084361582033\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.23821046948432922, 'task_ids': ('09c534e7', '09c534e7', '09c534e7', '0a1d4ef5', '0a1d4ef5', '0a1d4ef5', '0a2355a6', '0a2355a6', '0a2355a6', '0a2355a6', '0b17323b', '0b17323b', '0bb8deee', '0bb8deee', '0bb8deee', '0becf7df', '0becf7df', '0becf7df', '0c786b71', '0c786b71', '0c786b71', '0c9aba6e', '0c9aba6e', '0c9aba6e', '0c9aba6e', '0d87d2a6', '0d87d2a6', '0d87d2a6', '0e671a1a', '0e671a1a', '0e671a1a', '0e671a1a'), 'test_accuracy': 0.9448611121624708, 'test_diff_accuracy': 0.2433084361582033, '09c534e7_test_accuracy': 0.8488888740539551, '09c534e7_test_diff_accuracy': 0.0, '0a1d4ef5_test_accuracy': 0.9188888669013977, '0a1d4ef5_test_diff_accuracy': 0.8638059701492538, '0a2355a6_test_accuracy': 0.9166666865348816, '0a2355a6_test_diff_accuracy': 0.0, '0b17323b_test_accuracy': 0.995555579662323, '0b17323b_test_diff_accuracy': 0.0, '0bb8deee_test_accuracy': 0.9777777791023254, '0bb8deee_test_diff_accuracy': 0.6875, '0becf7df_test_accuracy': 0.9811111092567444, '0becf7df_test_diff_accuracy': 0.0, '0c786b71_test_accuracy': 0.9466666579246521, '0c786b71_test_diff_accuracy': 0.0, '0c9aba6e_test_accuracy': 0.992222249507904, '0c9aba6e_test_diff_accuracy': 0.7407407407407407, '0d87d2a6_test_accuracy': 0.898888885974884, '0d87d2a6_test_diff_accuracy': 0.0, '0e671a1a_test_accuracy': 0.9744444489479065, '0e671a1a_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.23821046948432922, 'task_ids': ('09c534e7', '09c534e7', '09c534e7', '0a1d4ef5', '0a1d4ef5', '0a1d4ef5', '0a2355a6', '0a2355a6', '0a2355a6', '0a2355a6', '0b17323b', '0b17323b', '0bb8deee', '0bb8deee', '0bb8deee', '0becf7df', '0becf7df', '0becf7df', '0c786b71', '0c786b71', '0c786b71', '0c9aba6e', '0c9aba6e', '0c9aba6e', '0c9aba6e', '0d87d2a6', '0d87d2a6', '0d87d2a6', '0e671a1a', '0e671a1a', '0e671a1a', '0e671a1a'), 'test_accuracy': 0.9448611121624708, 'test_diff_accuracy': 0.2433084361582033, '09c534e7_test_accuracy': 0.8488888740539551, '09c534e7_test_diff_accuracy': 0.0, '0a1d4ef5_test_accuracy': 0.9188888669013977, '0a1d4ef5_test_diff_accuracy': 0.8638059701492538, '0a2355a6_test_accuracy': 0.9166666865348816, '0a2355a6_test_diff_accuracy': 0.0, '0b17323b_test_accuracy': 0.995555579662323, '0b17323b_test_diff_accuracy': 0.0, '0bb8deee_test_accuracy': 0.9777777791023254, '0bb8deee_test_diff_accuracy': 0.6875, '0becf7df_test_accuracy': 0.9811111092567444, '0becf7df_test_diff_accuracy': 0.0, '0c786b71_test_accuracy': 0.9466666579246521, '0c786b71_test_diff_accuracy': 0.0, '0c9aba6e_test_accuracy': 0.992222249507904, '0c9aba6e_test_diff_accuracy': 0.7407407407407407, '0d87d2a6_test_accuracy': 0.898888885974884, '0d87d2a6_test_diff_accuracy': 0.0, '0e671a1a_test_accuracy': 0.9744444489479065, '0e671a1a_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('0f63c0b9', '0f63c0b9', '0f63c0b9', '0f63c0b9', '103eff5b', '103eff5b', '11e1fe23', '11e1fe23', '12422b43', '12422b43', '12422b43', '12422b43', '12422b43', '12997ef3', '12997ef3', '12997ef3', '12997ef3', '12eac192', '12eac192', '12eac192', '12eac192', '136b0064', '136b0064', '136b0064', '13713586', '13713586', '13713586', '137f0df0', '137f0df0', '137f0df0', '140c817e', '140c817e')], batch_idx: 2\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('0f63c0b9', '0f63c0b9', '0f63c0b9', '0f63c0b9', '103eff5b', '103eff5b', '11e1fe23', '11e1fe23', '12422b43', '12422b43', '12422b43', '12422b43', '12422b43', '12997ef3', '12997ef3', '12997ef3', '12997ef3', '12eac192', '12eac192', '12eac192', '12eac192', '136b0064', '136b0064', '136b0064', '13713586', '13713586', '13713586', '137f0df0', '137f0df0', '137f0df0', '140c817e', '140c817e')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.3333333333333333\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.2916666666666667\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.3684210526315789\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.38461538461538464\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7027027027027027\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7058823529411765\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7254901960784313\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.29349371790885925, Avg accuracy: 0.9423611182719469, Avg diff accuracy: 0.10975349028028981\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.29349371790885925, avg_accuracy=0.9423611182719469, diff_accuracy=0.10975349028028981\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.29349371790885925, 'task_ids': ('0f63c0b9', '0f63c0b9', '0f63c0b9', '0f63c0b9', '103eff5b', '103eff5b', '11e1fe23', '11e1fe23', '12422b43', '12422b43', '12422b43', '12422b43', '12422b43', '12997ef3', '12997ef3', '12997ef3', '12997ef3', '12eac192', '12eac192', '12eac192', '12eac192', '136b0064', '136b0064', '136b0064', '13713586', '13713586', '13713586', '137f0df0', '137f0df0', '137f0df0', '140c817e', '140c817e'), 'test_accuracy': 0.9423611182719469, 'test_diff_accuracy': 0.10975349028028981, '0f63c0b9_test_accuracy': 0.894444465637207, '0f63c0b9_test_diff_accuracy': 0.0, '103eff5b_test_accuracy': 0.9333333373069763, '103eff5b_test_diff_accuracy': 0.0, '11e1fe23_test_accuracy': 0.992222249507904, '11e1fe23_test_diff_accuracy': 0.0, '12422b43_test_accuracy': 0.9833333492279053, '12422b43_test_diff_accuracy': 0.0, '12997ef3_test_accuracy': 0.9911110997200012, '12997ef3_test_diff_accuracy': 0.38461538461538464, '12eac192_test_accuracy': 0.9933333396911621, '12eac192_test_diff_accuracy': 0.0, '136b0064_test_accuracy': 0.9844444394111633, '136b0064_test_diff_accuracy': 0.7254901960784313, '13713586_test_accuracy': 0.8255555629730225, '13713586_test_diff_accuracy': 0.0, '137f0df0_test_accuracy': 0.902222216129303, '137f0df0_test_diff_accuracy': 0.0, '140c817e_test_accuracy': 0.9100000262260437, '140c817e_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.29349371790885925, 'task_ids': ('0f63c0b9', '0f63c0b9', '0f63c0b9', '0f63c0b9', '103eff5b', '103eff5b', '11e1fe23', '11e1fe23', '12422b43', '12422b43', '12422b43', '12422b43', '12422b43', '12997ef3', '12997ef3', '12997ef3', '12997ef3', '12eac192', '12eac192', '12eac192', '12eac192', '136b0064', '136b0064', '136b0064', '13713586', '13713586', '13713586', '137f0df0', '137f0df0', '137f0df0', '140c817e', '140c817e'), 'test_accuracy': 0.9423611182719469, 'test_diff_accuracy': 0.10975349028028981, '0f63c0b9_test_accuracy': 0.894444465637207, '0f63c0b9_test_diff_accuracy': 0.0, '103eff5b_test_accuracy': 0.9333333373069763, '103eff5b_test_diff_accuracy': 0.0, '11e1fe23_test_accuracy': 0.992222249507904, '11e1fe23_test_diff_accuracy': 0.0, '12422b43_test_accuracy': 0.9833333492279053, '12422b43_test_diff_accuracy': 0.0, '12997ef3_test_accuracy': 0.9911110997200012, '12997ef3_test_diff_accuracy': 0.38461538461538464, '12eac192_test_accuracy': 0.9933333396911621, '12eac192_test_diff_accuracy': 0.0, '136b0064_test_accuracy': 0.9844444394111633, '136b0064_test_diff_accuracy': 0.7254901960784313, '13713586_test_accuracy': 0.8255555629730225, '13713586_test_diff_accuracy': 0.0, '137f0df0_test_accuracy': 0.902222216129303, '137f0df0_test_diff_accuracy': 0.0, '140c817e_test_accuracy': 0.9100000262260437, '140c817e_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('140c817e', '14754a24', '14754a24', '14754a24', '14754a24', '15113be4', '15113be4', '15113be4', '15663ba9', '15663ba9', '15663ba9', '15696249', '15696249', '15696249', '15696249', '16b78196', '16b78196', '17b80ad2', '17b80ad2', '17b80ad2', '17b80ad2', '17cae0c1', '17cae0c1', '17cae0c1', '17cae0c1', '18419cfa', '18419cfa', '18419cfa', '184a9768', '184a9768', '184a9768', '195ba7dc')], batch_idx: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('140c817e', '14754a24', '14754a24', '14754a24', '14754a24', '15113be4', '15113be4', '15113be4', '15663ba9', '15663ba9', '15663ba9', '15696249', '15696249', '15696249', '15696249', '16b78196', '16b78196', '17b80ad2', '17b80ad2', '17b80ad2', '17b80ad2', '17cae0c1', '17cae0c1', '17cae0c1', '17cae0c1', '18419cfa', '18419cfa', '18419cfa', '184a9768', '184a9768', '184a9768', '195ba7dc')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.25\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.25\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.25\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.46846846846846846\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.53125\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5818181818181818\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6122448979591837\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5227272727272727\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.3418425917625427, Avg accuracy: 0.8920486252754927, Avg diff accuracy: 0.12395340065540958\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.3418425917625427, avg_accuracy=0.8920486252754927, diff_accuracy=0.12395340065540958\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.3418425917625427, 'task_ids': ('140c817e', '14754a24', '14754a24', '14754a24', '14754a24', '15113be4', '15113be4', '15113be4', '15663ba9', '15663ba9', '15663ba9', '15696249', '15696249', '15696249', '15696249', '16b78196', '16b78196', '17b80ad2', '17b80ad2', '17b80ad2', '17b80ad2', '17cae0c1', '17cae0c1', '17cae0c1', '17cae0c1', '18419cfa', '18419cfa', '18419cfa', '184a9768', '184a9768', '184a9768', '195ba7dc'), 'test_accuracy': 0.8920486252754927, 'test_diff_accuracy': 0.12395340065540958, '140c817e_test_accuracy': 0.8655555844306946, '140c817e_test_diff_accuracy': 0.0, '14754a24_test_accuracy': 0.8955555558204651, '14754a24_test_diff_accuracy': 0.0, '15113be4_test_accuracy': 0.601111114025116, '15113be4_test_diff_accuracy': 0.0, '15663ba9_test_accuracy': 0.9355555772781372, '15663ba9_test_diff_accuracy': 0.0, '15696249_test_accuracy': 0.9700000286102295, '15696249_test_diff_accuracy': 0.25, '16b78196_test_accuracy': 0.7811111211776733, '16b78196_test_diff_accuracy': 0.46846846846846846, '17b80ad2_test_accuracy': 0.992222249507904, '17b80ad2_test_diff_accuracy': 0.0, '17cae0c1_test_accuracy': 0.9700000286102295, '17cae0c1_test_diff_accuracy': 0.0, '18419cfa_test_accuracy': 0.9377777576446533, '18419cfa_test_diff_accuracy': 0.0, '184a9768_test_accuracy': 0.8799999952316284, '184a9768_test_diff_accuracy': 0.6122448979591837, '195ba7dc_test_accuracy': 0.9766666889190674, '195ba7dc_test_diff_accuracy': 0.5227272727272727}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.3418425917625427, 'task_ids': ('140c817e', '14754a24', '14754a24', '14754a24', '14754a24', '15113be4', '15113be4', '15113be4', '15663ba9', '15663ba9', '15663ba9', '15696249', '15696249', '15696249', '15696249', '16b78196', '16b78196', '17b80ad2', '17b80ad2', '17b80ad2', '17b80ad2', '17cae0c1', '17cae0c1', '17cae0c1', '17cae0c1', '18419cfa', '18419cfa', '18419cfa', '184a9768', '184a9768', '184a9768', '195ba7dc'), 'test_accuracy': 0.8920486252754927, 'test_diff_accuracy': 0.12395340065540958, '140c817e_test_accuracy': 0.8655555844306946, '140c817e_test_diff_accuracy': 0.0, '14754a24_test_accuracy': 0.8955555558204651, '14754a24_test_diff_accuracy': 0.0, '15113be4_test_accuracy': 0.601111114025116, '15113be4_test_diff_accuracy': 0.0, '15663ba9_test_accuracy': 0.9355555772781372, '15663ba9_test_diff_accuracy': 0.0, '15696249_test_accuracy': 0.9700000286102295, '15696249_test_diff_accuracy': 0.25, '16b78196_test_accuracy': 0.7811111211776733, '16b78196_test_diff_accuracy': 0.46846846846846846, '17b80ad2_test_accuracy': 0.992222249507904, '17b80ad2_test_diff_accuracy': 0.0, '17cae0c1_test_accuracy': 0.9700000286102295, '17cae0c1_test_diff_accuracy': 0.0, '18419cfa_test_accuracy': 0.9377777576446533, '18419cfa_test_diff_accuracy': 0.0, '184a9768_test_accuracy': 0.8799999952316284, '184a9768_test_diff_accuracy': 0.6122448979591837, '195ba7dc_test_accuracy': 0.9766666889190674, '195ba7dc_test_diff_accuracy': 0.5227272727272727}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 1,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 1,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('195ba7dc', '195ba7dc', '195ba7dc', '1990f7a8', '1990f7a8', '1990f7a8', '19bb5feb', '19bb5feb', '19bb5feb', '1a2e2828', '1a2e2828', '1a2e2828', '1a2e2828', '1a2e2828', '1a6449f1', '1a6449f1', '1a6449f1', '1acc24af', '1acc24af', '1acc24af', '1acc24af', '1c02dbbe', '1c02dbbe', '1c02dbbe', '1c0d0a4b', '1c0d0a4b', '1c0d0a4b', '1c56ad9f', '1c56ad9f', '1c56ad9f', '1c56ad9f', '1d0a4b61')], batch_idx: 4\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('195ba7dc', '195ba7dc', '195ba7dc', '1990f7a8', '1990f7a8', '1990f7a8', '19bb5feb', '19bb5feb', '19bb5feb', '1a2e2828', '1a2e2828', '1a2e2828', '1a2e2828', '1a2e2828', '1a6449f1', '1a6449f1', '1a6449f1', '1acc24af', '1acc24af', '1acc24af', '1acc24af', '1c02dbbe', '1c02dbbe', '1c02dbbe', '1c0d0a4b', '1c0d0a4b', '1c0d0a4b', '1c56ad9f', '1c56ad9f', '1c56ad9f', '1c56ad9f', '1d0a4b61')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5217391304347826\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4772727272727273\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6349206349206349\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9844961240310077\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5740740740740741\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9803921568627451\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9615384615384616\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9883720930232558\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9871794871794872\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8833333333333333\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8917748917748918\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9640718562874252\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.046511627906976744\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.05970149253731343\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.08\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6296296296296297\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6296296296296297\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5277777777777778\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.23224544525146484, Avg accuracy: 0.9443750018253922, Avg diff accuracy: 0.5257004727566923\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.23224544525146484, avg_accuracy=0.9443750018253922, diff_accuracy=0.5257004727566923\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.23224544525146484, 'task_ids': ('195ba7dc', '195ba7dc', '195ba7dc', '1990f7a8', '1990f7a8', '1990f7a8', '19bb5feb', '19bb5feb', '19bb5feb', '1a2e2828', '1a2e2828', '1a2e2828', '1a2e2828', '1a2e2828', '1a6449f1', '1a6449f1', '1a6449f1', '1acc24af', '1acc24af', '1acc24af', '1acc24af', '1c02dbbe', '1c02dbbe', '1c02dbbe', '1c0d0a4b', '1c0d0a4b', '1c0d0a4b', '1c56ad9f', '1c56ad9f', '1c56ad9f', '1c56ad9f', '1d0a4b61'), 'test_accuracy': 0.9443750018253922, 'test_diff_accuracy': 0.5257004727566923, '195ba7dc_test_accuracy': 0.9744444489479065, '195ba7dc_test_diff_accuracy': 0.4772727272727273, '1990f7a8_test_accuracy': 0.9788888692855835, '1990f7a8_test_diff_accuracy': 0.5, '19bb5feb_test_accuracy': 0.948888897895813, '19bb5feb_test_diff_accuracy': 0.5740740740740741, '1a2e2828_test_accuracy': 0.9988889098167419, '1a2e2828_test_diff_accuracy': 1.0, '1a6449f1_test_accuracy': 0.9933333396911621, '1a6449f1_test_diff_accuracy': 0.9640718562874252, '1acc24af_test_accuracy': 0.9599999785423279, '1acc24af_test_diff_accuracy': 0.0, '1c02dbbe_test_accuracy': 0.8266666531562805, '1c02dbbe_test_diff_accuracy': 0.08, '1c0d0a4b_test_accuracy': 0.9811111092567444, '1c0d0a4b_test_diff_accuracy': 0.5277777777777778, '1c56ad9f_test_accuracy': 0.9555555582046509, '1c56ad9f_test_diff_accuracy': 0.5, '1d0a4b61_test_accuracy': 0.3055555522441864, '1d0a4b61_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.23224544525146484, 'task_ids': ('195ba7dc', '195ba7dc', '195ba7dc', '1990f7a8', '1990f7a8', '1990f7a8', '19bb5feb', '19bb5feb', '19bb5feb', '1a2e2828', '1a2e2828', '1a2e2828', '1a2e2828', '1a2e2828', '1a6449f1', '1a6449f1', '1a6449f1', '1acc24af', '1acc24af', '1acc24af', '1acc24af', '1c02dbbe', '1c02dbbe', '1c02dbbe', '1c0d0a4b', '1c0d0a4b', '1c0d0a4b', '1c56ad9f', '1c56ad9f', '1c56ad9f', '1c56ad9f', '1d0a4b61'), 'test_accuracy': 0.9443750018253922, 'test_diff_accuracy': 0.5257004727566923, '195ba7dc_test_accuracy': 0.9744444489479065, '195ba7dc_test_diff_accuracy': 0.4772727272727273, '1990f7a8_test_accuracy': 0.9788888692855835, '1990f7a8_test_diff_accuracy': 0.5, '19bb5feb_test_accuracy': 0.948888897895813, '19bb5feb_test_diff_accuracy': 0.5740740740740741, '1a2e2828_test_accuracy': 0.9988889098167419, '1a2e2828_test_diff_accuracy': 1.0, '1a6449f1_test_accuracy': 0.9933333396911621, '1a6449f1_test_diff_accuracy': 0.9640718562874252, '1acc24af_test_accuracy': 0.9599999785423279, '1acc24af_test_diff_accuracy': 0.0, '1c02dbbe_test_accuracy': 0.8266666531562805, '1c02dbbe_test_diff_accuracy': 0.08, '1c0d0a4b_test_accuracy': 0.9811111092567444, '1c0d0a4b_test_diff_accuracy': 0.5277777777777778, '1c56ad9f_test_accuracy': 0.9555555582046509, '1c56ad9f_test_diff_accuracy': 0.5, '1d0a4b61_test_accuracy': 0.3055555522441864, '1d0a4b61_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 1,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 1,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 1,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 1,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('1d0a4b61', '1d0a4b61', '1d398264', '1d398264', '1d398264', '1da012fc', '1da012fc', '1e81d6f9', '1e81d6f9', '1e81d6f9', '1e97544e', '1e97544e', '1e97544e', '2037f2c7', '2037f2c7', '2037f2c7', '2072aba6', '2072aba6', '2072aba6', '20818e16', '20818e16', '20818e16', '20981f0e', '20981f0e', '20981f0e', '212895b5', '212895b5', '212895b5', '21f83797', '21f83797', '22a4bbc2', '22a4bbc2')], batch_idx: 5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('1d0a4b61', '1d0a4b61', '1d398264', '1d398264', '1d398264', '1da012fc', '1da012fc', '1e81d6f9', '1e81d6f9', '1e81d6f9', '1e97544e', '1e97544e', '1e97544e', '2037f2c7', '2037f2c7', '2037f2c7', '2072aba6', '2072aba6', '2072aba6', '20818e16', '20818e16', '20818e16', '20981f0e', '20981f0e', '20981f0e', '212895b5', '212895b5', '212895b5', '21f83797', '21f83797', '22a4bbc2', '22a4bbc2')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9572192513368984\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9144736842105263\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9285714285714286\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.047619047619047616\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8140703517587939\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8691588785046729\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4861111111111111\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.4968261420726776, Avg accuracy: 0.8606944475322962, Avg diff accuracy: 0.29741324228476496\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.4968261420726776, avg_accuracy=0.8606944475322962, diff_accuracy=0.29741324228476496\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.4968261420726776, 'task_ids': ('1d0a4b61', '1d0a4b61', '1d398264', '1d398264', '1d398264', '1da012fc', '1da012fc', '1e81d6f9', '1e81d6f9', '1e81d6f9', '1e97544e', '1e97544e', '1e97544e', '2037f2c7', '2037f2c7', '2037f2c7', '2072aba6', '2072aba6', '2072aba6', '20818e16', '20818e16', '20818e16', '20981f0e', '20981f0e', '20981f0e', '212895b5', '212895b5', '212895b5', '21f83797', '21f83797', '22a4bbc2', '22a4bbc2'), 'test_accuracy': 0.8606944475322962, 'test_diff_accuracy': 0.29741324228476496, '1d0a4b61_test_accuracy': 0.3055555522441864, '1d0a4b61_test_diff_accuracy': 0.0, '1d398264_test_accuracy': 0.9288889169692993, '1d398264_test_diff_accuracy': 0.0, '1da012fc_test_accuracy': 0.9288889169692993, '1da012fc_test_diff_accuracy': 0.0, '1e81d6f9_test_accuracy': 0.9611111283302307, '1e81d6f9_test_diff_accuracy': 1.0, '1e97544e_test_accuracy': 0.4144444465637207, '1e97544e_test_diff_accuracy': 0.0, '2037f2c7_test_accuracy': 0.9933333396911621, '2037f2c7_test_diff_accuracy': 0.9285714285714286, '2072aba6_test_accuracy': 0.9777777791023254, '2072aba6_test_diff_accuracy': 0.047619047619047616, '20818e16_test_accuracy': 0.9288889169692993, '20818e16_test_diff_accuracy': 0.4861111111111111, '20981f0e_test_accuracy': 0.9700000286102295, '20981f0e_test_diff_accuracy': 0.5, '212895b5_test_accuracy': 0.9255555272102356, '212895b5_test_diff_accuracy': 0.0, '21f83797_test_accuracy': 0.9233333468437195, '21f83797_test_diff_accuracy': 0.0, '22a4bbc2_test_accuracy': 0.9311110973358154, '22a4bbc2_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.4968261420726776, 'task_ids': ('1d0a4b61', '1d0a4b61', '1d398264', '1d398264', '1d398264', '1da012fc', '1da012fc', '1e81d6f9', '1e81d6f9', '1e81d6f9', '1e97544e', '1e97544e', '1e97544e', '2037f2c7', '2037f2c7', '2037f2c7', '2072aba6', '2072aba6', '2072aba6', '20818e16', '20818e16', '20818e16', '20981f0e', '20981f0e', '20981f0e', '212895b5', '212895b5', '212895b5', '21f83797', '21f83797', '22a4bbc2', '22a4bbc2'), 'test_accuracy': 0.8606944475322962, 'test_diff_accuracy': 0.29741324228476496, '1d0a4b61_test_accuracy': 0.3055555522441864, '1d0a4b61_test_diff_accuracy': 0.0, '1d398264_test_accuracy': 0.9288889169692993, '1d398264_test_diff_accuracy': 0.0, '1da012fc_test_accuracy': 0.9288889169692993, '1da012fc_test_diff_accuracy': 0.0, '1e81d6f9_test_accuracy': 0.9611111283302307, '1e81d6f9_test_diff_accuracy': 1.0, '1e97544e_test_accuracy': 0.4144444465637207, '1e97544e_test_diff_accuracy': 0.0, '2037f2c7_test_accuracy': 0.9933333396911621, '2037f2c7_test_diff_accuracy': 0.9285714285714286, '2072aba6_test_accuracy': 0.9777777791023254, '2072aba6_test_diff_accuracy': 0.047619047619047616, '20818e16_test_accuracy': 0.9288889169692993, '20818e16_test_diff_accuracy': 0.4861111111111111, '20981f0e_test_accuracy': 0.9700000286102295, '20981f0e_test_diff_accuracy': 0.5, '212895b5_test_accuracy': 0.9255555272102356, '212895b5_test_diff_accuracy': 0.0, '21f83797_test_accuracy': 0.9233333468437195, '21f83797_test_diff_accuracy': 0.0, '22a4bbc2_test_accuracy': 0.9311110973358154, '22a4bbc2_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[3, 3, 2,  ..., 8, 1, 1],\n",
            "          [8, 2, 1,  ..., 6, 2, 6],\n",
            "          [1, 8, 3,  ..., 3, 2, 3],\n",
            "          ...,\n",
            "          [2, 3, 2,  ..., 2, 3, 2],\n",
            "          [2, 1, 8,  ..., 1, 8, 3],\n",
            "          [1, 6, 3,  ..., 1, 1, 8]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[3, 3, 2,  ..., 8, 1, 1],\n",
            "          [8, 2, 1,  ..., 6, 2, 6],\n",
            "          [1, 8, 3,  ..., 3, 2, 3],\n",
            "          ...,\n",
            "          [2, 3, 2,  ..., 2, 3, 2],\n",
            "          [2, 1, 8,  ..., 1, 8, 3],\n",
            "          [1, 6, 3,  ..., 1, 1, 8]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('22a4bbc2', '22a4bbc2', '25094a63', '25094a63', '2546ccf6', '2546ccf6', '256b0a75', '256b0a75', '256b0a75', '2685904e', '2685904e', '2685904e', '2685904e', '2685904e', '2685904e', '2697da3f', '2697da3f', '2697da3f', '2697da3f', '2753e76c', '2753e76c', '2753e76c', '27a77e38', '27a77e38', '27a77e38', '27f8ce4f', '27f8ce4f', '27f8ce4f', '27f8ce4f', '281123b4', '281123b4', '281123b4')], batch_idx: 6\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('22a4bbc2', '22a4bbc2', '25094a63', '25094a63', '2546ccf6', '2546ccf6', '256b0a75', '256b0a75', '256b0a75', '2685904e', '2685904e', '2685904e', '2685904e', '2685904e', '2685904e', '2697da3f', '2697da3f', '2697da3f', '2697da3f', '2753e76c', '2753e76c', '2753e76c', '27a77e38', '27a77e38', '27a77e38', '27f8ce4f', '27f8ce4f', '27f8ce4f', '27f8ce4f', '281123b4', '281123b4', '281123b4')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.17391304347826086\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.18181818181818182\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.14705882352941177\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.16129032258064516\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.922077922077922\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8809523809523809\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8952380952380953\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.25\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.2\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7254901960784313\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6938775510204082\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.75\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.47957876324653625, Avg accuracy: 0.8837499981746078, Avg diff accuracy: 0.1869286411491793\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.47957876324653625, avg_accuracy=0.8837499981746078, diff_accuracy=0.1869286411491793\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.47957876324653625, 'task_ids': ('22a4bbc2', '22a4bbc2', '25094a63', '25094a63', '2546ccf6', '2546ccf6', '256b0a75', '256b0a75', '256b0a75', '2685904e', '2685904e', '2685904e', '2685904e', '2685904e', '2685904e', '2697da3f', '2697da3f', '2697da3f', '2697da3f', '2753e76c', '2753e76c', '2753e76c', '27a77e38', '27a77e38', '27a77e38', '27f8ce4f', '27f8ce4f', '27f8ce4f', '27f8ce4f', '281123b4', '281123b4', '281123b4'), 'test_accuracy': 0.8837499981746078, 'test_diff_accuracy': 0.1869286411491793, '22a4bbc2_test_accuracy': 0.949999988079071, '22a4bbc2_test_diff_accuracy': 0.0, '25094a63_test_accuracy': 0.20555555820465088, '25094a63_test_diff_accuracy': 0.0, '2546ccf6_test_accuracy': 0.8422222137451172, '2546ccf6_test_diff_accuracy': 0.0, '256b0a75_test_accuracy': 0.6255555748939514, '256b0a75_test_diff_accuracy': 0.0, '2685904e_test_accuracy': 0.9744444489479065, '2685904e_test_diff_accuracy': 0.0, '2697da3f_test_accuracy': 0.9377777576446533, '2697da3f_test_diff_accuracy': 0.16129032258064516, '2753e76c_test_accuracy': 0.9877777695655823, '2753e76c_test_diff_accuracy': 0.8952380952380953, '27a77e38_test_accuracy': 0.9677777886390686, '27a77e38_test_diff_accuracy': 0.0, '27f8ce4f_test_accuracy': 0.9700000286102295, '27f8ce4f_test_diff_accuracy': 0.0, '281123b4_test_accuracy': 0.9844444394111633, '281123b4_test_diff_accuracy': 0.75}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.47957876324653625, 'task_ids': ('22a4bbc2', '22a4bbc2', '25094a63', '25094a63', '2546ccf6', '2546ccf6', '256b0a75', '256b0a75', '256b0a75', '2685904e', '2685904e', '2685904e', '2685904e', '2685904e', '2685904e', '2697da3f', '2697da3f', '2697da3f', '2697da3f', '2753e76c', '2753e76c', '2753e76c', '27a77e38', '27a77e38', '27a77e38', '27f8ce4f', '27f8ce4f', '27f8ce4f', '27f8ce4f', '281123b4', '281123b4', '281123b4'), 'test_accuracy': 0.8837499981746078, 'test_diff_accuracy': 0.1869286411491793, '22a4bbc2_test_accuracy': 0.949999988079071, '22a4bbc2_test_diff_accuracy': 0.0, '25094a63_test_accuracy': 0.20555555820465088, '25094a63_test_diff_accuracy': 0.0, '2546ccf6_test_accuracy': 0.8422222137451172, '2546ccf6_test_diff_accuracy': 0.0, '256b0a75_test_accuracy': 0.6255555748939514, '256b0a75_test_diff_accuracy': 0.0, '2685904e_test_accuracy': 0.9744444489479065, '2685904e_test_diff_accuracy': 0.0, '2697da3f_test_accuracy': 0.9377777576446533, '2697da3f_test_diff_accuracy': 0.16129032258064516, '2753e76c_test_accuracy': 0.9877777695655823, '2753e76c_test_diff_accuracy': 0.8952380952380953, '27a77e38_test_accuracy': 0.9677777886390686, '27a77e38_test_diff_accuracy': 0.0, '27f8ce4f_test_accuracy': 0.9700000286102295, '27f8ce4f_test_diff_accuracy': 0.0, '281123b4_test_accuracy': 0.9844444394111633, '281123b4_test_diff_accuracy': 0.75}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('281123b4', '281123b4', '281123b4', '292dd178', '292dd178', '292dd178', '29700607', '29700607', '29700607', '2a5f8217', '2a5f8217', '2a5f8217', '2b01abd0', '2b01abd0', '2b01abd0', '2c0b0aff', '2c0b0aff', '2c0b0aff', '2c0b0aff', '2c737e39', '2c737e39', '2c737e39', '2f0c5170', '2f0c5170', '2f0c5170', '310f3251', '310f3251', '310f3251', '310f3251', '310f3251', '3194b014', '3194b014')], batch_idx: 7\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('281123b4', '281123b4', '281123b4', '292dd178', '292dd178', '292dd178', '29700607', '29700607', '29700607', '2a5f8217', '2a5f8217', '2a5f8217', '2b01abd0', '2b01abd0', '2b01abd0', '2c0b0aff', '2c0b0aff', '2c0b0aff', '2c0b0aff', '2c737e39', '2c737e39', '2c737e39', '2f0c5170', '2f0c5170', '2f0c5170', '310f3251', '310f3251', '310f3251', '310f3251', '310f3251', '3194b014', '3194b014')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.717391304347826\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6511627906976745\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.75\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8042553191489362\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8251533742331288\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7115384615384616\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.69\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.1\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.16666666666666666\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.14285714285714285\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8835227272727273\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.919431279620853\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9528985507246377\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9095022624434389\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9482071713147411\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.2770877480506897, Avg accuracy: 0.9597916640341282, Avg diff accuracy: 0.3178933453395698\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.2770877480506897, avg_accuracy=0.9597916640341282, diff_accuracy=0.3178933453395698\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.2770877480506897, 'task_ids': ('281123b4', '281123b4', '281123b4', '292dd178', '292dd178', '292dd178', '29700607', '29700607', '29700607', '2a5f8217', '2a5f8217', '2a5f8217', '2b01abd0', '2b01abd0', '2b01abd0', '2c0b0aff', '2c0b0aff', '2c0b0aff', '2c0b0aff', '2c737e39', '2c737e39', '2c737e39', '2f0c5170', '2f0c5170', '2f0c5170', '310f3251', '310f3251', '310f3251', '310f3251', '310f3251', '3194b014', '3194b014'), 'test_accuracy': 0.9597916640341282, 'test_diff_accuracy': 0.3178933453395698, '281123b4_test_accuracy': 0.9844444394111633, '281123b4_test_diff_accuracy': 0.75, '292dd178_test_accuracy': 0.8899999856948853, '292dd178_test_diff_accuracy': 0.0, '29700607_test_accuracy': 0.9622222185134888, '29700607_test_diff_accuracy': 0.0, '2a5f8217_test_accuracy': 0.9666666388511658, '2a5f8217_test_diff_accuracy': 0.0, '2b01abd0_test_accuracy': 0.9655555486679077, '2b01abd0_test_diff_accuracy': 0.0, '2c0b0aff_test_accuracy': 0.897777795791626, '2c0b0aff_test_diff_accuracy': 0.69, '2c737e39_test_accuracy': 0.9855555295944214, '2c737e39_test_diff_accuracy': 0.14285714285714285, '2f0c5170_test_accuracy': 0.9855555295944214, '2f0c5170_test_diff_accuracy': 0.9528985507246377, '310f3251_test_accuracy': 0.9800000190734863, '310f3251_test_diff_accuracy': 0.0, '3194b014_test_accuracy': 0.9788888692855835, '3194b014_test_diff_accuracy': 0.9482071713147411}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.2770877480506897, 'task_ids': ('281123b4', '281123b4', '281123b4', '292dd178', '292dd178', '292dd178', '29700607', '29700607', '29700607', '2a5f8217', '2a5f8217', '2a5f8217', '2b01abd0', '2b01abd0', '2b01abd0', '2c0b0aff', '2c0b0aff', '2c0b0aff', '2c0b0aff', '2c737e39', '2c737e39', '2c737e39', '2f0c5170', '2f0c5170', '2f0c5170', '310f3251', '310f3251', '310f3251', '310f3251', '310f3251', '3194b014', '3194b014'), 'test_accuracy': 0.9597916640341282, 'test_diff_accuracy': 0.3178933453395698, '281123b4_test_accuracy': 0.9844444394111633, '281123b4_test_diff_accuracy': 0.75, '292dd178_test_accuracy': 0.8899999856948853, '292dd178_test_diff_accuracy': 0.0, '29700607_test_accuracy': 0.9622222185134888, '29700607_test_diff_accuracy': 0.0, '2a5f8217_test_accuracy': 0.9666666388511658, '2a5f8217_test_diff_accuracy': 0.0, '2b01abd0_test_accuracy': 0.9655555486679077, '2b01abd0_test_diff_accuracy': 0.0, '2c0b0aff_test_accuracy': 0.897777795791626, '2c0b0aff_test_diff_accuracy': 0.69, '2c737e39_test_accuracy': 0.9855555295944214, '2c737e39_test_diff_accuracy': 0.14285714285714285, '2f0c5170_test_accuracy': 0.9855555295944214, '2f0c5170_test_diff_accuracy': 0.9528985507246377, '310f3251_test_accuracy': 0.9800000190734863, '310f3251_test_diff_accuracy': 0.0, '3194b014_test_accuracy': 0.9788888692855835, '3194b014_test_diff_accuracy': 0.9482071713147411}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('3194b014', '319f2597', '319f2597', '319f2597', '31adaf00', '31adaf00', '31adaf00', '31d5ba1a', '31d5ba1a', '31d5ba1a', '31d5ba1a', '31d5ba1a', '32e9702f', '32e9702f', '32e9702f', '332efdb3', '332efdb3', '332efdb3', '3391f8c0', '3391f8c0', '3391f8c0', '3391f8c0', '33b52de3', '33b52de3', '3490cc26', '3490cc26', '3490cc26', '3490cc26', '34b99a2b', '34b99a2b', '34b99a2b', '34b99a2b')], batch_idx: 8\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('3194b014', '319f2597', '319f2597', '319f2597', '31adaf00', '31adaf00', '31adaf00', '31d5ba1a', '31d5ba1a', '31d5ba1a', '31d5ba1a', '31d5ba1a', '32e9702f', '32e9702f', '32e9702f', '332efdb3', '332efdb3', '332efdb3', '3391f8c0', '3391f8c0', '3391f8c0', '3391f8c0', '33b52de3', '33b52de3', '3490cc26', '3490cc26', '3490cc26', '3490cc26', '34b99a2b', '34b99a2b', '34b99a2b', '34b99a2b')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9098039215686274\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.953125\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.967741935483871\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.75\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.631578947368421\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6666666666666666\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6111111111111112\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6111111111111112\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.3333333333333333\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.25\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.3333333333333333\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6551724137931034\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.64\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6428571428571429\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5806451612903226\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.3190476894378662, Avg accuracy: 0.9235763922333717, Avg diff accuracy: 0.34489000243490764\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.3190476894378662, avg_accuracy=0.9235763922333717, diff_accuracy=0.34489000243490764\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.3190476894378662, 'task_ids': ('3194b014', '319f2597', '319f2597', '319f2597', '31adaf00', '31adaf00', '31adaf00', '31d5ba1a', '31d5ba1a', '31d5ba1a', '31d5ba1a', '31d5ba1a', '32e9702f', '32e9702f', '32e9702f', '332efdb3', '332efdb3', '332efdb3', '3391f8c0', '3391f8c0', '3391f8c0', '3391f8c0', '33b52de3', '33b52de3', '3490cc26', '3490cc26', '3490cc26', '3490cc26', '34b99a2b', '34b99a2b', '34b99a2b', '34b99a2b'), 'test_accuracy': 0.9235763922333717, 'test_diff_accuracy': 0.34489000243490764, '3194b014_test_accuracy': 0.9744444489479065, '3194b014_test_diff_accuracy': 0.9098039215686274, '319f2597_test_accuracy': 0.6288889050483704, '319f2597_test_diff_accuracy': 1.0, '31adaf00_test_accuracy': 0.9277777671813965, '31adaf00_test_diff_accuracy': 0.0, '31d5ba1a_test_accuracy': 0.992222249507904, '31d5ba1a_test_diff_accuracy': 0.6111111111111112, '32e9702f_test_accuracy': 0.945555567741394, '32e9702f_test_diff_accuracy': 0.0, '332efdb3_test_accuracy': 0.9277777671813965, '332efdb3_test_diff_accuracy': 0.0, '3391f8c0_test_accuracy': 0.9888888597488403, '3391f8c0_test_diff_accuracy': 0.5, '33b52de3_test_accuracy': 0.8577777743339539, '33b52de3_test_diff_accuracy': 0.0, '3490cc26_test_accuracy': 0.8644444346427917, '3490cc26_test_diff_accuracy': 0.0, '34b99a2b_test_accuracy': 0.9855555295944214, '34b99a2b_test_diff_accuracy': 0.5806451612903226}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.3190476894378662, 'task_ids': ('3194b014', '319f2597', '319f2597', '319f2597', '31adaf00', '31adaf00', '31adaf00', '31d5ba1a', '31d5ba1a', '31d5ba1a', '31d5ba1a', '31d5ba1a', '32e9702f', '32e9702f', '32e9702f', '332efdb3', '332efdb3', '332efdb3', '3391f8c0', '3391f8c0', '3391f8c0', '3391f8c0', '33b52de3', '33b52de3', '3490cc26', '3490cc26', '3490cc26', '3490cc26', '34b99a2b', '34b99a2b', '34b99a2b', '34b99a2b'), 'test_accuracy': 0.9235763922333717, 'test_diff_accuracy': 0.34489000243490764, '3194b014_test_accuracy': 0.9744444489479065, '3194b014_test_diff_accuracy': 0.9098039215686274, '319f2597_test_accuracy': 0.6288889050483704, '319f2597_test_diff_accuracy': 1.0, '31adaf00_test_accuracy': 0.9277777671813965, '31adaf00_test_diff_accuracy': 0.0, '31d5ba1a_test_accuracy': 0.992222249507904, '31d5ba1a_test_diff_accuracy': 0.6111111111111112, '32e9702f_test_accuracy': 0.945555567741394, '32e9702f_test_diff_accuracy': 0.0, '332efdb3_test_accuracy': 0.9277777671813965, '332efdb3_test_diff_accuracy': 0.0, '3391f8c0_test_accuracy': 0.9888888597488403, '3391f8c0_test_diff_accuracy': 0.5, '33b52de3_test_accuracy': 0.8577777743339539, '33b52de3_test_diff_accuracy': 0.0, '3490cc26_test_accuracy': 0.8644444346427917, '3490cc26_test_diff_accuracy': 0.0, '34b99a2b_test_accuracy': 0.9855555295944214, '34b99a2b_test_diff_accuracy': 0.5806451612903226}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[3, 3, 3,  ..., 3, 3, 3],\n",
            "          [3, 3, 1,  ..., 3, 3, 3],\n",
            "          [3, 3, 1,  ..., 3, 3, 3],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[3, 3, 3,  ..., 3, 3, 3],\n",
            "          [3, 3, 1,  ..., 3, 3, 3],\n",
            "          [3, 3, 1,  ..., 3, 3, 3],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('351d6448', '351d6448', '358ba94e', '358ba94e', '358ba94e', '358ba94e', '37d3e8b2', '37d3e8b2', '37d3e8b2', '3979b1a8', '3979b1a8', '3a301edc', '3a301edc', '3a301edc', '3a301edc', '3a301edc', '3b4c2228', '3b4c2228', '3b4c2228', '3b4c2228', '3b4c2228', '3d31c5b3', '3d31c5b3', '3d31c5b3', '3d31c5b3', '3d31c5b3', '3d31c5b3', '3ed85e70', '3ed85e70', '3ed85e70', '3ee1011a', '3ee1011a')], batch_idx: 9\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('351d6448', '351d6448', '358ba94e', '358ba94e', '358ba94e', '358ba94e', '37d3e8b2', '37d3e8b2', '37d3e8b2', '3979b1a8', '3979b1a8', '3a301edc', '3a301edc', '3a301edc', '3a301edc', '3a301edc', '3b4c2228', '3b4c2228', '3b4c2228', '3b4c2228', '3b4c2228', '3d31c5b3', '3d31c5b3', '3d31c5b3', '3d31c5b3', '3d31c5b3', '3d31c5b3', '3ed85e70', '3ed85e70', '3ed85e70', '3ee1011a', '3ee1011a')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9411764705882353\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8305084745762712\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8556701030927835\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.847457627118644\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9259259259259259\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8285714285714286\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9259259259259259\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9285714285714286\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.85\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8461538461538461\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9230769230769231\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6052631578947368\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5777777777777777\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5909090909090909\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.64\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.625\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6086956521739131\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.2647058823529412\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.21739130434782608\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.34507545828819275, Avg accuracy: 0.9226041734218597, Avg diff accuracy: 0.43227440684555307\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.34507545828819275, avg_accuracy=0.9226041734218597, diff_accuracy=0.43227440684555307\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.34507545828819275, 'task_ids': ('351d6448', '351d6448', '358ba94e', '358ba94e', '358ba94e', '358ba94e', '37d3e8b2', '37d3e8b2', '37d3e8b2', '3979b1a8', '3979b1a8', '3a301edc', '3a301edc', '3a301edc', '3a301edc', '3a301edc', '3b4c2228', '3b4c2228', '3b4c2228', '3b4c2228', '3b4c2228', '3d31c5b3', '3d31c5b3', '3d31c5b3', '3d31c5b3', '3d31c5b3', '3d31c5b3', '3ed85e70', '3ed85e70', '3ed85e70', '3ee1011a', '3ee1011a'), 'test_accuracy': 0.9226041734218597, 'test_diff_accuracy': 0.43227440684555307, '351d6448_test_accuracy': 0.9888888597488403, '351d6448_test_diff_accuracy': 0.8305084745762712, '358ba94e_test_accuracy': 0.9733333587646484, '358ba94e_test_diff_accuracy': 0.8285714285714286, '37d3e8b2_test_accuracy': 0.8755555748939514, '37d3e8b2_test_diff_accuracy': 0.0, '3979b1a8_test_accuracy': 0.8888888955116272, '3979b1a8_test_diff_accuracy': 0.0, '3a301edc_test_accuracy': 0.9722222089767456, '3a301edc_test_diff_accuracy': 0.0, '3b4c2228_test_accuracy': 0.9988889098167419, '3b4c2228_test_diff_accuracy': 0.9230769230769231, '3d31c5b3_test_accuracy': 0.9800000190734863, '3d31c5b3_test_diff_accuracy': 0.6086956521739131, '3ed85e70_test_accuracy': 0.7022222280502319, '3ed85e70_test_diff_accuracy': 0.0, '3ee1011a_test_accuracy': 0.9599999785423279, '3ee1011a_test_diff_accuracy': 0.21739130434782608}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.34507545828819275, 'task_ids': ('351d6448', '351d6448', '358ba94e', '358ba94e', '358ba94e', '358ba94e', '37d3e8b2', '37d3e8b2', '37d3e8b2', '3979b1a8', '3979b1a8', '3a301edc', '3a301edc', '3a301edc', '3a301edc', '3a301edc', '3b4c2228', '3b4c2228', '3b4c2228', '3b4c2228', '3b4c2228', '3d31c5b3', '3d31c5b3', '3d31c5b3', '3d31c5b3', '3d31c5b3', '3d31c5b3', '3ed85e70', '3ed85e70', '3ed85e70', '3ee1011a', '3ee1011a'), 'test_accuracy': 0.9226041734218597, 'test_diff_accuracy': 0.43227440684555307, '351d6448_test_accuracy': 0.9888888597488403, '351d6448_test_diff_accuracy': 0.8305084745762712, '358ba94e_test_accuracy': 0.9733333587646484, '358ba94e_test_diff_accuracy': 0.8285714285714286, '37d3e8b2_test_accuracy': 0.8755555748939514, '37d3e8b2_test_diff_accuracy': 0.0, '3979b1a8_test_accuracy': 0.8888888955116272, '3979b1a8_test_diff_accuracy': 0.0, '3a301edc_test_accuracy': 0.9722222089767456, '3a301edc_test_diff_accuracy': 0.0, '3b4c2228_test_accuracy': 0.9988889098167419, '3b4c2228_test_diff_accuracy': 0.9230769230769231, '3d31c5b3_test_accuracy': 0.9800000190734863, '3d31c5b3_test_diff_accuracy': 0.6086956521739131, '3ed85e70_test_accuracy': 0.7022222280502319, '3ed85e70_test_diff_accuracy': 0.0, '3ee1011a_test_accuracy': 0.9599999785423279, '3ee1011a_test_diff_accuracy': 0.21739130434782608}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('3ee1011a', '3f23242b', '3f23242b', '40f6cd08', '40f6cd08', '40f6cd08', '414297c0', '414297c0', '414297c0', '423a55dc', '423a55dc', '423a55dc', '423a55dc', '423a55dc', '42918530', '42918530', '42918530', '42918530', '42a15761', '42a15761', '42a15761', '4364c1c4', '4364c1c4', '4364c1c4', '456873bc', '456873bc', '456873bc', '45737921', '45737921', '45737921', '45bbe264', '45bbe264')], batch_idx: 10\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('3ee1011a', '3f23242b', '3f23242b', '40f6cd08', '40f6cd08', '40f6cd08', '414297c0', '414297c0', '414297c0', '423a55dc', '423a55dc', '423a55dc', '423a55dc', '423a55dc', '42918530', '42918530', '42918530', '42918530', '42a15761', '42a15761', '42a15761', '4364c1c4', '4364c1c4', '4364c1c4', '456873bc', '456873bc', '456873bc', '45737921', '45737921', '45737921', '45bbe264', '45bbe264')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.136986301369863\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5142857142857142\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.35344827586206895\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5409836065573771\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5882352941176471\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.52\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7976190476190477\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7567567567567568\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7567567567567568\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.35555434226989746, Avg accuracy: 0.8881597276777029, Avg diff accuracy: 0.24890849229141349\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.35555434226989746, avg_accuracy=0.8881597276777029, diff_accuracy=0.24890849229141349\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.35555434226989746, 'task_ids': ('3ee1011a', '3f23242b', '3f23242b', '40f6cd08', '40f6cd08', '40f6cd08', '414297c0', '414297c0', '414297c0', '423a55dc', '423a55dc', '423a55dc', '423a55dc', '423a55dc', '42918530', '42918530', '42918530', '42918530', '42a15761', '42a15761', '42a15761', '4364c1c4', '4364c1c4', '4364c1c4', '456873bc', '456873bc', '456873bc', '45737921', '45737921', '45737921', '45bbe264', '45bbe264'), 'test_accuracy': 0.8881597276777029, 'test_diff_accuracy': 0.24890849229141349, '3ee1011a_test_accuracy': 0.9288889169692993, '3ee1011a_test_diff_accuracy': 0.136986301369863, '3f23242b_test_accuracy': 0.9744444489479065, '3f23242b_test_diff_accuracy': 0.0, '40f6cd08_test_accuracy': 0.6166666746139526, '40f6cd08_test_diff_accuracy': 0.0, '414297c0_test_accuracy': 0.9200000166893005, '414297c0_test_diff_accuracy': 0.5409836065573771, '423a55dc_test_accuracy': 0.9944444298744202, '423a55dc_test_diff_accuracy': 0.5, '42918530_test_accuracy': 0.8077777624130249, '42918530_test_diff_accuracy': 0.0, '42a15761_test_accuracy': 0.8911111354827881, '42a15761_test_diff_accuracy': 0.5, '4364c1c4_test_accuracy': 0.8266666531562805, '4364c1c4_test_diff_accuracy': 0.0, '456873bc_test_accuracy': 0.9722222089767456, '456873bc_test_diff_accuracy': 0.7567567567567568, '45737921_test_accuracy': 0.9599999785423279, '45737921_test_diff_accuracy': 0.0, '45bbe264_test_accuracy': 0.9422222375869751, '45bbe264_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.35555434226989746, 'task_ids': ('3ee1011a', '3f23242b', '3f23242b', '40f6cd08', '40f6cd08', '40f6cd08', '414297c0', '414297c0', '414297c0', '423a55dc', '423a55dc', '423a55dc', '423a55dc', '423a55dc', '42918530', '42918530', '42918530', '42918530', '42a15761', '42a15761', '42a15761', '4364c1c4', '4364c1c4', '4364c1c4', '456873bc', '456873bc', '456873bc', '45737921', '45737921', '45737921', '45bbe264', '45bbe264'), 'test_accuracy': 0.8881597276777029, 'test_diff_accuracy': 0.24890849229141349, '3ee1011a_test_accuracy': 0.9288889169692993, '3ee1011a_test_diff_accuracy': 0.136986301369863, '3f23242b_test_accuracy': 0.9744444489479065, '3f23242b_test_diff_accuracy': 0.0, '40f6cd08_test_accuracy': 0.6166666746139526, '40f6cd08_test_diff_accuracy': 0.0, '414297c0_test_accuracy': 0.9200000166893005, '414297c0_test_diff_accuracy': 0.5409836065573771, '423a55dc_test_accuracy': 0.9944444298744202, '423a55dc_test_diff_accuracy': 0.5, '42918530_test_accuracy': 0.8077777624130249, '42918530_test_diff_accuracy': 0.0, '42a15761_test_accuracy': 0.8911111354827881, '42a15761_test_diff_accuracy': 0.5, '4364c1c4_test_accuracy': 0.8266666531562805, '4364c1c4_test_diff_accuracy': 0.0, '456873bc_test_accuracy': 0.9722222089767456, '456873bc_test_diff_accuracy': 0.7567567567567568, '45737921_test_accuracy': 0.9599999785423279, '45737921_test_diff_accuracy': 0.0, '45bbe264_test_accuracy': 0.9422222375869751, '45bbe264_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('45bbe264', '477d2879', '477d2879', '477d2879', '47996f11', '47996f11', '47996f11', '47996f11', '48131b3c', '48131b3c', '48131b3c', '4852f2fa', '4852f2fa', '4852f2fa', '4852f2fa', '4852f2fa', '48f8583b', '48f8583b', '48f8583b', '48f8583b', '48f8583b', '48f8583b', '4aab4007', '4aab4007', '4aab4007', '4acc7107', '4acc7107', '4acc7107', '4acc7107', '4b6b68e5', '4b6b68e5', '4b6b68e5')], batch_idx: 11\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('45bbe264', '477d2879', '477d2879', '477d2879', '47996f11', '47996f11', '47996f11', '47996f11', '48131b3c', '48131b3c', '48131b3c', '4852f2fa', '4852f2fa', '4852f2fa', '4852f2fa', '4852f2fa', '48f8583b', '48f8583b', '48f8583b', '48f8583b', '48f8583b', '48f8583b', '4aab4007', '4aab4007', '4aab4007', '4acc7107', '4acc7107', '4acc7107', '4acc7107', '4b6b68e5', '4b6b68e5', '4b6b68e5')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.02564102564102564\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.08888888888888889\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.08421052631578947\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.22608695652173913\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.043478260869565216\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.2\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.09523809523809523\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.3157894736842105\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5454545454545454\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.35294117647058826\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.30434782608695654\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.2857142857142857\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4444444444444444\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.3333333333333333\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.25\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.25\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4827586206896552\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.44680851063829785\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.022727272727272728\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.09090909090909091\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.8300538063049316, Avg accuracy: 0.7661111173219979, Avg diff accuracy: 0.19964913542586826\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.8300538063049316, avg_accuracy=0.7661111173219979, diff_accuracy=0.19964913542586826\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.8300538063049316, 'task_ids': ('45bbe264', '477d2879', '477d2879', '477d2879', '47996f11', '47996f11', '47996f11', '47996f11', '48131b3c', '48131b3c', '48131b3c', '4852f2fa', '4852f2fa', '4852f2fa', '4852f2fa', '4852f2fa', '48f8583b', '48f8583b', '48f8583b', '48f8583b', '48f8583b', '48f8583b', '4aab4007', '4aab4007', '4aab4007', '4acc7107', '4acc7107', '4acc7107', '4acc7107', '4b6b68e5', '4b6b68e5', '4b6b68e5'), 'test_accuracy': 0.7661111173219979, 'test_diff_accuracy': 0.19964913542586826, '45bbe264_test_accuracy': 0.9233333468437195, '45bbe264_test_diff_accuracy': 0.0, '477d2879_test_accuracy': 0.8122222423553467, '477d2879_test_diff_accuracy': 0.0, '47996f11_test_accuracy': 0.20777778327465057, '47996f11_test_diff_accuracy': 0.22608695652173913, '48131b3c_test_accuracy': 0.9555555582046509, '48131b3c_test_diff_accuracy': 0.09523809523809523, '4852f2fa_test_accuracy': 0.9777777791023254, '4852f2fa_test_diff_accuracy': 0.2857142857142857, '48f8583b_test_accuracy': 0.9700000286102295, '48f8583b_test_diff_accuracy': 0.25, '4aab4007_test_accuracy': 0.12888889014720917, '4aab4007_test_diff_accuracy': 0.0, '4acc7107_test_accuracy': 0.9711111187934875, '4acc7107_test_diff_accuracy': 0.44680851063829785, '4b6b68e5_test_accuracy': 0.8700000047683716, '4b6b68e5_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.8300538063049316, 'task_ids': ('45bbe264', '477d2879', '477d2879', '477d2879', '47996f11', '47996f11', '47996f11', '47996f11', '48131b3c', '48131b3c', '48131b3c', '4852f2fa', '4852f2fa', '4852f2fa', '4852f2fa', '4852f2fa', '48f8583b', '48f8583b', '48f8583b', '48f8583b', '48f8583b', '48f8583b', '4aab4007', '4aab4007', '4aab4007', '4acc7107', '4acc7107', '4acc7107', '4acc7107', '4b6b68e5', '4b6b68e5', '4b6b68e5'), 'test_accuracy': 0.7661111173219979, 'test_diff_accuracy': 0.19964913542586826, '45bbe264_test_accuracy': 0.9233333468437195, '45bbe264_test_diff_accuracy': 0.0, '477d2879_test_accuracy': 0.8122222423553467, '477d2879_test_diff_accuracy': 0.0, '47996f11_test_accuracy': 0.20777778327465057, '47996f11_test_diff_accuracy': 0.22608695652173913, '48131b3c_test_accuracy': 0.9555555582046509, '48131b3c_test_diff_accuracy': 0.09523809523809523, '4852f2fa_test_accuracy': 0.9777777791023254, '4852f2fa_test_diff_accuracy': 0.2857142857142857, '48f8583b_test_accuracy': 0.9700000286102295, '48f8583b_test_diff_accuracy': 0.25, '4aab4007_test_accuracy': 0.12888889014720917, '4aab4007_test_diff_accuracy': 0.0, '4acc7107_test_accuracy': 0.9711111187934875, '4acc7107_test_diff_accuracy': 0.44680851063829785, '4b6b68e5_test_accuracy': 0.8700000047683716, '4b6b68e5_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('4c177718', '4c177718', '4c177718', '4c177718', '4cd1b7b2', '4cd1b7b2', '4cd1b7b2', '4e45f183', '4e45f183', '4e45f183', '4e469f39', '4e469f39', '4e469f39', '4f537728', '4f537728', '4ff4c9da', '4ff4c9da', '4ff4c9da', '505fff84', '505fff84', '505fff84', '505fff84', '505fff84', '506d28a5', '506d28a5', '506d28a5', '506d28a5', '50a16a69', '50a16a69', '50a16a69', '50aad11f', '50aad11f')], batch_idx: 12\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('4c177718', '4c177718', '4c177718', '4c177718', '4cd1b7b2', '4cd1b7b2', '4cd1b7b2', '4e45f183', '4e45f183', '4e45f183', '4e469f39', '4e469f39', '4e469f39', '4f537728', '4f537728', '4ff4c9da', '4ff4c9da', '4ff4c9da', '505fff84', '505fff84', '505fff84', '505fff84', '505fff84', '506d28a5', '506d28a5', '506d28a5', '506d28a5', '50a16a69', '50a16a69', '50a16a69', '50aad11f', '50aad11f')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7547169811320755\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7391304347826086\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7142857142857143\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7804878048780488\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.041666666666666664\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8651685393258427\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8823529411764706\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9259259259259259\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8837209302325582\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8979591836734694\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.39285714285714285\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5172413793103449\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.12\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4666666666666667\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.27849647402763367, Avg accuracy: 0.9005208313465118, Avg diff accuracy: 0.32756813471604795\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.27849647402763367, avg_accuracy=0.9005208313465118, diff_accuracy=0.32756813471604795\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.27849647402763367, 'task_ids': ('4c177718', '4c177718', '4c177718', '4c177718', '4cd1b7b2', '4cd1b7b2', '4cd1b7b2', '4e45f183', '4e45f183', '4e45f183', '4e469f39', '4e469f39', '4e469f39', '4f537728', '4f537728', '4ff4c9da', '4ff4c9da', '4ff4c9da', '505fff84', '505fff84', '505fff84', '505fff84', '505fff84', '506d28a5', '506d28a5', '506d28a5', '506d28a5', '50a16a69', '50a16a69', '50a16a69', '50aad11f', '50aad11f'), 'test_accuracy': 0.9005208313465118, 'test_diff_accuracy': 0.32756813471604795, '4c177718_test_accuracy': 0.9900000095367432, '4c177718_test_diff_accuracy': 0.7804878048780488, '4cd1b7b2_test_accuracy': 0.9822221994400024, '4cd1b7b2_test_diff_accuracy': 0.0, '4e45f183_test_accuracy': 0.7522222399711609, '4e45f183_test_diff_accuracy': 0.041666666666666664, '4e469f39_test_accuracy': 0.9511111378669739, '4e469f39_test_diff_accuracy': 0.0, '4f537728_test_accuracy': 0.8122222423553467, '4f537728_test_diff_accuracy': 0.0, '4ff4c9da_test_accuracy': 0.7333333492279053, '4ff4c9da_test_diff_accuracy': 0.0, '505fff84_test_accuracy': 0.9900000095367432, '505fff84_test_diff_accuracy': 0.8979591836734694, '506d28a5_test_accuracy': 0.9844444394111633, '506d28a5_test_diff_accuracy': 0.5172413793103449, '50a16a69_test_accuracy': 0.9100000262260437, '50a16a69_test_diff_accuracy': 0.0, '50aad11f_test_accuracy': 0.9822221994400024, '50aad11f_test_diff_accuracy': 0.5}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.27849647402763367, 'task_ids': ('4c177718', '4c177718', '4c177718', '4c177718', '4cd1b7b2', '4cd1b7b2', '4cd1b7b2', '4e45f183', '4e45f183', '4e45f183', '4e469f39', '4e469f39', '4e469f39', '4f537728', '4f537728', '4ff4c9da', '4ff4c9da', '4ff4c9da', '505fff84', '505fff84', '505fff84', '505fff84', '505fff84', '506d28a5', '506d28a5', '506d28a5', '506d28a5', '50a16a69', '50a16a69', '50a16a69', '50aad11f', '50aad11f'), 'test_accuracy': 0.9005208313465118, 'test_diff_accuracy': 0.32756813471604795, '4c177718_test_accuracy': 0.9900000095367432, '4c177718_test_diff_accuracy': 0.7804878048780488, '4cd1b7b2_test_accuracy': 0.9822221994400024, '4cd1b7b2_test_diff_accuracy': 0.0, '4e45f183_test_accuracy': 0.7522222399711609, '4e45f183_test_diff_accuracy': 0.041666666666666664, '4e469f39_test_accuracy': 0.9511111378669739, '4e469f39_test_diff_accuracy': 0.0, '4f537728_test_accuracy': 0.8122222423553467, '4f537728_test_diff_accuracy': 0.0, '4ff4c9da_test_accuracy': 0.7333333492279053, '4ff4c9da_test_diff_accuracy': 0.0, '505fff84_test_accuracy': 0.9900000095367432, '505fff84_test_diff_accuracy': 0.8979591836734694, '506d28a5_test_accuracy': 0.9844444394111633, '506d28a5_test_diff_accuracy': 0.5172413793103449, '50a16a69_test_accuracy': 0.9100000262260437, '50a16a69_test_diff_accuracy': 0.0, '50aad11f_test_accuracy': 0.9822221994400024, '50aad11f_test_diff_accuracy': 0.5}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('50aad11f', '50f325b5', '50f325b5', '50f325b5', '50f325b5', '516b51b7', '516b51b7', '516b51b7', '5207a7b5', '5207a7b5', '5207a7b5', '5289ad53', '5289ad53', '5289ad53', '5289ad53', '52fd389e', '52fd389e', '52fd389e', '54db823b', '54db823b', '54db823b', '54db823b', '55059096', '55059096', '55059096', '551d5bf1', '551d5bf1', '55783887', '55783887', '55783887', '55783887', '55783887')], batch_idx: 13\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('50aad11f', '50f325b5', '50f325b5', '50f325b5', '50f325b5', '516b51b7', '516b51b7', '516b51b7', '5207a7b5', '5207a7b5', '5207a7b5', '5289ad53', '5289ad53', '5289ad53', '5289ad53', '52fd389e', '52fd389e', '52fd389e', '54db823b', '54db823b', '54db823b', '54db823b', '55059096', '55059096', '55059096', '551d5bf1', '551d5bf1', '55783887', '55783887', '55783887', '55783887', '55783887')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.43478260869565216\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9473684210526315\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.96\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9642857142857143\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6528497409326425\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.4569234848022461, Avg accuracy: 0.8798958323895931, Avg diff accuracy: 0.2643527026552075\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.4569234848022461, avg_accuracy=0.8798958323895931, diff_accuracy=0.2643527026552075\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.4569234848022461, 'task_ids': ('50aad11f', '50f325b5', '50f325b5', '50f325b5', '50f325b5', '516b51b7', '516b51b7', '516b51b7', '5207a7b5', '5207a7b5', '5207a7b5', '5289ad53', '5289ad53', '5289ad53', '5289ad53', '52fd389e', '52fd389e', '52fd389e', '54db823b', '54db823b', '54db823b', '54db823b', '55059096', '55059096', '55059096', '551d5bf1', '551d5bf1', '55783887', '55783887', '55783887', '55783887', '55783887'), 'test_accuracy': 0.8798958323895931, 'test_diff_accuracy': 0.2643527026552075, '50aad11f_test_accuracy': 0.9711111187934875, '50aad11f_test_diff_accuracy': 0.43478260869565216, '50f325b5_test_accuracy': 0.757777750492096, '50f325b5_test_diff_accuracy': 0.0, '516b51b7_test_accuracy': 0.8899999856948853, '516b51b7_test_diff_accuracy': 0.0, '5207a7b5_test_accuracy': 0.9300000071525574, '5207a7b5_test_diff_accuracy': 0.0, '5289ad53_test_accuracy': 0.9233333468437195, '5289ad53_test_diff_accuracy': 0.6528497409326425, '52fd389e_test_accuracy': 0.6399999856948853, '52fd389e_test_diff_accuracy': 0.0, '54db823b_test_accuracy': 0.9166666865348816, '54db823b_test_diff_accuracy': 1.0, '55059096_test_accuracy': 0.9755555391311646, '55059096_test_diff_accuracy': 0.0, '551d5bf1_test_accuracy': 0.7733333110809326, '551d5bf1_test_diff_accuracy': 0.0, '55783887_test_accuracy': 0.7333333492279053, '55783887_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.4569234848022461, 'task_ids': ('50aad11f', '50f325b5', '50f325b5', '50f325b5', '50f325b5', '516b51b7', '516b51b7', '516b51b7', '5207a7b5', '5207a7b5', '5207a7b5', '5289ad53', '5289ad53', '5289ad53', '5289ad53', '52fd389e', '52fd389e', '52fd389e', '54db823b', '54db823b', '54db823b', '54db823b', '55059096', '55059096', '55059096', '551d5bf1', '551d5bf1', '55783887', '55783887', '55783887', '55783887', '55783887'), 'test_accuracy': 0.8798958323895931, 'test_diff_accuracy': 0.2643527026552075, '50aad11f_test_accuracy': 0.9711111187934875, '50aad11f_test_diff_accuracy': 0.43478260869565216, '50f325b5_test_accuracy': 0.757777750492096, '50f325b5_test_diff_accuracy': 0.0, '516b51b7_test_accuracy': 0.8899999856948853, '516b51b7_test_diff_accuracy': 0.0, '5207a7b5_test_accuracy': 0.9300000071525574, '5207a7b5_test_diff_accuracy': 0.0, '5289ad53_test_accuracy': 0.9233333468437195, '5289ad53_test_diff_accuracy': 0.6528497409326425, '52fd389e_test_accuracy': 0.6399999856948853, '52fd389e_test_diff_accuracy': 0.0, '54db823b_test_accuracy': 0.9166666865348816, '54db823b_test_diff_accuracy': 1.0, '55059096_test_accuracy': 0.9755555391311646, '55059096_test_diff_accuracy': 0.0, '551d5bf1_test_accuracy': 0.7733333110809326, '551d5bf1_test_diff_accuracy': 0.0, '55783887_test_accuracy': 0.7333333492279053, '55783887_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('575b1a71', '575b1a71', '575b1a71', '5783df64', '5783df64', '5783df64', '5833af48', '5833af48', '5833af48', '58743b76', '58743b76', '58e15b12', '58e15b12', '58e15b12', '59341089', '59341089', '59341089', '59341089', '5a5a2103', '5a5a2103', '5af49b42', '5af49b42', '5af49b42', '5b526a93', '5b526a93', '5b692c0f', '5b692c0f', '5b6cbef5', '5b6cbef5', '5b6cbef5', '5b6cbef5', '5b6cbef5')], batch_idx: 14\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('575b1a71', '575b1a71', '575b1a71', '5783df64', '5783df64', '5783df64', '5833af48', '5833af48', '5833af48', '58743b76', '58743b76', '58e15b12', '58e15b12', '58e15b12', '59341089', '59341089', '59341089', '59341089', '5a5a2103', '5a5a2103', '5af49b42', '5af49b42', '5af49b42', '5b526a93', '5b526a93', '5b692c0f', '5b692c0f', '5b6cbef5', '5b6cbef5', '5b6cbef5', '5b6cbef5', '5b6cbef5')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4375\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.47058823529411764\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4666666666666667\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.64\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5168539325842697\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6461538461538462\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.045454545454545456\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.045454545454545456\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.22727272727272727\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.25\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.07547169811320754\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.16666666666666666\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0625\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.1\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.05\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.35447943210601807, Avg accuracy: 0.9240625035017729, Avg diff accuracy: 0.13126821448939352\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.35447943210601807, avg_accuracy=0.9240625035017729, diff_accuracy=0.13126821448939352\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.35447943210601807, 'task_ids': ('575b1a71', '575b1a71', '575b1a71', '5783df64', '5783df64', '5783df64', '5833af48', '5833af48', '5833af48', '58743b76', '58743b76', '58e15b12', '58e15b12', '58e15b12', '59341089', '59341089', '59341089', '59341089', '5a5a2103', '5a5a2103', '5af49b42', '5af49b42', '5af49b42', '5b526a93', '5b526a93', '5b692c0f', '5b692c0f', '5b6cbef5', '5b6cbef5', '5b6cbef5', '5b6cbef5', '5b6cbef5'), 'test_accuracy': 0.9240625035017729, 'test_diff_accuracy': 0.13126821448939352, '575b1a71_test_accuracy': 0.8888888955116272, '575b1a71_test_diff_accuracy': 0.0, '5783df64_test_accuracy': 0.9900000095367432, '5783df64_test_diff_accuracy': 0.4666666666666667, '5833af48_test_accuracy': 0.9399999976158142, '5833af48_test_diff_accuracy': 0.6461538461538462, '58743b76_test_accuracy': 0.945555567741394, '58743b76_test_diff_accuracy': 0.0, '58e15b12_test_accuracy': 0.9200000166893005, '58e15b12_test_diff_accuracy': 0.0, '59341089_test_accuracy': 0.9599999785423279, '59341089_test_diff_accuracy': 0.0, '5a5a2103_test_accuracy': 0.7766666412353516, '5a5a2103_test_diff_accuracy': 0.045454545454545456, '5af49b42_test_accuracy': 0.9766666889190674, '5af49b42_test_diff_accuracy': 0.0, '5b526a93_test_accuracy': 0.8933333158493042, '5b526a93_test_diff_accuracy': 0.0, '5b692c0f_test_accuracy': 0.9277777671813965, '5b692c0f_test_diff_accuracy': 0.25, '5b6cbef5_test_accuracy': 0.8888888955116272, '5b6cbef5_test_diff_accuracy': 0.05}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.35447943210601807, 'task_ids': ('575b1a71', '575b1a71', '575b1a71', '5783df64', '5783df64', '5783df64', '5833af48', '5833af48', '5833af48', '58743b76', '58743b76', '58e15b12', '58e15b12', '58e15b12', '59341089', '59341089', '59341089', '59341089', '5a5a2103', '5a5a2103', '5af49b42', '5af49b42', '5af49b42', '5b526a93', '5b526a93', '5b692c0f', '5b692c0f', '5b6cbef5', '5b6cbef5', '5b6cbef5', '5b6cbef5', '5b6cbef5'), 'test_accuracy': 0.9240625035017729, 'test_diff_accuracy': 0.13126821448939352, '575b1a71_test_accuracy': 0.8888888955116272, '575b1a71_test_diff_accuracy': 0.0, '5783df64_test_accuracy': 0.9900000095367432, '5783df64_test_diff_accuracy': 0.4666666666666667, '5833af48_test_accuracy': 0.9399999976158142, '5833af48_test_diff_accuracy': 0.6461538461538462, '58743b76_test_accuracy': 0.945555567741394, '58743b76_test_diff_accuracy': 0.0, '58e15b12_test_accuracy': 0.9200000166893005, '58e15b12_test_diff_accuracy': 0.0, '59341089_test_accuracy': 0.9599999785423279, '59341089_test_diff_accuracy': 0.0, '5a5a2103_test_accuracy': 0.7766666412353516, '5a5a2103_test_diff_accuracy': 0.045454545454545456, '5af49b42_test_accuracy': 0.9766666889190674, '5af49b42_test_diff_accuracy': 0.0, '5b526a93_test_accuracy': 0.8933333158493042, '5b526a93_test_diff_accuracy': 0.0, '5b692c0f_test_accuracy': 0.9277777671813965, '5b692c0f_test_diff_accuracy': 0.25, '5b6cbef5_test_accuracy': 0.8888888955116272, '5b6cbef5_test_diff_accuracy': 0.05}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('5d2a5c43', '5d2a5c43', '5d2a5c43', '5d2a5c43', '5d2a5c43', '5ffb2104', '5ffb2104', '5ffb2104', '604001fa', '604001fa', '604001fa', '604001fa', '60a26a3e', '60a26a3e', '60a26a3e', '60c09cac', '60c09cac', '626c0bcc', '626c0bcc', '626c0bcc', '62ab2642', '62ab2642', '62ab2642', '62b74c02', '62b74c02', '62b74c02', '639f5a19', '639f5a19', '642248e4', '642248e4', '642248e4', '642d658d')], batch_idx: 15\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('5d2a5c43', '5d2a5c43', '5d2a5c43', '5d2a5c43', '5d2a5c43', '5ffb2104', '5ffb2104', '5ffb2104', '604001fa', '604001fa', '604001fa', '604001fa', '60a26a3e', '60a26a3e', '60a26a3e', '60c09cac', '60c09cac', '626c0bcc', '626c0bcc', '626c0bcc', '62ab2642', '62ab2642', '62ab2642', '62b74c02', '62b74c02', '62b74c02', '639f5a19', '639f5a19', '642248e4', '642248e4', '642248e4', '642d658d')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.47058823529411764\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4444444444444444\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.47368421052631576\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.47058823529411764\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.25\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.2727272727272727\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.2857142857142857\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.2857142857142857\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.05555555555555555\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7910750507099391\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.18470335006713867, Avg accuracy: 0.9562500026077032, Avg diff accuracy: 0.18125286174938546\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.18470335006713867, avg_accuracy=0.9562500026077032, diff_accuracy=0.18125286174938546\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.18470335006713867, 'task_ids': ('5d2a5c43', '5d2a5c43', '5d2a5c43', '5d2a5c43', '5d2a5c43', '5ffb2104', '5ffb2104', '5ffb2104', '604001fa', '604001fa', '604001fa', '604001fa', '60a26a3e', '60a26a3e', '60a26a3e', '60c09cac', '60c09cac', '626c0bcc', '626c0bcc', '626c0bcc', '62ab2642', '62ab2642', '62ab2642', '62b74c02', '62b74c02', '62b74c02', '639f5a19', '639f5a19', '642248e4', '642248e4', '642248e4', '642d658d'), 'test_accuracy': 0.9562500026077032, 'test_diff_accuracy': 0.18125286174938546, '5d2a5c43_test_accuracy': 0.9777777791023254, '5d2a5c43_test_diff_accuracy': 0.47368421052631576, '5ffb2104_test_accuracy': 0.9900000095367432, '5ffb2104_test_diff_accuracy': 0.47058823529411764, '604001fa_test_accuracy': 0.9833333492279053, '604001fa_test_diff_accuracy': 0.2857142857142857, '60a26a3e_test_accuracy': 0.9644444584846497, '60a26a3e_test_diff_accuracy': 0.0, '60c09cac_test_accuracy': 0.9777777791023254, '60c09cac_test_diff_accuracy': 0.05555555555555555, '626c0bcc_test_accuracy': 0.9855555295944214, '626c0bcc_test_diff_accuracy': 0.0, '62ab2642_test_accuracy': 0.9233333468437195, '62ab2642_test_diff_accuracy': 0.0, '62b74c02_test_accuracy': 0.9544444680213928, '62b74c02_test_diff_accuracy': 0.0, '639f5a19_test_accuracy': 0.7599999904632568, '639f5a19_test_diff_accuracy': 0.0, '642248e4_test_accuracy': 0.9599999785423279, '642248e4_test_diff_accuracy': 0.0, '642d658d_test_accuracy': 0.8855555653572083, '642d658d_test_diff_accuracy': 0.7910750507099391}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.18470335006713867, 'task_ids': ('5d2a5c43', '5d2a5c43', '5d2a5c43', '5d2a5c43', '5d2a5c43', '5ffb2104', '5ffb2104', '5ffb2104', '604001fa', '604001fa', '604001fa', '604001fa', '60a26a3e', '60a26a3e', '60a26a3e', '60c09cac', '60c09cac', '626c0bcc', '626c0bcc', '626c0bcc', '62ab2642', '62ab2642', '62ab2642', '62b74c02', '62b74c02', '62b74c02', '639f5a19', '639f5a19', '642248e4', '642248e4', '642248e4', '642d658d'), 'test_accuracy': 0.9562500026077032, 'test_diff_accuracy': 0.18125286174938546, '5d2a5c43_test_accuracy': 0.9777777791023254, '5d2a5c43_test_diff_accuracy': 0.47368421052631576, '5ffb2104_test_accuracy': 0.9900000095367432, '5ffb2104_test_diff_accuracy': 0.47058823529411764, '604001fa_test_accuracy': 0.9833333492279053, '604001fa_test_diff_accuracy': 0.2857142857142857, '60a26a3e_test_accuracy': 0.9644444584846497, '60a26a3e_test_diff_accuracy': 0.0, '60c09cac_test_accuracy': 0.9777777791023254, '60c09cac_test_diff_accuracy': 0.05555555555555555, '626c0bcc_test_accuracy': 0.9855555295944214, '626c0bcc_test_diff_accuracy': 0.0, '62ab2642_test_accuracy': 0.9233333468437195, '62ab2642_test_diff_accuracy': 0.0, '62b74c02_test_accuracy': 0.9544444680213928, '62b74c02_test_diff_accuracy': 0.0, '639f5a19_test_accuracy': 0.7599999904632568, '639f5a19_test_diff_accuracy': 0.0, '642248e4_test_accuracy': 0.9599999785423279, '642248e4_test_diff_accuracy': 0.0, '642d658d_test_accuracy': 0.8855555653572083, '642d658d_test_diff_accuracy': 0.7910750507099391}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('642d658d', '642d658d', '64a7c07e', '64a7c07e', '64a7c07e', '66e6c45b', '66e6c45b', '66f2d22f', '66f2d22f', '66f2d22f', '66f2d22f', '67636eac', '67636eac', '67636eac', '67b4a34d', '67b4a34d', '67b4a34d', '67c52801', '67c52801', '67c52801', '67c52801', '68b67ca3', '68b67ca3', '68b67ca3', '692cd3b6', '692cd3b6', '692cd3b6', '695367ec', '695367ec', '695367ec', '696d4842', '696d4842')], batch_idx: 16\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('642d658d', '642d658d', '64a7c07e', '64a7c07e', '64a7c07e', '66e6c45b', '66e6c45b', '66f2d22f', '66f2d22f', '66f2d22f', '66f2d22f', '67636eac', '67636eac', '67636eac', '67b4a34d', '67b4a34d', '67b4a34d', '67c52801', '67c52801', '67c52801', '67c52801', '68b67ca3', '68b67ca3', '68b67ca3', '692cd3b6', '692cd3b6', '692cd3b6', '695367ec', '695367ec', '695367ec', '696d4842', '696d4842')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.997093023255814\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9970238095238095\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6428571428571429\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8125\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8275862068965517\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7419354838709677\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9317269076305221\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9475806451612904\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8622047244094488\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.05\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.008130081300813009\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.10843373493975904\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.23099343478679657, Avg accuracy: 0.9687847271561623, Avg diff accuracy: 0.4789709924951912\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.23099343478679657, avg_accuracy=0.9687847271561623, diff_accuracy=0.4789709924951912\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.23099343478679657, 'task_ids': ('642d658d', '642d658d', '64a7c07e', '64a7c07e', '64a7c07e', '66e6c45b', '66e6c45b', '66f2d22f', '66f2d22f', '66f2d22f', '66f2d22f', '67636eac', '67636eac', '67636eac', '67b4a34d', '67b4a34d', '67b4a34d', '67c52801', '67c52801', '67c52801', '67c52801', '68b67ca3', '68b67ca3', '68b67ca3', '692cd3b6', '692cd3b6', '692cd3b6', '695367ec', '695367ec', '695367ec', '696d4842', '696d4842'), 'test_accuracy': 0.9687847271561623, 'test_diff_accuracy': 0.4789709924951912, '642d658d_test_accuracy': 0.9988889098167419, '642d658d_test_diff_accuracy': 0.9970238095238095, '64a7c07e_test_accuracy': 0.9822221994400024, '64a7c07e_test_diff_accuracy': 0.5, '66e6c45b_test_accuracy': 0.995555579662323, '66e6c45b_test_diff_accuracy': 0.5, '66f2d22f_test_accuracy': 0.9911110997200012, '66f2d22f_test_diff_accuracy': 0.7419354838709677, '67636eac_test_accuracy': 0.9888888597488403, '67636eac_test_diff_accuracy': 0.5, '67b4a34d_test_accuracy': 0.9588888883590698, '67b4a34d_test_diff_accuracy': 0.8622047244094488, '67c52801_test_accuracy': 0.9666666388511658, '67c52801_test_diff_accuracy': 0.5, '68b67ca3_test_accuracy': 0.995555579662323, '68b67ca3_test_diff_accuracy': 0.5, '692cd3b6_test_accuracy': 0.855555534362793, '692cd3b6_test_diff_accuracy': 0.0, '695367ec_test_accuracy': 0.9100000262260437, '695367ec_test_diff_accuracy': 0.10843373493975904, '696d4842_test_accuracy': 0.9688888788223267, '696d4842_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.23099343478679657, 'task_ids': ('642d658d', '642d658d', '64a7c07e', '64a7c07e', '64a7c07e', '66e6c45b', '66e6c45b', '66f2d22f', '66f2d22f', '66f2d22f', '66f2d22f', '67636eac', '67636eac', '67636eac', '67b4a34d', '67b4a34d', '67b4a34d', '67c52801', '67c52801', '67c52801', '67c52801', '68b67ca3', '68b67ca3', '68b67ca3', '692cd3b6', '692cd3b6', '692cd3b6', '695367ec', '695367ec', '695367ec', '696d4842', '696d4842'), 'test_accuracy': 0.9687847271561623, 'test_diff_accuracy': 0.4789709924951912, '642d658d_test_accuracy': 0.9988889098167419, '642d658d_test_diff_accuracy': 0.9970238095238095, '64a7c07e_test_accuracy': 0.9822221994400024, '64a7c07e_test_diff_accuracy': 0.5, '66e6c45b_test_accuracy': 0.995555579662323, '66e6c45b_test_diff_accuracy': 0.5, '66f2d22f_test_accuracy': 0.9911110997200012, '66f2d22f_test_diff_accuracy': 0.7419354838709677, '67636eac_test_accuracy': 0.9888888597488403, '67636eac_test_diff_accuracy': 0.5, '67b4a34d_test_accuracy': 0.9588888883590698, '67b4a34d_test_diff_accuracy': 0.8622047244094488, '67c52801_test_accuracy': 0.9666666388511658, '67c52801_test_diff_accuracy': 0.5, '68b67ca3_test_accuracy': 0.995555579662323, '68b67ca3_test_diff_accuracy': 0.5, '692cd3b6_test_accuracy': 0.855555534362793, '692cd3b6_test_diff_accuracy': 0.0, '695367ec_test_accuracy': 0.9100000262260437, '695367ec_test_diff_accuracy': 0.10843373493975904, '696d4842_test_accuracy': 0.9688888788223267, '696d4842_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 5, 5,  ..., 5, 0, 0],\n",
            "          [0, 5, 5,  ..., 5, 0, 0],\n",
            "          ...,\n",
            "          [0, 5, 5,  ..., 5, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('696d4842', '69889d6e', '69889d6e', '69889d6e', '69889d6e', '6a11f6da', '6a11f6da', '6a11f6da', '6a11f6da', '6a11f6da', '6ad5bdfd', '6ad5bdfd', '6ad5bdfd', '6df30ad6', '6df30ad6', '6df30ad6', '6df30ad6', '6df30ad6', '6ea4a07e', '6ea4a07e', '6ea4a07e', '6ea4a07e', '6ea4a07e', '6ea4a07e', '6f473927', '6f473927', '6f473927', '6f473927', '7039b2d7', '7039b2d7', '7039b2d7', '705a3229')], batch_idx: 17\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('696d4842', '69889d6e', '69889d6e', '69889d6e', '69889d6e', '6a11f6da', '6a11f6da', '6a11f6da', '6a11f6da', '6a11f6da', '6ad5bdfd', '6ad5bdfd', '6ad5bdfd', '6df30ad6', '6df30ad6', '6df30ad6', '6df30ad6', '6df30ad6', '6ea4a07e', '6ea4a07e', '6ea4a07e', '6ea4a07e', '6ea4a07e', '6ea4a07e', '6f473927', '6f473927', '6f473927', '6f473927', '7039b2d7', '7039b2d7', '7039b2d7', '705a3229')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5869565217391305\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5714285714285714\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5555555555555556\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5813953488372093\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5957446808510638\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4782608695652174\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.42105263157894735\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.47368421052631576\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4583333333333333\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.55\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7368421052631579\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7333333333333333\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.25\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.2222222222222222\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.3333333333333333\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4444444444444444\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4444444444444444\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.3333333333333333\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4444444444444444\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.09615384615384616\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.17857142857142858\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.2727272727272727\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.3076923076923077\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9907621247113164\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9929478138222849\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9690721649484536\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.14405301213264465, Avg accuracy: 0.9824652783572674, Avg diff accuracy: 0.40696051071440525\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.14405301213264465, avg_accuracy=0.9824652783572674, diff_accuracy=0.40696051071440525\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.14405301213264465, 'task_ids': ('696d4842', '69889d6e', '69889d6e', '69889d6e', '69889d6e', '6a11f6da', '6a11f6da', '6a11f6da', '6a11f6da', '6a11f6da', '6ad5bdfd', '6ad5bdfd', '6ad5bdfd', '6df30ad6', '6df30ad6', '6df30ad6', '6df30ad6', '6df30ad6', '6ea4a07e', '6ea4a07e', '6ea4a07e', '6ea4a07e', '6ea4a07e', '6ea4a07e', '6f473927', '6f473927', '6f473927', '6f473927', '7039b2d7', '7039b2d7', '7039b2d7', '705a3229'), 'test_accuracy': 0.9824652783572674, 'test_diff_accuracy': 0.40696051071440525, '696d4842_test_accuracy': 0.9599999785423279, '696d4842_test_diff_accuracy': 0.0, '69889d6e_test_accuracy': 0.9777777791023254, '69889d6e_test_diff_accuracy': 0.0, '6a11f6da_test_accuracy': 0.9766666889190674, '6a11f6da_test_diff_accuracy': 0.5957446808510638, '6ad5bdfd_test_accuracy': 0.9833333492279053, '6ad5bdfd_test_diff_accuracy': 0.47368421052631576, '6df30ad6_test_accuracy': 0.9933333396911621, '6df30ad6_test_diff_accuracy': 0.25, '6ea4a07e_test_accuracy': 0.9944444298744202, '6ea4a07e_test_diff_accuracy': 0.4444444444444444, '6f473927_test_accuracy': 0.9900000095367432, '6f473927_test_diff_accuracy': 0.3076923076923077, '7039b2d7_test_accuracy': 0.9933333396911621, '7039b2d7_test_diff_accuracy': 0.9690721649484536, '705a3229_test_accuracy': 0.9888888597488403, '705a3229_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.14405301213264465, 'task_ids': ('696d4842', '69889d6e', '69889d6e', '69889d6e', '69889d6e', '6a11f6da', '6a11f6da', '6a11f6da', '6a11f6da', '6a11f6da', '6ad5bdfd', '6ad5bdfd', '6ad5bdfd', '6df30ad6', '6df30ad6', '6df30ad6', '6df30ad6', '6df30ad6', '6ea4a07e', '6ea4a07e', '6ea4a07e', '6ea4a07e', '6ea4a07e', '6ea4a07e', '6f473927', '6f473927', '6f473927', '6f473927', '7039b2d7', '7039b2d7', '7039b2d7', '705a3229'), 'test_accuracy': 0.9824652783572674, 'test_diff_accuracy': 0.40696051071440525, '696d4842_test_accuracy': 0.9599999785423279, '696d4842_test_diff_accuracy': 0.0, '69889d6e_test_accuracy': 0.9777777791023254, '69889d6e_test_diff_accuracy': 0.0, '6a11f6da_test_accuracy': 0.9766666889190674, '6a11f6da_test_diff_accuracy': 0.5957446808510638, '6ad5bdfd_test_accuracy': 0.9833333492279053, '6ad5bdfd_test_diff_accuracy': 0.47368421052631576, '6df30ad6_test_accuracy': 0.9933333396911621, '6df30ad6_test_diff_accuracy': 0.25, '6ea4a07e_test_accuracy': 0.9944444298744202, '6ea4a07e_test_diff_accuracy': 0.4444444444444444, '6f473927_test_accuracy': 0.9900000095367432, '6f473927_test_diff_accuracy': 0.3076923076923077, '7039b2d7_test_accuracy': 0.9933333396911621, '7039b2d7_test_diff_accuracy': 0.9690721649484536, '705a3229_test_accuracy': 0.9888888597488403, '705a3229_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('705a3229', '705a3229', '705a3229', '712bf12e', '712bf12e', '712bf12e', '72207abc', '72207abc', '72207abc', '72a961c9', '72a961c9', '72a961c9', '72a961c9', '73182012', '73182012', '73182012', '73c3b0d8', '73c3b0d8', '73c3b0d8', '73c3b0d8', '73ccf9c2', '73ccf9c2', '73ccf9c2', '759f3fd3', '759f3fd3', '762cd429', '762cd429', '762cd429', '770cc55f', '770cc55f', '770cc55f', '770cc55f')], batch_idx: 18\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('705a3229', '705a3229', '705a3229', '712bf12e', '712bf12e', '712bf12e', '72207abc', '72207abc', '72207abc', '72a961c9', '72a961c9', '72a961c9', '72a961c9', '73182012', '73182012', '73182012', '73c3b0d8', '73c3b0d8', '73c3b0d8', '73c3b0d8', '73ccf9c2', '73ccf9c2', '73ccf9c2', '759f3fd3', '759f3fd3', '762cd429', '762cd429', '762cd429', '770cc55f', '770cc55f', '770cc55f', '770cc55f')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8648648648648649\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7857142857142857\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.16666666666666666\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.2222222222222222\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.29411764705882354\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8421052631578947\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8823529411764706\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7846153846153846\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.2715076804161072, Avg accuracy: 0.9537847265601158, Avg diff accuracy: 0.19820810235864414\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.2715076804161072, avg_accuracy=0.9537847265601158, diff_accuracy=0.19820810235864414\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.2715076804161072, 'task_ids': ('705a3229', '705a3229', '705a3229', '712bf12e', '712bf12e', '712bf12e', '72207abc', '72207abc', '72207abc', '72a961c9', '72a961c9', '72a961c9', '72a961c9', '73182012', '73182012', '73182012', '73c3b0d8', '73c3b0d8', '73c3b0d8', '73c3b0d8', '73ccf9c2', '73ccf9c2', '73ccf9c2', '759f3fd3', '759f3fd3', '762cd429', '762cd429', '762cd429', '770cc55f', '770cc55f', '770cc55f', '770cc55f'), 'test_accuracy': 0.9537847265601158, 'test_diff_accuracy': 0.19820810235864414, '705a3229_test_accuracy': 0.9911110997200012, '705a3229_test_diff_accuracy': 0.0, '712bf12e_test_accuracy': 0.898888885974884, '712bf12e_test_diff_accuracy': 0.0, '72207abc_test_accuracy': 0.9933333396911621, '72207abc_test_diff_accuracy': 0.0, '72a961c9_test_accuracy': 0.9788888692855835, '72a961c9_test_diff_accuracy': 0.0, '73182012_test_accuracy': 0.9866666793823242, '73182012_test_diff_accuracy': 1.0, '73c3b0d8_test_accuracy': 0.995555579662323, '73c3b0d8_test_diff_accuracy': 0.5, '73ccf9c2_test_accuracy': 0.9844444394111633, '73ccf9c2_test_diff_accuracy': 0.7846153846153846, '759f3fd3_test_accuracy': 0.9333333373069763, '759f3fd3_test_diff_accuracy': 0.0, '762cd429_test_accuracy': 0.6222222447395325, '762cd429_test_diff_accuracy': 0.0, '770cc55f_test_accuracy': 0.9744444489479065, '770cc55f_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.2715076804161072, 'task_ids': ('705a3229', '705a3229', '705a3229', '712bf12e', '712bf12e', '712bf12e', '72207abc', '72207abc', '72207abc', '72a961c9', '72a961c9', '72a961c9', '72a961c9', '73182012', '73182012', '73182012', '73c3b0d8', '73c3b0d8', '73c3b0d8', '73c3b0d8', '73ccf9c2', '73ccf9c2', '73ccf9c2', '759f3fd3', '759f3fd3', '762cd429', '762cd429', '762cd429', '770cc55f', '770cc55f', '770cc55f', '770cc55f'), 'test_accuracy': 0.9537847265601158, 'test_diff_accuracy': 0.19820810235864414, '705a3229_test_accuracy': 0.9911110997200012, '705a3229_test_diff_accuracy': 0.0, '712bf12e_test_accuracy': 0.898888885974884, '712bf12e_test_diff_accuracy': 0.0, '72207abc_test_accuracy': 0.9933333396911621, '72207abc_test_diff_accuracy': 0.0, '72a961c9_test_accuracy': 0.9788888692855835, '72a961c9_test_diff_accuracy': 0.0, '73182012_test_accuracy': 0.9866666793823242, '73182012_test_diff_accuracy': 1.0, '73c3b0d8_test_accuracy': 0.995555579662323, '73c3b0d8_test_diff_accuracy': 0.5, '73ccf9c2_test_accuracy': 0.9844444394111633, '73ccf9c2_test_diff_accuracy': 0.7846153846153846, '759f3fd3_test_accuracy': 0.9333333373069763, '759f3fd3_test_diff_accuracy': 0.0, '762cd429_test_accuracy': 0.6222222447395325, '762cd429_test_diff_accuracy': 0.0, '770cc55f_test_accuracy': 0.9744444489479065, '770cc55f_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('782b5218', '782b5218', '782b5218', '79369cc6', '79369cc6', '79369cc6', '7953d61e', '7953d61e', '7953d61e', '7953d61e', '7953d61e', '79fb03f4', '79fb03f4', '79fb03f4', '79fb03f4', '79fb03f4', '79fb03f4', '7bb29440', '7bb29440', '7bb29440', '7bb29440', '7bb29440', '7c8af763', '7c8af763', '7c8af763', '7c9b52a0', '7c9b52a0', '7c9b52a0', '7d18a6fb', '7d18a6fb', '7d18a6fb', '7d1f7ee8')], batch_idx: 19\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('782b5218', '782b5218', '782b5218', '79369cc6', '79369cc6', '79369cc6', '7953d61e', '7953d61e', '7953d61e', '7953d61e', '7953d61e', '79fb03f4', '79fb03f4', '79fb03f4', '79fb03f4', '79fb03f4', '79fb03f4', '7bb29440', '7bb29440', '7bb29440', '7bb29440', '7bb29440', '7c8af763', '7c8af763', '7c8af763', '7c9b52a0', '7c9b52a0', '7c9b52a0', '7d18a6fb', '7d18a6fb', '7d18a6fb', '7d1f7ee8')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.525\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.36363636363636365\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5135135135135135\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9034090909090909\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9299363057324841\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9647577092511013\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6341463414634146\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.803680981595092\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9541284403669725\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5299539170506913\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.3964757709251101\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7710843373493976\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7628865979381443\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7916666666666666\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.32043546438217163, Avg accuracy: 0.9210416711866856, Avg diff accuracy: 0.30763362613743883\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.32043546438217163, avg_accuracy=0.9210416711866856, diff_accuracy=0.30763362613743883\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.32043546438217163, 'task_ids': ('782b5218', '782b5218', '782b5218', '79369cc6', '79369cc6', '79369cc6', '7953d61e', '7953d61e', '7953d61e', '7953d61e', '7953d61e', '79fb03f4', '79fb03f4', '79fb03f4', '79fb03f4', '79fb03f4', '79fb03f4', '7bb29440', '7bb29440', '7bb29440', '7bb29440', '7bb29440', '7c8af763', '7c8af763', '7c8af763', '7c9b52a0', '7c9b52a0', '7c9b52a0', '7d18a6fb', '7d18a6fb', '7d18a6fb', '7d1f7ee8'), 'test_accuracy': 0.9210416711866856, 'test_diff_accuracy': 0.30763362613743883, '782b5218_test_accuracy': 0.948888897895813, '782b5218_test_diff_accuracy': 0.5135135135135135, '79369cc6_test_accuracy': 0.8155555725097656, '79369cc6_test_diff_accuracy': 0.0, '7953d61e_test_accuracy': 0.9288889169692993, '7953d61e_test_diff_accuracy': 0.0, '79fb03f4_test_accuracy': 0.9788888692855835, '79fb03f4_test_diff_accuracy': 0.0, '7bb29440_test_accuracy': 0.9611111283302307, '7bb29440_test_diff_accuracy': 0.803680981595092, '7c8af763_test_accuracy': 0.8888888955116272, '7c8af763_test_diff_accuracy': 0.0, '7c9b52a0_test_accuracy': 0.846666693687439, '7c9b52a0_test_diff_accuracy': 0.3964757709251101, '7d18a6fb_test_accuracy': 0.9777777791023254, '7d18a6fb_test_diff_accuracy': 0.7916666666666666, '7d1f7ee8_test_accuracy': 0.7955555319786072, '7d1f7ee8_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.32043546438217163, 'task_ids': ('782b5218', '782b5218', '782b5218', '79369cc6', '79369cc6', '79369cc6', '7953d61e', '7953d61e', '7953d61e', '7953d61e', '7953d61e', '79fb03f4', '79fb03f4', '79fb03f4', '79fb03f4', '79fb03f4', '79fb03f4', '7bb29440', '7bb29440', '7bb29440', '7bb29440', '7bb29440', '7c8af763', '7c8af763', '7c8af763', '7c9b52a0', '7c9b52a0', '7c9b52a0', '7d18a6fb', '7d18a6fb', '7d18a6fb', '7d1f7ee8'), 'test_accuracy': 0.9210416711866856, 'test_diff_accuracy': 0.30763362613743883, '782b5218_test_accuracy': 0.948888897895813, '782b5218_test_diff_accuracy': 0.5135135135135135, '79369cc6_test_accuracy': 0.8155555725097656, '79369cc6_test_diff_accuracy': 0.0, '7953d61e_test_accuracy': 0.9288889169692993, '7953d61e_test_diff_accuracy': 0.0, '79fb03f4_test_accuracy': 0.9788888692855835, '79fb03f4_test_diff_accuracy': 0.0, '7bb29440_test_accuracy': 0.9611111283302307, '7bb29440_test_diff_accuracy': 0.803680981595092, '7c8af763_test_accuracy': 0.8888888955116272, '7c8af763_test_diff_accuracy': 0.0, '7c9b52a0_test_accuracy': 0.846666693687439, '7c9b52a0_test_diff_accuracy': 0.3964757709251101, '7d18a6fb_test_accuracy': 0.9777777791023254, '7d18a6fb_test_diff_accuracy': 0.7916666666666666, '7d1f7ee8_test_accuracy': 0.7955555319786072, '7d1f7ee8_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('7d1f7ee8', '7d1f7ee8', '7d419a02', '7d419a02', '7d419a02', '7e02026e', '7e02026e', '7e02026e', '7ee1c6ea', '7ee1c6ea', '7ee1c6ea', '817e6c09', '817e6c09', '817e6c09', '817e6c09', '817e6c09', '81c0276b', '81c0276b', '81c0276b', '833dafe3', '833dafe3', '845d6e51', '845d6e51', '845d6e51', '84db8fc4', '84db8fc4', '84db8fc4', '84db8fc4', '84f2aca1', '84f2aca1', '84f2aca1', '84f2aca1')], batch_idx: 20\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('7d1f7ee8', '7d1f7ee8', '7d419a02', '7d419a02', '7d419a02', '7e02026e', '7e02026e', '7e02026e', '7ee1c6ea', '7ee1c6ea', '7ee1c6ea', '817e6c09', '817e6c09', '817e6c09', '817e6c09', '817e6c09', '81c0276b', '81c0276b', '81c0276b', '833dafe3', '833dafe3', '845d6e51', '845d6e51', '845d6e51', '84db8fc4', '84db8fc4', '84db8fc4', '84db8fc4', '84f2aca1', '84f2aca1', '84f2aca1', '84f2aca1')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9512195121951219\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9603174603174603\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9517241379310345\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.07692307692307693\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.06976744186046512\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.22447605431079865, Avg accuracy: 0.929479168727994, Avg diff accuracy: 0.09406098841334871\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.22447605431079865, avg_accuracy=0.929479168727994, diff_accuracy=0.09406098841334871\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.22447605431079865, 'task_ids': ('7d1f7ee8', '7d1f7ee8', '7d419a02', '7d419a02', '7d419a02', '7e02026e', '7e02026e', '7e02026e', '7ee1c6ea', '7ee1c6ea', '7ee1c6ea', '817e6c09', '817e6c09', '817e6c09', '817e6c09', '817e6c09', '81c0276b', '81c0276b', '81c0276b', '833dafe3', '833dafe3', '845d6e51', '845d6e51', '845d6e51', '84db8fc4', '84db8fc4', '84db8fc4', '84db8fc4', '84f2aca1', '84f2aca1', '84f2aca1', '84f2aca1'), 'test_accuracy': 0.929479168727994, 'test_diff_accuracy': 0.09406098841334871, '7d1f7ee8_test_accuracy': 0.9133333563804626, '7d1f7ee8_test_diff_accuracy': 0.0, '7d419a02_test_accuracy': 0.7944444417953491, '7d419a02_test_diff_accuracy': 0.0, '7e02026e_test_accuracy': 0.8788889050483704, '7e02026e_test_diff_accuracy': 0.0, '7ee1c6ea_test_accuracy': 0.9077777862548828, '7ee1c6ea_test_diff_accuracy': 0.0, '817e6c09_test_accuracy': 0.9911110997200012, '817e6c09_test_diff_accuracy': 0.0, '81c0276b_test_accuracy': 0.992222249507904, '81c0276b_test_diff_accuracy': 0.9517241379310345, '833dafe3_test_accuracy': 0.9555555582046509, '833dafe3_test_diff_accuracy': 0.06976744186046512, '845d6e51_test_accuracy': 0.9599999785423279, '845d6e51_test_diff_accuracy': 0.0, '84db8fc4_test_accuracy': 0.8888888955116272, '84db8fc4_test_diff_accuracy': 0.0, '84f2aca1_test_accuracy': 0.9399999976158142, '84f2aca1_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.22447605431079865, 'task_ids': ('7d1f7ee8', '7d1f7ee8', '7d419a02', '7d419a02', '7d419a02', '7e02026e', '7e02026e', '7e02026e', '7ee1c6ea', '7ee1c6ea', '7ee1c6ea', '817e6c09', '817e6c09', '817e6c09', '817e6c09', '817e6c09', '81c0276b', '81c0276b', '81c0276b', '833dafe3', '833dafe3', '845d6e51', '845d6e51', '845d6e51', '84db8fc4', '84db8fc4', '84db8fc4', '84db8fc4', '84f2aca1', '84f2aca1', '84f2aca1', '84f2aca1'), 'test_accuracy': 0.929479168727994, 'test_diff_accuracy': 0.09406098841334871, '7d1f7ee8_test_accuracy': 0.9133333563804626, '7d1f7ee8_test_diff_accuracy': 0.0, '7d419a02_test_accuracy': 0.7944444417953491, '7d419a02_test_diff_accuracy': 0.0, '7e02026e_test_accuracy': 0.8788889050483704, '7e02026e_test_diff_accuracy': 0.0, '7ee1c6ea_test_accuracy': 0.9077777862548828, '7ee1c6ea_test_diff_accuracy': 0.0, '817e6c09_test_accuracy': 0.9911110997200012, '817e6c09_test_diff_accuracy': 0.0, '81c0276b_test_accuracy': 0.992222249507904, '81c0276b_test_diff_accuracy': 0.9517241379310345, '833dafe3_test_accuracy': 0.9555555582046509, '833dafe3_test_diff_accuracy': 0.06976744186046512, '845d6e51_test_accuracy': 0.9599999785423279, '845d6e51_test_diff_accuracy': 0.0, '84db8fc4_test_accuracy': 0.8888888955116272, '84db8fc4_test_diff_accuracy': 0.0, '84f2aca1_test_accuracy': 0.9399999976158142, '84f2aca1_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('8597cfd7', '8597cfd7', '8597cfd7', '8597cfd7', '85b81ff1', '85b81ff1', '85b81ff1', '85b81ff1', '85fa5666', '85fa5666', '85fa5666', '85fa5666', '8719f442', '8719f442', '8719f442', '88207623', '88207623', '891232d6', '891232d6', '891232d6', '891232d6', '896d5239', '896d5239', '896d5239', '8a371977', '8a371977', '8a371977', '8b28cd80', '8b28cd80', '8b28cd80', '8b28cd80', '8b28cd80')], batch_idx: 21\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('8597cfd7', '8597cfd7', '8597cfd7', '8597cfd7', '85b81ff1', '85b81ff1', '85b81ff1', '85b81ff1', '85fa5666', '85fa5666', '85fa5666', '85fa5666', '8719f442', '8719f442', '8719f442', '88207623', '88207623', '891232d6', '891232d6', '891232d6', '891232d6', '896d5239', '896d5239', '896d5239', '8a371977', '8a371977', '8a371977', '8b28cd80', '8b28cd80', '8b28cd80', '8b28cd80', '8b28cd80')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8181818181818182\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8333333333333334\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8181818181818182\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.02127659574468085\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.021739130434782608\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.021739130434782608\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.021739130434782608\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.42091232538223267, Avg accuracy: 0.8844791669398546, Avg diff accuracy: 0.16738096739831246\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.42091232538223267, avg_accuracy=0.8844791669398546, diff_accuracy=0.16738096739831246\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.42091232538223267, 'task_ids': ('8597cfd7', '8597cfd7', '8597cfd7', '8597cfd7', '85b81ff1', '85b81ff1', '85b81ff1', '85b81ff1', '85fa5666', '85fa5666', '85fa5666', '85fa5666', '8719f442', '8719f442', '8719f442', '88207623', '88207623', '891232d6', '891232d6', '891232d6', '891232d6', '896d5239', '896d5239', '896d5239', '8a371977', '8a371977', '8a371977', '8b28cd80', '8b28cd80', '8b28cd80', '8b28cd80', '8b28cd80'), 'test_accuracy': 0.8844791669398546, 'test_diff_accuracy': 0.16738096739831246, '8597cfd7_test_accuracy': 0.995555579662323, '8597cfd7_test_diff_accuracy': 0.8181818181818182, '85b81ff1_test_accuracy': 0.8744444251060486, '85b81ff1_test_diff_accuracy': 0.5, '85fa5666_test_accuracy': 0.9788888692855835, '85fa5666_test_diff_accuracy': 0.0, '8719f442_test_accuracy': 0.9566666483879089, '8719f442_test_diff_accuracy': 0.0, '88207623_test_accuracy': 0.9333333373069763, '88207623_test_diff_accuracy': 0.0, '891232d6_test_accuracy': 0.9733333587646484, '891232d6_test_diff_accuracy': 0.0, '896d5239_test_accuracy': 0.847777783870697, '896d5239_test_diff_accuracy': 0.0, '8a371977_test_accuracy': 0.3055555522441864, '8a371977_test_diff_accuracy': 0.0, '8b28cd80_test_accuracy': 0.949999988079071, '8b28cd80_test_diff_accuracy': 0.021739130434782608}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.42091232538223267, 'task_ids': ('8597cfd7', '8597cfd7', '8597cfd7', '8597cfd7', '85b81ff1', '85b81ff1', '85b81ff1', '85b81ff1', '85fa5666', '85fa5666', '85fa5666', '85fa5666', '8719f442', '8719f442', '8719f442', '88207623', '88207623', '891232d6', '891232d6', '891232d6', '891232d6', '896d5239', '896d5239', '896d5239', '8a371977', '8a371977', '8a371977', '8b28cd80', '8b28cd80', '8b28cd80', '8b28cd80', '8b28cd80'), 'test_accuracy': 0.8844791669398546, 'test_diff_accuracy': 0.16738096739831246, '8597cfd7_test_accuracy': 0.995555579662323, '8597cfd7_test_diff_accuracy': 0.8181818181818182, '85b81ff1_test_accuracy': 0.8744444251060486, '85b81ff1_test_diff_accuracy': 0.5, '85fa5666_test_accuracy': 0.9788888692855835, '85fa5666_test_diff_accuracy': 0.0, '8719f442_test_accuracy': 0.9566666483879089, '8719f442_test_diff_accuracy': 0.0, '88207623_test_accuracy': 0.9333333373069763, '88207623_test_diff_accuracy': 0.0, '891232d6_test_accuracy': 0.9733333587646484, '891232d6_test_diff_accuracy': 0.0, '896d5239_test_accuracy': 0.847777783870697, '896d5239_test_diff_accuracy': 0.0, '8a371977_test_accuracy': 0.3055555522441864, '8a371977_test_diff_accuracy': 0.0, '8b28cd80_test_accuracy': 0.949999988079071, '8b28cd80_test_diff_accuracy': 0.021739130434782608}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('8ba14f53', '8ba14f53', '8ba14f53', '8ba14f53', '8ba14f53', '8ba14f53', '8cb8642d', '8cb8642d', '8cb8642d', '8dae5dfc', '8dae5dfc', '8dae5dfc', '8dae5dfc', '8e2edd66', '8e2edd66', '8e2edd66', '8ee62060', '8ee62060', '8ee62060', '8fbca751', '8fbca751', '8fbca751', '90347967', '90347967', '90347967', '903d1b4a', '903d1b4a', '903d1b4a', '903d1b4a', '9110e3c5', '9110e3c5', '9110e3c5')], batch_idx: 22\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('8ba14f53', '8ba14f53', '8ba14f53', '8ba14f53', '8ba14f53', '8ba14f53', '8cb8642d', '8cb8642d', '8cb8642d', '8dae5dfc', '8dae5dfc', '8dae5dfc', '8dae5dfc', '8e2edd66', '8e2edd66', '8e2edd66', '8ee62060', '8ee62060', '8ee62060', '8fbca751', '8fbca751', '8fbca751', '90347967', '90347967', '90347967', '903d1b4a', '903d1b4a', '903d1b4a', '903d1b4a', '9110e3c5', '9110e3c5', '9110e3c5')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8095238095238095\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8076923076923077\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.75\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8181818181818182\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8888888888888888\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8333333333333334\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6896551724137931\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7636363636363637\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6746987951807228\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.13793103448275862\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.23809523809523808\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8461538461538461\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.85\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8709677419354839\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.24392108619213104, Avg accuracy: 0.9270833320915699, Avg diff accuracy: 0.4180861984224489\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.24392108619213104, avg_accuracy=0.9270833320915699, diff_accuracy=0.4180861984224489\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.24392108619213104, 'task_ids': ('8ba14f53', '8ba14f53', '8ba14f53', '8ba14f53', '8ba14f53', '8ba14f53', '8cb8642d', '8cb8642d', '8cb8642d', '8dae5dfc', '8dae5dfc', '8dae5dfc', '8dae5dfc', '8e2edd66', '8e2edd66', '8e2edd66', '8ee62060', '8ee62060', '8ee62060', '8fbca751', '8fbca751', '8fbca751', '90347967', '90347967', '90347967', '903d1b4a', '903d1b4a', '903d1b4a', '903d1b4a', '9110e3c5', '9110e3c5', '9110e3c5'), 'test_accuracy': 0.9270833320915699, 'test_diff_accuracy': 0.4180861984224489, '8ba14f53_test_accuracy': 0.9944444298744202, '8ba14f53_test_diff_accuracy': 0.8333333333333334, '8cb8642d_test_accuracy': 0.8822222352027893, '8cb8642d_test_diff_accuracy': 0.6746987951807228, '8dae5dfc_test_accuracy': 0.8233333230018616, '8dae5dfc_test_diff_accuracy': 0.0, '8e2edd66_test_accuracy': 0.9900000095367432, '8e2edd66_test_diff_accuracy': 0.4, '8ee62060_test_accuracy': 0.9833333492279053, '8ee62060_test_diff_accuracy': 0.5, '8fbca751_test_accuracy': 0.9822221994400024, '8fbca751_test_diff_accuracy': 0.0, '90347967_test_accuracy': 0.9933333396911621, '90347967_test_diff_accuracy': 0.5, '903d1b4a_test_accuracy': 0.7155555486679077, '903d1b4a_test_diff_accuracy': 0.0, '9110e3c5_test_accuracy': 0.995555579662323, '9110e3c5_test_diff_accuracy': 0.8709677419354839}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.24392108619213104, 'task_ids': ('8ba14f53', '8ba14f53', '8ba14f53', '8ba14f53', '8ba14f53', '8ba14f53', '8cb8642d', '8cb8642d', '8cb8642d', '8dae5dfc', '8dae5dfc', '8dae5dfc', '8dae5dfc', '8e2edd66', '8e2edd66', '8e2edd66', '8ee62060', '8ee62060', '8ee62060', '8fbca751', '8fbca751', '8fbca751', '90347967', '90347967', '90347967', '903d1b4a', '903d1b4a', '903d1b4a', '903d1b4a', '9110e3c5', '9110e3c5', '9110e3c5'), 'test_accuracy': 0.9270833320915699, 'test_diff_accuracy': 0.4180861984224489, '8ba14f53_test_accuracy': 0.9944444298744202, '8ba14f53_test_diff_accuracy': 0.8333333333333334, '8cb8642d_test_accuracy': 0.8822222352027893, '8cb8642d_test_diff_accuracy': 0.6746987951807228, '8dae5dfc_test_accuracy': 0.8233333230018616, '8dae5dfc_test_diff_accuracy': 0.0, '8e2edd66_test_accuracy': 0.9900000095367432, '8e2edd66_test_diff_accuracy': 0.4, '8ee62060_test_accuracy': 0.9833333492279053, '8ee62060_test_diff_accuracy': 0.5, '8fbca751_test_accuracy': 0.9822221994400024, '8fbca751_test_diff_accuracy': 0.0, '90347967_test_accuracy': 0.9933333396911621, '90347967_test_diff_accuracy': 0.5, '903d1b4a_test_accuracy': 0.7155555486679077, '903d1b4a_test_diff_accuracy': 0.0, '9110e3c5_test_accuracy': 0.995555579662323, '9110e3c5_test_diff_accuracy': 0.8709677419354839}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('9110e3c5', '9110e3c5', '9110e3c5', '9110e3c5', '917bccba', '917bccba', '917bccba', '929ab4e9', '929ab4e9', '929ab4e9', '929ab4e9', '92e50de0', '92e50de0', '92e50de0', '9356391f', '9356391f', '93b4f4b3', '93b4f4b3', '93c31fbe', '93c31fbe', '93c31fbe', '94133066', '94133066', '94133066', '94414823', '94414823', '94414823', '94be5b80', '94be5b80', '95a58926', '95a58926', '95a58926')], batch_idx: 23\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('9110e3c5', '9110e3c5', '9110e3c5', '9110e3c5', '917bccba', '917bccba', '917bccba', '929ab4e9', '929ab4e9', '929ab4e9', '929ab4e9', '92e50de0', '92e50de0', '92e50de0', '9356391f', '9356391f', '93b4f4b3', '93b4f4b3', '93c31fbe', '93c31fbe', '93c31fbe', '94133066', '94133066', '94133066', '94414823', '94414823', '94414823', '94be5b80', '94be5b80', '95a58926', '95a58926', '95a58926')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8461538461538461\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8461538461538461\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.896551724137931\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6129032258064516\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6551724137931034\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5757575757575758\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.40540540540540543\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4105263157894737\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.35294117647058826\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.3684210526315789\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.47368421052631576\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4930555555555556\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4846153846153846\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.47619047619047616\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.21428571428571427\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.375\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5833333333333334\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7704918032786885\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.3698630136986301\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.544943630695343, Avg accuracy: 0.8382291728630662, Avg diff accuracy: 0.34720331479949684\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.544943630695343, avg_accuracy=0.8382291728630662, diff_accuracy=0.34720331479949684\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.544943630695343, 'task_ids': ('9110e3c5', '9110e3c5', '9110e3c5', '9110e3c5', '917bccba', '917bccba', '917bccba', '929ab4e9', '929ab4e9', '929ab4e9', '929ab4e9', '92e50de0', '92e50de0', '92e50de0', '9356391f', '9356391f', '93b4f4b3', '93b4f4b3', '93c31fbe', '93c31fbe', '93c31fbe', '94133066', '94133066', '94133066', '94414823', '94414823', '94414823', '94be5b80', '94be5b80', '95a58926', '95a58926', '95a58926'), 'test_accuracy': 0.8382291728630662, 'test_diff_accuracy': 0.34720331479949684, '9110e3c5_test_accuracy': 0.996666669845581, '9110e3c5_test_diff_accuracy': 0.9, '917bccba_test_accuracy': 0.9666666388511658, '917bccba_test_diff_accuracy': 0.5757575757575758, '929ab4e9_test_accuracy': 0.36000001430511475, '929ab4e9_test_diff_accuracy': 0.0, '92e50de0_test_accuracy': 0.6511111259460449, '92e50de0_test_diff_accuracy': 0.0, '9356391f_test_accuracy': 0.8899999856948853, '9356391f_test_diff_accuracy': 0.0, '93b4f4b3_test_accuracy': 0.9133333563804626, '93b4f4b3_test_diff_accuracy': 0.4105263157894737, '93c31fbe_test_accuracy': 0.9511111378669739, '93c31fbe_test_diff_accuracy': 0.47368421052631576, '94133066_test_accuracy': 0.8666666746139526, '94133066_test_diff_accuracy': 0.47619047619047616, '94414823_test_accuracy': 0.9577777981758118, '94414823_test_diff_accuracy': 0.0, '94be5b80_test_accuracy': 0.9555555582046509, '94be5b80_test_diff_accuracy': 0.375, '95a58926_test_accuracy': 0.7599999904632568, '95a58926_test_diff_accuracy': 0.3698630136986301}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.544943630695343, 'task_ids': ('9110e3c5', '9110e3c5', '9110e3c5', '9110e3c5', '917bccba', '917bccba', '917bccba', '929ab4e9', '929ab4e9', '929ab4e9', '929ab4e9', '92e50de0', '92e50de0', '92e50de0', '9356391f', '9356391f', '93b4f4b3', '93b4f4b3', '93c31fbe', '93c31fbe', '93c31fbe', '94133066', '94133066', '94133066', '94414823', '94414823', '94414823', '94be5b80', '94be5b80', '95a58926', '95a58926', '95a58926'), 'test_accuracy': 0.8382291728630662, 'test_diff_accuracy': 0.34720331479949684, '9110e3c5_test_accuracy': 0.996666669845581, '9110e3c5_test_diff_accuracy': 0.9, '917bccba_test_accuracy': 0.9666666388511658, '917bccba_test_diff_accuracy': 0.5757575757575758, '929ab4e9_test_accuracy': 0.36000001430511475, '929ab4e9_test_diff_accuracy': 0.0, '92e50de0_test_accuracy': 0.6511111259460449, '92e50de0_test_diff_accuracy': 0.0, '9356391f_test_accuracy': 0.8899999856948853, '9356391f_test_diff_accuracy': 0.0, '93b4f4b3_test_accuracy': 0.9133333563804626, '93b4f4b3_test_diff_accuracy': 0.4105263157894737, '93c31fbe_test_accuracy': 0.9511111378669739, '93c31fbe_test_diff_accuracy': 0.47368421052631576, '94133066_test_accuracy': 0.8666666746139526, '94133066_test_diff_accuracy': 0.47619047619047616, '94414823_test_accuracy': 0.9577777981758118, '94414823_test_diff_accuracy': 0.0, '94be5b80_test_accuracy': 0.9555555582046509, '94be5b80_test_diff_accuracy': 0.375, '95a58926_test_accuracy': 0.7599999904632568, '95a58926_test_diff_accuracy': 0.3698630136986301}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('963f59bc', '963f59bc', '963f59bc', '963f59bc', '96a8c0cd', '96a8c0cd', '96a8c0cd', '96a8c0cd', '97239e3d', '97239e3d', '97239e3d', '9772c176', '9772c176', '981571dc', '981571dc', '981571dc', '981571dc', '992798f6', '992798f6', '992798f6', '992798f6', '99306f82', '99306f82', '99306f82', '9a4bb226', '9a4bb226', '9a4bb226', '9b2a60aa', '9b2a60aa', '9b2a60aa', '9b365c51', '9b365c51')], batch_idx: 24\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('963f59bc', '963f59bc', '963f59bc', '963f59bc', '96a8c0cd', '96a8c0cd', '96a8c0cd', '96a8c0cd', '97239e3d', '97239e3d', '97239e3d', '9772c176', '9772c176', '981571dc', '981571dc', '981571dc', '981571dc', '992798f6', '992798f6', '992798f6', '992798f6', '99306f82', '99306f82', '99306f82', '9a4bb226', '9a4bb226', '9a4bb226', '9b2a60aa', '9b2a60aa', '9b2a60aa', '9b365c51', '9b365c51')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7619047619047619\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.75\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.375\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.43902439024390244\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.600387692451477, Avg accuracy: 0.8136458347580628, Avg diff accuracy: 0.09768528600464577\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.600387692451477, avg_accuracy=0.8136458347580628, diff_accuracy=0.09768528600464577\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.600387692451477, 'task_ids': ('963f59bc', '963f59bc', '963f59bc', '963f59bc', '96a8c0cd', '96a8c0cd', '96a8c0cd', '96a8c0cd', '97239e3d', '97239e3d', '97239e3d', '9772c176', '9772c176', '981571dc', '981571dc', '981571dc', '981571dc', '992798f6', '992798f6', '992798f6', '992798f6', '99306f82', '99306f82', '99306f82', '9a4bb226', '9a4bb226', '9a4bb226', '9b2a60aa', '9b2a60aa', '9b2a60aa', '9b365c51', '9b365c51'), 'test_accuracy': 0.8136458347580628, 'test_diff_accuracy': 0.09768528600464577, '963f59bc_test_accuracy': 0.9800000190734863, '963f59bc_test_diff_accuracy': 0.0, '96a8c0cd_test_accuracy': 0.9544444680213928, '96a8c0cd_test_diff_accuracy': 0.0, '97239e3d_test_accuracy': 0.800000011920929, '97239e3d_test_diff_accuracy': 0.0, '9772c176_test_accuracy': 0.8266666531562805, '9772c176_test_diff_accuracy': 0.0, '981571dc_test_accuracy': 0.0011111111380159855, '981571dc_test_diff_accuracy': 0.0, '992798f6_test_accuracy': 0.9855555295944214, '992798f6_test_diff_accuracy': 0.0, '99306f82_test_accuracy': 0.8844444155693054, '99306f82_test_diff_accuracy': 0.0, '9a4bb226_test_accuracy': 0.9900000095367432, '9a4bb226_test_diff_accuracy': 0.8, '9b2a60aa_test_accuracy': 0.9644444584846497, '9b2a60aa_test_diff_accuracy': 0.0, '9b365c51_test_accuracy': 0.9744444489479065, '9b365c51_test_diff_accuracy': 0.43902439024390244}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.600387692451477, 'task_ids': ('963f59bc', '963f59bc', '963f59bc', '963f59bc', '96a8c0cd', '96a8c0cd', '96a8c0cd', '96a8c0cd', '97239e3d', '97239e3d', '97239e3d', '9772c176', '9772c176', '981571dc', '981571dc', '981571dc', '981571dc', '992798f6', '992798f6', '992798f6', '992798f6', '99306f82', '99306f82', '99306f82', '9a4bb226', '9a4bb226', '9a4bb226', '9b2a60aa', '9b2a60aa', '9b2a60aa', '9b365c51', '9b365c51'), 'test_accuracy': 0.8136458347580628, 'test_diff_accuracy': 0.09768528600464577, '963f59bc_test_accuracy': 0.9800000190734863, '963f59bc_test_diff_accuracy': 0.0, '96a8c0cd_test_accuracy': 0.9544444680213928, '96a8c0cd_test_diff_accuracy': 0.0, '97239e3d_test_accuracy': 0.800000011920929, '97239e3d_test_diff_accuracy': 0.0, '9772c176_test_accuracy': 0.8266666531562805, '9772c176_test_diff_accuracy': 0.0, '981571dc_test_accuracy': 0.0011111111380159855, '981571dc_test_diff_accuracy': 0.0, '992798f6_test_accuracy': 0.9855555295944214, '992798f6_test_diff_accuracy': 0.0, '99306f82_test_accuracy': 0.8844444155693054, '99306f82_test_diff_accuracy': 0.0, '9a4bb226_test_accuracy': 0.9900000095367432, '9a4bb226_test_diff_accuracy': 0.8, '9b2a60aa_test_accuracy': 0.9644444584846497, '9b2a60aa_test_diff_accuracy': 0.0, '9b365c51_test_accuracy': 0.9744444489479065, '9b365c51_test_diff_accuracy': 0.43902439024390244}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('9b365c51', '9b4c17c4', '9b4c17c4', '9b4c17c4', '9b4c17c4', '9bebae7a', '9bebae7a', '9bebae7a', '9bebae7a', '9bebae7a', '9c1e755f', '9c1e755f', '9c1e755f', '9c1e755f', '9c56f360', '9c56f360', '9c56f360', '9caba7c3', '9caba7c3', '9caba7c3', '9ddd00f0', '9ddd00f0', '9def23fe', '9def23fe', '9def23fe', '9f27f097', '9f27f097', '9f27f097', 'a04b2602', 'a04b2602', 'a04b2602', 'a096bf4d')], batch_idx: 25\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('9b365c51', '9b4c17c4', '9b4c17c4', '9b4c17c4', '9b4c17c4', '9bebae7a', '9bebae7a', '9bebae7a', '9bebae7a', '9bebae7a', '9c1e755f', '9c1e755f', '9c1e755f', '9c1e755f', '9c56f360', '9c56f360', '9c56f360', '9caba7c3', '9caba7c3', '9caba7c3', '9ddd00f0', '9ddd00f0', '9def23fe', '9def23fe', '9def23fe', '9f27f097', '9f27f097', '9f27f097', 'a04b2602', 'a04b2602', 'a04b2602', 'a096bf4d')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5185185185185185\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.14285714285714285\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.35294117647058826\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4166666666666667\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4166666666666667\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.35294117647058826\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.3883328437805176, Avg accuracy: 0.8817361071705818, Avg diff accuracy: 0.11564347961406785\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.3883328437805176, avg_accuracy=0.8817361071705818, diff_accuracy=0.11564347961406785\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.3883328437805176, 'task_ids': ('9b365c51', '9b4c17c4', '9b4c17c4', '9b4c17c4', '9b4c17c4', '9bebae7a', '9bebae7a', '9bebae7a', '9bebae7a', '9bebae7a', '9c1e755f', '9c1e755f', '9c1e755f', '9c1e755f', '9c56f360', '9c56f360', '9c56f360', '9caba7c3', '9caba7c3', '9caba7c3', '9ddd00f0', '9ddd00f0', '9def23fe', '9def23fe', '9def23fe', '9f27f097', '9f27f097', '9f27f097', 'a04b2602', 'a04b2602', 'a04b2602', 'a096bf4d'), 'test_accuracy': 0.8817361071705818, 'test_diff_accuracy': 0.11564347961406785, '9b365c51_test_accuracy': 0.9711111187934875, '9b365c51_test_diff_accuracy': 0.5185185185185185, '9b4c17c4_test_accuracy': 0.8533333539962769, '9b4c17c4_test_diff_accuracy': 0.0, '9bebae7a_test_accuracy': 0.9755555391311646, '9bebae7a_test_diff_accuracy': 0.35294117647058826, '9c1e755f_test_accuracy': 0.9244444370269775, '9c1e755f_test_diff_accuracy': 0.0, '9c56f360_test_accuracy': 0.9611111283302307, '9c56f360_test_diff_accuracy': 0.5, '9caba7c3_test_accuracy': 0.7400000095367432, '9caba7c3_test_diff_accuracy': 0.0, '9ddd00f0_test_accuracy': 0.9866666793823242, '9ddd00f0_test_diff_accuracy': 0.0, '9def23fe_test_accuracy': 0.8388888835906982, '9def23fe_test_diff_accuracy': 0.0, '9f27f097_test_accuracy': 0.8399999737739563, '9f27f097_test_diff_accuracy': 0.0, 'a04b2602_test_accuracy': 0.9333333373069763, 'a04b2602_test_diff_accuracy': 0.0, 'a096bf4d_test_accuracy': 0.7155555486679077, 'a096bf4d_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.3883328437805176, 'task_ids': ('9b365c51', '9b4c17c4', '9b4c17c4', '9b4c17c4', '9b4c17c4', '9bebae7a', '9bebae7a', '9bebae7a', '9bebae7a', '9bebae7a', '9c1e755f', '9c1e755f', '9c1e755f', '9c1e755f', '9c56f360', '9c56f360', '9c56f360', '9caba7c3', '9caba7c3', '9caba7c3', '9ddd00f0', '9ddd00f0', '9def23fe', '9def23fe', '9def23fe', '9f27f097', '9f27f097', '9f27f097', 'a04b2602', 'a04b2602', 'a04b2602', 'a096bf4d'), 'test_accuracy': 0.8817361071705818, 'test_diff_accuracy': 0.11564347961406785, '9b365c51_test_accuracy': 0.9711111187934875, '9b365c51_test_diff_accuracy': 0.5185185185185185, '9b4c17c4_test_accuracy': 0.8533333539962769, '9b4c17c4_test_diff_accuracy': 0.0, '9bebae7a_test_accuracy': 0.9755555391311646, '9bebae7a_test_diff_accuracy': 0.35294117647058826, '9c1e755f_test_accuracy': 0.9244444370269775, '9c1e755f_test_diff_accuracy': 0.0, '9c56f360_test_accuracy': 0.9611111283302307, '9c56f360_test_diff_accuracy': 0.5, '9caba7c3_test_accuracy': 0.7400000095367432, '9caba7c3_test_diff_accuracy': 0.0, '9ddd00f0_test_accuracy': 0.9866666793823242, '9ddd00f0_test_diff_accuracy': 0.0, '9def23fe_test_accuracy': 0.8388888835906982, '9def23fe_test_diff_accuracy': 0.0, '9f27f097_test_accuracy': 0.8399999737739563, '9f27f097_test_diff_accuracy': 0.0, 'a04b2602_test_accuracy': 0.9333333373069763, 'a04b2602_test_diff_accuracy': 0.0, 'a096bf4d_test_accuracy': 0.7155555486679077, 'a096bf4d_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('a096bf4d', 'a096bf4d', 'a3f84088', 'a3f84088', 'a3f84088', 'a3f84088', 'a406ac07', 'a406ac07', 'a406ac07', 'a57f2f04', 'a57f2f04', 'a57f2f04', 'a59b95c0', 'a59b95c0', 'a59b95c0', 'a59b95c0', 'a59b95c0', 'a680ac02', 'a680ac02', 'a680ac02', 'a8610ef7', 'a8610ef7', 'a8610ef7', 'a8610ef7', 'a934301b', 'a934301b', 'a934301b', 'aa18de87', 'aa18de87', 'aa18de87', 'aa18de87', 'aa300dc3')], batch_idx: 26\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('a096bf4d', 'a096bf4d', 'a3f84088', 'a3f84088', 'a3f84088', 'a3f84088', 'a406ac07', 'a406ac07', 'a406ac07', 'a57f2f04', 'a57f2f04', 'a57f2f04', 'a59b95c0', 'a59b95c0', 'a59b95c0', 'a59b95c0', 'a59b95c0', 'a680ac02', 'a680ac02', 'a680ac02', 'a8610ef7', 'a8610ef7', 'a8610ef7', 'a8610ef7', 'a934301b', 'a934301b', 'a934301b', 'aa18de87', 'aa18de87', 'aa18de87', 'aa18de87', 'aa300dc3')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6216216216216216\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6621621621621622\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6666666666666666\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.3979282081127167, Avg accuracy: 0.9047569409012794, Avg diff accuracy: 0.15470157657657657\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.3979282081127167, avg_accuracy=0.9047569409012794, diff_accuracy=0.15470157657657657\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.3979282081127167, 'task_ids': ('a096bf4d', 'a096bf4d', 'a3f84088', 'a3f84088', 'a3f84088', 'a3f84088', 'a406ac07', 'a406ac07', 'a406ac07', 'a57f2f04', 'a57f2f04', 'a57f2f04', 'a59b95c0', 'a59b95c0', 'a59b95c0', 'a59b95c0', 'a59b95c0', 'a680ac02', 'a680ac02', 'a680ac02', 'a8610ef7', 'a8610ef7', 'a8610ef7', 'a8610ef7', 'a934301b', 'a934301b', 'a934301b', 'aa18de87', 'aa18de87', 'aa18de87', 'aa18de87', 'aa300dc3'), 'test_accuracy': 0.9047569409012794, 'test_diff_accuracy': 0.15470157657657657, 'a096bf4d_test_accuracy': 0.8399999737739563, 'a096bf4d_test_diff_accuracy': 0.0, 'a3f84088_test_accuracy': 0.7322221994400024, 'a3f84088_test_diff_accuracy': 0.0, 'a406ac07_test_accuracy': 0.9566666483879089, 'a406ac07_test_diff_accuracy': 0.0, 'a57f2f04_test_accuracy': 0.6822222471237183, 'a57f2f04_test_diff_accuracy': 0.0, 'a59b95c0_test_accuracy': 0.9100000262260437, 'a59b95c0_test_diff_accuracy': 0.0, 'a680ac02_test_accuracy': 0.9555555582046509, 'a680ac02_test_diff_accuracy': 0.6666666666666666, 'a8610ef7_test_accuracy': 0.9766666889190674, 'a8610ef7_test_diff_accuracy': 0.0, 'a934301b_test_accuracy': 0.9599999785423279, 'a934301b_test_diff_accuracy': 1.0, 'aa18de87_test_accuracy': 0.9811111092567444, 'aa18de87_test_diff_accuracy': 0.0, 'aa300dc3_test_accuracy': 0.9300000071525574, 'aa300dc3_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.3979282081127167, 'task_ids': ('a096bf4d', 'a096bf4d', 'a3f84088', 'a3f84088', 'a3f84088', 'a3f84088', 'a406ac07', 'a406ac07', 'a406ac07', 'a57f2f04', 'a57f2f04', 'a57f2f04', 'a59b95c0', 'a59b95c0', 'a59b95c0', 'a59b95c0', 'a59b95c0', 'a680ac02', 'a680ac02', 'a680ac02', 'a8610ef7', 'a8610ef7', 'a8610ef7', 'a8610ef7', 'a934301b', 'a934301b', 'a934301b', 'aa18de87', 'aa18de87', 'aa18de87', 'aa18de87', 'aa300dc3'), 'test_accuracy': 0.9047569409012794, 'test_diff_accuracy': 0.15470157657657657, 'a096bf4d_test_accuracy': 0.8399999737739563, 'a096bf4d_test_diff_accuracy': 0.0, 'a3f84088_test_accuracy': 0.7322221994400024, 'a3f84088_test_diff_accuracy': 0.0, 'a406ac07_test_accuracy': 0.9566666483879089, 'a406ac07_test_diff_accuracy': 0.0, 'a57f2f04_test_accuracy': 0.6822222471237183, 'a57f2f04_test_diff_accuracy': 0.0, 'a59b95c0_test_accuracy': 0.9100000262260437, 'a59b95c0_test_diff_accuracy': 0.0, 'a680ac02_test_accuracy': 0.9555555582046509, 'a680ac02_test_diff_accuracy': 0.6666666666666666, 'a8610ef7_test_accuracy': 0.9766666889190674, 'a8610ef7_test_diff_accuracy': 0.0, 'a934301b_test_accuracy': 0.9599999785423279, 'a934301b_test_diff_accuracy': 1.0, 'aa18de87_test_accuracy': 0.9811111092567444, 'aa18de87_test_diff_accuracy': 0.0, 'aa300dc3_test_accuracy': 0.9300000071525574, 'aa300dc3_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('aa300dc3', 'aa300dc3', 'aa300dc3', 'aa4ec2a5', 'aa4ec2a5', 'aa4ec2a5', 'aab50785', 'aab50785', 'aab50785', 'aab50785', 'aab50785', 'ac0c5833', 'ac0c5833', 'ac0c5833', 'ac2e8ecf', 'ac2e8ecf', 'ac2e8ecf', 'ac3e2b04', 'ac3e2b04', 'ac3e2b04', 'ac3e2b04', 'ac605cbb', 'ac605cbb', 'ac605cbb', 'ac605cbb', 'ac605cbb', 'ac605cbb', 'ad7e01d0', 'ad7e01d0', 'ad7e01d0', 'ad7e01d0', 'ae58858e')], batch_idx: 27\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('aa300dc3', 'aa300dc3', 'aa300dc3', 'aa4ec2a5', 'aa4ec2a5', 'aa4ec2a5', 'aab50785', 'aab50785', 'aab50785', 'aab50785', 'aab50785', 'ac0c5833', 'ac0c5833', 'ac0c5833', 'ac2e8ecf', 'ac2e8ecf', 'ac2e8ecf', 'ac3e2b04', 'ac3e2b04', 'ac3e2b04', 'ac3e2b04', 'ac605cbb', 'ac605cbb', 'ac605cbb', 'ac605cbb', 'ac605cbb', 'ac605cbb', 'ad7e01d0', 'ad7e01d0', 'ad7e01d0', 'ad7e01d0', 'ae58858e')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8760330578512396\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9154929577464789\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.94\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8688524590163934\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9010989010989011\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4507042253521127\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4845360824742268\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.16666666666666666\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0967741935483871\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.07692307692307693\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.36217039823532104, Avg accuracy: 0.9083680585026741, Avg diff accuracy: 0.19615880064617136\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.36217039823532104, avg_accuracy=0.9083680585026741, diff_accuracy=0.19615880064617136\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.36217039823532104, 'task_ids': ('aa300dc3', 'aa300dc3', 'aa300dc3', 'aa4ec2a5', 'aa4ec2a5', 'aa4ec2a5', 'aab50785', 'aab50785', 'aab50785', 'aab50785', 'aab50785', 'ac0c5833', 'ac0c5833', 'ac0c5833', 'ac2e8ecf', 'ac2e8ecf', 'ac2e8ecf', 'ac3e2b04', 'ac3e2b04', 'ac3e2b04', 'ac3e2b04', 'ac605cbb', 'ac605cbb', 'ac605cbb', 'ac605cbb', 'ac605cbb', 'ac605cbb', 'ad7e01d0', 'ad7e01d0', 'ad7e01d0', 'ad7e01d0', 'ae58858e'), 'test_accuracy': 0.9083680585026741, 'test_diff_accuracy': 0.19615880064617136, 'aa300dc3_test_accuracy': 0.9255555272102356, 'aa300dc3_test_diff_accuracy': 0.0, 'aa4ec2a5_test_accuracy': 0.6666666865348816, 'aa4ec2a5_test_diff_accuracy': 0.0, 'aab50785_test_accuracy': 0.9900000095367432, 'aab50785_test_diff_accuracy': 0.9010989010989011, 'ac0c5833_test_accuracy': 0.9599999785423279, 'ac0c5833_test_diff_accuracy': 0.0, 'ac2e8ecf_test_accuracy': 0.9388889074325562, 'ac2e8ecf_test_diff_accuracy': 0.4845360824742268, 'ac3e2b04_test_accuracy': 0.897777795791626, 'ac3e2b04_test_diff_accuracy': 0.0, 'ac605cbb_test_accuracy': 0.992222249507904, 'ac605cbb_test_diff_accuracy': 0.0, 'ad7e01d0_test_accuracy': 0.7866666913032532, 'ad7e01d0_test_diff_accuracy': 0.07692307692307693, 'ae58858e_test_accuracy': 0.9755555391311646, 'ae58858e_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.36217039823532104, 'task_ids': ('aa300dc3', 'aa300dc3', 'aa300dc3', 'aa4ec2a5', 'aa4ec2a5', 'aa4ec2a5', 'aab50785', 'aab50785', 'aab50785', 'aab50785', 'aab50785', 'ac0c5833', 'ac0c5833', 'ac0c5833', 'ac2e8ecf', 'ac2e8ecf', 'ac2e8ecf', 'ac3e2b04', 'ac3e2b04', 'ac3e2b04', 'ac3e2b04', 'ac605cbb', 'ac605cbb', 'ac605cbb', 'ac605cbb', 'ac605cbb', 'ac605cbb', 'ad7e01d0', 'ad7e01d0', 'ad7e01d0', 'ad7e01d0', 'ae58858e'), 'test_accuracy': 0.9083680585026741, 'test_diff_accuracy': 0.19615880064617136, 'aa300dc3_test_accuracy': 0.9255555272102356, 'aa300dc3_test_diff_accuracy': 0.0, 'aa4ec2a5_test_accuracy': 0.6666666865348816, 'aa4ec2a5_test_diff_accuracy': 0.0, 'aab50785_test_accuracy': 0.9900000095367432, 'aab50785_test_diff_accuracy': 0.9010989010989011, 'ac0c5833_test_accuracy': 0.9599999785423279, 'ac0c5833_test_diff_accuracy': 0.0, 'ac2e8ecf_test_accuracy': 0.9388889074325562, 'ac2e8ecf_test_diff_accuracy': 0.4845360824742268, 'ac3e2b04_test_accuracy': 0.897777795791626, 'ac3e2b04_test_diff_accuracy': 0.0, 'ac605cbb_test_accuracy': 0.992222249507904, 'ac605cbb_test_diff_accuracy': 0.0, 'ad7e01d0_test_accuracy': 0.7866666913032532, 'ad7e01d0_test_diff_accuracy': 0.07692307692307693, 'ae58858e_test_accuracy': 0.9755555391311646, 'ae58858e_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('ae58858e', 'ae58858e', 'ae58858e', 'aee291af', 'aee291af', 'aee291af', 'af22c60d', 'af22c60d', 'af22c60d', 'af22c60d', 'af24b4cc', 'af24b4cc', 'af24b4cc', 'b0722778', 'b0722778', 'b0f4d537', 'b0f4d537', 'b0f4d537', 'b0f4d537', 'b15fca0b', 'b15fca0b', 'b15fca0b', 'b15fca0b', 'b15fca0b', 'b1fc8b8e', 'b1fc8b8e', 'b1fc8b8e', 'b1fc8b8e', 'b1fc8b8e', 'b20f7c8b', 'b20f7c8b', 'b20f7c8b')], batch_idx: 28\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('ae58858e', 'ae58858e', 'ae58858e', 'aee291af', 'aee291af', 'aee291af', 'af22c60d', 'af22c60d', 'af22c60d', 'af22c60d', 'af24b4cc', 'af24b4cc', 'af24b4cc', 'b0722778', 'b0722778', 'b0f4d537', 'b0f4d537', 'b0f4d537', 'b0f4d537', 'b15fca0b', 'b15fca0b', 'b15fca0b', 'b15fca0b', 'b15fca0b', 'b1fc8b8e', 'b1fc8b8e', 'b1fc8b8e', 'b1fc8b8e', 'b1fc8b8e', 'b20f7c8b', 'b20f7c8b', 'b20f7c8b')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9448818897637795\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9362549800796812\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.939873417721519\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.85\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8461538461538461\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8717948717948718\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7142857142857143\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7317073170731707\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5961538461538461\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6231884057971014\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6346153846153846\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4375\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.5331350564956665, Avg accuracy: 0.8368402756750584, Avg diff accuracy: 0.3664503022949661\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.5331350564956665, avg_accuracy=0.8368402756750584, diff_accuracy=0.3664503022949661\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.5331350564956665, 'task_ids': ('ae58858e', 'ae58858e', 'ae58858e', 'aee291af', 'aee291af', 'aee291af', 'af22c60d', 'af22c60d', 'af22c60d', 'af22c60d', 'af24b4cc', 'af24b4cc', 'af24b4cc', 'b0722778', 'b0722778', 'b0f4d537', 'b0f4d537', 'b0f4d537', 'b0f4d537', 'b15fca0b', 'b15fca0b', 'b15fca0b', 'b15fca0b', 'b15fca0b', 'b1fc8b8e', 'b1fc8b8e', 'b1fc8b8e', 'b1fc8b8e', 'b1fc8b8e', 'b20f7c8b', 'b20f7c8b', 'b20f7c8b'), 'test_accuracy': 0.8368402756750584, 'test_diff_accuracy': 0.3664503022949661, 'ae58858e_test_accuracy': 0.9855555295944214, 'ae58858e_test_diff_accuracy': 0.0, 'aee291af_test_accuracy': 0.9700000286102295, 'aee291af_test_diff_accuracy': 0.939873417721519, 'af22c60d_test_accuracy': 0.0, 'af22c60d_test_diff_accuracy': 0.0, 'af24b4cc_test_accuracy': 0.9933333396911621, 'af24b4cc_test_diff_accuracy': 0.8717948717948718, 'b0722778_test_accuracy': 0.9866666793823242, 'b0722778_test_diff_accuracy': 0.7317073170731707, 'b0f4d537_test_accuracy': 0.9788888692855835, 'b0f4d537_test_diff_accuracy': 0.6346153846153846, 'b15fca0b_test_accuracy': 0.9399999976158142, 'b15fca0b_test_diff_accuracy': 0.0, 'b1fc8b8e_test_accuracy': 0.9855555295944214, 'b1fc8b8e_test_diff_accuracy': 0.4375, 'b20f7c8b_test_accuracy': 0.7744444608688354, 'b20f7c8b_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.5331350564956665, 'task_ids': ('ae58858e', 'ae58858e', 'ae58858e', 'aee291af', 'aee291af', 'aee291af', 'af22c60d', 'af22c60d', 'af22c60d', 'af22c60d', 'af24b4cc', 'af24b4cc', 'af24b4cc', 'b0722778', 'b0722778', 'b0f4d537', 'b0f4d537', 'b0f4d537', 'b0f4d537', 'b15fca0b', 'b15fca0b', 'b15fca0b', 'b15fca0b', 'b15fca0b', 'b1fc8b8e', 'b1fc8b8e', 'b1fc8b8e', 'b1fc8b8e', 'b1fc8b8e', 'b20f7c8b', 'b20f7c8b', 'b20f7c8b'), 'test_accuracy': 0.8368402756750584, 'test_diff_accuracy': 0.3664503022949661, 'ae58858e_test_accuracy': 0.9855555295944214, 'ae58858e_test_diff_accuracy': 0.0, 'aee291af_test_accuracy': 0.9700000286102295, 'aee291af_test_diff_accuracy': 0.939873417721519, 'af22c60d_test_accuracy': 0.0, 'af22c60d_test_diff_accuracy': 0.0, 'af24b4cc_test_accuracy': 0.9933333396911621, 'af24b4cc_test_diff_accuracy': 0.8717948717948718, 'b0722778_test_accuracy': 0.9866666793823242, 'b0722778_test_diff_accuracy': 0.7317073170731707, 'b0f4d537_test_accuracy': 0.9788888692855835, 'b0f4d537_test_diff_accuracy': 0.6346153846153846, 'b15fca0b_test_accuracy': 0.9399999976158142, 'b15fca0b_test_diff_accuracy': 0.0, 'b1fc8b8e_test_accuracy': 0.9855555295944214, 'b1fc8b8e_test_diff_accuracy': 0.4375, 'b20f7c8b_test_accuracy': 0.7744444608688354, 'b20f7c8b_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('b457fec5', 'b457fec5', 'b457fec5', 'b4a43f3b', 'b4a43f3b', 'b4a43f3b', 'b4a43f3b', 'b7999b51', 'b7999b51', 'b7999b51', 'b7cb93ac', 'b7cb93ac', 'b7cb93ac', 'b7f8a4d8', 'b7f8a4d8', 'b7f8a4d8', 'b7fb29bc', 'b7fb29bc', 'b7fb29bc', 'b942fd60', 'b942fd60', 'b942fd60', 'b942fd60', 'b942fd60', 'b942fd60', 'b9630600', 'b9630600', 'b9630600', 'ba9d41b8', 'ba9d41b8', 'ba9d41b8', 'baf41dbf')], batch_idx: 29\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('b457fec5', 'b457fec5', 'b457fec5', 'b4a43f3b', 'b4a43f3b', 'b4a43f3b', 'b4a43f3b', 'b7999b51', 'b7999b51', 'b7999b51', 'b7cb93ac', 'b7cb93ac', 'b7cb93ac', 'b7f8a4d8', 'b7f8a4d8', 'b7f8a4d8', 'b7fb29bc', 'b7fb29bc', 'b7fb29bc', 'b942fd60', 'b942fd60', 'b942fd60', 'b942fd60', 'b942fd60', 'b942fd60', 'b9630600', 'b9630600', 'b9630600', 'ba9d41b8', 'ba9d41b8', 'ba9d41b8', 'baf41dbf')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.49122807017543857\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4805194805194805\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.44\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4642857142857143\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8732394366197183\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8529411764705882\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.85\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4444444444444444\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.45454545454545453\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.34615384615384615\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.36363636363636365\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.2608695652173913\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.3113536536693573, Avg accuracy: 0.9131249999627471, Avg diff accuracy: 0.32255823600213873\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.3113536536693573, avg_accuracy=0.9131249999627471, diff_accuracy=0.32255823600213873\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.3113536536693573, 'task_ids': ('b457fec5', 'b457fec5', 'b457fec5', 'b4a43f3b', 'b4a43f3b', 'b4a43f3b', 'b4a43f3b', 'b7999b51', 'b7999b51', 'b7999b51', 'b7cb93ac', 'b7cb93ac', 'b7cb93ac', 'b7f8a4d8', 'b7f8a4d8', 'b7f8a4d8', 'b7fb29bc', 'b7fb29bc', 'b7fb29bc', 'b942fd60', 'b942fd60', 'b942fd60', 'b942fd60', 'b942fd60', 'b942fd60', 'b9630600', 'b9630600', 'b9630600', 'ba9d41b8', 'ba9d41b8', 'ba9d41b8', 'baf41dbf'), 'test_accuracy': 0.9131249999627471, 'test_diff_accuracy': 0.32255823600213873, 'b457fec5_test_accuracy': 0.9066666960716248, 'b457fec5_test_diff_accuracy': 0.0, 'b4a43f3b_test_accuracy': 0.9666666388511658, 'b4a43f3b_test_diff_accuracy': 0.4642857142857143, 'b7999b51_test_accuracy': 0.9911110997200012, 'b7999b51_test_diff_accuracy': 0.85, 'b7cb93ac_test_accuracy': 0.9866666793823242, 'b7cb93ac_test_diff_accuracy': 0.5, 'b7f8a4d8_test_accuracy': 0.75, 'b7f8a4d8_test_diff_accuracy': 0.0, 'b7fb29bc_test_accuracy': 0.9100000262260437, 'b7fb29bc_test_diff_accuracy': 0.0, 'b942fd60_test_accuracy': 0.9722222089767456, 'b942fd60_test_diff_accuracy': 0.0, 'b9630600_test_accuracy': 0.8533333539962769, 'b9630600_test_diff_accuracy': 0.36363636363636365, 'ba9d41b8_test_accuracy': 0.8822222352027893, 'ba9d41b8_test_diff_accuracy': 1.0, 'baf41dbf_test_accuracy': 0.9655555486679077, 'baf41dbf_test_diff_accuracy': 0.2608695652173913}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.3113536536693573, 'task_ids': ('b457fec5', 'b457fec5', 'b457fec5', 'b4a43f3b', 'b4a43f3b', 'b4a43f3b', 'b4a43f3b', 'b7999b51', 'b7999b51', 'b7999b51', 'b7cb93ac', 'b7cb93ac', 'b7cb93ac', 'b7f8a4d8', 'b7f8a4d8', 'b7f8a4d8', 'b7fb29bc', 'b7fb29bc', 'b7fb29bc', 'b942fd60', 'b942fd60', 'b942fd60', 'b942fd60', 'b942fd60', 'b942fd60', 'b9630600', 'b9630600', 'b9630600', 'ba9d41b8', 'ba9d41b8', 'ba9d41b8', 'baf41dbf'), 'test_accuracy': 0.9131249999627471, 'test_diff_accuracy': 0.32255823600213873, 'b457fec5_test_accuracy': 0.9066666960716248, 'b457fec5_test_diff_accuracy': 0.0, 'b4a43f3b_test_accuracy': 0.9666666388511658, 'b4a43f3b_test_diff_accuracy': 0.4642857142857143, 'b7999b51_test_accuracy': 0.9911110997200012, 'b7999b51_test_diff_accuracy': 0.85, 'b7cb93ac_test_accuracy': 0.9866666793823242, 'b7cb93ac_test_diff_accuracy': 0.5, 'b7f8a4d8_test_accuracy': 0.75, 'b7f8a4d8_test_diff_accuracy': 0.0, 'b7fb29bc_test_accuracy': 0.9100000262260437, 'b7fb29bc_test_diff_accuracy': 0.0, 'b942fd60_test_accuracy': 0.9722222089767456, 'b942fd60_test_diff_accuracy': 0.0, 'b9630600_test_accuracy': 0.8533333539962769, 'b9630600_test_diff_accuracy': 0.36363636363636365, 'ba9d41b8_test_accuracy': 0.8822222352027893, 'ba9d41b8_test_diff_accuracy': 1.0, 'baf41dbf_test_accuracy': 0.9655555486679077, 'baf41dbf_test_diff_accuracy': 0.2608695652173913}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('baf41dbf', 'baf41dbf', 'bb52a14b', 'bb52a14b', 'bb52a14b', 'bbb1b8b6', 'bbb1b8b6', 'bbb1b8b6', 'bbb1b8b6', 'bbb1b8b6', 'bbb1b8b6', 'bbb1b8b6', 'bc4146bd', 'bc4146bd', 'bc4146bd', 'bc4146bd', 'bcb3040b', 'bcb3040b', 'bcb3040b', 'bd14c3bf', 'bd14c3bf', 'bd14c3bf', 'be03b35f', 'be03b35f', 'be03b35f', 'bf32578f', 'bf32578f', 'bf32578f', 'bf699163', 'bf699163', 'bf89d739', 'bf89d739')], batch_idx: 30\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('baf41dbf', 'baf41dbf', 'bb52a14b', 'bb52a14b', 'bb52a14b', 'bbb1b8b6', 'bbb1b8b6', 'bbb1b8b6', 'bbb1b8b6', 'bbb1b8b6', 'bbb1b8b6', 'bbb1b8b6', 'bc4146bd', 'bc4146bd', 'bc4146bd', 'bc4146bd', 'bcb3040b', 'bcb3040b', 'bcb3040b', 'bd14c3bf', 'bd14c3bf', 'bd14c3bf', 'be03b35f', 'be03b35f', 'be03b35f', 'bf32578f', 'bf32578f', 'bf32578f', 'bf699163', 'bf699163', 'bf89d739', 'bf89d739')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.16666666666666666\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.1875\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.46153846153846156\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6956521739130435\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.46153846153846156\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.45454545454545453\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5789473684210527\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6470588235294118\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4782608695652174\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8333333333333334\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.3333333333333333\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.42857142857142855\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.38461538461538464\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9704797047970479\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9737704918032787\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.1945578008890152, Avg accuracy: 0.9569097217172384, Avg diff accuracy: 0.30174412363036174\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.1945578008890152, avg_accuracy=0.9569097217172384, diff_accuracy=0.30174412363036174\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.1945578008890152, 'task_ids': ('baf41dbf', 'baf41dbf', 'bb52a14b', 'bb52a14b', 'bb52a14b', 'bbb1b8b6', 'bbb1b8b6', 'bbb1b8b6', 'bbb1b8b6', 'bbb1b8b6', 'bbb1b8b6', 'bbb1b8b6', 'bc4146bd', 'bc4146bd', 'bc4146bd', 'bc4146bd', 'bcb3040b', 'bcb3040b', 'bcb3040b', 'bd14c3bf', 'bd14c3bf', 'bd14c3bf', 'be03b35f', 'be03b35f', 'be03b35f', 'bf32578f', 'bf32578f', 'bf32578f', 'bf699163', 'bf699163', 'bf89d739', 'bf89d739'), 'test_accuracy': 0.9569097217172384, 'test_diff_accuracy': 0.30174412363036174, 'baf41dbf_test_accuracy': 0.9366666674613953, 'baf41dbf_test_diff_accuracy': 0.1875, 'bb52a14b_test_accuracy': 0.9177777767181396, 'bb52a14b_test_diff_accuracy': 0.0, 'bbb1b8b6_test_accuracy': 0.9822221994400024, 'bbb1b8b6_test_diff_accuracy': 0.4782608695652174, 'bc4146bd_test_accuracy': 0.9111111164093018, 'bc4146bd_test_diff_accuracy': 0.0, 'bcb3040b_test_accuracy': 0.9399999976158142, 'bcb3040b_test_diff_accuracy': 0.0, 'bd14c3bf_test_accuracy': 0.9144444465637207, 'bd14c3bf_test_diff_accuracy': 0.0, 'be03b35f_test_accuracy': 0.9977777600288391, 'be03b35f_test_diff_accuracy': 0.8333333333333334, 'bf32578f_test_accuracy': 0.9911110997200012, 'bf32578f_test_diff_accuracy': 0.38461538461538464, 'bf699163_test_accuracy': 0.9900000095367432, 'bf699163_test_diff_accuracy': 0.9737704918032787, 'bf89d739_test_accuracy': 0.9755555391311646, 'bf89d739_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.1945578008890152, 'task_ids': ('baf41dbf', 'baf41dbf', 'bb52a14b', 'bb52a14b', 'bb52a14b', 'bbb1b8b6', 'bbb1b8b6', 'bbb1b8b6', 'bbb1b8b6', 'bbb1b8b6', 'bbb1b8b6', 'bbb1b8b6', 'bc4146bd', 'bc4146bd', 'bc4146bd', 'bc4146bd', 'bcb3040b', 'bcb3040b', 'bcb3040b', 'bd14c3bf', 'bd14c3bf', 'bd14c3bf', 'be03b35f', 'be03b35f', 'be03b35f', 'bf32578f', 'bf32578f', 'bf32578f', 'bf699163', 'bf699163', 'bf89d739', 'bf89d739'), 'test_accuracy': 0.9569097217172384, 'test_diff_accuracy': 0.30174412363036174, 'baf41dbf_test_accuracy': 0.9366666674613953, 'baf41dbf_test_diff_accuracy': 0.1875, 'bb52a14b_test_accuracy': 0.9177777767181396, 'bb52a14b_test_diff_accuracy': 0.0, 'bbb1b8b6_test_accuracy': 0.9822221994400024, 'bbb1b8b6_test_diff_accuracy': 0.4782608695652174, 'bc4146bd_test_accuracy': 0.9111111164093018, 'bc4146bd_test_diff_accuracy': 0.0, 'bcb3040b_test_accuracy': 0.9399999976158142, 'bcb3040b_test_diff_accuracy': 0.0, 'bd14c3bf_test_accuracy': 0.9144444465637207, 'bd14c3bf_test_diff_accuracy': 0.0, 'be03b35f_test_accuracy': 0.9977777600288391, 'be03b35f_test_diff_accuracy': 0.8333333333333334, 'bf32578f_test_accuracy': 0.9911110997200012, 'bf32578f_test_diff_accuracy': 0.38461538461538464, 'bf699163_test_accuracy': 0.9900000095367432, 'bf699163_test_diff_accuracy': 0.9737704918032787, 'bf89d739_test_accuracy': 0.9755555391311646, 'bf89d739_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('bf89d739', 'bf89d739', 'c074846d', 'c074846d', 'c074846d', 'c074846d', 'c074846d', 'c1990cce', 'c1990cce', 'c1990cce', 'c3202e5a', 'c3202e5a', 'c3202e5a', 'c35c1b4c', 'c35c1b4c', 'c35c1b4c', 'c48954c1', 'c48954c1', 'c48954c1', 'c62e2108', 'c62e2108', 'c62e2108', 'c64f1187', 'c64f1187', 'c658a4bd', 'c658a4bd', 'c663677b', 'c663677b', 'c663677b', 'c6e1b8da', 'c6e1b8da', 'c6e1b8da')], batch_idx: 31\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('bf89d739', 'bf89d739', 'c074846d', 'c074846d', 'c074846d', 'c074846d', 'c074846d', 'c1990cce', 'c1990cce', 'c1990cce', 'c3202e5a', 'c3202e5a', 'c3202e5a', 'c35c1b4c', 'c35c1b4c', 'c35c1b4c', 'c48954c1', 'c48954c1', 'c48954c1', 'c62e2108', 'c62e2108', 'c62e2108', 'c64f1187', 'c64f1187', 'c658a4bd', 'c658a4bd', 'c663677b', 'c663677b', 'c663677b', 'c6e1b8da', 'c6e1b8da', 'c6e1b8da')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.02564102564102564\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.125\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.07142857142857142\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9642857142857143\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9715639810426541\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9864864864864865\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.02857142857142857\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.024390243902439025\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.07692307692307693\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7272727272727273\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.648936170212766\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.40476190476190477\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.34513274336283184\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.2978723404255319\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4666666666666667\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5869565217391305\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.5282468199729919, Avg accuracy: 0.8724305611103773, Avg diff accuracy: 0.21099655008509235\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.5282468199729919, avg_accuracy=0.8724305611103773, diff_accuracy=0.21099655008509235\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.5282468199729919, 'task_ids': ('bf89d739', 'bf89d739', 'c074846d', 'c074846d', 'c074846d', 'c074846d', 'c074846d', 'c1990cce', 'c1990cce', 'c1990cce', 'c3202e5a', 'c3202e5a', 'c3202e5a', 'c35c1b4c', 'c35c1b4c', 'c35c1b4c', 'c48954c1', 'c48954c1', 'c48954c1', 'c62e2108', 'c62e2108', 'c62e2108', 'c64f1187', 'c64f1187', 'c658a4bd', 'c658a4bd', 'c663677b', 'c663677b', 'c663677b', 'c6e1b8da', 'c6e1b8da', 'c6e1b8da'), 'test_accuracy': 0.8724305611103773, 'test_diff_accuracy': 0.21099655008509235, 'bf89d739_test_accuracy': 0.9700000286102295, 'bf89d739_test_diff_accuracy': 0.0, 'c074846d_test_accuracy': 0.9944444298744202, 'c074846d_test_diff_accuracy': 0.0, 'c1990cce_test_accuracy': 0.9855555295944214, 'c1990cce_test_diff_accuracy': 0.07142857142857142, 'c3202e5a_test_accuracy': 0.995555579662323, 'c3202e5a_test_diff_accuracy': 0.9864864864864865, 'c35c1b4c_test_accuracy': 0.9133333563804626, 'c35c1b4c_test_diff_accuracy': 0.0, 'c48954c1_test_accuracy': 0.9100000262260437, 'c48954c1_test_diff_accuracy': 0.0, 'c62e2108_test_accuracy': 0.8933333158493042, 'c62e2108_test_diff_accuracy': 0.07692307692307693, 'c64f1187_test_accuracy': 0.9622222185134888, 'c64f1187_test_diff_accuracy': 0.648936170212766, 'c658a4bd_test_accuracy': 0.9100000262260437, 'c658a4bd_test_diff_accuracy': 0.34513274336283184, 'c663677b_test_accuracy': 0.1899999976158142, 'c663677b_test_diff_accuracy': 0.0, 'c6e1b8da_test_accuracy': 0.8922222256660461, 'c6e1b8da_test_diff_accuracy': 0.5869565217391305}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.5282468199729919, 'task_ids': ('bf89d739', 'bf89d739', 'c074846d', 'c074846d', 'c074846d', 'c074846d', 'c074846d', 'c1990cce', 'c1990cce', 'c1990cce', 'c3202e5a', 'c3202e5a', 'c3202e5a', 'c35c1b4c', 'c35c1b4c', 'c35c1b4c', 'c48954c1', 'c48954c1', 'c48954c1', 'c62e2108', 'c62e2108', 'c62e2108', 'c64f1187', 'c64f1187', 'c658a4bd', 'c658a4bd', 'c663677b', 'c663677b', 'c663677b', 'c6e1b8da', 'c6e1b8da', 'c6e1b8da'), 'test_accuracy': 0.8724305611103773, 'test_diff_accuracy': 0.21099655008509235, 'bf89d739_test_accuracy': 0.9700000286102295, 'bf89d739_test_diff_accuracy': 0.0, 'c074846d_test_accuracy': 0.9944444298744202, 'c074846d_test_diff_accuracy': 0.0, 'c1990cce_test_accuracy': 0.9855555295944214, 'c1990cce_test_diff_accuracy': 0.07142857142857142, 'c3202e5a_test_accuracy': 0.995555579662323, 'c3202e5a_test_diff_accuracy': 0.9864864864864865, 'c35c1b4c_test_accuracy': 0.9133333563804626, 'c35c1b4c_test_diff_accuracy': 0.0, 'c48954c1_test_accuracy': 0.9100000262260437, 'c48954c1_test_diff_accuracy': 0.0, 'c62e2108_test_accuracy': 0.8933333158493042, 'c62e2108_test_diff_accuracy': 0.07692307692307693, 'c64f1187_test_accuracy': 0.9622222185134888, 'c64f1187_test_diff_accuracy': 0.648936170212766, 'c658a4bd_test_accuracy': 0.9100000262260437, 'c658a4bd_test_diff_accuracy': 0.34513274336283184, 'c663677b_test_accuracy': 0.1899999976158142, 'c663677b_test_diff_accuracy': 0.0, 'c6e1b8da_test_accuracy': 0.8922222256660461, 'c6e1b8da_test_diff_accuracy': 0.5869565217391305}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('c7d4e6ad', 'c7d4e6ad', 'c87289bb', 'c87289bb', 'c87289bb', 'c87289bb', 'c8b7cc0f', 'c8b7cc0f', 'c8b7cc0f', 'c92b942c', 'c92b942c', 'c92b942c', 'c92b942c', 'c97c0139', 'c97c0139', 'ca8de6ea', 'ca8de6ea', 'ca8de6ea', 'ca8f78db', 'ca8f78db', 'ca8f78db', 'cad67732', 'cad67732', 'cad67732', 'cb227835', 'cb227835', 'cb227835', 'ccd554ac', 'ccd554ac', 'ccd554ac', 'ccd554ac', 'ccd554ac')], batch_idx: 32\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('c7d4e6ad', 'c7d4e6ad', 'c87289bb', 'c87289bb', 'c87289bb', 'c87289bb', 'c8b7cc0f', 'c8b7cc0f', 'c8b7cc0f', 'c92b942c', 'c92b942c', 'c92b942c', 'c92b942c', 'c97c0139', 'c97c0139', 'ca8de6ea', 'ca8de6ea', 'ca8de6ea', 'ca8f78db', 'ca8f78db', 'ca8f78db', 'cad67732', 'cad67732', 'cad67732', 'cb227835', 'cb227835', 'cb227835', 'ccd554ac', 'ccd554ac', 'ccd554ac', 'ccd554ac', 'ccd554ac')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9166666666666666\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8620689655172413\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8857142857142857\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.3333333333333333\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.3333333333333333\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.3333333333333333\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.09090909090909091\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.03125\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.4812777638435364, Avg accuracy: 0.8679513931274414, Avg diff accuracy: 0.11833153152522764\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.4812777638435364, avg_accuracy=0.8679513931274414, diff_accuracy=0.11833153152522764\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.4812777638435364, 'task_ids': ('c7d4e6ad', 'c7d4e6ad', 'c87289bb', 'c87289bb', 'c87289bb', 'c87289bb', 'c8b7cc0f', 'c8b7cc0f', 'c8b7cc0f', 'c92b942c', 'c92b942c', 'c92b942c', 'c92b942c', 'c97c0139', 'c97c0139', 'ca8de6ea', 'ca8de6ea', 'ca8de6ea', 'ca8f78db', 'ca8f78db', 'ca8f78db', 'cad67732', 'cad67732', 'cad67732', 'cb227835', 'cb227835', 'cb227835', 'ccd554ac', 'ccd554ac', 'ccd554ac', 'ccd554ac', 'ccd554ac'), 'test_accuracy': 0.8679513931274414, 'test_diff_accuracy': 0.11833153152522764, 'c7d4e6ad_test_accuracy': 0.9766666889190674, 'c7d4e6ad_test_diff_accuracy': 0.0, 'c87289bb_test_accuracy': 0.9355555772781372, 'c87289bb_test_diff_accuracy': 0.0, 'c8b7cc0f_test_accuracy': 0.995555579662323, 'c8b7cc0f_test_diff_accuracy': 0.8857142857142857, 'c92b942c_test_accuracy': 0.9300000071525574, 'c92b942c_test_diff_accuracy': 0.0, 'c97c0139_test_accuracy': 0.9399999976158142, 'c97c0139_test_diff_accuracy': 0.0, 'ca8de6ea_test_accuracy': 0.9900000095367432, 'ca8de6ea_test_diff_accuracy': 0.3333333333333333, 'ca8f78db_test_accuracy': 0.0, 'ca8f78db_test_diff_accuracy': 0.0, 'cad67732_test_accuracy': 0.9822221994400024, 'cad67732_test_diff_accuracy': 0.0, 'cb227835_test_accuracy': 0.9777777791023254, 'cb227835_test_diff_accuracy': 0.0, 'ccd554ac_test_accuracy': 0.8577777743339539, 'ccd554ac_test_diff_accuracy': 0.03125}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.4812777638435364, 'task_ids': ('c7d4e6ad', 'c7d4e6ad', 'c87289bb', 'c87289bb', 'c87289bb', 'c87289bb', 'c8b7cc0f', 'c8b7cc0f', 'c8b7cc0f', 'c92b942c', 'c92b942c', 'c92b942c', 'c92b942c', 'c97c0139', 'c97c0139', 'ca8de6ea', 'ca8de6ea', 'ca8de6ea', 'ca8f78db', 'ca8f78db', 'ca8f78db', 'cad67732', 'cad67732', 'cad67732', 'cb227835', 'cb227835', 'cb227835', 'ccd554ac', 'ccd554ac', 'ccd554ac', 'ccd554ac', 'ccd554ac'), 'test_accuracy': 0.8679513931274414, 'test_diff_accuracy': 0.11833153152522764, 'c7d4e6ad_test_accuracy': 0.9766666889190674, 'c7d4e6ad_test_diff_accuracy': 0.0, 'c87289bb_test_accuracy': 0.9355555772781372, 'c87289bb_test_diff_accuracy': 0.0, 'c8b7cc0f_test_accuracy': 0.995555579662323, 'c8b7cc0f_test_diff_accuracy': 0.8857142857142857, 'c92b942c_test_accuracy': 0.9300000071525574, 'c92b942c_test_diff_accuracy': 0.0, 'c97c0139_test_accuracy': 0.9399999976158142, 'c97c0139_test_diff_accuracy': 0.0, 'ca8de6ea_test_accuracy': 0.9900000095367432, 'ca8de6ea_test_diff_accuracy': 0.3333333333333333, 'ca8f78db_test_accuracy': 0.0, 'ca8f78db_test_diff_accuracy': 0.0, 'cad67732_test_accuracy': 0.9822221994400024, 'cad67732_test_diff_accuracy': 0.0, 'cb227835_test_accuracy': 0.9777777791023254, 'cb227835_test_diff_accuracy': 0.0, 'ccd554ac_test_accuracy': 0.8577777743339539, 'ccd554ac_test_diff_accuracy': 0.03125}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('ccd554ac', 'cd3c21df', 'cd3c21df', 'cd3c21df', 'ce039d91', 'ce039d91', 'ce039d91', 'ce039d91', 'ce8d95cc', 'ce8d95cc', 'ce8d95cc', 'ce8d95cc', 'cf133acc', 'cf133acc', 'cf133acc', 'cfb2ce5a', 'cfb2ce5a', 'cfb2ce5a', 'd017b73f', 'd017b73f', 'd017b73f', 'd017b73f', 'd19f7514', 'd19f7514', 'd19f7514', 'd19f7514', 'd282b262', 'd282b262', 'd282b262', 'd2acf2cb', 'd2acf2cb', 'd2acf2cb')], batch_idx: 33\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('ccd554ac', 'cd3c21df', 'cd3c21df', 'cd3c21df', 'ce039d91', 'ce039d91', 'ce039d91', 'ce039d91', 'ce8d95cc', 'ce8d95cc', 'ce8d95cc', 'ce8d95cc', 'cf133acc', 'cf133acc', 'cf133acc', 'cfb2ce5a', 'cfb2ce5a', 'cfb2ce5a', 'd017b73f', 'd017b73f', 'd017b73f', 'd017b73f', 'd19f7514', 'd19f7514', 'd19f7514', 'd19f7514', 'd282b262', 'd282b262', 'd282b262', 'd2acf2cb', 'd2acf2cb', 'd2acf2cb')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.03125\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8333333333333334\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8181818181818182\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8125\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.68\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.75\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.78125\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6666666666666666\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5714285714285714\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4857142857142857\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.47058823529411764\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4473684210526316\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.47761194029850745\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.45454545454545453\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.2857142857142857\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.18037037551403046, Avg accuracy: 0.9664930570870638, Avg diff accuracy: 0.3458172816321773\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.18037037551403046, avg_accuracy=0.9664930570870638, diff_accuracy=0.3458172816321773\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.18037037551403046, 'task_ids': ('ccd554ac', 'cd3c21df', 'cd3c21df', 'cd3c21df', 'ce039d91', 'ce039d91', 'ce039d91', 'ce039d91', 'ce8d95cc', 'ce8d95cc', 'ce8d95cc', 'ce8d95cc', 'cf133acc', 'cf133acc', 'cf133acc', 'cfb2ce5a', 'cfb2ce5a', 'cfb2ce5a', 'd017b73f', 'd017b73f', 'd017b73f', 'd017b73f', 'd19f7514', 'd19f7514', 'd19f7514', 'd19f7514', 'd282b262', 'd282b262', 'd282b262', 'd2acf2cb', 'd2acf2cb', 'd2acf2cb'), 'test_accuracy': 0.9664930570870638, 'test_diff_accuracy': 0.3458172816321773, 'ccd554ac_test_accuracy': 0.8577777743339539, 'ccd554ac_test_diff_accuracy': 0.03125, 'cd3c21df_test_accuracy': 0.9933333396911621, 'cd3c21df_test_diff_accuracy': 0.8125, 'ce039d91_test_accuracy': 0.9788888692855835, 'ce039d91_test_diff_accuracy': 0.0, 'ce8d95cc_test_accuracy': 0.9744444489479065, 'ce8d95cc_test_diff_accuracy': 0.6666666666666666, 'cf133acc_test_accuracy': 0.9222221970558167, 'cf133acc_test_diff_accuracy': 0.0, 'cfb2ce5a_test_accuracy': 0.9288889169692993, 'cfb2ce5a_test_diff_accuracy': 0.0, 'd017b73f_test_accuracy': 0.9877777695655823, 'd017b73f_test_diff_accuracy': 0.5, 'd19f7514_test_accuracy': 0.9766666889190674, 'd19f7514_test_diff_accuracy': 0.4473684210526316, 'd282b262_test_accuracy': 0.9655555486679077, 'd282b262_test_diff_accuracy': 0.45454545454545453, 'd2acf2cb_test_accuracy': 0.9622222185134888, 'd2acf2cb_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.18037037551403046, 'task_ids': ('ccd554ac', 'cd3c21df', 'cd3c21df', 'cd3c21df', 'ce039d91', 'ce039d91', 'ce039d91', 'ce039d91', 'ce8d95cc', 'ce8d95cc', 'ce8d95cc', 'ce8d95cc', 'cf133acc', 'cf133acc', 'cf133acc', 'cfb2ce5a', 'cfb2ce5a', 'cfb2ce5a', 'd017b73f', 'd017b73f', 'd017b73f', 'd017b73f', 'd19f7514', 'd19f7514', 'd19f7514', 'd19f7514', 'd282b262', 'd282b262', 'd282b262', 'd2acf2cb', 'd2acf2cb', 'd2acf2cb'), 'test_accuracy': 0.9664930570870638, 'test_diff_accuracy': 0.3458172816321773, 'ccd554ac_test_accuracy': 0.8577777743339539, 'ccd554ac_test_diff_accuracy': 0.03125, 'cd3c21df_test_accuracy': 0.9933333396911621, 'cd3c21df_test_diff_accuracy': 0.8125, 'ce039d91_test_accuracy': 0.9788888692855835, 'ce039d91_test_diff_accuracy': 0.0, 'ce8d95cc_test_accuracy': 0.9744444489479065, 'ce8d95cc_test_diff_accuracy': 0.6666666666666666, 'cf133acc_test_accuracy': 0.9222221970558167, 'cf133acc_test_diff_accuracy': 0.0, 'cfb2ce5a_test_accuracy': 0.9288889169692993, 'cfb2ce5a_test_diff_accuracy': 0.0, 'd017b73f_test_accuracy': 0.9877777695655823, 'd017b73f_test_diff_accuracy': 0.5, 'd19f7514_test_accuracy': 0.9766666889190674, 'd19f7514_test_diff_accuracy': 0.4473684210526316, 'd282b262_test_accuracy': 0.9655555486679077, 'd282b262_test_diff_accuracy': 0.45454545454545453, 'd2acf2cb_test_accuracy': 0.9622222185134888, 'd2acf2cb_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('d304284e', 'd304284e', 'd37a1ef5', 'd37a1ef5', 'd37a1ef5', 'd47aa2ff', 'd47aa2ff', 'd47aa2ff', 'd492a647', 'd492a647', 'd4b1c2b1', 'd4b1c2b1', 'd4b1c2b1', 'd4b1c2b1', 'd4b1c2b1', 'd4b1c2b1', 'd4b1c2b1', 'd4c90558', 'd4c90558', 'd4c90558', 'd56f2372', 'd56f2372', 'd56f2372', 'd5c634a2', 'd5c634a2', 'd5c634a2', 'd5c634a2', 'd5c634a2', 'd5c634a2', 'd5c634a2', 'd931c21c', 'd931c21c')], batch_idx: 34\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('d304284e', 'd304284e', 'd37a1ef5', 'd37a1ef5', 'd37a1ef5', 'd47aa2ff', 'd47aa2ff', 'd47aa2ff', 'd492a647', 'd492a647', 'd4b1c2b1', 'd4b1c2b1', 'd4b1c2b1', 'd4b1c2b1', 'd4b1c2b1', 'd4b1c2b1', 'd4b1c2b1', 'd4c90558', 'd4c90558', 'd4c90558', 'd56f2372', 'd56f2372', 'd56f2372', 'd5c634a2', 'd5c634a2', 'd5c634a2', 'd5c634a2', 'd5c634a2', 'd5c634a2', 'd5c634a2', 'd931c21c', 'd931c21c')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7419354838709677\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7142857142857143\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7142857142857143\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8797814207650273\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9306930693069307\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9084967320261438\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8275862068965517\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7571428571428571\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8333333333333334\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7941176470588235\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7857142857142857\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7777777777777778\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7894736842105263\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7727272727272727\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.2449212372303009, Avg accuracy: 0.9594097211956978, Avg diff accuracy: 0.4946047249813102\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.2449212372303009, avg_accuracy=0.9594097211956978, diff_accuracy=0.4946047249813102\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.2449212372303009, 'task_ids': ('d304284e', 'd304284e', 'd37a1ef5', 'd37a1ef5', 'd37a1ef5', 'd47aa2ff', 'd47aa2ff', 'd47aa2ff', 'd492a647', 'd492a647', 'd4b1c2b1', 'd4b1c2b1', 'd4b1c2b1', 'd4b1c2b1', 'd4b1c2b1', 'd4b1c2b1', 'd4b1c2b1', 'd4c90558', 'd4c90558', 'd4c90558', 'd56f2372', 'd56f2372', 'd56f2372', 'd5c634a2', 'd5c634a2', 'd5c634a2', 'd5c634a2', 'd5c634a2', 'd5c634a2', 'd5c634a2', 'd931c21c', 'd931c21c'), 'test_accuracy': 0.9594097211956978, 'test_diff_accuracy': 0.4946047249813102, 'd304284e_test_accuracy': 0.8788889050483704, 'd304284e_test_diff_accuracy': 0.0, 'd37a1ef5_test_accuracy': 0.9200000166893005, 'd37a1ef5_test_diff_accuracy': 0.0, 'd47aa2ff_test_accuracy': 0.9888888597488403, 'd47aa2ff_test_diff_accuracy': 0.7142857142857143, 'd492a647_test_accuracy': 0.8933333158493042, 'd492a647_test_diff_accuracy': 0.0, 'd4b1c2b1_test_accuracy': 0.9599999785423279, 'd4b1c2b1_test_diff_accuracy': 0.0, 'd4c90558_test_accuracy': 0.9811111092567444, 'd4c90558_test_diff_accuracy': 0.9084967320261438, 'd56f2372_test_accuracy': 0.9900000095367432, 'd56f2372_test_diff_accuracy': 0.8333333333333334, 'd5c634a2_test_accuracy': 0.9944444298744202, 'd5c634a2_test_diff_accuracy': 0.7727272727272727, 'd931c21c_test_accuracy': 0.9811111092567444, 'd931c21c_test_diff_accuracy': 1.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.2449212372303009, 'task_ids': ('d304284e', 'd304284e', 'd37a1ef5', 'd37a1ef5', 'd37a1ef5', 'd47aa2ff', 'd47aa2ff', 'd47aa2ff', 'd492a647', 'd492a647', 'd4b1c2b1', 'd4b1c2b1', 'd4b1c2b1', 'd4b1c2b1', 'd4b1c2b1', 'd4b1c2b1', 'd4b1c2b1', 'd4c90558', 'd4c90558', 'd4c90558', 'd56f2372', 'd56f2372', 'd56f2372', 'd5c634a2', 'd5c634a2', 'd5c634a2', 'd5c634a2', 'd5c634a2', 'd5c634a2', 'd5c634a2', 'd931c21c', 'd931c21c'), 'test_accuracy': 0.9594097211956978, 'test_diff_accuracy': 0.4946047249813102, 'd304284e_test_accuracy': 0.8788889050483704, 'd304284e_test_diff_accuracy': 0.0, 'd37a1ef5_test_accuracy': 0.9200000166893005, 'd37a1ef5_test_diff_accuracy': 0.0, 'd47aa2ff_test_accuracy': 0.9888888597488403, 'd47aa2ff_test_diff_accuracy': 0.7142857142857143, 'd492a647_test_accuracy': 0.8933333158493042, 'd492a647_test_diff_accuracy': 0.0, 'd4b1c2b1_test_accuracy': 0.9599999785423279, 'd4b1c2b1_test_diff_accuracy': 0.0, 'd4c90558_test_accuracy': 0.9811111092567444, 'd4c90558_test_diff_accuracy': 0.9084967320261438, 'd56f2372_test_accuracy': 0.9900000095367432, 'd56f2372_test_diff_accuracy': 0.8333333333333334, 'd5c634a2_test_accuracy': 0.9944444298744202, 'd5c634a2_test_diff_accuracy': 0.7727272727272727, 'd931c21c_test_accuracy': 0.9811111092567444, 'd931c21c_test_diff_accuracy': 1.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('d931c21c', 'd931c21c', 'd94c3b52', 'd94c3b52', 'd94c3b52', 'da2b0fe3', 'da2b0fe3', 'da2b0fe3', 'da515329', 'da515329', 'da515329', 'dc2aa30b', 'dc2aa30b', 'dc2aa30b', 'dc2e9a9d', 'dc2e9a9d', 'dc2e9a9d', 'dd2401ed', 'dd2401ed', 'dd2401ed', 'dd2401ed', 'de493100', 'de493100', 'de493100', 'de493100', 'df8cc377', 'df8cc377', 'df8cc377', 'e0fb7511', 'e0fb7511', 'e0fb7511', 'e133d23d')], batch_idx: 35\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('d931c21c', 'd931c21c', 'd94c3b52', 'd94c3b52', 'd94c3b52', 'da2b0fe3', 'da2b0fe3', 'da2b0fe3', 'da515329', 'da515329', 'da515329', 'dc2aa30b', 'dc2aa30b', 'dc2aa30b', 'dc2e9a9d', 'dc2e9a9d', 'dc2e9a9d', 'dd2401ed', 'dd2401ed', 'dd2401ed', 'dd2401ed', 'de493100', 'de493100', 'de493100', 'de493100', 'df8cc377', 'df8cc377', 'df8cc377', 'e0fb7511', 'e0fb7511', 'e0fb7511', 'e133d23d')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4117647058823529\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.3333333333333333\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.22635135135135134\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.43191964285714285\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.19409761634506242\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.15607580824972128\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5714285714285714\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.5498566627502441, Avg accuracy: 0.8259027814492583, Avg diff accuracy: 0.1507803446702355\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.5498566627502441, avg_accuracy=0.8259027814492583, diff_accuracy=0.1507803446702355\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.5498566627502441, 'task_ids': ('d931c21c', 'd931c21c', 'd94c3b52', 'd94c3b52', 'd94c3b52', 'da2b0fe3', 'da2b0fe3', 'da2b0fe3', 'da515329', 'da515329', 'da515329', 'dc2aa30b', 'dc2aa30b', 'dc2aa30b', 'dc2e9a9d', 'dc2e9a9d', 'dc2e9a9d', 'dd2401ed', 'dd2401ed', 'dd2401ed', 'dd2401ed', 'de493100', 'de493100', 'de493100', 'de493100', 'df8cc377', 'df8cc377', 'df8cc377', 'e0fb7511', 'e0fb7511', 'e0fb7511', 'e133d23d'), 'test_accuracy': 0.8259027814492583, 'test_diff_accuracy': 0.1507803446702355, 'd931c21c_test_accuracy': 0.846666693687439, 'd931c21c_test_diff_accuracy': 0.0, 'd94c3b52_test_accuracy': 0.8455555438995361, 'd94c3b52_test_diff_accuracy': 0.0, 'da2b0fe3_test_accuracy': 0.9677777886390686, 'da2b0fe3_test_diff_accuracy': 0.0, 'da515329_test_accuracy': 0.8588888645172119, 'da515329_test_diff_accuracy': 0.0, 'dc2aa30b_test_accuracy': 0.9100000262260437, 'dc2aa30b_test_diff_accuracy': 0.0, 'dc2e9a9d_test_accuracy': 0.9133333563804626, 'dc2e9a9d_test_diff_accuracy': 0.0, 'dd2401ed_test_accuracy': 0.9811111092567444, 'dd2401ed_test_diff_accuracy': 0.5, 'de493100_test_accuracy': 0.15777777135372162, 'de493100_test_diff_accuracy': 0.15607580824972128, 'df8cc377_test_accuracy': 0.9744444489479065, 'df8cc377_test_diff_accuracy': 0.5, 'e0fb7511_test_accuracy': 0.8288888931274414, 'e0fb7511_test_diff_accuracy': 0.0, 'e133d23d_test_accuracy': 0.9933333396911621, 'e133d23d_test_diff_accuracy': 0.5714285714285714}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.5498566627502441, 'task_ids': ('d931c21c', 'd931c21c', 'd94c3b52', 'd94c3b52', 'd94c3b52', 'da2b0fe3', 'da2b0fe3', 'da2b0fe3', 'da515329', 'da515329', 'da515329', 'dc2aa30b', 'dc2aa30b', 'dc2aa30b', 'dc2e9a9d', 'dc2e9a9d', 'dc2e9a9d', 'dd2401ed', 'dd2401ed', 'dd2401ed', 'dd2401ed', 'de493100', 'de493100', 'de493100', 'de493100', 'df8cc377', 'df8cc377', 'df8cc377', 'e0fb7511', 'e0fb7511', 'e0fb7511', 'e133d23d'), 'test_accuracy': 0.8259027814492583, 'test_diff_accuracy': 0.1507803446702355, 'd931c21c_test_accuracy': 0.846666693687439, 'd931c21c_test_diff_accuracy': 0.0, 'd94c3b52_test_accuracy': 0.8455555438995361, 'd94c3b52_test_diff_accuracy': 0.0, 'da2b0fe3_test_accuracy': 0.9677777886390686, 'da2b0fe3_test_diff_accuracy': 0.0, 'da515329_test_accuracy': 0.8588888645172119, 'da515329_test_diff_accuracy': 0.0, 'dc2aa30b_test_accuracy': 0.9100000262260437, 'dc2aa30b_test_diff_accuracy': 0.0, 'dc2e9a9d_test_accuracy': 0.9133333563804626, 'dc2e9a9d_test_diff_accuracy': 0.0, 'dd2401ed_test_accuracy': 0.9811111092567444, 'dd2401ed_test_diff_accuracy': 0.5, 'de493100_test_accuracy': 0.15777777135372162, 'de493100_test_diff_accuracy': 0.15607580824972128, 'df8cc377_test_accuracy': 0.9744444489479065, 'df8cc377_test_diff_accuracy': 0.5, 'e0fb7511_test_accuracy': 0.8288888931274414, 'e0fb7511_test_diff_accuracy': 0.0, 'e133d23d_test_accuracy': 0.9933333396911621, 'e133d23d_test_diff_accuracy': 0.5714285714285714}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('e133d23d', 'e133d23d', 'e133d23d', 'e133d23d', 'e1baa8a4', 'e1baa8a4', 'e1baa8a4', 'e1baa8a4', 'e1d2900e', 'e1d2900e', 'e1d2900e', 'e2092e0c', 'e2092e0c', 'e2092e0c', 'e21a174a', 'e21a174a', 'e21a174a', 'e345f17b', 'e345f17b', 'e345f17b', 'e345f17b', 'e4075551', 'e4075551', 'e4075551', 'e41c6fd3', 'e41c6fd3', 'e41c6fd3', 'e57337a4', 'e57337a4', 'e57337a4', 'e5790162', 'e5790162')], batch_idx: 36\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('e133d23d', 'e133d23d', 'e133d23d', 'e133d23d', 'e1baa8a4', 'e1baa8a4', 'e1baa8a4', 'e1baa8a4', 'e1d2900e', 'e1d2900e', 'e1d2900e', 'e2092e0c', 'e2092e0c', 'e2092e0c', 'e21a174a', 'e21a174a', 'e21a174a', 'e345f17b', 'e345f17b', 'e345f17b', 'e345f17b', 'e4075551', 'e4075551', 'e4075551', 'e41c6fd3', 'e41c6fd3', 'e41c6fd3', 'e57337a4', 'e57337a4', 'e57337a4', 'e5790162', 'e5790162')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.38461538461538464\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.46153846153846156\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9845360824742269\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9700598802395209\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9760765550239234\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9103139013452914\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.24528301886792453\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.2972972972972973\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.2222222222222222\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7058823529411765\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.85\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8421052631578947\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8571428571428571\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.27314814814814814\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.2777777777777778\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.2137870341539383, Avg accuracy: 0.9569791667163372, Avg diff accuracy: 0.4486874750872534\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.2137870341539383, avg_accuracy=0.9569791667163372, diff_accuracy=0.4486874750872534\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.2137870341539383, 'task_ids': ('e133d23d', 'e133d23d', 'e133d23d', 'e133d23d', 'e1baa8a4', 'e1baa8a4', 'e1baa8a4', 'e1baa8a4', 'e1d2900e', 'e1d2900e', 'e1d2900e', 'e2092e0c', 'e2092e0c', 'e2092e0c', 'e21a174a', 'e21a174a', 'e21a174a', 'e345f17b', 'e345f17b', 'e345f17b', 'e345f17b', 'e4075551', 'e4075551', 'e4075551', 'e41c6fd3', 'e41c6fd3', 'e41c6fd3', 'e57337a4', 'e57337a4', 'e57337a4', 'e5790162', 'e5790162'), 'test_accuracy': 0.9569791667163372, 'test_diff_accuracy': 0.4486874750872534, 'e133d23d_test_accuracy': 0.995555579662323, 'e133d23d_test_diff_accuracy': 0.6, 'e1baa8a4_test_accuracy': 0.9755555391311646, 'e1baa8a4_test_diff_accuracy': 0.9103139013452914, 'e1d2900e_test_accuracy': 0.9877777695655823, 'e1d2900e_test_diff_accuracy': 0.5, 'e2092e0c_test_accuracy': 0.8888888955116272, 'e2092e0c_test_diff_accuracy': 0.0, 'e21a174a_test_accuracy': 0.9811111092567444, 'e21a174a_test_diff_accuracy': 0.2222222222222222, 'e345f17b_test_accuracy': 0.996666669845581, 'e345f17b_test_diff_accuracy': 0.8571428571428571, 'e4075551_test_accuracy': 0.9366666674613953, 'e4075551_test_diff_accuracy': 0.0, 'e41c6fd3_test_accuracy': 0.9333333373069763, 'e41c6fd3_test_diff_accuracy': 0.5, 'e57337a4_test_accuracy': 0.9933333396911621, 'e57337a4_test_diff_accuracy': 1.0, 'e5790162_test_accuracy': 0.9888888597488403, 'e5790162_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.2137870341539383, 'task_ids': ('e133d23d', 'e133d23d', 'e133d23d', 'e133d23d', 'e1baa8a4', 'e1baa8a4', 'e1baa8a4', 'e1baa8a4', 'e1d2900e', 'e1d2900e', 'e1d2900e', 'e2092e0c', 'e2092e0c', 'e2092e0c', 'e21a174a', 'e21a174a', 'e21a174a', 'e345f17b', 'e345f17b', 'e345f17b', 'e345f17b', 'e4075551', 'e4075551', 'e4075551', 'e41c6fd3', 'e41c6fd3', 'e41c6fd3', 'e57337a4', 'e57337a4', 'e57337a4', 'e5790162', 'e5790162'), 'test_accuracy': 0.9569791667163372, 'test_diff_accuracy': 0.4486874750872534, 'e133d23d_test_accuracy': 0.995555579662323, 'e133d23d_test_diff_accuracy': 0.6, 'e1baa8a4_test_accuracy': 0.9755555391311646, 'e1baa8a4_test_diff_accuracy': 0.9103139013452914, 'e1d2900e_test_accuracy': 0.9877777695655823, 'e1d2900e_test_diff_accuracy': 0.5, 'e2092e0c_test_accuracy': 0.8888888955116272, 'e2092e0c_test_diff_accuracy': 0.0, 'e21a174a_test_accuracy': 0.9811111092567444, 'e21a174a_test_diff_accuracy': 0.2222222222222222, 'e345f17b_test_accuracy': 0.996666669845581, 'e345f17b_test_diff_accuracy': 0.8571428571428571, 'e4075551_test_accuracy': 0.9366666674613953, 'e4075551_test_diff_accuracy': 0.0, 'e41c6fd3_test_accuracy': 0.9333333373069763, 'e41c6fd3_test_diff_accuracy': 0.5, 'e57337a4_test_accuracy': 0.9933333396911621, 'e57337a4_test_diff_accuracy': 1.0, 'e5790162_test_accuracy': 0.9888888597488403, 'e5790162_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('e5790162', 'e5790162', 'e5790162', 'e5c44e8f', 'e5c44e8f', 'e5c44e8f', 'e619ca6e', 'e619ca6e', 'e619ca6e', 'e633a9e5', 'e633a9e5', 'e633a9e5', 'e66aafb8', 'e66aafb8', 'e66aafb8', 'e66aafb8', 'e66aafb8', 'e681b708', 'e681b708', 'e681b708', 'e69241bd', 'e69241bd', 'e69241bd', 'e6de6e8f', 'e6de6e8f', 'e6de6e8f', 'e74e1818', 'e74e1818', 'e74e1818', 'e760a62e', 'e760a62e', 'e760a62e')], batch_idx: 37\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('e5790162', 'e5790162', 'e5790162', 'e5c44e8f', 'e5c44e8f', 'e5c44e8f', 'e619ca6e', 'e619ca6e', 'e619ca6e', 'e633a9e5', 'e633a9e5', 'e633a9e5', 'e66aafb8', 'e66aafb8', 'e66aafb8', 'e66aafb8', 'e66aafb8', 'e681b708', 'e681b708', 'e681b708', 'e69241bd', 'e69241bd', 'e69241bd', 'e6de6e8f', 'e6de6e8f', 'e6de6e8f', 'e74e1818', 'e74e1818', 'e74e1818', 'e760a62e', 'e760a62e', 'e760a62e')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8949343339587242\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8983957219251337\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9429097605893186\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.967032967032967\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9246704331450094\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5416666666666666\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.55\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5416666666666666\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.4079769551753998, Avg accuracy: 0.9159027803689241, Avg diff accuracy: 0.2425398921870152\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.4079769551753998, avg_accuracy=0.9159027803689241, diff_accuracy=0.2425398921870152\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.4079769551753998, 'task_ids': ('e5790162', 'e5790162', 'e5790162', 'e5c44e8f', 'e5c44e8f', 'e5c44e8f', 'e619ca6e', 'e619ca6e', 'e619ca6e', 'e633a9e5', 'e633a9e5', 'e633a9e5', 'e66aafb8', 'e66aafb8', 'e66aafb8', 'e66aafb8', 'e66aafb8', 'e681b708', 'e681b708', 'e681b708', 'e69241bd', 'e69241bd', 'e69241bd', 'e6de6e8f', 'e6de6e8f', 'e6de6e8f', 'e74e1818', 'e74e1818', 'e74e1818', 'e760a62e', 'e760a62e', 'e760a62e'), 'test_accuracy': 0.9159027803689241, 'test_diff_accuracy': 0.2425398921870152, 'e5790162_test_accuracy': 0.9855555295944214, 'e5790162_test_diff_accuracy': 0.0, 'e5c44e8f_test_accuracy': 0.9644444584846497, 'e5c44e8f_test_diff_accuracy': 0.0, 'e619ca6e_test_accuracy': 0.8777777552604675, 'e619ca6e_test_diff_accuracy': 0.0, 'e633a9e5_test_accuracy': 0.9722222089767456, 'e633a9e5_test_diff_accuracy': 0.0, 'e66aafb8_test_accuracy': 0.9522222280502319, 'e66aafb8_test_diff_accuracy': 0.9246704331450094, 'e681b708_test_accuracy': 0.9111111164093018, 'e681b708_test_diff_accuracy': 0.0, 'e69241bd_test_accuracy': 0.9555555582046509, 'e69241bd_test_diff_accuracy': 0.0, 'e6de6e8f_test_accuracy': 0.9877777695655823, 'e6de6e8f_test_diff_accuracy': 0.5416666666666666, 'e74e1818_test_accuracy': 0.9833333492279053, 'e74e1818_test_diff_accuracy': 0.5, 'e760a62e_test_accuracy': 0.5922222137451172, 'e760a62e_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.4079769551753998, 'task_ids': ('e5790162', 'e5790162', 'e5790162', 'e5c44e8f', 'e5c44e8f', 'e5c44e8f', 'e619ca6e', 'e619ca6e', 'e619ca6e', 'e633a9e5', 'e633a9e5', 'e633a9e5', 'e66aafb8', 'e66aafb8', 'e66aafb8', 'e66aafb8', 'e66aafb8', 'e681b708', 'e681b708', 'e681b708', 'e69241bd', 'e69241bd', 'e69241bd', 'e6de6e8f', 'e6de6e8f', 'e6de6e8f', 'e74e1818', 'e74e1818', 'e74e1818', 'e760a62e', 'e760a62e', 'e760a62e'), 'test_accuracy': 0.9159027803689241, 'test_diff_accuracy': 0.2425398921870152, 'e5790162_test_accuracy': 0.9855555295944214, 'e5790162_test_diff_accuracy': 0.0, 'e5c44e8f_test_accuracy': 0.9644444584846497, 'e5c44e8f_test_diff_accuracy': 0.0, 'e619ca6e_test_accuracy': 0.8777777552604675, 'e619ca6e_test_diff_accuracy': 0.0, 'e633a9e5_test_accuracy': 0.9722222089767456, 'e633a9e5_test_diff_accuracy': 0.0, 'e66aafb8_test_accuracy': 0.9522222280502319, 'e66aafb8_test_diff_accuracy': 0.9246704331450094, 'e681b708_test_accuracy': 0.9111111164093018, 'e681b708_test_diff_accuracy': 0.0, 'e69241bd_test_accuracy': 0.9555555582046509, 'e69241bd_test_diff_accuracy': 0.0, 'e6de6e8f_test_accuracy': 0.9877777695655823, 'e6de6e8f_test_diff_accuracy': 0.5416666666666666, 'e74e1818_test_accuracy': 0.9833333492279053, 'e74e1818_test_diff_accuracy': 0.5, 'e760a62e_test_accuracy': 0.5922222137451172, 'e760a62e_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('e7639916', 'e7639916', 'e7639916', 'e78887d1', 'e78887d1', 'e78887d1', 'e78887d1', 'e7a25a18', 'e7a25a18', 'e7b06bea', 'e7b06bea', 'e7b06bea', 'e7b06bea', 'e7b06bea', 'e7dd8335', 'e7dd8335', 'e7dd8335', 'e872b94a', 'e872b94a', 'e872b94a', 'e872b94a', 'e88171ec', 'e88171ec', 'e88171ec', 'e95e3d8e', 'e95e3d8e', 'e95e3d8e', 'e99362f0', 'e99362f0', 'e99362f0', 'e99362f0', 'e99362f0')], batch_idx: 38\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('e7639916', 'e7639916', 'e7639916', 'e78887d1', 'e78887d1', 'e78887d1', 'e78887d1', 'e7a25a18', 'e7a25a18', 'e7b06bea', 'e7b06bea', 'e7b06bea', 'e7b06bea', 'e7b06bea', 'e7dd8335', 'e7dd8335', 'e7dd8335', 'e872b94a', 'e872b94a', 'e872b94a', 'e872b94a', 'e88171ec', 'e88171ec', 'e88171ec', 'e95e3d8e', 'e95e3d8e', 'e95e3d8e', 'e99362f0', 'e99362f0', 'e99362f0', 'e99362f0', 'e99362f0')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8461538461538461\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7272727272727273\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6779661016949152\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.11627906976744186\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.3181818181818182\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6666666666666666\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6666666666666666\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.75\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6666666666666666\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.75\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6981132075471698\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7258064516129032\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6818181818181818\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7457627118644068\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7246376811594203\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.3182734549045563, Avg accuracy: 0.9137500021606684, Avg diff accuracy: 0.44568724365852597\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.3182734549045563, avg_accuracy=0.9137500021606684, diff_accuracy=0.44568724365852597\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.3182734549045563, 'task_ids': ('e7639916', 'e7639916', 'e7639916', 'e78887d1', 'e78887d1', 'e78887d1', 'e78887d1', 'e7a25a18', 'e7a25a18', 'e7b06bea', 'e7b06bea', 'e7b06bea', 'e7b06bea', 'e7b06bea', 'e7dd8335', 'e7dd8335', 'e7dd8335', 'e872b94a', 'e872b94a', 'e872b94a', 'e872b94a', 'e88171ec', 'e88171ec', 'e88171ec', 'e95e3d8e', 'e95e3d8e', 'e95e3d8e', 'e99362f0', 'e99362f0', 'e99362f0', 'e99362f0', 'e99362f0'), 'test_accuracy': 0.9137500021606684, 'test_diff_accuracy': 0.44568724365852597, 'e7639916_test_accuracy': 0.9644444584846497, 'e7639916_test_diff_accuracy': 0.0, 'e78887d1_test_accuracy': 0.9766666889190674, 'e78887d1_test_diff_accuracy': 0.6779661016949152, 'e7a25a18_test_accuracy': 0.9599999785423279, 'e7a25a18_test_diff_accuracy': 0.3181818181818182, 'e7b06bea_test_accuracy': 0.9833333492279053, 'e7b06bea_test_diff_accuracy': 0.75, 'e7dd8335_test_accuracy': 0.9777777791023254, 'e7dd8335_test_diff_accuracy': 0.0, 'e872b94a_test_accuracy': 1.0, 'e872b94a_test_diff_accuracy': 1.0, 'e88171ec_test_accuracy': 0.8411111235618591, 'e88171ec_test_diff_accuracy': 0.0, 'e95e3d8e_test_accuracy': 0.46222221851348877, 'e95e3d8e_test_diff_accuracy': 0.0, 'e99362f0_test_accuracy': 0.9766666889190674, 'e99362f0_test_diff_accuracy': 0.7246376811594203}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.3182734549045563, 'task_ids': ('e7639916', 'e7639916', 'e7639916', 'e78887d1', 'e78887d1', 'e78887d1', 'e78887d1', 'e7a25a18', 'e7a25a18', 'e7b06bea', 'e7b06bea', 'e7b06bea', 'e7b06bea', 'e7b06bea', 'e7dd8335', 'e7dd8335', 'e7dd8335', 'e872b94a', 'e872b94a', 'e872b94a', 'e872b94a', 'e88171ec', 'e88171ec', 'e88171ec', 'e95e3d8e', 'e95e3d8e', 'e95e3d8e', 'e99362f0', 'e99362f0', 'e99362f0', 'e99362f0', 'e99362f0'), 'test_accuracy': 0.9137500021606684, 'test_diff_accuracy': 0.44568724365852597, 'e7639916_test_accuracy': 0.9644444584846497, 'e7639916_test_diff_accuracy': 0.0, 'e78887d1_test_accuracy': 0.9766666889190674, 'e78887d1_test_diff_accuracy': 0.6779661016949152, 'e7a25a18_test_accuracy': 0.9599999785423279, 'e7a25a18_test_diff_accuracy': 0.3181818181818182, 'e7b06bea_test_accuracy': 0.9833333492279053, 'e7b06bea_test_diff_accuracy': 0.75, 'e7dd8335_test_accuracy': 0.9777777791023254, 'e7dd8335_test_diff_accuracy': 0.0, 'e872b94a_test_accuracy': 1.0, 'e872b94a_test_diff_accuracy': 1.0, 'e88171ec_test_accuracy': 0.8411111235618591, 'e88171ec_test_diff_accuracy': 0.0, 'e95e3d8e_test_accuracy': 0.46222221851348877, 'e95e3d8e_test_diff_accuracy': 0.0, 'e99362f0_test_accuracy': 0.9766666889190674, 'e99362f0_test_diff_accuracy': 0.7246376811594203}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('e99362f0', 'e9ac8c9e', 'e9ac8c9e', 'e9ac8c9e', 'e9b4f6fc', 'e9b4f6fc', 'e9b4f6fc', 'e9b4f6fc', 'e9bb6954', 'e9bb6954', 'e9bb6954', 'e9bb6954', 'e9c9d9a1', 'e9c9d9a1', 'e9c9d9a1', 'ea959feb', 'ea959feb', 'ea959feb', 'ea9794b1', 'ea9794b1', 'ea9794b1', 'ea9794b1', 'ea9794b1', 'ea9794b1', 'ecaa0ec1', 'ecaa0ec1', 'ecaa0ec1', 'ecaa0ec1', 'ed74f2f2', 'ed74f2f2', 'ed74f2f2', 'ed74f2f2')], batch_idx: 39\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('e99362f0', 'e9ac8c9e', 'e9ac8c9e', 'e9ac8c9e', 'e9b4f6fc', 'e9b4f6fc', 'e9b4f6fc', 'e9b4f6fc', 'e9bb6954', 'e9bb6954', 'e9bb6954', 'e9bb6954', 'e9c9d9a1', 'e9c9d9a1', 'e9c9d9a1', 'ea959feb', 'ea959feb', 'ea959feb', 'ea9794b1', 'ea9794b1', 'ea9794b1', 'ea9794b1', 'ea9794b1', 'ea9794b1', 'ecaa0ec1', 'ecaa0ec1', 'ecaa0ec1', 'ecaa0ec1', 'ed74f2f2', 'ed74f2f2', 'ed74f2f2', 'ed74f2f2')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7121212121212122\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.2\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.1\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.375\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4266666666666667\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.45\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5277777777777778\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.01282051282051282\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6333333333333333\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6271186440677966\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7090909090909091\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6792452830188679\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6274509803921569\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6071428571428571\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5714285714285714\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.36363636363636365\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4444444444444444\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5714285714285714\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5333333333333333\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5714285714285714\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5714285714285714\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5625\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.38374149799346924, Avg accuracy: 0.8990625031292439, Avg diff accuracy: 0.3555436438612662\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.38374149799346924, avg_accuracy=0.8990625031292439, diff_accuracy=0.3555436438612662\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.38374149799346924, 'task_ids': ('e99362f0', 'e9ac8c9e', 'e9ac8c9e', 'e9ac8c9e', 'e9b4f6fc', 'e9b4f6fc', 'e9b4f6fc', 'e9b4f6fc', 'e9bb6954', 'e9bb6954', 'e9bb6954', 'e9bb6954', 'e9c9d9a1', 'e9c9d9a1', 'e9c9d9a1', 'ea959feb', 'ea959feb', 'ea959feb', 'ea9794b1', 'ea9794b1', 'ea9794b1', 'ea9794b1', 'ea9794b1', 'ea9794b1', 'ecaa0ec1', 'ecaa0ec1', 'ecaa0ec1', 'ecaa0ec1', 'ed74f2f2', 'ed74f2f2', 'ed74f2f2', 'ed74f2f2'), 'test_accuracy': 0.8990625031292439, 'test_diff_accuracy': 0.3555436438612662, 'e99362f0_test_accuracy': 0.9777777791023254, 'e99362f0_test_diff_accuracy': 0.7121212121212122, 'e9ac8c9e_test_accuracy': 0.9599999785423279, 'e9ac8c9e_test_diff_accuracy': 0.1, 'e9b4f6fc_test_accuracy': 0.9811111092567444, 'e9b4f6fc_test_diff_accuracy': 0.5277777777777778, 'e9bb6954_test_accuracy': 0.8622221946716309, 'e9bb6954_test_diff_accuracy': 0.01282051282051282, 'e9c9d9a1_test_accuracy': 0.7688888907432556, 'e9c9d9a1_test_diff_accuracy': 0.0, 'ea959feb_test_accuracy': 0.3888888955116272, 'ea959feb_test_diff_accuracy': 0.0, 'ea9794b1_test_accuracy': 0.9688888788223267, 'ea9794b1_test_diff_accuracy': 0.6071428571428571, 'ecaa0ec1_test_accuracy': 0.9900000095367432, 'ecaa0ec1_test_diff_accuracy': 0.5714285714285714, 'ed74f2f2_test_accuracy': 0.992222249507904, 'ed74f2f2_test_diff_accuracy': 0.5625}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.38374149799346924, 'task_ids': ('e99362f0', 'e9ac8c9e', 'e9ac8c9e', 'e9ac8c9e', 'e9b4f6fc', 'e9b4f6fc', 'e9b4f6fc', 'e9b4f6fc', 'e9bb6954', 'e9bb6954', 'e9bb6954', 'e9bb6954', 'e9c9d9a1', 'e9c9d9a1', 'e9c9d9a1', 'ea959feb', 'ea959feb', 'ea959feb', 'ea9794b1', 'ea9794b1', 'ea9794b1', 'ea9794b1', 'ea9794b1', 'ea9794b1', 'ecaa0ec1', 'ecaa0ec1', 'ecaa0ec1', 'ecaa0ec1', 'ed74f2f2', 'ed74f2f2', 'ed74f2f2', 'ed74f2f2'), 'test_accuracy': 0.8990625031292439, 'test_diff_accuracy': 0.3555436438612662, 'e99362f0_test_accuracy': 0.9777777791023254, 'e99362f0_test_diff_accuracy': 0.7121212121212122, 'e9ac8c9e_test_accuracy': 0.9599999785423279, 'e9ac8c9e_test_diff_accuracy': 0.1, 'e9b4f6fc_test_accuracy': 0.9811111092567444, 'e9b4f6fc_test_diff_accuracy': 0.5277777777777778, 'e9bb6954_test_accuracy': 0.8622221946716309, 'e9bb6954_test_diff_accuracy': 0.01282051282051282, 'e9c9d9a1_test_accuracy': 0.7688888907432556, 'e9c9d9a1_test_diff_accuracy': 0.0, 'ea959feb_test_accuracy': 0.3888888955116272, 'ea959feb_test_diff_accuracy': 0.0, 'ea9794b1_test_accuracy': 0.9688888788223267, 'ea9794b1_test_diff_accuracy': 0.6071428571428571, 'ecaa0ec1_test_accuracy': 0.9900000095367432, 'ecaa0ec1_test_diff_accuracy': 0.5714285714285714, 'ed74f2f2_test_accuracy': 0.992222249507904, 'ed74f2f2_test_diff_accuracy': 0.5625}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('ed74f2f2', 'ed74f2f2', 'ed98d772', 'ed98d772', 'ed98d772', 'ed98d772', 'ed98d772', 'ef26cbf6', 'ef26cbf6', 'f0afb749', 'f0afb749', 'f0afb749', 'f0df5ff0', 'f0df5ff0', 'f0df5ff0', 'f21745ec', 'f21745ec', 'f21745ec', 'f3b10344', 'f3b10344', 'f3b10344', 'f3cdc58f', 'f3cdc58f', 'f3cdc58f', 'f3e62deb', 'f3e62deb', 'f3e62deb', 'f3e62deb', 'f3e62deb', 'f3e62deb', 'f4081712', 'f4081712')], batch_idx: 40\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('ed74f2f2', 'ed74f2f2', 'ed98d772', 'ed98d772', 'ed98d772', 'ed98d772', 'ed98d772', 'ef26cbf6', 'ef26cbf6', 'f0afb749', 'f0afb749', 'f0afb749', 'f0df5ff0', 'f0df5ff0', 'f0df5ff0', 'f21745ec', 'f21745ec', 'f21745ec', 'f3b10344', 'f3b10344', 'f3b10344', 'f3cdc58f', 'f3cdc58f', 'f3cdc58f', 'f3e62deb', 'f3e62deb', 'f3e62deb', 'f3e62deb', 'f3e62deb', 'f3e62deb', 'f4081712', 'f4081712')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6666666666666666\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6666666666666666\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.10526315789473684\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.043478260869565216\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.10526315789473684\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.2\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.07142857142857142\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.07407407407407407\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.1111111111111111\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.42105263157894735\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4375\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6296296296296297\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.43333333333333335\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4318181818181818\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4782608695652174\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9878048780487805\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.743006993006993\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.2850625216960907, Avg accuracy: 0.9323611035943031, Avg diff accuracy: 0.30019869323710036\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.2850625216960907, avg_accuracy=0.9323611035943031, diff_accuracy=0.30019869323710036\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.2850625216960907, 'task_ids': ('ed74f2f2', 'ed74f2f2', 'ed98d772', 'ed98d772', 'ed98d772', 'ed98d772', 'ed98d772', 'ef26cbf6', 'ef26cbf6', 'f0afb749', 'f0afb749', 'f0afb749', 'f0df5ff0', 'f0df5ff0', 'f0df5ff0', 'f21745ec', 'f21745ec', 'f21745ec', 'f3b10344', 'f3b10344', 'f3b10344', 'f3cdc58f', 'f3cdc58f', 'f3cdc58f', 'f3e62deb', 'f3e62deb', 'f3e62deb', 'f3e62deb', 'f3e62deb', 'f3e62deb', 'f4081712', 'f4081712'), 'test_accuracy': 0.9323611035943031, 'test_diff_accuracy': 0.30019869323710036, 'ed74f2f2_test_accuracy': 0.995555579662323, 'ed74f2f2_test_diff_accuracy': 0.6666666666666666, 'ed98d772_test_accuracy': 0.9822221994400024, 'ed98d772_test_diff_accuracy': 0.07142857142857142, 'ef26cbf6_test_accuracy': 0.95333331823349, 'ef26cbf6_test_diff_accuracy': 0.0, 'f0afb749_test_accuracy': 0.9822221994400024, 'f0afb749_test_diff_accuracy': 0.1111111111111111, 'f0df5ff0_test_accuracy': 0.8455555438995361, 'f0df5ff0_test_diff_accuracy': 0.0, 'f21745ec_test_accuracy': 0.8933333158493042, 'f21745ec_test_diff_accuracy': 0.6296296296296297, 'f3b10344_test_accuracy': 0.7277777791023254, 'f3b10344_test_diff_accuracy': 0.0, 'f3cdc58f_test_accuracy': 0.9855555295944214, 'f3cdc58f_test_diff_accuracy': 0.4782608695652174, 'f3e62deb_test_accuracy': 0.9911110997200012, 'f3e62deb_test_diff_accuracy': 0.5, 'f4081712_test_accuracy': 0.8322222232818604, 'f4081712_test_diff_accuracy': 0.743006993006993}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.2850625216960907, 'task_ids': ('ed74f2f2', 'ed74f2f2', 'ed98d772', 'ed98d772', 'ed98d772', 'ed98d772', 'ed98d772', 'ef26cbf6', 'ef26cbf6', 'f0afb749', 'f0afb749', 'f0afb749', 'f0df5ff0', 'f0df5ff0', 'f0df5ff0', 'f21745ec', 'f21745ec', 'f21745ec', 'f3b10344', 'f3b10344', 'f3b10344', 'f3cdc58f', 'f3cdc58f', 'f3cdc58f', 'f3e62deb', 'f3e62deb', 'f3e62deb', 'f3e62deb', 'f3e62deb', 'f3e62deb', 'f4081712', 'f4081712'), 'test_accuracy': 0.9323611035943031, 'test_diff_accuracy': 0.30019869323710036, 'ed74f2f2_test_accuracy': 0.995555579662323, 'ed74f2f2_test_diff_accuracy': 0.6666666666666666, 'ed98d772_test_accuracy': 0.9822221994400024, 'ed98d772_test_diff_accuracy': 0.07142857142857142, 'ef26cbf6_test_accuracy': 0.95333331823349, 'ef26cbf6_test_diff_accuracy': 0.0, 'f0afb749_test_accuracy': 0.9822221994400024, 'f0afb749_test_diff_accuracy': 0.1111111111111111, 'f0df5ff0_test_accuracy': 0.8455555438995361, 'f0df5ff0_test_diff_accuracy': 0.0, 'f21745ec_test_accuracy': 0.8933333158493042, 'f21745ec_test_diff_accuracy': 0.6296296296296297, 'f3b10344_test_accuracy': 0.7277777791023254, 'f3b10344_test_diff_accuracy': 0.0, 'f3cdc58f_test_accuracy': 0.9855555295944214, 'f3cdc58f_test_diff_accuracy': 0.4782608695652174, 'f3e62deb_test_accuracy': 0.9911110997200012, 'f3e62deb_test_diff_accuracy': 0.5, 'f4081712_test_accuracy': 0.8322222232818604, 'f4081712_test_diff_accuracy': 0.743006993006993}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('f4081712', 'f4081712', 'f4081712', 'f45f5ca7', 'f45f5ca7', 'f45f5ca7', 'f5aa3634', 'f5aa3634', 'f5aa3634', 'f5c89df1', 'f5c89df1', 'f5c89df1', 'f823c43c', 'f823c43c', 'f83cb3f6', 'f83cb3f6', 'f83cb3f6', 'f8be4b64', 'f8be4b64', 'f8be4b64', 'f8be4b64', 'f9a67cb5', 'f9a67cb5', 'f9a67cb5', 'f9d67f8b', 'f9d67f8b', 'f9d67f8b', 'f9d67f8b', 'fafd9572', 'fafd9572', 'fb791726', 'fb791726')], batch_idx: 41\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('f4081712', 'f4081712', 'f4081712', 'f45f5ca7', 'f45f5ca7', 'f45f5ca7', 'f5aa3634', 'f5aa3634', 'f5aa3634', 'f5c89df1', 'f5c89df1', 'f5c89df1', 'f823c43c', 'f823c43c', 'f83cb3f6', 'f83cb3f6', 'f83cb3f6', 'f8be4b64', 'f8be4b64', 'f8be4b64', 'f8be4b64', 'f9a67cb5', 'f9a67cb5', 'f9a67cb5', 'f9d67f8b', 'f9d67f8b', 'f9d67f8b', 'f9d67f8b', 'fafd9572', 'fafd9572', 'fb791726', 'fb791726')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8879159369527145\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9103690685413005\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9055944055944056\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.775\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8409090909090909\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.38461538461538464\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.3939393939393939\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5333333333333333\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5217391304347826\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5789473684210527\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7142857142857143\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.027777777777777776\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.09722222222222222\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.2549019607843137\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.16129032258064516\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.058823529411764705\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.5629342198371887, Avg accuracy: 0.8458333322778344, Avg diff accuracy: 0.3233332699938718\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.5629342198371887, avg_accuracy=0.8458333322778344, diff_accuracy=0.3233332699938718\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.5629342198371887, 'task_ids': ('f4081712', 'f4081712', 'f4081712', 'f45f5ca7', 'f45f5ca7', 'f45f5ca7', 'f5aa3634', 'f5aa3634', 'f5aa3634', 'f5c89df1', 'f5c89df1', 'f5c89df1', 'f823c43c', 'f823c43c', 'f83cb3f6', 'f83cb3f6', 'f83cb3f6', 'f8be4b64', 'f8be4b64', 'f8be4b64', 'f8be4b64', 'f9a67cb5', 'f9a67cb5', 'f9a67cb5', 'f9d67f8b', 'f9d67f8b', 'f9d67f8b', 'f9d67f8b', 'fafd9572', 'fafd9572', 'fb791726', 'fb791726'), 'test_accuracy': 0.8458333322778344, 'test_diff_accuracy': 0.3233332699938718, 'f4081712_test_accuracy': 0.9355555772781372, 'f4081712_test_diff_accuracy': 0.9055944055944056, 'f45f5ca7_test_accuracy': 0.9911110997200012, 'f45f5ca7_test_diff_accuracy': 0.5, 'f5aa3634_test_accuracy': 0.9911110997200012, 'f5aa3634_test_diff_accuracy': 0.8, 'f5c89df1_test_accuracy': 0.9844444394111633, 'f5c89df1_test_diff_accuracy': 0.5333333333333333, 'f823c43c_test_accuracy': 0.8399999737739563, 'f823c43c_test_diff_accuracy': 0.0, 'f83cb3f6_test_accuracy': 0.9855555295944214, 'f83cb3f6_test_diff_accuracy': 0.7142857142857143, 'f8be4b64_test_accuracy': 0.9688888788223267, 'f8be4b64_test_diff_accuracy': 0.0, 'f9a67cb5_test_accuracy': 0.9433333277702332, 'f9a67cb5_test_diff_accuracy': 0.0, 'f9d67f8b_test_accuracy': 0.1966666728258133, 'f9d67f8b_test_diff_accuracy': 0.16129032258064516, 'fafd9572_test_accuracy': 0.9866666793823242, 'fafd9572_test_diff_accuracy': 0.0, 'fb791726_test_accuracy': 0.9822221994400024, 'fb791726_test_diff_accuracy': 0.058823529411764705}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.5629342198371887, 'task_ids': ('f4081712', 'f4081712', 'f4081712', 'f45f5ca7', 'f45f5ca7', 'f45f5ca7', 'f5aa3634', 'f5aa3634', 'f5aa3634', 'f5c89df1', 'f5c89df1', 'f5c89df1', 'f823c43c', 'f823c43c', 'f83cb3f6', 'f83cb3f6', 'f83cb3f6', 'f8be4b64', 'f8be4b64', 'f8be4b64', 'f8be4b64', 'f9a67cb5', 'f9a67cb5', 'f9a67cb5', 'f9d67f8b', 'f9d67f8b', 'f9d67f8b', 'f9d67f8b', 'fafd9572', 'fafd9572', 'fb791726', 'fb791726'), 'test_accuracy': 0.8458333322778344, 'test_diff_accuracy': 0.3233332699938718, 'f4081712_test_accuracy': 0.9355555772781372, 'f4081712_test_diff_accuracy': 0.9055944055944056, 'f45f5ca7_test_accuracy': 0.9911110997200012, 'f45f5ca7_test_diff_accuracy': 0.5, 'f5aa3634_test_accuracy': 0.9911110997200012, 'f5aa3634_test_diff_accuracy': 0.8, 'f5c89df1_test_accuracy': 0.9844444394111633, 'f5c89df1_test_diff_accuracy': 0.5333333333333333, 'f823c43c_test_accuracy': 0.8399999737739563, 'f823c43c_test_diff_accuracy': 0.0, 'f83cb3f6_test_accuracy': 0.9855555295944214, 'f83cb3f6_test_diff_accuracy': 0.7142857142857143, 'f8be4b64_test_accuracy': 0.9688888788223267, 'f8be4b64_test_diff_accuracy': 0.0, 'f9a67cb5_test_accuracy': 0.9433333277702332, 'f9a67cb5_test_diff_accuracy': 0.0, 'f9d67f8b_test_accuracy': 0.1966666728258133, 'f9d67f8b_test_diff_accuracy': 0.16129032258064516, 'fafd9572_test_accuracy': 0.9866666793823242, 'fafd9572_test_diff_accuracy': 0.0, 'fb791726_test_accuracy': 0.9822221994400024, 'fb791726_test_diff_accuracy': 0.058823529411764705}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('fb791726', 'fc754716', 'fc754716', 'fc754716', 'fc754716', 'fd096ab6', 'fd096ab6', 'fd4b2b02', 'fd4b2b02', 'fd4b2b02', 'fe9372f3', 'fe9372f3', 'fea12743', 'fea12743', 'fea12743', 'ff72ca3e', 'ff72ca3e', 'ff72ca3e', 'ff72ca3e')], batch_idx: 42\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('fb791726', 'fc754716', 'fc754716', 'fc754716', 'fc754716', 'fd096ab6', 'fd096ab6', 'fd4b2b02', 'fd4b2b02', 'fd4b2b02', 'fe9372f3', 'fe9372f3', 'fea12743', 'fea12743', 'fea12743', 'ff72ca3e', 'ff72ca3e', 'ff72ca3e', 'ff72ca3e')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([19, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([19, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([19, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([19, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([19, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([19, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([19, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([19, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([19, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([19, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([19, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([19, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([19, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([19, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([19, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([19, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([19, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.058823529411764705\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.1111111111111111\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.07692307692307693\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.047619047619047616\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.058823529411764705\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.348099023103714, Avg accuracy: 0.8961403464016161, Avg diff accuracy: 0.01859475234088237\n",
            "/usr/local/python/3.12.1/lib/python3.12/site-packages/pytorch_lightning/utilities/data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 19. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.348099023103714, avg_accuracy=0.8961403464016161, diff_accuracy=0.01859475234088237\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.348099023103714, 'task_ids': ('fb791726', 'fc754716', 'fc754716', 'fc754716', 'fc754716', 'fd096ab6', 'fd096ab6', 'fd4b2b02', 'fd4b2b02', 'fd4b2b02', 'fe9372f3', 'fe9372f3', 'fea12743', 'fea12743', 'fea12743', 'ff72ca3e', 'ff72ca3e', 'ff72ca3e', 'ff72ca3e'), 'test_accuracy': 0.8961403464016161, 'test_diff_accuracy': 0.01859475234088237, 'fb791726_test_accuracy': 0.9644444584846497, 'fb791726_test_diff_accuracy': 0.058823529411764705, 'fc754716_test_accuracy': 0.9822221994400024, 'fc754716_test_diff_accuracy': 0.058823529411764705, 'fd096ab6_test_accuracy': 0.36000001430511475, 'fd096ab6_test_diff_accuracy': 0.0, 'fd4b2b02_test_accuracy': 0.8833333253860474, 'fd4b2b02_test_diff_accuracy': 0.0, 'fe9372f3_test_accuracy': 0.9622222185134888, 'fe9372f3_test_diff_accuracy': 0.0, 'fea12743_test_accuracy': 0.9433333277702332, 'fea12743_test_diff_accuracy': 0.0, 'ff72ca3e_test_accuracy': 0.9444444179534912, 'ff72ca3e_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.348099023103714, 'task_ids': ('fb791726', 'fc754716', 'fc754716', 'fc754716', 'fc754716', 'fd096ab6', 'fd096ab6', 'fd4b2b02', 'fd4b2b02', 'fd4b2b02', 'fe9372f3', 'fe9372f3', 'fea12743', 'fea12743', 'fea12743', 'ff72ca3e', 'ff72ca3e', 'ff72ca3e', 'ff72ca3e'), 'test_accuracy': 0.8961403464016161, 'test_diff_accuracy': 0.01859475234088237, 'fb791726_test_accuracy': 0.9644444584846497, 'fb791726_test_diff_accuracy': 0.058823529411764705, 'fc754716_test_accuracy': 0.9822221994400024, 'fc754716_test_diff_accuracy': 0.058823529411764705, 'fd096ab6_test_accuracy': 0.36000001430511475, 'fd096ab6_test_diff_accuracy': 0.0, 'fd4b2b02_test_accuracy': 0.8833333253860474, 'fd4b2b02_test_diff_accuracy': 0.0, 'fe9372f3_test_accuracy': 0.9622222185134888, 'fe9372f3_test_diff_accuracy': 0.0, 'fea12743_test_accuracy': 0.9433333277702332, 'fea12743_test_diff_accuracy': 0.0, 'ff72ca3e_test_accuracy': 0.9444444179534912, 'ff72ca3e_test_diff_accuracy': 0.0}\n",
            "DEBUG:__main__:DEBUG: Raw results from test: [{'00576224_test_accuracy': 0.9599999785423279, '00576224_test_diff_accuracy': 0.0, '009d5c81_test_accuracy': 0.9744443893432617, '009d5c81_test_diff_accuracy': 0.21003207564353943, '00dbd492_test_accuracy': 0.929444432258606, '00dbd492_test_diff_accuracy': 0.0, '03560426_test_accuracy': 0.9796295762062073, '03560426_test_diff_accuracy': 0.5188145637512207, '05a7bcf2_test_accuracy': 0.6566666960716248, '05a7bcf2_test_diff_accuracy': 0.0, '0607ce86_test_accuracy': 0.7966666221618652, '0607ce86_test_diff_accuracy': 0.6599085927009583, '0692e18c_test_accuracy': 0.9785184860229492, '0692e18c_test_diff_accuracy': 0.16984127461910248, '070dd51e_test_accuracy': 0.9611111283302307, '070dd51e_test_diff_accuracy': 0.0, '08573cc6_test_accuracy': 0.962592601776123, '08573cc6_test_diff_accuracy': 0.06767676770687103, '0934a4d8_test_accuracy': 0.37638890743255615, '0934a4d8_test_diff_accuracy': 0.37773966789245605, '09c534e7_test_accuracy': 0.7877777218818665, '09c534e7_test_diff_accuracy': 0.0, '0a1d4ef5_test_accuracy': 0.9511110782623291, '0a1d4ef5_test_diff_accuracy': 0.9168465733528137, '0a2355a6_test_accuracy': 0.9394444823265076, '0a2355a6_test_diff_accuracy': 0.0, '0b17323b_test_accuracy': 0.9938889145851135, '0b17323b_test_diff_accuracy': 0.0, '0bb8deee_test_accuracy': 0.9788889288902283, '0bb8deee_test_diff_accuracy': 0.6813034415245056, '0becf7df_test_accuracy': 0.9744444489479065, '0becf7df_test_diff_accuracy': 0.0, '0c786b71_test_accuracy': 0.9466666579246521, '0c786b71_test_diff_accuracy': 0.0, '0c9aba6e_test_accuracy': 0.9916666746139526, '0c9aba6e_test_diff_accuracy': 0.747855007648468, '0d87d2a6_test_accuracy': 0.9055555462837219, '0d87d2a6_test_diff_accuracy': 0.0, '0e671a1a_test_accuracy': 0.9724999666213989, '0e671a1a_test_diff_accuracy': 0.0, '0f63c0b9_test_accuracy': 0.8908333778381348, '0f63c0b9_test_diff_accuracy': 0.0, '103eff5b_test_accuracy': 0.9416666626930237, '103eff5b_test_diff_accuracy': 0.0, '11e1fe23_test_accuracy': 0.992222249507904, '11e1fe23_test_diff_accuracy': 0.0, '12422b43_test_accuracy': 0.9788888692855835, '12422b43_test_diff_accuracy': 0.0, '12997ef3_test_accuracy': 0.9844444394111633, '12997ef3_test_diff_accuracy': 0.3445091247558594, '12eac192_test_accuracy': 0.9725000262260437, '12eac192_test_diff_accuracy': 0.0, '136b0064_test_accuracy': 0.9822222590446472, '136b0064_test_diff_accuracy': 0.711358368396759, '13713586_test_accuracy': 0.859259307384491, '13713586_test_diff_accuracy': 0.0, '137f0df0_test_accuracy': 0.9185185432434082, '137f0df0_test_diff_accuracy': 0.0, '140c817e_test_accuracy': 0.8625926375389099, '140c817e_test_diff_accuracy': 0.0, '14754a24_test_accuracy': 0.8630555272102356, '14754a24_test_diff_accuracy': 0.0, '15113be4_test_accuracy': 0.6255555748939514, '15113be4_test_diff_accuracy': 0.0, '15663ba9_test_accuracy': 0.9422222971916199, '15663ba9_test_diff_accuracy': 0.0, '15696249_test_accuracy': 0.9700000286102295, '15696249_test_diff_accuracy': 0.1875, '16b78196_test_accuracy': 0.7916666865348816, '16b78196_test_diff_accuracy': 0.4842342138290405, '17b80ad2_test_accuracy': 0.9611111283302307, '17b80ad2_test_diff_accuracy': 0.0, '17cae0c1_test_accuracy': 0.9700000286102295, '17cae0c1_test_diff_accuracy': 0.0, '18419cfa_test_accuracy': 0.9344444274902344, '18419cfa_test_diff_accuracy': 0.0, '184a9768_test_accuracy': 0.8522222638130188, '184a9768_test_diff_accuracy': 0.575104296207428, '195ba7dc_test_accuracy': 0.9758332967758179, '195ba7dc_test_diff_accuracy': 0.5054347515106201, '1990f7a8_test_accuracy': 0.9740740656852722, '1990f7a8_test_diff_accuracy': 0.5, '19bb5feb_test_accuracy': 0.9729630351066589, '19bb5feb_test_diff_accuracy': 0.7311635613441467, '1a2e2828_test_accuracy': 0.9986666440963745, '1a2e2828_test_diff_accuracy': 0.9834964871406555, '1a6449f1_test_accuracy': 0.9829629063606262, '1a6449f1_test_diff_accuracy': 0.9130600094795227, '1acc24af_test_accuracy': 0.964722216129303, '1acc24af_test_diff_accuracy': 0.0, '1c02dbbe_test_accuracy': 0.860370397567749, '1c02dbbe_test_diff_accuracy': 0.06207104027271271, '1c0d0a4b_test_accuracy': 0.9825925827026367, '1c0d0a4b_test_diff_accuracy': 0.595678985118866, '1c56ad9f_test_accuracy': 0.9541666507720947, '1c56ad9f_test_diff_accuracy': 0.5, '1d0a4b61_test_accuracy': 0.3055555522441864, '1d0a4b61_test_diff_accuracy': 0.0, '1d398264_test_accuracy': 0.9462962746620178, '1d398264_test_diff_accuracy': 0.0, '1da012fc_test_accuracy': 0.9105556011199951, '1da012fc_test_diff_accuracy': 0.0, '1e81d6f9_test_accuracy': 0.9681481719017029, '1e81d6f9_test_diff_accuracy': 1.0, '1e97544e_test_accuracy': 0.41296300292015076, '1e97544e_test_diff_accuracy': 0.0, '2037f2c7_test_accuracy': 0.9900000095367432, '2037f2c7_test_diff_accuracy': 0.9334214329719543, '2072aba6_test_accuracy': 0.9807407259941101, '2072aba6_test_diff_accuracy': 0.01587301678955555, '20818e16_test_accuracy': 0.9385185241699219, '20818e16_test_diff_accuracy': 0.723113477230072, '20981f0e_test_accuracy': 0.9681481719017029, '20981f0e_test_diff_accuracy': 0.5, '212895b5_test_accuracy': 0.9196296334266663, '212895b5_test_diff_accuracy': 0.0, '21f83797_test_accuracy': 0.9238889217376709, '21f83797_test_diff_accuracy': 0.0, '22a4bbc2_test_accuracy': 0.9433333277702332, '22a4bbc2_test_diff_accuracy': 0.0, '25094a63_test_accuracy': 0.1827777773141861, '25094a63_test_diff_accuracy': 0.0, '2546ccf6_test_accuracy': 0.8550000190734863, '2546ccf6_test_diff_accuracy': 0.0, '256b0a75_test_accuracy': 0.6666666865348816, '256b0a75_test_diff_accuracy': 0.0, '2685904e_test_accuracy': 0.965925931930542, '2685904e_test_diff_accuracy': 0.0, '2697da3f_test_accuracy': 0.9511110782623291, '2697da3f_test_diff_accuracy': 0.16602009534835815, '2753e76c_test_accuracy': 0.9900000095367432, '2753e76c_test_diff_accuracy': 0.899422824382782, '27a77e38_test_accuracy': 0.9807407259941101, '27a77e38_test_diff_accuracy': 0.0, '27f8ce4f_test_accuracy': 0.9650000333786011, '27f8ce4f_test_diff_accuracy': 0.11249999701976776, '281123b4_test_accuracy': 0.9829630255699158, '281123b4_test_diff_accuracy': 0.7146536707878113, '292dd178_test_accuracy': 0.9081481099128723, '292dd178_test_diff_accuracy': 0.0, '29700607_test_accuracy': 0.9618518948554993, '29700607_test_diff_accuracy': 0.0, '2a5f8217_test_accuracy': 0.9774073958396912, '2a5f8217_test_diff_accuracy': 0.0, '2b01abd0_test_accuracy': 0.970740795135498, '2b01abd0_test_diff_accuracy': 0.0, '2c0b0aff_test_accuracy': 0.9119444489479065, '2c0b0aff_test_diff_accuracy': 0.7577368021011353, '2c737e39_test_accuracy': 0.9840741157531738, '2c737e39_test_diff_accuracy': 0.13650794327259064, '2f0c5170_test_accuracy': 0.9674074053764343, '2f0c5170_test_diff_accuracy': 0.9186174869537354, '310f3251_test_accuracy': 0.9700000882148743, '310f3251_test_diff_accuracy': 0.0, '3194b014_test_accuracy': 0.9770370125770569, '3194b014_test_diff_accuracy': 0.9225044250488281, '319f2597_test_accuracy': 0.6277777552604675, '319f2597_test_diff_accuracy': 0.9736223220825195, '31adaf00_test_accuracy': 0.9307407736778259, '31adaf00_test_diff_accuracy': 0.0, '31d5ba1a_test_accuracy': 0.9928889274597168, '31d5ba1a_test_diff_accuracy': 0.6540936231613159, '32e9702f_test_accuracy': 0.9548148512840271, '32e9702f_test_diff_accuracy': 0.0, '332efdb3_test_accuracy': 0.9533333778381348, '332efdb3_test_diff_accuracy': 0.0, '3391f8c0_test_accuracy': 0.9824999570846558, '3391f8c0_test_diff_accuracy': 0.3541666865348816, '33b52de3_test_accuracy': 0.8538888692855835, '33b52de3_test_diff_accuracy': 0.0, '3490cc26_test_accuracy': 0.9061111211776733, '3490cc26_test_diff_accuracy': 0.0, '34b99a2b_test_accuracy': 0.9883333444595337, '34b99a2b_test_diff_accuracy': 0.629668653011322, '351d6448_test_accuracy': 0.9927777647972107, '351d6448_test_diff_accuracy': 0.8858424425125122, '358ba94e_test_accuracy': 0.9744444489479065, '358ba94e_test_diff_accuracy': 0.8644062280654907, '37d3e8b2_test_accuracy': 0.8788889050483704, '37d3e8b2_test_diff_accuracy': 0.0, '3979b1a8_test_accuracy': 0.8888888955116272, '3979b1a8_test_diff_accuracy': 0.0, '3a301edc_test_accuracy': 0.9024444818496704, '3a301edc_test_diff_accuracy': 0.0, '3b4c2228_test_accuracy': 0.9979999661445618, '3b4c2228_test_diff_accuracy': 0.8947456479072571, '3d31c5b3_test_accuracy': 0.9794444441795349, '3d31c5b3_test_diff_accuracy': 0.6079409122467041, '3ed85e70_test_accuracy': 0.6381481885910034, '3ed85e70_test_diff_accuracy': 0.0, '3ee1011a_test_accuracy': 0.9537037014961243, '3ee1011a_test_diff_accuracy': 0.20636117458343506, '3f23242b_test_accuracy': 0.9550000429153442, '3f23242b_test_diff_accuracy': 0.0, '40f6cd08_test_accuracy': 0.6270370483398438, '40f6cd08_test_diff_accuracy': 0.0, '414297c0_test_accuracy': 0.8959259390830994, '414297c0_test_diff_accuracy': 0.4695725440979004, '423a55dc_test_accuracy': 0.9855555295944214, '423a55dc_test_diff_accuracy': 0.5216470956802368, '42918530_test_accuracy': 0.815833330154419, '42918530_test_diff_accuracy': 0.0, '42a15761_test_accuracy': 0.9062963128089905, '42a15761_test_diff_accuracy': 0.5, '4364c1c4_test_accuracy': 0.8177778124809265, '4364c1c4_test_diff_accuracy': 0.0, '456873bc_test_accuracy': 0.9514815211296082, '456873bc_test_diff_accuracy': 0.7703775763511658, '45737921_test_accuracy': 0.9733333587646484, '45737921_test_diff_accuracy': 0.0, '45bbe264_test_accuracy': 0.932962954044342, '45bbe264_test_diff_accuracy': 0.0, '477d2879_test_accuracy': 0.8122222423553467, '477d2879_test_diff_accuracy': 0.0, '47996f11_test_accuracy': 0.13833333551883698, '47996f11_test_diff_accuracy': 0.10620684921741486, '48131b3c_test_accuracy': 0.9733333587646484, '48131b3c_test_diff_accuracy': 0.11290545016527176, '4852f2fa_test_accuracy': 0.9853333234786987, '4852f2fa_test_diff_accuracy': 0.36084944009780884, '48f8583b_test_accuracy': 0.9798148274421692, '48f8583b_test_diff_accuracy': 0.29629629850387573, '4aab4007_test_accuracy': 0.12888889014720917, '4aab4007_test_diff_accuracy': 0.0, '4acc7107_test_accuracy': 0.9758333563804626, '4acc7107_test_diff_accuracy': 0.4823917746543884, '4b6b68e5_test_accuracy': 0.8622221946716309, '4b6b68e5_test_diff_accuracy': 0.03787878900766373, '4c177718_test_accuracy': 0.9872222542762756, '4c177718_test_diff_accuracy': 0.7471552491188049, '4cd1b7b2_test_accuracy': 0.9822222590446472, '4cd1b7b2_test_diff_accuracy': 0.0, '4e45f183_test_accuracy': 0.7507407665252686, '4e45f183_test_diff_accuracy': 0.013888888992369175, '4e469f39_test_accuracy': 0.9662962555885315, '4e469f39_test_diff_accuracy': 0.0, '4f537728_test_accuracy': 0.7972222566604614, '4f537728_test_diff_accuracy': 0.0, '4ff4c9da_test_accuracy': 0.6259259581565857, '4ff4c9da_test_diff_accuracy': 0.0, '505fff84_test_accuracy': 0.9913333654403687, '505fff84_test_diff_accuracy': 0.8910254240036011, '506d28a5_test_accuracy': 0.9822221994400024, '506d28a5_test_diff_accuracy': 0.47752460837364197, '50a16a69_test_accuracy': 0.8159258961677551, '50a16a69_test_diff_accuracy': 0.03999999910593033, '50aad11f_test_accuracy': 0.9785184860229492, '50aad11f_test_diff_accuracy': 0.4671497642993927, '50f325b5_test_accuracy': 0.801944375038147, '50f325b5_test_diff_accuracy': 0.0, '516b51b7_test_accuracy': 0.9188888669013977, '516b51b7_test_diff_accuracy': 0.0, '5207a7b5_test_accuracy': 0.9559259414672852, '5207a7b5_test_diff_accuracy': 0.0, '5289ad53_test_accuracy': 0.9755555391311646, '5289ad53_test_diff_accuracy': 0.8811259269714355, '52fd389e_test_accuracy': 0.7137036323547363, '52fd389e_test_diff_accuracy': 0.0, '54db823b_test_accuracy': 0.9066666960716248, '54db823b_test_diff_accuracy': 1.0, '55059096_test_accuracy': 0.9744443893432617, '55059096_test_diff_accuracy': 0.0, '551d5bf1_test_accuracy': 0.7644444704055786, '551d5bf1_test_diff_accuracy': 0.0, '55783887_test_accuracy': 0.8462222218513489, '55783887_test_diff_accuracy': 0.10000000149011612, '575b1a71_test_accuracy': 0.8888888955116272, '575b1a71_test_diff_accuracy': 0.0, '5783df64_test_accuracy': 0.9900000095367432, '5783df64_test_diff_accuracy': 0.45825162529945374, '5833af48_test_accuracy': 0.8825926184654236, '5833af48_test_diff_accuracy': 0.6010026335716248, '58743b76_test_accuracy': 0.9472222328186035, '58743b76_test_diff_accuracy': 0.0, '58e15b12_test_accuracy': 0.9170370697975159, '58e15b12_test_diff_accuracy': 0.0, '59341089_test_accuracy': 0.960277795791626, '59341089_test_diff_accuracy': 0.0, '5a5a2103_test_accuracy': 0.8194444179534912, '5a5a2103_test_diff_accuracy': 0.04545454680919647, '5af49b42_test_accuracy': 0.9737036824226379, '5af49b42_test_diff_accuracy': 0.0, '5b526a93_test_accuracy': 0.90666663646698, '5b526a93_test_diff_accuracy': 0.0, '5b692c0f_test_accuracy': 0.9133332967758179, '5b692c0f_test_diff_accuracy': 0.23863637447357178, '5b6cbef5_test_accuracy': 0.9197778701782227, '5b6cbef5_test_diff_accuracy': 0.09092767536640167, '5d2a5c43_test_accuracy': 0.9784444570541382, '5d2a5c43_test_diff_accuracy': 0.47774338722229004, '5ffb2104_test_accuracy': 0.987407386302948, '5ffb2104_test_diff_accuracy': 0.4901960790157318, '604001fa_test_accuracy': 0.9819444417953491, '604001fa_test_diff_accuracy': 0.2735389471054077, '60a26a3e_test_accuracy': 0.9718518257141113, '60a26a3e_test_diff_accuracy': 0.0, '60c09cac_test_accuracy': 0.9822221994400024, '60c09cac_test_diff_accuracy': 0.02777777798473835, '626c0bcc_test_accuracy': 0.9825925827026367, '626c0bcc_test_diff_accuracy': 0.0, '62ab2642_test_accuracy': 0.93666672706604, '62ab2642_test_diff_accuracy': 0.0, '62b74c02_test_accuracy': 0.9559259414672852, '62b74c02_test_diff_accuracy': 0.0, '639f5a19_test_accuracy': 0.7777777910232544, '639f5a19_test_diff_accuracy': 0.0, '642248e4_test_accuracy': 0.9570370316505432, '642248e4_test_diff_accuracy': 0.0, '642d658d_test_accuracy': 0.9611111283302307, '642d658d_test_diff_accuracy': 0.9283973574638367, '64a7c07e_test_accuracy': 0.9892592430114746, '64a7c07e_test_diff_accuracy': 0.5, '66e6c45b_test_accuracy': 0.995555579662323, '66e6c45b_test_diff_accuracy': 0.5, '66f2d22f_test_accuracy': 0.991944432258606, '66f2d22f_test_diff_accuracy': 0.7562196850776672, '67636eac_test_accuracy': 0.9862963557243347, '67636eac_test_diff_accuracy': 0.46666666865348816, '67b4a34d_test_accuracy': 0.9696295857429504, '67b4a34d_test_diff_accuracy': 0.9138374328613281, '67c52801_test_accuracy': 0.9786111116409302, '67c52801_test_diff_accuracy': 0.5, '68b67ca3_test_accuracy': 0.9944444298744202, '68b67ca3_test_diff_accuracy': 0.5, '692cd3b6_test_accuracy': 0.9007408022880554, '692cd3b6_test_diff_accuracy': 0.0, '695367ec_test_accuracy': 0.8937036991119385, '695367ec_test_diff_accuracy': 0.05552127584815025, '696d4842_test_accuracy': 0.962592601776123, '696d4842_test_diff_accuracy': 0.0, '69889d6e_test_accuracy': 0.980555534362793, '69889d6e_test_diff_accuracy': 0.0, '6a11f6da_test_accuracy': 0.975777804851532, '6a11f6da_test_diff_accuracy': 0.5782161355018616, '6ad5bdfd_test_accuracy': 0.9814814925193787, '6ad5bdfd_test_diff_accuracy': 0.45766592025756836, '6df30ad6_test_accuracy': 0.991777777671814, '6df30ad6_test_diff_accuracy': 0.5457017421722412, '6ea4a07e_test_accuracy': 0.9937036633491516, '6ea4a07e_test_diff_accuracy': 0.37037038803100586, '6f473927_test_accuracy': 0.9677777886390686, '6f473927_test_diff_accuracy': 0.21378621459007263, '7039b2d7_test_accuracy': 0.9840741157531738, '7039b2d7_test_diff_accuracy': 0.9842607378959656, '705a3229_test_accuracy': 0.9844444394111633, '705a3229_test_diff_accuracy': 0.0, '712bf12e_test_accuracy': 0.9170370101928711, '712bf12e_test_diff_accuracy': 0.0, '72207abc_test_accuracy': 0.9925925731658936, '72207abc_test_diff_accuracy': 0.0, '72a961c9_test_accuracy': 0.9844444990158081, '72a961c9_test_diff_accuracy': 0.0, '73182012_test_accuracy': 0.9881481528282166, '73182012_test_diff_accuracy': 0.8835263848304749, '73c3b0d8_test_accuracy': 0.9869444370269775, '73c3b0d8_test_diff_accuracy': 0.2957516312599182, '73ccf9c2_test_accuracy': 0.9881481528282166, '73ccf9c2_test_diff_accuracy': 0.8363578915596008, '759f3fd3_test_accuracy': 0.8427777886390686, '759f3fd3_test_diff_accuracy': 0.0, '762cd429_test_accuracy': 0.8118519186973572, '762cd429_test_diff_accuracy': 0.0, '770cc55f_test_accuracy': 0.9769444465637207, '770cc55f_test_diff_accuracy': 0.0, '782b5218_test_accuracy': 0.9344444274902344, '782b5218_test_diff_accuracy': 0.4673832952976227, '79369cc6_test_accuracy': 0.8040741086006165, '79369cc6_test_diff_accuracy': 0.0, '7953d61e_test_accuracy': 0.9288889169692993, '7953d61e_test_diff_accuracy': 0.0, '79fb03f4_test_accuracy': 0.93833327293396, '79fb03f4_test_diff_accuracy': 0.0, '7bb29440_test_accuracy': 0.9735555648803711, '7bb29440_test_diff_accuracy': 0.8471860885620117, '7c8af763_test_accuracy': 0.8888888955116272, '7c8af763_test_diff_accuracy': 0.0, '7c9b52a0_test_accuracy': 0.9074074625968933, '7c9b52a0_test_diff_accuracy': 0.6268526911735535, '7d18a6fb_test_accuracy': 0.9770370125770569, '7d18a6fb_test_diff_accuracy': 0.7752125263214111, '7d1f7ee8_test_accuracy': 0.8325925469398499, '7d1f7ee8_test_diff_accuracy': 0.0, '7d419a02_test_accuracy': 0.851111114025116, '7d419a02_test_diff_accuracy': 0.0, '7e02026e_test_accuracy': 0.9000000357627869, '7e02026e_test_diff_accuracy': 0.0, '7ee1c6ea_test_accuracy': 0.9133333563804626, '7ee1c6ea_test_diff_accuracy': 0.0, '817e6c09_test_accuracy': 0.9760000109672546, '817e6c09_test_diff_accuracy': 0.0, '81c0276b_test_accuracy': 0.9933333396911621, '81c0276b_test_diff_accuracy': 0.9544203281402588, '833dafe3_test_accuracy': 0.9644444584846497, '833dafe3_test_diff_accuracy': 0.07334525883197784, '845d6e51_test_accuracy': 0.9477777481079102, '845d6e51_test_diff_accuracy': 0.0, '84db8fc4_test_accuracy': 0.8888888955116272, '84db8fc4_test_diff_accuracy': 0.0, '84f2aca1_test_accuracy': 0.9650000333786011, '84f2aca1_test_diff_accuracy': 0.0, '8597cfd7_test_accuracy': 0.995555579662323, '8597cfd7_test_diff_accuracy': 0.8174242377281189, '85b81ff1_test_accuracy': 0.875, '85b81ff1_test_diff_accuracy': 0.5, '85fa5666_test_accuracy': 0.9622222185134888, '85fa5666_test_diff_accuracy': 0.0, '8719f442_test_accuracy': 0.9422221779823303, '8719f442_test_diff_accuracy': 0.0, '88207623_test_accuracy': 0.9388889074325562, '88207623_test_diff_accuracy': 0.0, '891232d6_test_accuracy': 0.8897222280502319, '891232d6_test_diff_accuracy': 0.0, '896d5239_test_accuracy': 0.8825926184654236, '896d5239_test_diff_accuracy': 0.0, '8a371977_test_accuracy': 0.43888890743255615, '8a371977_test_diff_accuracy': 0.0, '8b28cd80_test_accuracy': 0.948888897895813, '8b28cd80_test_diff_accuracy': 0.017298799008131027, '8ba14f53_test_accuracy': 0.9938888549804688, '8ba14f53_test_diff_accuracy': 0.8179367184638977, '8cb8642d_test_accuracy': 0.9296296238899231, '8cb8642d_test_diff_accuracy': 0.7093300819396973, '8dae5dfc_test_accuracy': 0.8263888359069824, '8dae5dfc_test_diff_accuracy': 0.0, '8e2edd66_test_accuracy': 0.9814814925193787, '8e2edd66_test_diff_accuracy': 0.2586754262447357, '8ee62060_test_accuracy': 0.9788889288902283, '8ee62060_test_diff_accuracy': 0.5, '8fbca751_test_accuracy': 0.9659258723258972, '8fbca751_test_diff_accuracy': 0.0, '90347967_test_accuracy': 0.9933333396911621, '90347967_test_diff_accuracy': 0.5, '903d1b4a_test_accuracy': 0.7155555486679077, '903d1b4a_test_diff_accuracy': 0.0, '9110e3c5_test_accuracy': 0.9960317611694336, '9110e3c5_test_diff_accuracy': 0.8651400804519653, '917bccba_test_accuracy': 0.9644444584846497, '917bccba_test_diff_accuracy': 0.6146110892295837, '929ab4e9_test_accuracy': 0.3613888919353485, '929ab4e9_test_diff_accuracy': 0.0, '92e50de0_test_accuracy': 0.6677777767181396, '92e50de0_test_diff_accuracy': 0.0, '9356391f_test_accuracy': 0.90666663646698, '9356391f_test_diff_accuracy': 0.0, '93b4f4b3_test_accuracy': 0.9233333468437195, '93b4f4b3_test_diff_accuracy': 0.40796583890914917, '93c31fbe_test_accuracy': 0.9399999976158142, '93c31fbe_test_diff_accuracy': 0.3983488082885742, '94133066_test_accuracy': 0.8922222256660461, '94133066_test_diff_accuracy': 0.48462045192718506, '94414823_test_accuracy': 0.9577777981758118, '94414823_test_diff_accuracy': 0.0, '94be5b80_test_accuracy': 0.9411110877990723, '94be5b80_test_diff_accuracy': 0.2946428656578064, '95a58926_test_accuracy': 0.8614814877510071, '95a58926_test_diff_accuracy': 0.5745627284049988, '963f59bc_test_accuracy': 0.9786111116409302, '963f59bc_test_diff_accuracy': 0.0, '96a8c0cd_test_accuracy': 0.9350000023841858, '96a8c0cd_test_diff_accuracy': 0.0, '97239e3d_test_accuracy': 0.7988889217376709, '97239e3d_test_diff_accuracy': 0.0, '9772c176_test_accuracy': 0.7477777600288391, '9772c176_test_diff_accuracy': 0.0, '981571dc_test_accuracy': 0.00027777778450399637, '981571dc_test_diff_accuracy': 0.0, '992798f6_test_accuracy': 0.9863889217376709, '992798f6_test_diff_accuracy': 0.0, '99306f82_test_accuracy': 0.9162963032722473, '99306f82_test_diff_accuracy': 0.0, '9a4bb226_test_accuracy': 0.9888889193534851, '9a4bb226_test_diff_accuracy': 0.7706348896026611, '9b2a60aa_test_accuracy': 0.965925931930542, '9b2a60aa_test_diff_accuracy': 0.0, '9b365c51_test_accuracy': 0.9670370221138, '9b365c51_test_diff_accuracy': 0.444180965423584, '9b4c17c4_test_accuracy': 0.8147222995758057, '9b4c17c4_test_diff_accuracy': 0.0, '9bebae7a_test_accuracy': 0.9786666631698608, '9bebae7a_test_diff_accuracy': 0.33641454577445984, '9c1e755f_test_accuracy': 0.9461110830307007, '9c1e755f_test_diff_accuracy': 0.0, '9c56f360_test_accuracy': 0.9737036824226379, '9c56f360_test_diff_accuracy': 0.5, '9caba7c3_test_accuracy': 0.7659258842468262, '9caba7c3_test_diff_accuracy': 0.0, '9ddd00f0_test_accuracy': 0.9533333778381348, '9ddd00f0_test_diff_accuracy': 0.0, '9def23fe_test_accuracy': 0.8311111330986023, '9def23fe_test_diff_accuracy': 0.0, '9f27f097_test_accuracy': 0.8399999737739563, '9f27f097_test_diff_accuracy': 0.0, 'a04b2602_test_accuracy': 0.8177778124809265, 'a04b2602_test_diff_accuracy': 0.0, 'a096bf4d_test_accuracy': 0.7333333492279053, 'a096bf4d_test_diff_accuracy': 0.0, 'a3f84088_test_accuracy': 0.8686110973358154, 'a3f84088_test_diff_accuracy': 0.0, 'a406ac07_test_accuracy': 0.958148181438446, 'a406ac07_test_diff_accuracy': 0.0, 'a57f2f04_test_accuracy': 0.6633333563804626, 'a57f2f04_test_diff_accuracy': 0.0, 'a59b95c0_test_accuracy': 0.9160000085830688, 'a59b95c0_test_diff_accuracy': 0.0, 'a680ac02_test_accuracy': 0.9644444584846497, 'a680ac02_test_diff_accuracy': 0.6501501202583313, 'a8610ef7_test_accuracy': 0.9766666889190674, 'a8610ef7_test_diff_accuracy': 0.0, 'a934301b_test_accuracy': 0.9674074053764343, 'a934301b_test_diff_accuracy': 1.0, 'aa18de87_test_accuracy': 0.9791666269302368, 'aa18de87_test_diff_accuracy': 0.0, 'aa300dc3_test_accuracy': 0.930555522441864, 'aa300dc3_test_diff_accuracy': 0.0, 'aa4ec2a5_test_accuracy': 0.43740740418434143, 'aa4ec2a5_test_diff_accuracy': 0.0, 'aab50785_test_accuracy': 0.9871110916137695, 'aab50785_test_diff_accuracy': 0.9002954363822937, 'ac0c5833_test_accuracy': 0.9518518447875977, 'ac0c5833_test_diff_accuracy': 0.0, 'ac2e8ecf_test_accuracy': 0.9529629349708557, 'ac2e8ecf_test_diff_accuracy': 0.4784134328365326, 'ac3e2b04_test_accuracy': 0.9386110901832581, 'ac3e2b04_test_diff_accuracy': 0.0, 'ac605cbb_test_accuracy': 0.9875926375389099, 'ac605cbb_test_diff_accuracy': 0.0, 'ad7e01d0_test_accuracy': 0.9144444465637207, 'ad7e01d0_test_diff_accuracy': 0.08509097993373871, 'ae58858e_test_accuracy': 0.9783333539962769, 'ae58858e_test_diff_accuracy': 0.0, 'aee291af_test_accuracy': 0.9762962460517883, 'aee291af_test_diff_accuracy': 0.9403367638587952, 'af22c60d_test_accuracy': 0.0, 'af22c60d_test_diff_accuracy': 0.0, 'af24b4cc_test_accuracy': 0.9929630160331726, 'af24b4cc_test_diff_accuracy': 0.8559829592704773, 'b0722778_test_accuracy': 0.9844444394111633, 'b0722778_test_diff_accuracy': 0.7229965329170227, 'b0f4d537_test_accuracy': 0.9722222089767456, 'b0f4d537_test_diff_accuracy': 0.6134893894195557, 'b15fca0b_test_accuracy': 0.9675555229187012, 'b15fca0b_test_diff_accuracy': 0.0, 'b1fc8b8e_test_accuracy': 0.9851110577583313, 'b1fc8b8e_test_diff_accuracy': 0.48750001192092896, 'b20f7c8b_test_accuracy': 0.7707407474517822, 'b20f7c8b_test_diff_accuracy': 0.0, 'b457fec5_test_accuracy': 0.9137037396430969, 'b457fec5_test_diff_accuracy': 0.0, 'b4a43f3b_test_accuracy': 0.9633333086967468, 'b4a43f3b_test_diff_accuracy': 0.46900829672813416, 'b7999b51_test_accuracy': 0.9900000095367432, 'b7999b51_test_diff_accuracy': 0.8587267994880676, 'b7cb93ac_test_accuracy': 0.9866666793823242, 'b7cb93ac_test_diff_accuracy': 0.4814814627170563, 'b7f8a4d8_test_accuracy': 0.6399999856948853, 'b7f8a4d8_test_diff_accuracy': 0.0, 'b7fb29bc_test_accuracy': 0.9100000262260437, 'b7fb29bc_test_diff_accuracy': 0.0, 'b942fd60_test_accuracy': 0.9666666984558105, 'b942fd60_test_diff_accuracy': 0.0, 'b9630600_test_accuracy': 0.8437037467956543, 'b9630600_test_diff_accuracy': 0.3881119191646576, 'ba9d41b8_test_accuracy': 0.9162963032722473, 'ba9d41b8_test_diff_accuracy': 1.0, 'baf41dbf_test_accuracy': 0.9592592716217041, 'baf41dbf_test_diff_accuracy': 0.20501208305358887, 'bb52a14b_test_accuracy': 0.9188888669013977, 'bb52a14b_test_diff_accuracy': 0.0, 'bbb1b8b6_test_accuracy': 0.9852380156517029, 'bbb1b8b6_test_diff_accuracy': 0.5396488308906555, 'bc4146bd_test_accuracy': 0.9111111164093018, 'bc4146bd_test_diff_accuracy': 0.0, 'bcb3040b_test_accuracy': 0.9196296334266663, 'bcb3040b_test_diff_accuracy': 0.0, 'bd14c3bf_test_accuracy': 0.9211111068725586, 'bd14c3bf_test_diff_accuracy': 0.0, 'be03b35f_test_accuracy': 0.9970369935035706, 'be03b35f_test_diff_accuracy': 0.8111111521720886, 'bf32578f_test_accuracy': 0.9881481528282166, 'bf32578f_test_diff_accuracy': 0.3821733891963959, 'bf699163_test_accuracy': 0.9900000095367432, 'bf699163_test_diff_accuracy': 0.9721251130104065, 'bf89d739_test_accuracy': 0.9780555367469788, 'bf89d739_test_diff_accuracy': 0.0, 'c074846d_test_accuracy': 0.9948889017105103, 'c074846d_test_diff_accuracy': 0.0, 'c1990cce_test_accuracy': 0.9785184860229492, 'c1990cce_test_diff_accuracy': 0.07402319461107254, 'c3202e5a_test_accuracy': 0.9929630160331726, 'c3202e5a_test_diff_accuracy': 0.9741120338439941, 'c35c1b4c_test_accuracy': 0.9144444465637207, 'c35c1b4c_test_diff_accuracy': 0.0, 'c48954c1_test_accuracy': 0.9100000262260437, 'c48954c1_test_diff_accuracy': 0.0, 'c62e2108_test_accuracy': 0.8962963223457336, 'c62e2108_test_diff_accuracy': 0.04329491779208183, 'c64f1187_test_accuracy': 0.9688888788223267, 'c64f1187_test_diff_accuracy': 0.6881044507026672, 'c658a4bd_test_accuracy': 0.9194444417953491, 'c658a4bd_test_diff_accuracy': 0.37494730949401855, 'c663677b_test_accuracy': 0.1899999976158142, 'c663677b_test_diff_accuracy': 0.0, 'c6e1b8da_test_accuracy': 0.8537037372589111, 'c6e1b8da_test_diff_accuracy': 0.45049849152565, 'c7d4e6ad_test_accuracy': 0.9777777791023254, 'c7d4e6ad_test_diff_accuracy': 0.0, 'c87289bb_test_accuracy': 0.9436111450195312, 'c87289bb_test_diff_accuracy': 0.0, 'c8b7cc0f_test_accuracy': 0.995555579662323, 'c8b7cc0f_test_diff_accuracy': 0.8881499767303467, 'c92b942c_test_accuracy': 0.9175000190734863, 'c92b942c_test_diff_accuracy': 0.0, 'c97c0139_test_accuracy': 0.9155555963516235, 'c97c0139_test_diff_accuracy': 0.0, 'ca8de6ea_test_accuracy': 0.9900000095367432, 'ca8de6ea_test_diff_accuracy': 0.3333333432674408, 'ca8f78db_test_accuracy': 0.0, 'ca8f78db_test_diff_accuracy': 0.0, 'cad67732_test_accuracy': 0.9740740656852722, 'cad67732_test_diff_accuracy': 0.0, 'cb227835_test_accuracy': 0.9792592525482178, 'cb227835_test_diff_accuracy': 0.0, 'ccd554ac_test_accuracy': 0.9307406544685364, 'ccd554ac_test_diff_accuracy': 0.02556818164885044, 'cd3c21df_test_accuracy': 0.9948148727416992, 'cd3c21df_test_diff_accuracy': 0.8213383555412292, 'ce039d91_test_accuracy': 0.9774999618530273, 'ce039d91_test_diff_accuracy': 0.0, 'ce8d95cc_test_accuracy': 0.9802777767181396, 'ce8d95cc_test_diff_accuracy': 0.7194792032241821, 'cf133acc_test_accuracy': 0.9370369911193848, 'cf133acc_test_diff_accuracy': 0.0, 'cfb2ce5a_test_accuracy': 0.9325925707817078, 'cfb2ce5a_test_diff_accuracy': 0.0, 'd017b73f_test_accuracy': 0.9883332848548889, 'd017b73f_test_diff_accuracy': 0.5, 'd19f7514_test_accuracy': 0.9808333516120911, 'd19f7514_test_diff_accuracy': 0.4937748610973358, 'd282b262_test_accuracy': 0.9677777290344238, 'd282b262_test_diff_accuracy': 0.4773857891559601, 'd2acf2cb_test_accuracy': 0.9551851749420166, 'd2acf2cb_test_diff_accuracy': 0.095238097012043, 'd304284e_test_accuracy': 0.8761111497879028, 'd304284e_test_diff_accuracy': 0.0, 'd37a1ef5_test_accuracy': 0.9344444274902344, 'd37a1ef5_test_diff_accuracy': 0.0, 'd47aa2ff_test_accuracy': 0.9896295666694641, 'd47aa2ff_test_diff_accuracy': 0.7235023379325867, 'd492a647_test_accuracy': 0.8811111450195312, 'd492a647_test_diff_accuracy': 0.0, 'd4b1c2b1_test_accuracy': 0.9442857503890991, 'd4b1c2b1_test_diff_accuracy': 0.2857142984867096, 'd4c90558_test_accuracy': 0.9829629063606262, 'd4c90558_test_diff_accuracy': 0.9063237309455872, 'd56f2372_test_accuracy': 0.9866666793823242, 'd56f2372_test_diff_accuracy': 0.8060207962989807, 'd5c634a2_test_accuracy': 0.9953967928886414, 'd5c634a2_test_diff_accuracy': 0.7885443568229675, 'd931c21c_test_accuracy': 0.9108333587646484, 'd931c21c_test_diff_accuracy': 0.25, 'd94c3b52_test_accuracy': 0.8414815068244934, 'd94c3b52_test_diff_accuracy': 0.0, 'da2b0fe3_test_accuracy': 0.9707407355308533, 'da2b0fe3_test_diff_accuracy': 0.0, 'da515329_test_accuracy': 0.8374074101448059, 'da515329_test_diff_accuracy': 0.0, 'dc2aa30b_test_accuracy': 0.9100000262260437, 'dc2aa30b_test_diff_accuracy': 0.0, 'dc2e9a9d_test_accuracy': 0.9233333468437195, 'dc2e9a9d_test_diff_accuracy': 0.0, 'dd2401ed_test_accuracy': 0.9811111092567444, 'dd2401ed_test_diff_accuracy': 0.43627452850341797, 'de493100_test_accuracy': 0.25111111998558044, 'de493100_test_diff_accuracy': 0.2521111071109772, 'df8cc377_test_accuracy': 0.9492592811584473, 'df8cc377_test_diff_accuracy': 0.5, 'e0fb7511_test_accuracy': 0.8314814567565918, 'e0fb7511_test_diff_accuracy': 0.0, 'e133d23d_test_accuracy': 0.9926666021347046, 'e133d23d_test_diff_accuracy': 0.5035164952278137, 'e1baa8a4_test_accuracy': 0.9894444942474365, 'e1baa8a4_test_diff_accuracy': 0.9602466225624084, 'e1d2900e_test_accuracy': 0.9777777194976807, 'e1d2900e_test_diff_accuracy': 0.5, 'e2092e0c_test_accuracy': 0.8866667151451111, 'e2092e0c_test_diff_accuracy': 0.0, 'e21a174a_test_accuracy': 0.9562962651252747, 'e21a174a_test_diff_accuracy': 0.254934161901474, 'e345f17b_test_accuracy': 0.9961110949516296, 'e345f17b_test_diff_accuracy': 0.8137826919555664, 'e4075551_test_accuracy': 0.9433333277702332, 'e4075551_test_diff_accuracy': 0.0, 'e41c6fd3_test_accuracy': 0.936296284198761, 'e41c6fd3_test_diff_accuracy': 0.5, 'e57337a4_test_accuracy': 0.8762962818145752, 'e57337a4_test_diff_accuracy': 0.5169753432273865, 'e5790162_test_accuracy': 0.988444447517395, 'e5790162_test_diff_accuracy': 0.0, 'e5c44e8f_test_accuracy': 0.9455555081367493, 'e5c44e8f_test_diff_accuracy': 0.0, 'e619ca6e_test_accuracy': 0.8762962818145752, 'e619ca6e_test_diff_accuracy': 0.0, 'e633a9e5_test_accuracy': 0.9722221493721008, 'e633a9e5_test_diff_accuracy': 0.0, 'e66aafb8_test_accuracy': 0.9508889317512512, 'e66aafb8_test_diff_accuracy': 0.9255886077880859, 'e681b708_test_accuracy': 0.8870370388031006, 'e681b708_test_diff_accuracy': 0.0, 'e69241bd_test_accuracy': 0.9433333277702332, 'e69241bd_test_diff_accuracy': 0.0, 'e6de6e8f_test_accuracy': 0.9877777695655823, 'e6de6e8f_test_diff_accuracy': 0.5444445013999939, 'e74e1818_test_accuracy': 0.9674074053764343, 'e74e1818_test_diff_accuracy': 0.5, 'e760a62e_test_accuracy': 0.618148148059845, 'e760a62e_test_diff_accuracy': 0.0, 'e7639916_test_accuracy': 0.9644444584846497, 'e7639916_test_diff_accuracy': 0.0, 'e78887d1_test_accuracy': 0.9794444441795349, 'e78887d1_test_diff_accuracy': 0.6878482103347778, 'e7a25a18_test_accuracy': 0.9244444370269775, 'e7a25a18_test_diff_accuracy': 0.2172304391860962, 'e7b06bea_test_accuracy': 0.9871110916137695, 'e7b06bea_test_diff_accuracy': 0.7000000476837158, 'e7dd8335_test_accuracy': 0.9785184860229492, 'e7dd8335_test_diff_accuracy': 0.0, 'e872b94a_test_accuracy': 1.0, 'e872b94a_test_diff_accuracy': 1.0, 'e88171ec_test_accuracy': 0.8096296787261963, 'e88171ec_test_diff_accuracy': 0.0, 'e95e3d8e_test_accuracy': 0.46222221851348877, 'e95e3d8e_test_diff_accuracy': 0.0, 'e99362f0_test_accuracy': 0.978518545627594, 'e99362f0_test_diff_accuracy': 0.7147099375724792, 'e9ac8c9e_test_accuracy': 0.9792592525482178, 'e9ac8c9e_test_diff_accuracy': 0.2666666805744171, 'e9b4f6fc_test_accuracy': 0.9619444012641907, 'e9b4f6fc_test_diff_accuracy': 0.44486111402511597, 'e9bb6954_test_accuracy': 0.9030555486679077, 'e9bb6954_test_diff_accuracy': 0.0032051282469183207, 'e9c9d9a1_test_accuracy': 0.8203703761100769, 'e9c9d9a1_test_diff_accuracy': 0.0, 'ea959feb_test_accuracy': 0.3888889253139496, 'ea959feb_test_diff_accuracy': 0.0, 'ea9794b1_test_accuracy': 0.9729629158973694, 'ea9794b1_test_diff_accuracy': 0.647230327129364, 'ecaa0ec1_test_accuracy': 0.9894444346427917, 'ecaa0ec1_test_diff_accuracy': 0.48773449659347534, 'ed74f2f2_test_accuracy': 0.9935185313224792, 'ed74f2f2_test_diff_accuracy': 0.5953373312950134, 'ed98d772_test_accuracy': 0.9777777791023254, 'ed98d772_test_diff_accuracy': 0.10508663952350616, 'ef26cbf6_test_accuracy': 0.95333331823349, 'ef26cbf6_test_diff_accuracy': 0.0, 'f0afb749_test_accuracy': 0.9822222590446472, 'f0afb749_test_diff_accuracy': 0.061728399246931076, 'f0df5ff0_test_accuracy': 0.8670370578765869, 'f0df5ff0_test_diff_accuracy': 0.0, 'f21745ec_test_accuracy': 0.8877778053283691, 'f21745ec_test_diff_accuracy': 0.4960607588291168, 'f3b10344_test_accuracy': 0.711481511592865, 'f3b10344_test_diff_accuracy': 0.0, 'f3cdc58f_test_accuracy': 0.9785184860229492, 'f3cdc58f_test_diff_accuracy': 0.44780412316322327, 'f3e62deb_test_accuracy': 0.9911110997200012, 'f3e62deb_test_diff_accuracy': 0.5, 'f4081712_test_accuracy': 0.9235555529594421, 'f4081712_test_diff_accuracy': 0.8869382739067078, 'f45f5ca7_test_accuracy': 0.9918518662452698, 'f45f5ca7_test_diff_accuracy': 0.5, 'f5aa3634_test_accuracy': 0.9911110997200012, 'f5aa3634_test_diff_accuracy': 0.8053030371665955, 'f5c89df1_test_accuracy': 0.9829629063606262, 'f5c89df1_test_diff_accuracy': 0.437296062707901, 'f823c43c_test_accuracy': 0.7616666555404663, 'f823c43c_test_diff_accuracy': 0.0, 'f83cb3f6_test_accuracy': 0.9807407259941101, 'f83cb3f6_test_diff_accuracy': 0.6049907803535461, 'f8be4b64_test_accuracy': 0.9094444513320923, 'f8be4b64_test_diff_accuracy': 0.0, 'f9a67cb5_test_accuracy': 0.9262962937355042, 'f9a67cb5_test_diff_accuracy': 0.0, 'f9d67f8b_test_accuracy': 0.15777777135372162, 'f9d67f8b_test_diff_accuracy': 0.13529807329177856, 'fafd9572_test_accuracy': 0.9700000286102295, 'fafd9572_test_diff_accuracy': 0.0, 'fb791726_test_accuracy': 0.961017370223999, 'fb791726_test_diff_accuracy': 0.03614457696676254, 'fc754716_test_accuracy': 0.9844443798065186, 'fc754716_test_diff_accuracy': 0.07361919432878494, 'fd096ab6_test_accuracy': 0.41111111640930176, 'fd096ab6_test_diff_accuracy': 0.0, 'fd4b2b02_test_accuracy': 0.9122222065925598, 'fd4b2b02_test_diff_accuracy': 0.0, 'fe9372f3_test_accuracy': 0.9600000977516174, 'fe9372f3_test_diff_accuracy': 0.0, 'fea12743_test_accuracy': 0.9288887977600098, 'fea12743_test_diff_accuracy': 0.0, 'ff72ca3e_test_accuracy': 0.9647221565246582, 'ff72ca3e_test_diff_accuracy': 0.0, 'avg_test_loss': 0.3664872646331787, 'avg_test_accuracy': 0.904828667640686, 'avg_test_diff_accuracy': 0.2692205607891083}]\n",
            "DEBUG:__main__:DEBUG: Evaluation results: {'test_loss': 0.3664872646331787, 'test_accuracy': 0.904828667640686, 'test_diff_accuracy': 0.2692205607891083, 'complete_task_accuracy': 0.2344139650872818}\n",
            "DEBUG:__main__:DEBUG: Individual metrics: {'00576224': {'test_accuracy': 0.9599999785423279, 'test_diff_accuracy': 0.0}, '009d5c81': {'test_accuracy': 0.9744443893432617, 'test_diff_accuracy': 0.21003207564353943}, '00dbd492': {'test_accuracy': 0.929444432258606, 'test_diff_accuracy': 0.0}, '03560426': {'test_accuracy': 0.9796295762062073, 'test_diff_accuracy': 0.5188145637512207}, '05a7bcf2': {'test_accuracy': 0.6566666960716248, 'test_diff_accuracy': 0.0}, '0607ce86': {'test_accuracy': 0.7966666221618652, 'test_diff_accuracy': 0.6599085927009583}, '0692e18c': {'test_accuracy': 0.9785184860229492, 'test_diff_accuracy': 0.16984127461910248}, '070dd51e': {'test_accuracy': 0.9611111283302307, 'test_diff_accuracy': 0.0}, '08573cc6': {'test_accuracy': 0.962592601776123, 'test_diff_accuracy': 0.06767676770687103}, '0934a4d8': {'test_accuracy': 0.37638890743255615, 'test_diff_accuracy': 0.37773966789245605}, '09c534e7': {'test_accuracy': 0.7877777218818665, 'test_diff_accuracy': 0.0}, '0a1d4ef5': {'test_accuracy': 0.9511110782623291, 'test_diff_accuracy': 0.9168465733528137}, '0a2355a6': {'test_accuracy': 0.9394444823265076, 'test_diff_accuracy': 0.0}, '0b17323b': {'test_accuracy': 0.9938889145851135, 'test_diff_accuracy': 0.0}, '0bb8deee': {'test_accuracy': 0.9788889288902283, 'test_diff_accuracy': 0.6813034415245056}, '0becf7df': {'test_accuracy': 0.9744444489479065, 'test_diff_accuracy': 0.0}, '0c786b71': {'test_accuracy': 0.9466666579246521, 'test_diff_accuracy': 0.0}, '0c9aba6e': {'test_accuracy': 0.9916666746139526, 'test_diff_accuracy': 0.747855007648468}, '0d87d2a6': {'test_accuracy': 0.9055555462837219, 'test_diff_accuracy': 0.0}, '0e671a1a': {'test_accuracy': 0.9724999666213989, 'test_diff_accuracy': 0.0}, '0f63c0b9': {'test_accuracy': 0.8908333778381348, 'test_diff_accuracy': 0.0}, '103eff5b': {'test_accuracy': 0.9416666626930237, 'test_diff_accuracy': 0.0}, '11e1fe23': {'test_accuracy': 0.992222249507904, 'test_diff_accuracy': 0.0}, '12422b43': {'test_accuracy': 0.9788888692855835, 'test_diff_accuracy': 0.0}, '12997ef3': {'test_accuracy': 0.9844444394111633, 'test_diff_accuracy': 0.3445091247558594}, '12eac192': {'test_accuracy': 0.9725000262260437, 'test_diff_accuracy': 0.0}, '136b0064': {'test_accuracy': 0.9822222590446472, 'test_diff_accuracy': 0.711358368396759}, '13713586': {'test_accuracy': 0.859259307384491, 'test_diff_accuracy': 0.0}, '137f0df0': {'test_accuracy': 0.9185185432434082, 'test_diff_accuracy': 0.0}, '140c817e': {'test_accuracy': 0.8625926375389099, 'test_diff_accuracy': 0.0}, '14754a24': {'test_accuracy': 0.8630555272102356, 'test_diff_accuracy': 0.0}, '15113be4': {'test_accuracy': 0.6255555748939514, 'test_diff_accuracy': 0.0}, '15663ba9': {'test_accuracy': 0.9422222971916199, 'test_diff_accuracy': 0.0}, '15696249': {'test_accuracy': 0.9700000286102295, 'test_diff_accuracy': 0.1875}, '16b78196': {'test_accuracy': 0.7916666865348816, 'test_diff_accuracy': 0.4842342138290405}, '17b80ad2': {'test_accuracy': 0.9611111283302307, 'test_diff_accuracy': 0.0}, '17cae0c1': {'test_accuracy': 0.9700000286102295, 'test_diff_accuracy': 0.0}, '18419cfa': {'test_accuracy': 0.9344444274902344, 'test_diff_accuracy': 0.0}, '184a9768': {'test_accuracy': 0.8522222638130188, 'test_diff_accuracy': 0.575104296207428}, '195ba7dc': {'test_accuracy': 0.9758332967758179, 'test_diff_accuracy': 0.5054347515106201}, '1990f7a8': {'test_accuracy': 0.9740740656852722, 'test_diff_accuracy': 0.5}, '19bb5feb': {'test_accuracy': 0.9729630351066589, 'test_diff_accuracy': 0.7311635613441467}, '1a2e2828': {'test_accuracy': 0.9986666440963745, 'test_diff_accuracy': 0.9834964871406555}, '1a6449f1': {'test_accuracy': 0.9829629063606262, 'test_diff_accuracy': 0.9130600094795227}, '1acc24af': {'test_accuracy': 0.964722216129303, 'test_diff_accuracy': 0.0}, '1c02dbbe': {'test_accuracy': 0.860370397567749, 'test_diff_accuracy': 0.06207104027271271}, '1c0d0a4b': {'test_accuracy': 0.9825925827026367, 'test_diff_accuracy': 0.595678985118866}, '1c56ad9f': {'test_accuracy': 0.9541666507720947, 'test_diff_accuracy': 0.5}, '1d0a4b61': {'test_accuracy': 0.3055555522441864, 'test_diff_accuracy': 0.0}, '1d398264': {'test_accuracy': 0.9462962746620178, 'test_diff_accuracy': 0.0}, '1da012fc': {'test_accuracy': 0.9105556011199951, 'test_diff_accuracy': 0.0}, '1e81d6f9': {'test_accuracy': 0.9681481719017029, 'test_diff_accuracy': 1.0}, '1e97544e': {'test_accuracy': 0.41296300292015076, 'test_diff_accuracy': 0.0}, '2037f2c7': {'test_accuracy': 0.9900000095367432, 'test_diff_accuracy': 0.9334214329719543}, '2072aba6': {'test_accuracy': 0.9807407259941101, 'test_diff_accuracy': 0.01587301678955555}, '20818e16': {'test_accuracy': 0.9385185241699219, 'test_diff_accuracy': 0.723113477230072}, '20981f0e': {'test_accuracy': 0.9681481719017029, 'test_diff_accuracy': 0.5}, '212895b5': {'test_accuracy': 0.9196296334266663, 'test_diff_accuracy': 0.0}, '21f83797': {'test_accuracy': 0.9238889217376709, 'test_diff_accuracy': 0.0}, '22a4bbc2': {'test_accuracy': 0.9433333277702332, 'test_diff_accuracy': 0.0}, '25094a63': {'test_accuracy': 0.1827777773141861, 'test_diff_accuracy': 0.0}, '2546ccf6': {'test_accuracy': 0.8550000190734863, 'test_diff_accuracy': 0.0}, '256b0a75': {'test_accuracy': 0.6666666865348816, 'test_diff_accuracy': 0.0}, '2685904e': {'test_accuracy': 0.965925931930542, 'test_diff_accuracy': 0.0}, '2697da3f': {'test_accuracy': 0.9511110782623291, 'test_diff_accuracy': 0.16602009534835815}, '2753e76c': {'test_accuracy': 0.9900000095367432, 'test_diff_accuracy': 0.899422824382782}, '27a77e38': {'test_accuracy': 0.9807407259941101, 'test_diff_accuracy': 0.0}, '27f8ce4f': {'test_accuracy': 0.9650000333786011, 'test_diff_accuracy': 0.11249999701976776}, '281123b4': {'test_accuracy': 0.9829630255699158, 'test_diff_accuracy': 0.7146536707878113}, '292dd178': {'test_accuracy': 0.9081481099128723, 'test_diff_accuracy': 0.0}, '29700607': {'test_accuracy': 0.9618518948554993, 'test_diff_accuracy': 0.0}, '2a5f8217': {'test_accuracy': 0.9774073958396912, 'test_diff_accuracy': 0.0}, '2b01abd0': {'test_accuracy': 0.970740795135498, 'test_diff_accuracy': 0.0}, '2c0b0aff': {'test_accuracy': 0.9119444489479065, 'test_diff_accuracy': 0.7577368021011353}, '2c737e39': {'test_accuracy': 0.9840741157531738, 'test_diff_accuracy': 0.13650794327259064}, '2f0c5170': {'test_accuracy': 0.9674074053764343, 'test_diff_accuracy': 0.9186174869537354}, '310f3251': {'test_accuracy': 0.9700000882148743, 'test_diff_accuracy': 0.0}, '3194b014': {'test_accuracy': 0.9770370125770569, 'test_diff_accuracy': 0.9225044250488281}, '319f2597': {'test_accuracy': 0.6277777552604675, 'test_diff_accuracy': 0.9736223220825195}, '31adaf00': {'test_accuracy': 0.9307407736778259, 'test_diff_accuracy': 0.0}, '31d5ba1a': {'test_accuracy': 0.9928889274597168, 'test_diff_accuracy': 0.6540936231613159}, '32e9702f': {'test_accuracy': 0.9548148512840271, 'test_diff_accuracy': 0.0}, '332efdb3': {'test_accuracy': 0.9533333778381348, 'test_diff_accuracy': 0.0}, '3391f8c0': {'test_accuracy': 0.9824999570846558, 'test_diff_accuracy': 0.3541666865348816}, '33b52de3': {'test_accuracy': 0.8538888692855835, 'test_diff_accuracy': 0.0}, '3490cc26': {'test_accuracy': 0.9061111211776733, 'test_diff_accuracy': 0.0}, '34b99a2b': {'test_accuracy': 0.9883333444595337, 'test_diff_accuracy': 0.629668653011322}, '351d6448': {'test_accuracy': 0.9927777647972107, 'test_diff_accuracy': 0.8858424425125122}, '358ba94e': {'test_accuracy': 0.9744444489479065, 'test_diff_accuracy': 0.8644062280654907}, '37d3e8b2': {'test_accuracy': 0.8788889050483704, 'test_diff_accuracy': 0.0}, '3979b1a8': {'test_accuracy': 0.8888888955116272, 'test_diff_accuracy': 0.0}, '3a301edc': {'test_accuracy': 0.9024444818496704, 'test_diff_accuracy': 0.0}, '3b4c2228': {'test_accuracy': 0.9979999661445618, 'test_diff_accuracy': 0.8947456479072571}, '3d31c5b3': {'test_accuracy': 0.9794444441795349, 'test_diff_accuracy': 0.6079409122467041}, '3ed85e70': {'test_accuracy': 0.6381481885910034, 'test_diff_accuracy': 0.0}, '3ee1011a': {'test_accuracy': 0.9537037014961243, 'test_diff_accuracy': 0.20636117458343506}, '3f23242b': {'test_accuracy': 0.9550000429153442, 'test_diff_accuracy': 0.0}, '40f6cd08': {'test_accuracy': 0.6270370483398438, 'test_diff_accuracy': 0.0}, '414297c0': {'test_accuracy': 0.8959259390830994, 'test_diff_accuracy': 0.4695725440979004}, '423a55dc': {'test_accuracy': 0.9855555295944214, 'test_diff_accuracy': 0.5216470956802368}, '42918530': {'test_accuracy': 0.815833330154419, 'test_diff_accuracy': 0.0}, '42a15761': {'test_accuracy': 0.9062963128089905, 'test_diff_accuracy': 0.5}, '4364c1c4': {'test_accuracy': 0.8177778124809265, 'test_diff_accuracy': 0.0}, '456873bc': {'test_accuracy': 0.9514815211296082, 'test_diff_accuracy': 0.7703775763511658}, '45737921': {'test_accuracy': 0.9733333587646484, 'test_diff_accuracy': 0.0}, '45bbe264': {'test_accuracy': 0.932962954044342, 'test_diff_accuracy': 0.0}, '477d2879': {'test_accuracy': 0.8122222423553467, 'test_diff_accuracy': 0.0}, '47996f11': {'test_accuracy': 0.13833333551883698, 'test_diff_accuracy': 0.10620684921741486}, '48131b3c': {'test_accuracy': 0.9733333587646484, 'test_diff_accuracy': 0.11290545016527176}, '4852f2fa': {'test_accuracy': 0.9853333234786987, 'test_diff_accuracy': 0.36084944009780884}, '48f8583b': {'test_accuracy': 0.9798148274421692, 'test_diff_accuracy': 0.29629629850387573}, '4aab4007': {'test_accuracy': 0.12888889014720917, 'test_diff_accuracy': 0.0}, '4acc7107': {'test_accuracy': 0.9758333563804626, 'test_diff_accuracy': 0.4823917746543884}, '4b6b68e5': {'test_accuracy': 0.8622221946716309, 'test_diff_accuracy': 0.03787878900766373}, '4c177718': {'test_accuracy': 0.9872222542762756, 'test_diff_accuracy': 0.7471552491188049}, '4cd1b7b2': {'test_accuracy': 0.9822222590446472, 'test_diff_accuracy': 0.0}, '4e45f183': {'test_accuracy': 0.7507407665252686, 'test_diff_accuracy': 0.013888888992369175}, '4e469f39': {'test_accuracy': 0.9662962555885315, 'test_diff_accuracy': 0.0}, '4f537728': {'test_accuracy': 0.7972222566604614, 'test_diff_accuracy': 0.0}, '4ff4c9da': {'test_accuracy': 0.6259259581565857, 'test_diff_accuracy': 0.0}, '505fff84': {'test_accuracy': 0.9913333654403687, 'test_diff_accuracy': 0.8910254240036011}, '506d28a5': {'test_accuracy': 0.9822221994400024, 'test_diff_accuracy': 0.47752460837364197}, '50a16a69': {'test_accuracy': 0.8159258961677551, 'test_diff_accuracy': 0.03999999910593033}, '50aad11f': {'test_accuracy': 0.9785184860229492, 'test_diff_accuracy': 0.4671497642993927}, '50f325b5': {'test_accuracy': 0.801944375038147, 'test_diff_accuracy': 0.0}, '516b51b7': {'test_accuracy': 0.9188888669013977, 'test_diff_accuracy': 0.0}, '5207a7b5': {'test_accuracy': 0.9559259414672852, 'test_diff_accuracy': 0.0}, '5289ad53': {'test_accuracy': 0.9755555391311646, 'test_diff_accuracy': 0.8811259269714355}, '52fd389e': {'test_accuracy': 0.7137036323547363, 'test_diff_accuracy': 0.0}, '54db823b': {'test_accuracy': 0.9066666960716248, 'test_diff_accuracy': 1.0}, '55059096': {'test_accuracy': 0.9744443893432617, 'test_diff_accuracy': 0.0}, '551d5bf1': {'test_accuracy': 0.7644444704055786, 'test_diff_accuracy': 0.0}, '55783887': {'test_accuracy': 0.8462222218513489, 'test_diff_accuracy': 0.10000000149011612}, '575b1a71': {'test_accuracy': 0.8888888955116272, 'test_diff_accuracy': 0.0}, '5783df64': {'test_accuracy': 0.9900000095367432, 'test_diff_accuracy': 0.45825162529945374}, '5833af48': {'test_accuracy': 0.8825926184654236, 'test_diff_accuracy': 0.6010026335716248}, '58743b76': {'test_accuracy': 0.9472222328186035, 'test_diff_accuracy': 0.0}, '58e15b12': {'test_accuracy': 0.9170370697975159, 'test_diff_accuracy': 0.0}, '59341089': {'test_accuracy': 0.960277795791626, 'test_diff_accuracy': 0.0}, '5a5a2103': {'test_accuracy': 0.8194444179534912, 'test_diff_accuracy': 0.04545454680919647}, '5af49b42': {'test_accuracy': 0.9737036824226379, 'test_diff_accuracy': 0.0}, '5b526a93': {'test_accuracy': 0.90666663646698, 'test_diff_accuracy': 0.0}, '5b692c0f': {'test_accuracy': 0.9133332967758179, 'test_diff_accuracy': 0.23863637447357178}, '5b6cbef5': {'test_accuracy': 0.9197778701782227, 'test_diff_accuracy': 0.09092767536640167}, '5d2a5c43': {'test_accuracy': 0.9784444570541382, 'test_diff_accuracy': 0.47774338722229004}, '5ffb2104': {'test_accuracy': 0.987407386302948, 'test_diff_accuracy': 0.4901960790157318}, '604001fa': {'test_accuracy': 0.9819444417953491, 'test_diff_accuracy': 0.2735389471054077}, '60a26a3e': {'test_accuracy': 0.9718518257141113, 'test_diff_accuracy': 0.0}, '60c09cac': {'test_accuracy': 0.9822221994400024, 'test_diff_accuracy': 0.02777777798473835}, '626c0bcc': {'test_accuracy': 0.9825925827026367, 'test_diff_accuracy': 0.0}, '62ab2642': {'test_accuracy': 0.93666672706604, 'test_diff_accuracy': 0.0}, '62b74c02': {'test_accuracy': 0.9559259414672852, 'test_diff_accuracy': 0.0}, '639f5a19': {'test_accuracy': 0.7777777910232544, 'test_diff_accuracy': 0.0}, '642248e4': {'test_accuracy': 0.9570370316505432, 'test_diff_accuracy': 0.0}, '642d658d': {'test_accuracy': 0.9611111283302307, 'test_diff_accuracy': 0.9283973574638367}, '64a7c07e': {'test_accuracy': 0.9892592430114746, 'test_diff_accuracy': 0.5}, '66e6c45b': {'test_accuracy': 0.995555579662323, 'test_diff_accuracy': 0.5}, '66f2d22f': {'test_accuracy': 0.991944432258606, 'test_diff_accuracy': 0.7562196850776672}, '67636eac': {'test_accuracy': 0.9862963557243347, 'test_diff_accuracy': 0.46666666865348816}, '67b4a34d': {'test_accuracy': 0.9696295857429504, 'test_diff_accuracy': 0.9138374328613281}, '67c52801': {'test_accuracy': 0.9786111116409302, 'test_diff_accuracy': 0.5}, '68b67ca3': {'test_accuracy': 0.9944444298744202, 'test_diff_accuracy': 0.5}, '692cd3b6': {'test_accuracy': 0.9007408022880554, 'test_diff_accuracy': 0.0}, '695367ec': {'test_accuracy': 0.8937036991119385, 'test_diff_accuracy': 0.05552127584815025}, '696d4842': {'test_accuracy': 0.962592601776123, 'test_diff_accuracy': 0.0}, '69889d6e': {'test_accuracy': 0.980555534362793, 'test_diff_accuracy': 0.0}, '6a11f6da': {'test_accuracy': 0.975777804851532, 'test_diff_accuracy': 0.5782161355018616}, '6ad5bdfd': {'test_accuracy': 0.9814814925193787, 'test_diff_accuracy': 0.45766592025756836}, '6df30ad6': {'test_accuracy': 0.991777777671814, 'test_diff_accuracy': 0.5457017421722412}, '6ea4a07e': {'test_accuracy': 0.9937036633491516, 'test_diff_accuracy': 0.37037038803100586}, '6f473927': {'test_accuracy': 0.9677777886390686, 'test_diff_accuracy': 0.21378621459007263}, '7039b2d7': {'test_accuracy': 0.9840741157531738, 'test_diff_accuracy': 0.9842607378959656}, '705a3229': {'test_accuracy': 0.9844444394111633, 'test_diff_accuracy': 0.0}, '712bf12e': {'test_accuracy': 0.9170370101928711, 'test_diff_accuracy': 0.0}, '72207abc': {'test_accuracy': 0.9925925731658936, 'test_diff_accuracy': 0.0}, '72a961c9': {'test_accuracy': 0.9844444990158081, 'test_diff_accuracy': 0.0}, '73182012': {'test_accuracy': 0.9881481528282166, 'test_diff_accuracy': 0.8835263848304749}, '73c3b0d8': {'test_accuracy': 0.9869444370269775, 'test_diff_accuracy': 0.2957516312599182}, '73ccf9c2': {'test_accuracy': 0.9881481528282166, 'test_diff_accuracy': 0.8363578915596008}, '759f3fd3': {'test_accuracy': 0.8427777886390686, 'test_diff_accuracy': 0.0}, '762cd429': {'test_accuracy': 0.8118519186973572, 'test_diff_accuracy': 0.0}, '770cc55f': {'test_accuracy': 0.9769444465637207, 'test_diff_accuracy': 0.0}, '782b5218': {'test_accuracy': 0.9344444274902344, 'test_diff_accuracy': 0.4673832952976227}, '79369cc6': {'test_accuracy': 0.8040741086006165, 'test_diff_accuracy': 0.0}, '7953d61e': {'test_accuracy': 0.9288889169692993, 'test_diff_accuracy': 0.0}, '79fb03f4': {'test_accuracy': 0.93833327293396, 'test_diff_accuracy': 0.0}, '7bb29440': {'test_accuracy': 0.9735555648803711, 'test_diff_accuracy': 0.8471860885620117}, '7c8af763': {'test_accuracy': 0.8888888955116272, 'test_diff_accuracy': 0.0}, '7c9b52a0': {'test_accuracy': 0.9074074625968933, 'test_diff_accuracy': 0.6268526911735535}, '7d18a6fb': {'test_accuracy': 0.9770370125770569, 'test_diff_accuracy': 0.7752125263214111}, '7d1f7ee8': {'test_accuracy': 0.8325925469398499, 'test_diff_accuracy': 0.0}, '7d419a02': {'test_accuracy': 0.851111114025116, 'test_diff_accuracy': 0.0}, '7e02026e': {'test_accuracy': 0.9000000357627869, 'test_diff_accuracy': 0.0}, '7ee1c6ea': {'test_accuracy': 0.9133333563804626, 'test_diff_accuracy': 0.0}, '817e6c09': {'test_accuracy': 0.9760000109672546, 'test_diff_accuracy': 0.0}, '81c0276b': {'test_accuracy': 0.9933333396911621, 'test_diff_accuracy': 0.9544203281402588}, '833dafe3': {'test_accuracy': 0.9644444584846497, 'test_diff_accuracy': 0.07334525883197784}, '845d6e51': {'test_accuracy': 0.9477777481079102, 'test_diff_accuracy': 0.0}, '84db8fc4': {'test_accuracy': 0.8888888955116272, 'test_diff_accuracy': 0.0}, '84f2aca1': {'test_accuracy': 0.9650000333786011, 'test_diff_accuracy': 0.0}, '8597cfd7': {'test_accuracy': 0.995555579662323, 'test_diff_accuracy': 0.8174242377281189}, '85b81ff1': {'test_accuracy': 0.875, 'test_diff_accuracy': 0.5}, '85fa5666': {'test_accuracy': 0.9622222185134888, 'test_diff_accuracy': 0.0}, '8719f442': {'test_accuracy': 0.9422221779823303, 'test_diff_accuracy': 0.0}, '88207623': {'test_accuracy': 0.9388889074325562, 'test_diff_accuracy': 0.0}, '891232d6': {'test_accuracy': 0.8897222280502319, 'test_diff_accuracy': 0.0}, '896d5239': {'test_accuracy': 0.8825926184654236, 'test_diff_accuracy': 0.0}, '8a371977': {'test_accuracy': 0.43888890743255615, 'test_diff_accuracy': 0.0}, '8b28cd80': {'test_accuracy': 0.948888897895813, 'test_diff_accuracy': 0.017298799008131027}, '8ba14f53': {'test_accuracy': 0.9938888549804688, 'test_diff_accuracy': 0.8179367184638977}, '8cb8642d': {'test_accuracy': 0.9296296238899231, 'test_diff_accuracy': 0.7093300819396973}, '8dae5dfc': {'test_accuracy': 0.8263888359069824, 'test_diff_accuracy': 0.0}, '8e2edd66': {'test_accuracy': 0.9814814925193787, 'test_diff_accuracy': 0.2586754262447357}, '8ee62060': {'test_accuracy': 0.9788889288902283, 'test_diff_accuracy': 0.5}, '8fbca751': {'test_accuracy': 0.9659258723258972, 'test_diff_accuracy': 0.0}, '90347967': {'test_accuracy': 0.9933333396911621, 'test_diff_accuracy': 0.5}, '903d1b4a': {'test_accuracy': 0.7155555486679077, 'test_diff_accuracy': 0.0}, '9110e3c5': {'test_accuracy': 0.9960317611694336, 'test_diff_accuracy': 0.8651400804519653}, '917bccba': {'test_accuracy': 0.9644444584846497, 'test_diff_accuracy': 0.6146110892295837}, '929ab4e9': {'test_accuracy': 0.3613888919353485, 'test_diff_accuracy': 0.0}, '92e50de0': {'test_accuracy': 0.6677777767181396, 'test_diff_accuracy': 0.0}, '9356391f': {'test_accuracy': 0.90666663646698, 'test_diff_accuracy': 0.0}, '93b4f4b3': {'test_accuracy': 0.9233333468437195, 'test_diff_accuracy': 0.40796583890914917}, '93c31fbe': {'test_accuracy': 0.9399999976158142, 'test_diff_accuracy': 0.3983488082885742}, '94133066': {'test_accuracy': 0.8922222256660461, 'test_diff_accuracy': 0.48462045192718506}, '94414823': {'test_accuracy': 0.9577777981758118, 'test_diff_accuracy': 0.0}, '94be5b80': {'test_accuracy': 0.9411110877990723, 'test_diff_accuracy': 0.2946428656578064}, '95a58926': {'test_accuracy': 0.8614814877510071, 'test_diff_accuracy': 0.5745627284049988}, '963f59bc': {'test_accuracy': 0.9786111116409302, 'test_diff_accuracy': 0.0}, '96a8c0cd': {'test_accuracy': 0.9350000023841858, 'test_diff_accuracy': 0.0}, '97239e3d': {'test_accuracy': 0.7988889217376709, 'test_diff_accuracy': 0.0}, '9772c176': {'test_accuracy': 0.7477777600288391, 'test_diff_accuracy': 0.0}, '981571dc': {'test_accuracy': 0.00027777778450399637, 'test_diff_accuracy': 0.0}, '992798f6': {'test_accuracy': 0.9863889217376709, 'test_diff_accuracy': 0.0}, '99306f82': {'test_accuracy': 0.9162963032722473, 'test_diff_accuracy': 0.0}, '9a4bb226': {'test_accuracy': 0.9888889193534851, 'test_diff_accuracy': 0.7706348896026611}, '9b2a60aa': {'test_accuracy': 0.965925931930542, 'test_diff_accuracy': 0.0}, '9b365c51': {'test_accuracy': 0.9670370221138, 'test_diff_accuracy': 0.444180965423584}, '9b4c17c4': {'test_accuracy': 0.8147222995758057, 'test_diff_accuracy': 0.0}, '9bebae7a': {'test_accuracy': 0.9786666631698608, 'test_diff_accuracy': 0.33641454577445984}, '9c1e755f': {'test_accuracy': 0.9461110830307007, 'test_diff_accuracy': 0.0}, '9c56f360': {'test_accuracy': 0.9737036824226379, 'test_diff_accuracy': 0.5}, '9caba7c3': {'test_accuracy': 0.7659258842468262, 'test_diff_accuracy': 0.0}, '9ddd00f0': {'test_accuracy': 0.9533333778381348, 'test_diff_accuracy': 0.0}, '9def23fe': {'test_accuracy': 0.8311111330986023, 'test_diff_accuracy': 0.0}, '9f27f097': {'test_accuracy': 0.8399999737739563, 'test_diff_accuracy': 0.0}, 'a04b2602': {'test_accuracy': 0.8177778124809265, 'test_diff_accuracy': 0.0}, 'a096bf4d': {'test_accuracy': 0.7333333492279053, 'test_diff_accuracy': 0.0}, 'a3f84088': {'test_accuracy': 0.8686110973358154, 'test_diff_accuracy': 0.0}, 'a406ac07': {'test_accuracy': 0.958148181438446, 'test_diff_accuracy': 0.0}, 'a57f2f04': {'test_accuracy': 0.6633333563804626, 'test_diff_accuracy': 0.0}, 'a59b95c0': {'test_accuracy': 0.9160000085830688, 'test_diff_accuracy': 0.0}, 'a680ac02': {'test_accuracy': 0.9644444584846497, 'test_diff_accuracy': 0.6501501202583313}, 'a8610ef7': {'test_accuracy': 0.9766666889190674, 'test_diff_accuracy': 0.0}, 'a934301b': {'test_accuracy': 0.9674074053764343, 'test_diff_accuracy': 1.0}, 'aa18de87': {'test_accuracy': 0.9791666269302368, 'test_diff_accuracy': 0.0}, 'aa300dc3': {'test_accuracy': 0.930555522441864, 'test_diff_accuracy': 0.0}, 'aa4ec2a5': {'test_accuracy': 0.43740740418434143, 'test_diff_accuracy': 0.0}, 'aab50785': {'test_accuracy': 0.9871110916137695, 'test_diff_accuracy': 0.9002954363822937}, 'ac0c5833': {'test_accuracy': 0.9518518447875977, 'test_diff_accuracy': 0.0}, 'ac2e8ecf': {'test_accuracy': 0.9529629349708557, 'test_diff_accuracy': 0.4784134328365326}, 'ac3e2b04': {'test_accuracy': 0.9386110901832581, 'test_diff_accuracy': 0.0}, 'ac605cbb': {'test_accuracy': 0.9875926375389099, 'test_diff_accuracy': 0.0}, 'ad7e01d0': {'test_accuracy': 0.9144444465637207, 'test_diff_accuracy': 0.08509097993373871}, 'ae58858e': {'test_accuracy': 0.9783333539962769, 'test_diff_accuracy': 0.0}, 'aee291af': {'test_accuracy': 0.9762962460517883, 'test_diff_accuracy': 0.9403367638587952}, 'af22c60d': {'test_accuracy': 0.0, 'test_diff_accuracy': 0.0}, 'af24b4cc': {'test_accuracy': 0.9929630160331726, 'test_diff_accuracy': 0.8559829592704773}, 'b0722778': {'test_accuracy': 0.9844444394111633, 'test_diff_accuracy': 0.7229965329170227}, 'b0f4d537': {'test_accuracy': 0.9722222089767456, 'test_diff_accuracy': 0.6134893894195557}, 'b15fca0b': {'test_accuracy': 0.9675555229187012, 'test_diff_accuracy': 0.0}, 'b1fc8b8e': {'test_accuracy': 0.9851110577583313, 'test_diff_accuracy': 0.48750001192092896}, 'b20f7c8b': {'test_accuracy': 0.7707407474517822, 'test_diff_accuracy': 0.0}, 'b457fec5': {'test_accuracy': 0.9137037396430969, 'test_diff_accuracy': 0.0}, 'b4a43f3b': {'test_accuracy': 0.9633333086967468, 'test_diff_accuracy': 0.46900829672813416}, 'b7999b51': {'test_accuracy': 0.9900000095367432, 'test_diff_accuracy': 0.8587267994880676}, 'b7cb93ac': {'test_accuracy': 0.9866666793823242, 'test_diff_accuracy': 0.4814814627170563}, 'b7f8a4d8': {'test_accuracy': 0.6399999856948853, 'test_diff_accuracy': 0.0}, 'b7fb29bc': {'test_accuracy': 0.9100000262260437, 'test_diff_accuracy': 0.0}, 'b942fd60': {'test_accuracy': 0.9666666984558105, 'test_diff_accuracy': 0.0}, 'b9630600': {'test_accuracy': 0.8437037467956543, 'test_diff_accuracy': 0.3881119191646576}, 'ba9d41b8': {'test_accuracy': 0.9162963032722473, 'test_diff_accuracy': 1.0}, 'baf41dbf': {'test_accuracy': 0.9592592716217041, 'test_diff_accuracy': 0.20501208305358887}, 'bb52a14b': {'test_accuracy': 0.9188888669013977, 'test_diff_accuracy': 0.0}, 'bbb1b8b6': {'test_accuracy': 0.9852380156517029, 'test_diff_accuracy': 0.5396488308906555}, 'bc4146bd': {'test_accuracy': 0.9111111164093018, 'test_diff_accuracy': 0.0}, 'bcb3040b': {'test_accuracy': 0.9196296334266663, 'test_diff_accuracy': 0.0}, 'bd14c3bf': {'test_accuracy': 0.9211111068725586, 'test_diff_accuracy': 0.0}, 'be03b35f': {'test_accuracy': 0.9970369935035706, 'test_diff_accuracy': 0.8111111521720886}, 'bf32578f': {'test_accuracy': 0.9881481528282166, 'test_diff_accuracy': 0.3821733891963959}, 'bf699163': {'test_accuracy': 0.9900000095367432, 'test_diff_accuracy': 0.9721251130104065}, 'bf89d739': {'test_accuracy': 0.9780555367469788, 'test_diff_accuracy': 0.0}, 'c074846d': {'test_accuracy': 0.9948889017105103, 'test_diff_accuracy': 0.0}, 'c1990cce': {'test_accuracy': 0.9785184860229492, 'test_diff_accuracy': 0.07402319461107254}, 'c3202e5a': {'test_accuracy': 0.9929630160331726, 'test_diff_accuracy': 0.9741120338439941}, 'c35c1b4c': {'test_accuracy': 0.9144444465637207, 'test_diff_accuracy': 0.0}, 'c48954c1': {'test_accuracy': 0.9100000262260437, 'test_diff_accuracy': 0.0}, 'c62e2108': {'test_accuracy': 0.8962963223457336, 'test_diff_accuracy': 0.04329491779208183}, 'c64f1187': {'test_accuracy': 0.9688888788223267, 'test_diff_accuracy': 0.6881044507026672}, 'c658a4bd': {'test_accuracy': 0.9194444417953491, 'test_diff_accuracy': 0.37494730949401855}, 'c663677b': {'test_accuracy': 0.1899999976158142, 'test_diff_accuracy': 0.0}, 'c6e1b8da': {'test_accuracy': 0.8537037372589111, 'test_diff_accuracy': 0.45049849152565}, 'c7d4e6ad': {'test_accuracy': 0.9777777791023254, 'test_diff_accuracy': 0.0}, 'c87289bb': {'test_accuracy': 0.9436111450195312, 'test_diff_accuracy': 0.0}, 'c8b7cc0f': {'test_accuracy': 0.995555579662323, 'test_diff_accuracy': 0.8881499767303467}, 'c92b942c': {'test_accuracy': 0.9175000190734863, 'test_diff_accuracy': 0.0}, 'c97c0139': {'test_accuracy': 0.9155555963516235, 'test_diff_accuracy': 0.0}, 'ca8de6ea': {'test_accuracy': 0.9900000095367432, 'test_diff_accuracy': 0.3333333432674408}, 'ca8f78db': {'test_accuracy': 0.0, 'test_diff_accuracy': 0.0}, 'cad67732': {'test_accuracy': 0.9740740656852722, 'test_diff_accuracy': 0.0}, 'cb227835': {'test_accuracy': 0.9792592525482178, 'test_diff_accuracy': 0.0}, 'ccd554ac': {'test_accuracy': 0.9307406544685364, 'test_diff_accuracy': 0.02556818164885044}, 'cd3c21df': {'test_accuracy': 0.9948148727416992, 'test_diff_accuracy': 0.8213383555412292}, 'ce039d91': {'test_accuracy': 0.9774999618530273, 'test_diff_accuracy': 0.0}, 'ce8d95cc': {'test_accuracy': 0.9802777767181396, 'test_diff_accuracy': 0.7194792032241821}, 'cf133acc': {'test_accuracy': 0.9370369911193848, 'test_diff_accuracy': 0.0}, 'cfb2ce5a': {'test_accuracy': 0.9325925707817078, 'test_diff_accuracy': 0.0}, 'd017b73f': {'test_accuracy': 0.9883332848548889, 'test_diff_accuracy': 0.5}, 'd19f7514': {'test_accuracy': 0.9808333516120911, 'test_diff_accuracy': 0.4937748610973358}, 'd282b262': {'test_accuracy': 0.9677777290344238, 'test_diff_accuracy': 0.4773857891559601}, 'd2acf2cb': {'test_accuracy': 0.9551851749420166, 'test_diff_accuracy': 0.095238097012043}, 'd304284e': {'test_accuracy': 0.8761111497879028, 'test_diff_accuracy': 0.0}, 'd37a1ef5': {'test_accuracy': 0.9344444274902344, 'test_diff_accuracy': 0.0}, 'd47aa2ff': {'test_accuracy': 0.9896295666694641, 'test_diff_accuracy': 0.7235023379325867}, 'd492a647': {'test_accuracy': 0.8811111450195312, 'test_diff_accuracy': 0.0}, 'd4b1c2b1': {'test_accuracy': 0.9442857503890991, 'test_diff_accuracy': 0.2857142984867096}, 'd4c90558': {'test_accuracy': 0.9829629063606262, 'test_diff_accuracy': 0.9063237309455872}, 'd56f2372': {'test_accuracy': 0.9866666793823242, 'test_diff_accuracy': 0.8060207962989807}, 'd5c634a2': {'test_accuracy': 0.9953967928886414, 'test_diff_accuracy': 0.7885443568229675}, 'd931c21c': {'test_accuracy': 0.9108333587646484, 'test_diff_accuracy': 0.25}, 'd94c3b52': {'test_accuracy': 0.8414815068244934, 'test_diff_accuracy': 0.0}, 'da2b0fe3': {'test_accuracy': 0.9707407355308533, 'test_diff_accuracy': 0.0}, 'da515329': {'test_accuracy': 0.8374074101448059, 'test_diff_accuracy': 0.0}, 'dc2aa30b': {'test_accuracy': 0.9100000262260437, 'test_diff_accuracy': 0.0}, 'dc2e9a9d': {'test_accuracy': 0.9233333468437195, 'test_diff_accuracy': 0.0}, 'dd2401ed': {'test_accuracy': 0.9811111092567444, 'test_diff_accuracy': 0.43627452850341797}, 'de493100': {'test_accuracy': 0.25111111998558044, 'test_diff_accuracy': 0.2521111071109772}, 'df8cc377': {'test_accuracy': 0.9492592811584473, 'test_diff_accuracy': 0.5}, 'e0fb7511': {'test_accuracy': 0.8314814567565918, 'test_diff_accuracy': 0.0}, 'e133d23d': {'test_accuracy': 0.9926666021347046, 'test_diff_accuracy': 0.5035164952278137}, 'e1baa8a4': {'test_accuracy': 0.9894444942474365, 'test_diff_accuracy': 0.9602466225624084}, 'e1d2900e': {'test_accuracy': 0.9777777194976807, 'test_diff_accuracy': 0.5}, 'e2092e0c': {'test_accuracy': 0.8866667151451111, 'test_diff_accuracy': 0.0}, 'e21a174a': {'test_accuracy': 0.9562962651252747, 'test_diff_accuracy': 0.254934161901474}, 'e345f17b': {'test_accuracy': 0.9961110949516296, 'test_diff_accuracy': 0.8137826919555664}, 'e4075551': {'test_accuracy': 0.9433333277702332, 'test_diff_accuracy': 0.0}, 'e41c6fd3': {'test_accuracy': 0.936296284198761, 'test_diff_accuracy': 0.5}, 'e57337a4': {'test_accuracy': 0.8762962818145752, 'test_diff_accuracy': 0.5169753432273865}, 'e5790162': {'test_accuracy': 0.988444447517395, 'test_diff_accuracy': 0.0}, 'e5c44e8f': {'test_accuracy': 0.9455555081367493, 'test_diff_accuracy': 0.0}, 'e619ca6e': {'test_accuracy': 0.8762962818145752, 'test_diff_accuracy': 0.0}, 'e633a9e5': {'test_accuracy': 0.9722221493721008, 'test_diff_accuracy': 0.0}, 'e66aafb8': {'test_accuracy': 0.9508889317512512, 'test_diff_accuracy': 0.9255886077880859}, 'e681b708': {'test_accuracy': 0.8870370388031006, 'test_diff_accuracy': 0.0}, 'e69241bd': {'test_accuracy': 0.9433333277702332, 'test_diff_accuracy': 0.0}, 'e6de6e8f': {'test_accuracy': 0.9877777695655823, 'test_diff_accuracy': 0.5444445013999939}, 'e74e1818': {'test_accuracy': 0.9674074053764343, 'test_diff_accuracy': 0.5}, 'e760a62e': {'test_accuracy': 0.618148148059845, 'test_diff_accuracy': 0.0}, 'e7639916': {'test_accuracy': 0.9644444584846497, 'test_diff_accuracy': 0.0}, 'e78887d1': {'test_accuracy': 0.9794444441795349, 'test_diff_accuracy': 0.6878482103347778}, 'e7a25a18': {'test_accuracy': 0.9244444370269775, 'test_diff_accuracy': 0.2172304391860962}, 'e7b06bea': {'test_accuracy': 0.9871110916137695, 'test_diff_accuracy': 0.7000000476837158}, 'e7dd8335': {'test_accuracy': 0.9785184860229492, 'test_diff_accuracy': 0.0}, 'e872b94a': {'test_accuracy': 1.0, 'test_diff_accuracy': 1.0}, 'e88171ec': {'test_accuracy': 0.8096296787261963, 'test_diff_accuracy': 0.0}, 'e95e3d8e': {'test_accuracy': 0.46222221851348877, 'test_diff_accuracy': 0.0}, 'e99362f0': {'test_accuracy': 0.978518545627594, 'test_diff_accuracy': 0.7147099375724792}, 'e9ac8c9e': {'test_accuracy': 0.9792592525482178, 'test_diff_accuracy': 0.2666666805744171}, 'e9b4f6fc': {'test_accuracy': 0.9619444012641907, 'test_diff_accuracy': 0.44486111402511597}, 'e9bb6954': {'test_accuracy': 0.9030555486679077, 'test_diff_accuracy': 0.0032051282469183207}, 'e9c9d9a1': {'test_accuracy': 0.8203703761100769, 'test_diff_accuracy': 0.0}, 'ea959feb': {'test_accuracy': 0.3888889253139496, 'test_diff_accuracy': 0.0}, 'ea9794b1': {'test_accuracy': 0.9729629158973694, 'test_diff_accuracy': 0.647230327129364}, 'ecaa0ec1': {'test_accuracy': 0.9894444346427917, 'test_diff_accuracy': 0.48773449659347534}, 'ed74f2f2': {'test_accuracy': 0.9935185313224792, 'test_diff_accuracy': 0.5953373312950134}, 'ed98d772': {'test_accuracy': 0.9777777791023254, 'test_diff_accuracy': 0.10508663952350616}, 'ef26cbf6': {'test_accuracy': 0.95333331823349, 'test_diff_accuracy': 0.0}, 'f0afb749': {'test_accuracy': 0.9822222590446472, 'test_diff_accuracy': 0.061728399246931076}, 'f0df5ff0': {'test_accuracy': 0.8670370578765869, 'test_diff_accuracy': 0.0}, 'f21745ec': {'test_accuracy': 0.8877778053283691, 'test_diff_accuracy': 0.4960607588291168}, 'f3b10344': {'test_accuracy': 0.711481511592865, 'test_diff_accuracy': 0.0}, 'f3cdc58f': {'test_accuracy': 0.9785184860229492, 'test_diff_accuracy': 0.44780412316322327}, 'f3e62deb': {'test_accuracy': 0.9911110997200012, 'test_diff_accuracy': 0.5}, 'f4081712': {'test_accuracy': 0.9235555529594421, 'test_diff_accuracy': 0.8869382739067078}, 'f45f5ca7': {'test_accuracy': 0.9918518662452698, 'test_diff_accuracy': 0.5}, 'f5aa3634': {'test_accuracy': 0.9911110997200012, 'test_diff_accuracy': 0.8053030371665955}, 'f5c89df1': {'test_accuracy': 0.9829629063606262, 'test_diff_accuracy': 0.437296062707901}, 'f823c43c': {'test_accuracy': 0.7616666555404663, 'test_diff_accuracy': 0.0}, 'f83cb3f6': {'test_accuracy': 0.9807407259941101, 'test_diff_accuracy': 0.6049907803535461}, 'f8be4b64': {'test_accuracy': 0.9094444513320923, 'test_diff_accuracy': 0.0}, 'f9a67cb5': {'test_accuracy': 0.9262962937355042, 'test_diff_accuracy': 0.0}, 'f9d67f8b': {'test_accuracy': 0.15777777135372162, 'test_diff_accuracy': 0.13529807329177856}, 'fafd9572': {'test_accuracy': 0.9700000286102295, 'test_diff_accuracy': 0.0}, 'fb791726': {'test_accuracy': 0.961017370223999, 'test_diff_accuracy': 0.03614457696676254}, 'fc754716': {'test_accuracy': 0.9844443798065186, 'test_diff_accuracy': 0.07361919432878494}, 'fd096ab6': {'test_accuracy': 0.41111111640930176, 'test_diff_accuracy': 0.0}, 'fd4b2b02': {'test_accuracy': 0.9122222065925598, 'test_diff_accuracy': 0.0}, 'fe9372f3': {'test_accuracy': 0.9600000977516174, 'test_diff_accuracy': 0.0}, 'fea12743': {'test_accuracy': 0.9288887977600098, 'test_diff_accuracy': 0.0}, 'ff72ca3e': {'test_accuracy': 0.9647221565246582, 'test_diff_accuracy': 0.0}, 'avg': {'test_accuracy': 0.904828667640686, 'test_diff_accuracy': 0.2692205607891083}}\n",
            "INFO:__main__:Evaluation Results:\n",
            "INFO:__main__:Task 00576224: Accuracy = 0.9600, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 009d5c81: Accuracy = 0.9744, Diff Accuracy = 0.2100\n",
            "INFO:__main__:Task 00dbd492: Accuracy = 0.9294, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 03560426: Accuracy = 0.9796, Diff Accuracy = 0.5188\n",
            "INFO:__main__:Task 05a7bcf2: Accuracy = 0.6567, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 0607ce86: Accuracy = 0.7967, Diff Accuracy = 0.6599\n",
            "INFO:__main__:Task 0692e18c: Accuracy = 0.9785, Diff Accuracy = 0.1698\n",
            "INFO:__main__:Task 070dd51e: Accuracy = 0.9611, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 08573cc6: Accuracy = 0.9626, Diff Accuracy = 0.0677\n",
            "INFO:__main__:Task 0934a4d8: Accuracy = 0.3764, Diff Accuracy = 0.3777\n",
            "INFO:__main__:Task 09c534e7: Accuracy = 0.7878, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 0a1d4ef5: Accuracy = 0.9511, Diff Accuracy = 0.9168\n",
            "INFO:__main__:Task 0a2355a6: Accuracy = 0.9394, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 0b17323b: Accuracy = 0.9939, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 0bb8deee: Accuracy = 0.9789, Diff Accuracy = 0.6813\n",
            "INFO:__main__:Task 0becf7df: Accuracy = 0.9744, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 0c786b71: Accuracy = 0.9467, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 0c9aba6e: Accuracy = 0.9917, Diff Accuracy = 0.7479\n",
            "INFO:__main__:Task 0d87d2a6: Accuracy = 0.9056, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 0e671a1a: Accuracy = 0.9725, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 0f63c0b9: Accuracy = 0.8908, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 103eff5b: Accuracy = 0.9417, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 11e1fe23: Accuracy = 0.9922, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 12422b43: Accuracy = 0.9789, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 12997ef3: Accuracy = 0.9844, Diff Accuracy = 0.3445\n",
            "INFO:__main__:Task 12eac192: Accuracy = 0.9725, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 136b0064: Accuracy = 0.9822, Diff Accuracy = 0.7114\n",
            "INFO:__main__:Task 13713586: Accuracy = 0.8593, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 137f0df0: Accuracy = 0.9185, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 140c817e: Accuracy = 0.8626, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 14754a24: Accuracy = 0.8631, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 15113be4: Accuracy = 0.6256, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 15663ba9: Accuracy = 0.9422, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 15696249: Accuracy = 0.9700, Diff Accuracy = 0.1875\n",
            "INFO:__main__:Task 16b78196: Accuracy = 0.7917, Diff Accuracy = 0.4842\n",
            "INFO:__main__:Task 17b80ad2: Accuracy = 0.9611, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 17cae0c1: Accuracy = 0.9700, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 18419cfa: Accuracy = 0.9344, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 184a9768: Accuracy = 0.8522, Diff Accuracy = 0.5751\n",
            "INFO:__main__:Task 195ba7dc: Accuracy = 0.9758, Diff Accuracy = 0.5054\n",
            "INFO:__main__:Task 1990f7a8: Accuracy = 0.9741, Diff Accuracy = 0.5000\n",
            "INFO:__main__:Task 19bb5feb: Accuracy = 0.9730, Diff Accuracy = 0.7312\n",
            "INFO:__main__:Task 1a2e2828: Accuracy = 0.9987, Diff Accuracy = 0.9835\n",
            "INFO:__main__:Task 1a6449f1: Accuracy = 0.9830, Diff Accuracy = 0.9131\n",
            "INFO:__main__:Task 1acc24af: Accuracy = 0.9647, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 1c02dbbe: Accuracy = 0.8604, Diff Accuracy = 0.0621\n",
            "INFO:__main__:Task 1c0d0a4b: Accuracy = 0.9826, Diff Accuracy = 0.5957\n",
            "INFO:__main__:Task 1c56ad9f: Accuracy = 0.9542, Diff Accuracy = 0.5000\n",
            "INFO:__main__:Task 1d0a4b61: Accuracy = 0.3056, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 1d398264: Accuracy = 0.9463, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 1da012fc: Accuracy = 0.9106, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 1e81d6f9: Accuracy = 0.9681, Diff Accuracy = 1.0000\n",
            "INFO:__main__:Task 1e97544e: Accuracy = 0.4130, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 2037f2c7: Accuracy = 0.9900, Diff Accuracy = 0.9334\n",
            "INFO:__main__:Task 2072aba6: Accuracy = 0.9807, Diff Accuracy = 0.0159\n",
            "INFO:__main__:Task 20818e16: Accuracy = 0.9385, Diff Accuracy = 0.7231\n",
            "INFO:__main__:Task 20981f0e: Accuracy = 0.9681, Diff Accuracy = 0.5000\n",
            "INFO:__main__:Task 212895b5: Accuracy = 0.9196, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 21f83797: Accuracy = 0.9239, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 22a4bbc2: Accuracy = 0.9433, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 25094a63: Accuracy = 0.1828, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 2546ccf6: Accuracy = 0.8550, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 256b0a75: Accuracy = 0.6667, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 2685904e: Accuracy = 0.9659, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 2697da3f: Accuracy = 0.9511, Diff Accuracy = 0.1660\n",
            "INFO:__main__:Task 2753e76c: Accuracy = 0.9900, Diff Accuracy = 0.8994\n",
            "INFO:__main__:Task 27a77e38: Accuracy = 0.9807, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 27f8ce4f: Accuracy = 0.9650, Diff Accuracy = 0.1125\n",
            "INFO:__main__:Task 281123b4: Accuracy = 0.9830, Diff Accuracy = 0.7147\n",
            "INFO:__main__:Task 292dd178: Accuracy = 0.9081, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 29700607: Accuracy = 0.9619, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 2a5f8217: Accuracy = 0.9774, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 2b01abd0: Accuracy = 0.9707, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 2c0b0aff: Accuracy = 0.9119, Diff Accuracy = 0.7577\n",
            "INFO:__main__:Task 2c737e39: Accuracy = 0.9841, Diff Accuracy = 0.1365\n",
            "INFO:__main__:Task 2f0c5170: Accuracy = 0.9674, Diff Accuracy = 0.9186\n",
            "INFO:__main__:Task 310f3251: Accuracy = 0.9700, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 3194b014: Accuracy = 0.9770, Diff Accuracy = 0.9225\n",
            "INFO:__main__:Task 319f2597: Accuracy = 0.6278, Diff Accuracy = 0.9736\n",
            "INFO:__main__:Task 31adaf00: Accuracy = 0.9307, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 31d5ba1a: Accuracy = 0.9929, Diff Accuracy = 0.6541\n",
            "INFO:__main__:Task 32e9702f: Accuracy = 0.9548, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 332efdb3: Accuracy = 0.9533, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 3391f8c0: Accuracy = 0.9825, Diff Accuracy = 0.3542\n",
            "INFO:__main__:Task 33b52de3: Accuracy = 0.8539, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 3490cc26: Accuracy = 0.9061, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 34b99a2b: Accuracy = 0.9883, Diff Accuracy = 0.6297\n",
            "INFO:__main__:Task 351d6448: Accuracy = 0.9928, Diff Accuracy = 0.8858\n",
            "INFO:__main__:Task 358ba94e: Accuracy = 0.9744, Diff Accuracy = 0.8644\n",
            "INFO:__main__:Task 37d3e8b2: Accuracy = 0.8789, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 3979b1a8: Accuracy = 0.8889, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 3a301edc: Accuracy = 0.9024, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 3b4c2228: Accuracy = 0.9980, Diff Accuracy = 0.8947\n",
            "INFO:__main__:Task 3d31c5b3: Accuracy = 0.9794, Diff Accuracy = 0.6079\n",
            "INFO:__main__:Task 3ed85e70: Accuracy = 0.6381, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 3ee1011a: Accuracy = 0.9537, Diff Accuracy = 0.2064\n",
            "INFO:__main__:Task 3f23242b: Accuracy = 0.9550, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 40f6cd08: Accuracy = 0.6270, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 414297c0: Accuracy = 0.8959, Diff Accuracy = 0.4696\n",
            "INFO:__main__:Task 423a55dc: Accuracy = 0.9856, Diff Accuracy = 0.5216\n",
            "INFO:__main__:Task 42918530: Accuracy = 0.8158, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 42a15761: Accuracy = 0.9063, Diff Accuracy = 0.5000\n",
            "INFO:__main__:Task 4364c1c4: Accuracy = 0.8178, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 456873bc: Accuracy = 0.9515, Diff Accuracy = 0.7704\n",
            "INFO:__main__:Task 45737921: Accuracy = 0.9733, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 45bbe264: Accuracy = 0.9330, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 477d2879: Accuracy = 0.8122, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 47996f11: Accuracy = 0.1383, Diff Accuracy = 0.1062\n",
            "INFO:__main__:Task 48131b3c: Accuracy = 0.9733, Diff Accuracy = 0.1129\n",
            "INFO:__main__:Task 4852f2fa: Accuracy = 0.9853, Diff Accuracy = 0.3608\n",
            "INFO:__main__:Task 48f8583b: Accuracy = 0.9798, Diff Accuracy = 0.2963\n",
            "INFO:__main__:Task 4aab4007: Accuracy = 0.1289, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 4acc7107: Accuracy = 0.9758, Diff Accuracy = 0.4824\n",
            "INFO:__main__:Task 4b6b68e5: Accuracy = 0.8622, Diff Accuracy = 0.0379\n",
            "INFO:__main__:Task 4c177718: Accuracy = 0.9872, Diff Accuracy = 0.7472\n",
            "INFO:__main__:Task 4cd1b7b2: Accuracy = 0.9822, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 4e45f183: Accuracy = 0.7507, Diff Accuracy = 0.0139\n",
            "INFO:__main__:Task 4e469f39: Accuracy = 0.9663, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 4f537728: Accuracy = 0.7972, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 4ff4c9da: Accuracy = 0.6259, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 505fff84: Accuracy = 0.9913, Diff Accuracy = 0.8910\n",
            "INFO:__main__:Task 506d28a5: Accuracy = 0.9822, Diff Accuracy = 0.4775\n",
            "INFO:__main__:Task 50a16a69: Accuracy = 0.8159, Diff Accuracy = 0.0400\n",
            "INFO:__main__:Task 50aad11f: Accuracy = 0.9785, Diff Accuracy = 0.4671\n",
            "INFO:__main__:Task 50f325b5: Accuracy = 0.8019, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 516b51b7: Accuracy = 0.9189, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 5207a7b5: Accuracy = 0.9559, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 5289ad53: Accuracy = 0.9756, Diff Accuracy = 0.8811\n",
            "INFO:__main__:Task 52fd389e: Accuracy = 0.7137, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 54db823b: Accuracy = 0.9067, Diff Accuracy = 1.0000\n",
            "INFO:__main__:Task 55059096: Accuracy = 0.9744, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 551d5bf1: Accuracy = 0.7644, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 55783887: Accuracy = 0.8462, Diff Accuracy = 0.1000\n",
            "INFO:__main__:Task 575b1a71: Accuracy = 0.8889, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 5783df64: Accuracy = 0.9900, Diff Accuracy = 0.4583\n",
            "INFO:__main__:Task 5833af48: Accuracy = 0.8826, Diff Accuracy = 0.6010\n",
            "INFO:__main__:Task 58743b76: Accuracy = 0.9472, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 58e15b12: Accuracy = 0.9170, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 59341089: Accuracy = 0.9603, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 5a5a2103: Accuracy = 0.8194, Diff Accuracy = 0.0455\n",
            "INFO:__main__:Task 5af49b42: Accuracy = 0.9737, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 5b526a93: Accuracy = 0.9067, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 5b692c0f: Accuracy = 0.9133, Diff Accuracy = 0.2386\n",
            "INFO:__main__:Task 5b6cbef5: Accuracy = 0.9198, Diff Accuracy = 0.0909\n",
            "INFO:__main__:Task 5d2a5c43: Accuracy = 0.9784, Diff Accuracy = 0.4777\n",
            "INFO:__main__:Task 5ffb2104: Accuracy = 0.9874, Diff Accuracy = 0.4902\n",
            "INFO:__main__:Task 604001fa: Accuracy = 0.9819, Diff Accuracy = 0.2735\n",
            "INFO:__main__:Task 60a26a3e: Accuracy = 0.9719, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 60c09cac: Accuracy = 0.9822, Diff Accuracy = 0.0278\n",
            "INFO:__main__:Task 626c0bcc: Accuracy = 0.9826, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 62ab2642: Accuracy = 0.9367, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 62b74c02: Accuracy = 0.9559, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 639f5a19: Accuracy = 0.7778, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 642248e4: Accuracy = 0.9570, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 642d658d: Accuracy = 0.9611, Diff Accuracy = 0.9284\n",
            "INFO:__main__:Task 64a7c07e: Accuracy = 0.9893, Diff Accuracy = 0.5000\n",
            "INFO:__main__:Task 66e6c45b: Accuracy = 0.9956, Diff Accuracy = 0.5000\n",
            "INFO:__main__:Task 66f2d22f: Accuracy = 0.9919, Diff Accuracy = 0.7562\n",
            "INFO:__main__:Task 67636eac: Accuracy = 0.9863, Diff Accuracy = 0.4667\n",
            "INFO:__main__:Task 67b4a34d: Accuracy = 0.9696, Diff Accuracy = 0.9138\n",
            "INFO:__main__:Task 67c52801: Accuracy = 0.9786, Diff Accuracy = 0.5000\n",
            "INFO:__main__:Task 68b67ca3: Accuracy = 0.9944, Diff Accuracy = 0.5000\n",
            "INFO:__main__:Task 692cd3b6: Accuracy = 0.9007, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 695367ec: Accuracy = 0.8937, Diff Accuracy = 0.0555\n",
            "INFO:__main__:Task 696d4842: Accuracy = 0.9626, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 69889d6e: Accuracy = 0.9806, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 6a11f6da: Accuracy = 0.9758, Diff Accuracy = 0.5782\n",
            "INFO:__main__:Task 6ad5bdfd: Accuracy = 0.9815, Diff Accuracy = 0.4577\n",
            "INFO:__main__:Task 6df30ad6: Accuracy = 0.9918, Diff Accuracy = 0.5457\n",
            "INFO:__main__:Task 6ea4a07e: Accuracy = 0.9937, Diff Accuracy = 0.3704\n",
            "INFO:__main__:Task 6f473927: Accuracy = 0.9678, Diff Accuracy = 0.2138\n",
            "INFO:__main__:Task 7039b2d7: Accuracy = 0.9841, Diff Accuracy = 0.9843\n",
            "INFO:__main__:Task 705a3229: Accuracy = 0.9844, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 712bf12e: Accuracy = 0.9170, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 72207abc: Accuracy = 0.9926, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 72a961c9: Accuracy = 0.9844, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 73182012: Accuracy = 0.9881, Diff Accuracy = 0.8835\n",
            "INFO:__main__:Task 73c3b0d8: Accuracy = 0.9869, Diff Accuracy = 0.2958\n",
            "INFO:__main__:Task 73ccf9c2: Accuracy = 0.9881, Diff Accuracy = 0.8364\n",
            "INFO:__main__:Task 759f3fd3: Accuracy = 0.8428, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 762cd429: Accuracy = 0.8119, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 770cc55f: Accuracy = 0.9769, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 782b5218: Accuracy = 0.9344, Diff Accuracy = 0.4674\n",
            "INFO:__main__:Task 79369cc6: Accuracy = 0.8041, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 7953d61e: Accuracy = 0.9289, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 79fb03f4: Accuracy = 0.9383, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 7bb29440: Accuracy = 0.9736, Diff Accuracy = 0.8472\n",
            "INFO:__main__:Task 7c8af763: Accuracy = 0.8889, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 7c9b52a0: Accuracy = 0.9074, Diff Accuracy = 0.6269\n",
            "INFO:__main__:Task 7d18a6fb: Accuracy = 0.9770, Diff Accuracy = 0.7752\n",
            "INFO:__main__:Task 7d1f7ee8: Accuracy = 0.8326, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 7d419a02: Accuracy = 0.8511, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 7e02026e: Accuracy = 0.9000, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 7ee1c6ea: Accuracy = 0.9133, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 817e6c09: Accuracy = 0.9760, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 81c0276b: Accuracy = 0.9933, Diff Accuracy = 0.9544\n",
            "INFO:__main__:Task 833dafe3: Accuracy = 0.9644, Diff Accuracy = 0.0733\n",
            "INFO:__main__:Task 845d6e51: Accuracy = 0.9478, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 84db8fc4: Accuracy = 0.8889, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 84f2aca1: Accuracy = 0.9650, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 8597cfd7: Accuracy = 0.9956, Diff Accuracy = 0.8174\n",
            "INFO:__main__:Task 85b81ff1: Accuracy = 0.8750, Diff Accuracy = 0.5000\n",
            "INFO:__main__:Task 85fa5666: Accuracy = 0.9622, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 8719f442: Accuracy = 0.9422, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 88207623: Accuracy = 0.9389, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 891232d6: Accuracy = 0.8897, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 896d5239: Accuracy = 0.8826, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 8a371977: Accuracy = 0.4389, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 8b28cd80: Accuracy = 0.9489, Diff Accuracy = 0.0173\n",
            "INFO:__main__:Task 8ba14f53: Accuracy = 0.9939, Diff Accuracy = 0.8179\n",
            "INFO:__main__:Task 8cb8642d: Accuracy = 0.9296, Diff Accuracy = 0.7093\n",
            "INFO:__main__:Task 8dae5dfc: Accuracy = 0.8264, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 8e2edd66: Accuracy = 0.9815, Diff Accuracy = 0.2587\n",
            "INFO:__main__:Task 8ee62060: Accuracy = 0.9789, Diff Accuracy = 0.5000\n",
            "INFO:__main__:Task 8fbca751: Accuracy = 0.9659, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 90347967: Accuracy = 0.9933, Diff Accuracy = 0.5000\n",
            "INFO:__main__:Task 903d1b4a: Accuracy = 0.7156, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 9110e3c5: Accuracy = 0.9960, Diff Accuracy = 0.8651\n",
            "INFO:__main__:Task 917bccba: Accuracy = 0.9644, Diff Accuracy = 0.6146\n",
            "INFO:__main__:Task 929ab4e9: Accuracy = 0.3614, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 92e50de0: Accuracy = 0.6678, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 9356391f: Accuracy = 0.9067, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 93b4f4b3: Accuracy = 0.9233, Diff Accuracy = 0.4080\n",
            "INFO:__main__:Task 93c31fbe: Accuracy = 0.9400, Diff Accuracy = 0.3983\n",
            "INFO:__main__:Task 94133066: Accuracy = 0.8922, Diff Accuracy = 0.4846\n",
            "INFO:__main__:Task 94414823: Accuracy = 0.9578, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 94be5b80: Accuracy = 0.9411, Diff Accuracy = 0.2946\n",
            "INFO:__main__:Task 95a58926: Accuracy = 0.8615, Diff Accuracy = 0.5746\n",
            "INFO:__main__:Task 963f59bc: Accuracy = 0.9786, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 96a8c0cd: Accuracy = 0.9350, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 97239e3d: Accuracy = 0.7989, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 9772c176: Accuracy = 0.7478, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 981571dc: Accuracy = 0.0003, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 992798f6: Accuracy = 0.9864, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 99306f82: Accuracy = 0.9163, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 9a4bb226: Accuracy = 0.9889, Diff Accuracy = 0.7706\n",
            "INFO:__main__:Task 9b2a60aa: Accuracy = 0.9659, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 9b365c51: Accuracy = 0.9670, Diff Accuracy = 0.4442\n",
            "INFO:__main__:Task 9b4c17c4: Accuracy = 0.8147, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 9bebae7a: Accuracy = 0.9787, Diff Accuracy = 0.3364\n",
            "INFO:__main__:Task 9c1e755f: Accuracy = 0.9461, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 9c56f360: Accuracy = 0.9737, Diff Accuracy = 0.5000\n",
            "INFO:__main__:Task 9caba7c3: Accuracy = 0.7659, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 9ddd00f0: Accuracy = 0.9533, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 9def23fe: Accuracy = 0.8311, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 9f27f097: Accuracy = 0.8400, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task a04b2602: Accuracy = 0.8178, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task a096bf4d: Accuracy = 0.7333, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task a3f84088: Accuracy = 0.8686, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task a406ac07: Accuracy = 0.9581, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task a57f2f04: Accuracy = 0.6633, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task a59b95c0: Accuracy = 0.9160, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task a680ac02: Accuracy = 0.9644, Diff Accuracy = 0.6502\n",
            "INFO:__main__:Task a8610ef7: Accuracy = 0.9767, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task a934301b: Accuracy = 0.9674, Diff Accuracy = 1.0000\n",
            "INFO:__main__:Task aa18de87: Accuracy = 0.9792, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task aa300dc3: Accuracy = 0.9306, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task aa4ec2a5: Accuracy = 0.4374, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task aab50785: Accuracy = 0.9871, Diff Accuracy = 0.9003\n",
            "INFO:__main__:Task ac0c5833: Accuracy = 0.9519, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task ac2e8ecf: Accuracy = 0.9530, Diff Accuracy = 0.4784\n",
            "INFO:__main__:Task ac3e2b04: Accuracy = 0.9386, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task ac605cbb: Accuracy = 0.9876, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task ad7e01d0: Accuracy = 0.9144, Diff Accuracy = 0.0851\n",
            "INFO:__main__:Task ae58858e: Accuracy = 0.9783, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task aee291af: Accuracy = 0.9763, Diff Accuracy = 0.9403\n",
            "INFO:__main__:Task af22c60d: Accuracy = 0.0000, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task af24b4cc: Accuracy = 0.9930, Diff Accuracy = 0.8560\n",
            "INFO:__main__:Task b0722778: Accuracy = 0.9844, Diff Accuracy = 0.7230\n",
            "INFO:__main__:Task b0f4d537: Accuracy = 0.9722, Diff Accuracy = 0.6135\n",
            "INFO:__main__:Task b15fca0b: Accuracy = 0.9676, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task b1fc8b8e: Accuracy = 0.9851, Diff Accuracy = 0.4875\n",
            "INFO:__main__:Task b20f7c8b: Accuracy = 0.7707, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task b457fec5: Accuracy = 0.9137, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task b4a43f3b: Accuracy = 0.9633, Diff Accuracy = 0.4690\n",
            "INFO:__main__:Task b7999b51: Accuracy = 0.9900, Diff Accuracy = 0.8587\n",
            "INFO:__main__:Task b7cb93ac: Accuracy = 0.9867, Diff Accuracy = 0.4815\n",
            "INFO:__main__:Task b7f8a4d8: Accuracy = 0.6400, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task b7fb29bc: Accuracy = 0.9100, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task b942fd60: Accuracy = 0.9667, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task b9630600: Accuracy = 0.8437, Diff Accuracy = 0.3881\n",
            "INFO:__main__:Task ba9d41b8: Accuracy = 0.9163, Diff Accuracy = 1.0000\n",
            "INFO:__main__:Task baf41dbf: Accuracy = 0.9593, Diff Accuracy = 0.2050\n",
            "INFO:__main__:Task bb52a14b: Accuracy = 0.9189, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task bbb1b8b6: Accuracy = 0.9852, Diff Accuracy = 0.5396\n",
            "INFO:__main__:Task bc4146bd: Accuracy = 0.9111, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task bcb3040b: Accuracy = 0.9196, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task bd14c3bf: Accuracy = 0.9211, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task be03b35f: Accuracy = 0.9970, Diff Accuracy = 0.8111\n",
            "INFO:__main__:Task bf32578f: Accuracy = 0.9881, Diff Accuracy = 0.3822\n",
            "INFO:__main__:Task bf699163: Accuracy = 0.9900, Diff Accuracy = 0.9721\n",
            "INFO:__main__:Task bf89d739: Accuracy = 0.9781, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task c074846d: Accuracy = 0.9949, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task c1990cce: Accuracy = 0.9785, Diff Accuracy = 0.0740\n",
            "INFO:__main__:Task c3202e5a: Accuracy = 0.9930, Diff Accuracy = 0.9741\n",
            "INFO:__main__:Task c35c1b4c: Accuracy = 0.9144, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task c48954c1: Accuracy = 0.9100, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task c62e2108: Accuracy = 0.8963, Diff Accuracy = 0.0433\n",
            "INFO:__main__:Task c64f1187: Accuracy = 0.9689, Diff Accuracy = 0.6881\n",
            "INFO:__main__:Task c658a4bd: Accuracy = 0.9194, Diff Accuracy = 0.3749\n",
            "INFO:__main__:Task c663677b: Accuracy = 0.1900, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task c6e1b8da: Accuracy = 0.8537, Diff Accuracy = 0.4505\n",
            "INFO:__main__:Task c7d4e6ad: Accuracy = 0.9778, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task c87289bb: Accuracy = 0.9436, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task c8b7cc0f: Accuracy = 0.9956, Diff Accuracy = 0.8881\n",
            "INFO:__main__:Task c92b942c: Accuracy = 0.9175, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task c97c0139: Accuracy = 0.9156, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task ca8de6ea: Accuracy = 0.9900, Diff Accuracy = 0.3333\n",
            "INFO:__main__:Task ca8f78db: Accuracy = 0.0000, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task cad67732: Accuracy = 0.9741, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task cb227835: Accuracy = 0.9793, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task ccd554ac: Accuracy = 0.9307, Diff Accuracy = 0.0256\n",
            "INFO:__main__:Task cd3c21df: Accuracy = 0.9948, Diff Accuracy = 0.8213\n",
            "INFO:__main__:Task ce039d91: Accuracy = 0.9775, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task ce8d95cc: Accuracy = 0.9803, Diff Accuracy = 0.7195\n",
            "INFO:__main__:Task cf133acc: Accuracy = 0.9370, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task cfb2ce5a: Accuracy = 0.9326, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task d017b73f: Accuracy = 0.9883, Diff Accuracy = 0.5000\n",
            "INFO:__main__:Task d19f7514: Accuracy = 0.9808, Diff Accuracy = 0.4938\n",
            "INFO:__main__:Task d282b262: Accuracy = 0.9678, Diff Accuracy = 0.4774\n",
            "INFO:__main__:Task d2acf2cb: Accuracy = 0.9552, Diff Accuracy = 0.0952\n",
            "INFO:__main__:Task d304284e: Accuracy = 0.8761, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task d37a1ef5: Accuracy = 0.9344, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task d47aa2ff: Accuracy = 0.9896, Diff Accuracy = 0.7235\n",
            "INFO:__main__:Task d492a647: Accuracy = 0.8811, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task d4b1c2b1: Accuracy = 0.9443, Diff Accuracy = 0.2857\n",
            "INFO:__main__:Task d4c90558: Accuracy = 0.9830, Diff Accuracy = 0.9063\n",
            "INFO:__main__:Task d56f2372: Accuracy = 0.9867, Diff Accuracy = 0.8060\n",
            "INFO:__main__:Task d5c634a2: Accuracy = 0.9954, Diff Accuracy = 0.7885\n",
            "INFO:__main__:Task d931c21c: Accuracy = 0.9108, Diff Accuracy = 0.2500\n",
            "INFO:__main__:Task d94c3b52: Accuracy = 0.8415, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task da2b0fe3: Accuracy = 0.9707, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task da515329: Accuracy = 0.8374, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task dc2aa30b: Accuracy = 0.9100, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task dc2e9a9d: Accuracy = 0.9233, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task dd2401ed: Accuracy = 0.9811, Diff Accuracy = 0.4363\n",
            "INFO:__main__:Task de493100: Accuracy = 0.2511, Diff Accuracy = 0.2521\n",
            "INFO:__main__:Task df8cc377: Accuracy = 0.9493, Diff Accuracy = 0.5000\n",
            "INFO:__main__:Task e0fb7511: Accuracy = 0.8315, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task e133d23d: Accuracy = 0.9927, Diff Accuracy = 0.5035\n",
            "INFO:__main__:Task e1baa8a4: Accuracy = 0.9894, Diff Accuracy = 0.9602\n",
            "INFO:__main__:Task e1d2900e: Accuracy = 0.9778, Diff Accuracy = 0.5000\n",
            "INFO:__main__:Task e2092e0c: Accuracy = 0.8867, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task e21a174a: Accuracy = 0.9563, Diff Accuracy = 0.2549\n",
            "INFO:__main__:Task e345f17b: Accuracy = 0.9961, Diff Accuracy = 0.8138\n",
            "INFO:__main__:Task e4075551: Accuracy = 0.9433, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task e41c6fd3: Accuracy = 0.9363, Diff Accuracy = 0.5000\n",
            "INFO:__main__:Task e57337a4: Accuracy = 0.8763, Diff Accuracy = 0.5170\n",
            "INFO:__main__:Task e5790162: Accuracy = 0.9884, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task e5c44e8f: Accuracy = 0.9456, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task e619ca6e: Accuracy = 0.8763, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task e633a9e5: Accuracy = 0.9722, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task e66aafb8: Accuracy = 0.9509, Diff Accuracy = 0.9256\n",
            "INFO:__main__:Task e681b708: Accuracy = 0.8870, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task e69241bd: Accuracy = 0.9433, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task e6de6e8f: Accuracy = 0.9878, Diff Accuracy = 0.5444\n",
            "INFO:__main__:Task e74e1818: Accuracy = 0.9674, Diff Accuracy = 0.5000\n",
            "INFO:__main__:Task e760a62e: Accuracy = 0.6181, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task e7639916: Accuracy = 0.9644, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task e78887d1: Accuracy = 0.9794, Diff Accuracy = 0.6878\n",
            "INFO:__main__:Task e7a25a18: Accuracy = 0.9244, Diff Accuracy = 0.2172\n",
            "INFO:__main__:Task e7b06bea: Accuracy = 0.9871, Diff Accuracy = 0.7000\n",
            "INFO:__main__:Task e7dd8335: Accuracy = 0.9785, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task e872b94a: Accuracy = 1.0000, Diff Accuracy = 1.0000\n",
            "INFO:__main__:Task e88171ec: Accuracy = 0.8096, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task e95e3d8e: Accuracy = 0.4622, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task e99362f0: Accuracy = 0.9785, Diff Accuracy = 0.7147\n",
            "INFO:__main__:Task e9ac8c9e: Accuracy = 0.9793, Diff Accuracy = 0.2667\n",
            "INFO:__main__:Task e9b4f6fc: Accuracy = 0.9619, Diff Accuracy = 0.4449\n",
            "INFO:__main__:Task e9bb6954: Accuracy = 0.9031, Diff Accuracy = 0.0032\n",
            "INFO:__main__:Task e9c9d9a1: Accuracy = 0.8204, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task ea959feb: Accuracy = 0.3889, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task ea9794b1: Accuracy = 0.9730, Diff Accuracy = 0.6472\n",
            "INFO:__main__:Task ecaa0ec1: Accuracy = 0.9894, Diff Accuracy = 0.4877\n",
            "INFO:__main__:Task ed74f2f2: Accuracy = 0.9935, Diff Accuracy = 0.5953\n",
            "INFO:__main__:Task ed98d772: Accuracy = 0.9778, Diff Accuracy = 0.1051\n",
            "INFO:__main__:Task ef26cbf6: Accuracy = 0.9533, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task f0afb749: Accuracy = 0.9822, Diff Accuracy = 0.0617\n",
            "INFO:__main__:Task f0df5ff0: Accuracy = 0.8670, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task f21745ec: Accuracy = 0.8878, Diff Accuracy = 0.4961\n",
            "INFO:__main__:Task f3b10344: Accuracy = 0.7115, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task f3cdc58f: Accuracy = 0.9785, Diff Accuracy = 0.4478\n",
            "INFO:__main__:Task f3e62deb: Accuracy = 0.9911, Diff Accuracy = 0.5000\n",
            "INFO:__main__:Task f4081712: Accuracy = 0.9236, Diff Accuracy = 0.8869\n",
            "INFO:__main__:Task f45f5ca7: Accuracy = 0.9919, Diff Accuracy = 0.5000\n",
            "INFO:__main__:Task f5aa3634: Accuracy = 0.9911, Diff Accuracy = 0.8053\n",
            "INFO:__main__:Task f5c89df1: Accuracy = 0.9830, Diff Accuracy = 0.4373\n",
            "INFO:__main__:Task f823c43c: Accuracy = 0.7617, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task f83cb3f6: Accuracy = 0.9807, Diff Accuracy = 0.6050\n",
            "INFO:__main__:Task f8be4b64: Accuracy = 0.9094, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task f9a67cb5: Accuracy = 0.9263, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task f9d67f8b: Accuracy = 0.1578, Diff Accuracy = 0.1353\n",
            "INFO:__main__:Task fafd9572: Accuracy = 0.9700, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task fb791726: Accuracy = 0.9610, Diff Accuracy = 0.0361\n",
            "INFO:__main__:Task fc754716: Accuracy = 0.9844, Diff Accuracy = 0.0736\n",
            "INFO:__main__:Task fd096ab6: Accuracy = 0.4111, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task fd4b2b02: Accuracy = 0.9122, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task fe9372f3: Accuracy = 0.9600, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task fea12743: Accuracy = 0.9289, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task ff72ca3e: Accuracy = 0.9647, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task avg: Accuracy = 0.9048, Diff Accuracy = 0.2692\n",
            "DEBUG:__main__:DEBUG: Data to be saved: {'aggregate_results': {'test_loss': 0.3664872646331787, 'test_accuracy': 0.904828667640686, 'test_diff_accuracy': 0.2692205607891083, 'complete_task_accuracy': 0.2344139650872818}, 'individual_metrics': {'00576224': {'test_accuracy': 0.9599999785423279, 'test_diff_accuracy': 0.0}, '009d5c81': {'test_accuracy': 0.9744443893432617, 'test_diff_accuracy': 0.21003207564353943}, '00dbd492': {'test_accuracy': 0.929444432258606, 'test_diff_accuracy': 0.0}, '03560426': {'test_accuracy': 0.9796295762062073, 'test_diff_accuracy': 0.5188145637512207}, '05a7bcf2': {'test_accuracy': 0.6566666960716248, 'test_diff_accuracy': 0.0}, '0607ce86': {'test_accuracy': 0.7966666221618652, 'test_diff_accuracy': 0.6599085927009583}, '0692e18c': {'test_accuracy': 0.9785184860229492, 'test_diff_accuracy': 0.16984127461910248}, '070dd51e': {'test_accuracy': 0.9611111283302307, 'test_diff_accuracy': 0.0}, '08573cc6': {'test_accuracy': 0.962592601776123, 'test_diff_accuracy': 0.06767676770687103}, '0934a4d8': {'test_accuracy': 0.37638890743255615, 'test_diff_accuracy': 0.37773966789245605}, '09c534e7': {'test_accuracy': 0.7877777218818665, 'test_diff_accuracy': 0.0}, '0a1d4ef5': {'test_accuracy': 0.9511110782623291, 'test_diff_accuracy': 0.9168465733528137}, '0a2355a6': {'test_accuracy': 0.9394444823265076, 'test_diff_accuracy': 0.0}, '0b17323b': {'test_accuracy': 0.9938889145851135, 'test_diff_accuracy': 0.0}, '0bb8deee': {'test_accuracy': 0.9788889288902283, 'test_diff_accuracy': 0.6813034415245056}, '0becf7df': {'test_accuracy': 0.9744444489479065, 'test_diff_accuracy': 0.0}, '0c786b71': {'test_accuracy': 0.9466666579246521, 'test_diff_accuracy': 0.0}, '0c9aba6e': {'test_accuracy': 0.9916666746139526, 'test_diff_accuracy': 0.747855007648468}, '0d87d2a6': {'test_accuracy': 0.9055555462837219, 'test_diff_accuracy': 0.0}, '0e671a1a': {'test_accuracy': 0.9724999666213989, 'test_diff_accuracy': 0.0}, '0f63c0b9': {'test_accuracy': 0.8908333778381348, 'test_diff_accuracy': 0.0}, '103eff5b': {'test_accuracy': 0.9416666626930237, 'test_diff_accuracy': 0.0}, '11e1fe23': {'test_accuracy': 0.992222249507904, 'test_diff_accuracy': 0.0}, '12422b43': {'test_accuracy': 0.9788888692855835, 'test_diff_accuracy': 0.0}, '12997ef3': {'test_accuracy': 0.9844444394111633, 'test_diff_accuracy': 0.3445091247558594}, '12eac192': {'test_accuracy': 0.9725000262260437, 'test_diff_accuracy': 0.0}, '136b0064': {'test_accuracy': 0.9822222590446472, 'test_diff_accuracy': 0.711358368396759}, '13713586': {'test_accuracy': 0.859259307384491, 'test_diff_accuracy': 0.0}, '137f0df0': {'test_accuracy': 0.9185185432434082, 'test_diff_accuracy': 0.0}, '140c817e': {'test_accuracy': 0.8625926375389099, 'test_diff_accuracy': 0.0}, '14754a24': {'test_accuracy': 0.8630555272102356, 'test_diff_accuracy': 0.0}, '15113be4': {'test_accuracy': 0.6255555748939514, 'test_diff_accuracy': 0.0}, '15663ba9': {'test_accuracy': 0.9422222971916199, 'test_diff_accuracy': 0.0}, '15696249': {'test_accuracy': 0.9700000286102295, 'test_diff_accuracy': 0.1875}, '16b78196': {'test_accuracy': 0.7916666865348816, 'test_diff_accuracy': 0.4842342138290405}, '17b80ad2': {'test_accuracy': 0.9611111283302307, 'test_diff_accuracy': 0.0}, '17cae0c1': {'test_accuracy': 0.9700000286102295, 'test_diff_accuracy': 0.0}, '18419cfa': {'test_accuracy': 0.9344444274902344, 'test_diff_accuracy': 0.0}, '184a9768': {'test_accuracy': 0.8522222638130188, 'test_diff_accuracy': 0.575104296207428}, '195ba7dc': {'test_accuracy': 0.9758332967758179, 'test_diff_accuracy': 0.5054347515106201}, '1990f7a8': {'test_accuracy': 0.9740740656852722, 'test_diff_accuracy': 0.5}, '19bb5feb': {'test_accuracy': 0.9729630351066589, 'test_diff_accuracy': 0.7311635613441467}, '1a2e2828': {'test_accuracy': 0.9986666440963745, 'test_diff_accuracy': 0.9834964871406555}, '1a6449f1': {'test_accuracy': 0.9829629063606262, 'test_diff_accuracy': 0.9130600094795227}, '1acc24af': {'test_accuracy': 0.964722216129303, 'test_diff_accuracy': 0.0}, '1c02dbbe': {'test_accuracy': 0.860370397567749, 'test_diff_accuracy': 0.06207104027271271}, '1c0d0a4b': {'test_accuracy': 0.9825925827026367, 'test_diff_accuracy': 0.595678985118866}, '1c56ad9f': {'test_accuracy': 0.9541666507720947, 'test_diff_accuracy': 0.5}, '1d0a4b61': {'test_accuracy': 0.3055555522441864, 'test_diff_accuracy': 0.0}, '1d398264': {'test_accuracy': 0.9462962746620178, 'test_diff_accuracy': 0.0}, '1da012fc': {'test_accuracy': 0.9105556011199951, 'test_diff_accuracy': 0.0}, '1e81d6f9': {'test_accuracy': 0.9681481719017029, 'test_diff_accuracy': 1.0}, '1e97544e': {'test_accuracy': 0.41296300292015076, 'test_diff_accuracy': 0.0}, '2037f2c7': {'test_accuracy': 0.9900000095367432, 'test_diff_accuracy': 0.9334214329719543}, '2072aba6': {'test_accuracy': 0.9807407259941101, 'test_diff_accuracy': 0.01587301678955555}, '20818e16': {'test_accuracy': 0.9385185241699219, 'test_diff_accuracy': 0.723113477230072}, '20981f0e': {'test_accuracy': 0.9681481719017029, 'test_diff_accuracy': 0.5}, '212895b5': {'test_accuracy': 0.9196296334266663, 'test_diff_accuracy': 0.0}, '21f83797': {'test_accuracy': 0.9238889217376709, 'test_diff_accuracy': 0.0}, '22a4bbc2': {'test_accuracy': 0.9433333277702332, 'test_diff_accuracy': 0.0}, '25094a63': {'test_accuracy': 0.1827777773141861, 'test_diff_accuracy': 0.0}, '2546ccf6': {'test_accuracy': 0.8550000190734863, 'test_diff_accuracy': 0.0}, '256b0a75': {'test_accuracy': 0.6666666865348816, 'test_diff_accuracy': 0.0}, '2685904e': {'test_accuracy': 0.965925931930542, 'test_diff_accuracy': 0.0}, '2697da3f': {'test_accuracy': 0.9511110782623291, 'test_diff_accuracy': 0.16602009534835815}, '2753e76c': {'test_accuracy': 0.9900000095367432, 'test_diff_accuracy': 0.899422824382782}, '27a77e38': {'test_accuracy': 0.9807407259941101, 'test_diff_accuracy': 0.0}, '27f8ce4f': {'test_accuracy': 0.9650000333786011, 'test_diff_accuracy': 0.11249999701976776}, '281123b4': {'test_accuracy': 0.9829630255699158, 'test_diff_accuracy': 0.7146536707878113}, '292dd178': {'test_accuracy': 0.9081481099128723, 'test_diff_accuracy': 0.0}, '29700607': {'test_accuracy': 0.9618518948554993, 'test_diff_accuracy': 0.0}, '2a5f8217': {'test_accuracy': 0.9774073958396912, 'test_diff_accuracy': 0.0}, '2b01abd0': {'test_accuracy': 0.970740795135498, 'test_diff_accuracy': 0.0}, '2c0b0aff': {'test_accuracy': 0.9119444489479065, 'test_diff_accuracy': 0.7577368021011353}, '2c737e39': {'test_accuracy': 0.9840741157531738, 'test_diff_accuracy': 0.13650794327259064}, '2f0c5170': {'test_accuracy': 0.9674074053764343, 'test_diff_accuracy': 0.9186174869537354}, '310f3251': {'test_accuracy': 0.9700000882148743, 'test_diff_accuracy': 0.0}, '3194b014': {'test_accuracy': 0.9770370125770569, 'test_diff_accuracy': 0.9225044250488281}, '319f2597': {'test_accuracy': 0.6277777552604675, 'test_diff_accuracy': 0.9736223220825195}, '31adaf00': {'test_accuracy': 0.9307407736778259, 'test_diff_accuracy': 0.0}, '31d5ba1a': {'test_accuracy': 0.9928889274597168, 'test_diff_accuracy': 0.6540936231613159}, '32e9702f': {'test_accuracy': 0.9548148512840271, 'test_diff_accuracy': 0.0}, '332efdb3': {'test_accuracy': 0.9533333778381348, 'test_diff_accuracy': 0.0}, '3391f8c0': {'test_accuracy': 0.9824999570846558, 'test_diff_accuracy': 0.3541666865348816}, '33b52de3': {'test_accuracy': 0.8538888692855835, 'test_diff_accuracy': 0.0}, '3490cc26': {'test_accuracy': 0.9061111211776733, 'test_diff_accuracy': 0.0}, '34b99a2b': {'test_accuracy': 0.9883333444595337, 'test_diff_accuracy': 0.629668653011322}, '351d6448': {'test_accuracy': 0.9927777647972107, 'test_diff_accuracy': 0.8858424425125122}, '358ba94e': {'test_accuracy': 0.9744444489479065, 'test_diff_accuracy': 0.8644062280654907}, '37d3e8b2': {'test_accuracy': 0.8788889050483704, 'test_diff_accuracy': 0.0}, '3979b1a8': {'test_accuracy': 0.8888888955116272, 'test_diff_accuracy': 0.0}, '3a301edc': {'test_accuracy': 0.9024444818496704, 'test_diff_accuracy': 0.0}, '3b4c2228': {'test_accuracy': 0.9979999661445618, 'test_diff_accuracy': 0.8947456479072571}, '3d31c5b3': {'test_accuracy': 0.9794444441795349, 'test_diff_accuracy': 0.6079409122467041}, '3ed85e70': {'test_accuracy': 0.6381481885910034, 'test_diff_accuracy': 0.0}, '3ee1011a': {'test_accuracy': 0.9537037014961243, 'test_diff_accuracy': 0.20636117458343506}, '3f23242b': {'test_accuracy': 0.9550000429153442, 'test_diff_accuracy': 0.0}, '40f6cd08': {'test_accuracy': 0.6270370483398438, 'test_diff_accuracy': 0.0}, '414297c0': {'test_accuracy': 0.8959259390830994, 'test_diff_accuracy': 0.4695725440979004}, '423a55dc': {'test_accuracy': 0.9855555295944214, 'test_diff_accuracy': 0.5216470956802368}, '42918530': {'test_accuracy': 0.815833330154419, 'test_diff_accuracy': 0.0}, '42a15761': {'test_accuracy': 0.9062963128089905, 'test_diff_accuracy': 0.5}, '4364c1c4': {'test_accuracy': 0.8177778124809265, 'test_diff_accuracy': 0.0}, '456873bc': {'test_accuracy': 0.9514815211296082, 'test_diff_accuracy': 0.7703775763511658}, '45737921': {'test_accuracy': 0.9733333587646484, 'test_diff_accuracy': 0.0}, '45bbe264': {'test_accuracy': 0.932962954044342, 'test_diff_accuracy': 0.0}, '477d2879': {'test_accuracy': 0.8122222423553467, 'test_diff_accuracy': 0.0}, '47996f11': {'test_accuracy': 0.13833333551883698, 'test_diff_accuracy': 0.10620684921741486}, '48131b3c': {'test_accuracy': 0.9733333587646484, 'test_diff_accuracy': 0.11290545016527176}, '4852f2fa': {'test_accuracy': 0.9853333234786987, 'test_diff_accuracy': 0.36084944009780884}, '48f8583b': {'test_accuracy': 0.9798148274421692, 'test_diff_accuracy': 0.29629629850387573}, '4aab4007': {'test_accuracy': 0.12888889014720917, 'test_diff_accuracy': 0.0}, '4acc7107': {'test_accuracy': 0.9758333563804626, 'test_diff_accuracy': 0.4823917746543884}, '4b6b68e5': {'test_accuracy': 0.8622221946716309, 'test_diff_accuracy': 0.03787878900766373}, '4c177718': {'test_accuracy': 0.9872222542762756, 'test_diff_accuracy': 0.7471552491188049}, '4cd1b7b2': {'test_accuracy': 0.9822222590446472, 'test_diff_accuracy': 0.0}, '4e45f183': {'test_accuracy': 0.7507407665252686, 'test_diff_accuracy': 0.013888888992369175}, '4e469f39': {'test_accuracy': 0.9662962555885315, 'test_diff_accuracy': 0.0}, '4f537728': {'test_accuracy': 0.7972222566604614, 'test_diff_accuracy': 0.0}, '4ff4c9da': {'test_accuracy': 0.6259259581565857, 'test_diff_accuracy': 0.0}, '505fff84': {'test_accuracy': 0.9913333654403687, 'test_diff_accuracy': 0.8910254240036011}, '506d28a5': {'test_accuracy': 0.9822221994400024, 'test_diff_accuracy': 0.47752460837364197}, '50a16a69': {'test_accuracy': 0.8159258961677551, 'test_diff_accuracy': 0.03999999910593033}, '50aad11f': {'test_accuracy': 0.9785184860229492, 'test_diff_accuracy': 0.4671497642993927}, '50f325b5': {'test_accuracy': 0.801944375038147, 'test_diff_accuracy': 0.0}, '516b51b7': {'test_accuracy': 0.9188888669013977, 'test_diff_accuracy': 0.0}, '5207a7b5': {'test_accuracy': 0.9559259414672852, 'test_diff_accuracy': 0.0}, '5289ad53': {'test_accuracy': 0.9755555391311646, 'test_diff_accuracy': 0.8811259269714355}, '52fd389e': {'test_accuracy': 0.7137036323547363, 'test_diff_accuracy': 0.0}, '54db823b': {'test_accuracy': 0.9066666960716248, 'test_diff_accuracy': 1.0}, '55059096': {'test_accuracy': 0.9744443893432617, 'test_diff_accuracy': 0.0}, '551d5bf1': {'test_accuracy': 0.7644444704055786, 'test_diff_accuracy': 0.0}, '55783887': {'test_accuracy': 0.8462222218513489, 'test_diff_accuracy': 0.10000000149011612}, '575b1a71': {'test_accuracy': 0.8888888955116272, 'test_diff_accuracy': 0.0}, '5783df64': {'test_accuracy': 0.9900000095367432, 'test_diff_accuracy': 0.45825162529945374}, '5833af48': {'test_accuracy': 0.8825926184654236, 'test_diff_accuracy': 0.6010026335716248}, '58743b76': {'test_accuracy': 0.9472222328186035, 'test_diff_accuracy': 0.0}, '58e15b12': {'test_accuracy': 0.9170370697975159, 'test_diff_accuracy': 0.0}, '59341089': {'test_accuracy': 0.960277795791626, 'test_diff_accuracy': 0.0}, '5a5a2103': {'test_accuracy': 0.8194444179534912, 'test_diff_accuracy': 0.04545454680919647}, '5af49b42': {'test_accuracy': 0.9737036824226379, 'test_diff_accuracy': 0.0}, '5b526a93': {'test_accuracy': 0.90666663646698, 'test_diff_accuracy': 0.0}, '5b692c0f': {'test_accuracy': 0.9133332967758179, 'test_diff_accuracy': 0.23863637447357178}, '5b6cbef5': {'test_accuracy': 0.9197778701782227, 'test_diff_accuracy': 0.09092767536640167}, '5d2a5c43': {'test_accuracy': 0.9784444570541382, 'test_diff_accuracy': 0.47774338722229004}, '5ffb2104': {'test_accuracy': 0.987407386302948, 'test_diff_accuracy': 0.4901960790157318}, '604001fa': {'test_accuracy': 0.9819444417953491, 'test_diff_accuracy': 0.2735389471054077}, '60a26a3e': {'test_accuracy': 0.9718518257141113, 'test_diff_accuracy': 0.0}, '60c09cac': {'test_accuracy': 0.9822221994400024, 'test_diff_accuracy': 0.02777777798473835}, '626c0bcc': {'test_accuracy': 0.9825925827026367, 'test_diff_accuracy': 0.0}, '62ab2642': {'test_accuracy': 0.93666672706604, 'test_diff_accuracy': 0.0}, '62b74c02': {'test_accuracy': 0.9559259414672852, 'test_diff_accuracy': 0.0}, '639f5a19': {'test_accuracy': 0.7777777910232544, 'test_diff_accuracy': 0.0}, '642248e4': {'test_accuracy': 0.9570370316505432, 'test_diff_accuracy': 0.0}, '642d658d': {'test_accuracy': 0.9611111283302307, 'test_diff_accuracy': 0.9283973574638367}, '64a7c07e': {'test_accuracy': 0.9892592430114746, 'test_diff_accuracy': 0.5}, '66e6c45b': {'test_accuracy': 0.995555579662323, 'test_diff_accuracy': 0.5}, '66f2d22f': {'test_accuracy': 0.991944432258606, 'test_diff_accuracy': 0.7562196850776672}, '67636eac': {'test_accuracy': 0.9862963557243347, 'test_diff_accuracy': 0.46666666865348816}, '67b4a34d': {'test_accuracy': 0.9696295857429504, 'test_diff_accuracy': 0.9138374328613281}, '67c52801': {'test_accuracy': 0.9786111116409302, 'test_diff_accuracy': 0.5}, '68b67ca3': {'test_accuracy': 0.9944444298744202, 'test_diff_accuracy': 0.5}, '692cd3b6': {'test_accuracy': 0.9007408022880554, 'test_diff_accuracy': 0.0}, '695367ec': {'test_accuracy': 0.8937036991119385, 'test_diff_accuracy': 0.05552127584815025}, '696d4842': {'test_accuracy': 0.962592601776123, 'test_diff_accuracy': 0.0}, '69889d6e': {'test_accuracy': 0.980555534362793, 'test_diff_accuracy': 0.0}, '6a11f6da': {'test_accuracy': 0.975777804851532, 'test_diff_accuracy': 0.5782161355018616}, '6ad5bdfd': {'test_accuracy': 0.9814814925193787, 'test_diff_accuracy': 0.45766592025756836}, '6df30ad6': {'test_accuracy': 0.991777777671814, 'test_diff_accuracy': 0.5457017421722412}, '6ea4a07e': {'test_accuracy': 0.9937036633491516, 'test_diff_accuracy': 0.37037038803100586}, '6f473927': {'test_accuracy': 0.9677777886390686, 'test_diff_accuracy': 0.21378621459007263}, '7039b2d7': {'test_accuracy': 0.9840741157531738, 'test_diff_accuracy': 0.9842607378959656}, '705a3229': {'test_accuracy': 0.9844444394111633, 'test_diff_accuracy': 0.0}, '712bf12e': {'test_accuracy': 0.9170370101928711, 'test_diff_accuracy': 0.0}, '72207abc': {'test_accuracy': 0.9925925731658936, 'test_diff_accuracy': 0.0}, '72a961c9': {'test_accuracy': 0.9844444990158081, 'test_diff_accuracy': 0.0}, '73182012': {'test_accuracy': 0.9881481528282166, 'test_diff_accuracy': 0.8835263848304749}, '73c3b0d8': {'test_accuracy': 0.9869444370269775, 'test_diff_accuracy': 0.2957516312599182}, '73ccf9c2': {'test_accuracy': 0.9881481528282166, 'test_diff_accuracy': 0.8363578915596008}, '759f3fd3': {'test_accuracy': 0.8427777886390686, 'test_diff_accuracy': 0.0}, '762cd429': {'test_accuracy': 0.8118519186973572, 'test_diff_accuracy': 0.0}, '770cc55f': {'test_accuracy': 0.9769444465637207, 'test_diff_accuracy': 0.0}, '782b5218': {'test_accuracy': 0.9344444274902344, 'test_diff_accuracy': 0.4673832952976227}, '79369cc6': {'test_accuracy': 0.8040741086006165, 'test_diff_accuracy': 0.0}, '7953d61e': {'test_accuracy': 0.9288889169692993, 'test_diff_accuracy': 0.0}, '79fb03f4': {'test_accuracy': 0.93833327293396, 'test_diff_accuracy': 0.0}, '7bb29440': {'test_accuracy': 0.9735555648803711, 'test_diff_accuracy': 0.8471860885620117}, '7c8af763': {'test_accuracy': 0.8888888955116272, 'test_diff_accuracy': 0.0}, '7c9b52a0': {'test_accuracy': 0.9074074625968933, 'test_diff_accuracy': 0.6268526911735535}, '7d18a6fb': {'test_accuracy': 0.9770370125770569, 'test_diff_accuracy': 0.7752125263214111}, '7d1f7ee8': {'test_accuracy': 0.8325925469398499, 'test_diff_accuracy': 0.0}, '7d419a02': {'test_accuracy': 0.851111114025116, 'test_diff_accuracy': 0.0}, '7e02026e': {'test_accuracy': 0.9000000357627869, 'test_diff_accuracy': 0.0}, '7ee1c6ea': {'test_accuracy': 0.9133333563804626, 'test_diff_accuracy': 0.0}, '817e6c09': {'test_accuracy': 0.9760000109672546, 'test_diff_accuracy': 0.0}, '81c0276b': {'test_accuracy': 0.9933333396911621, 'test_diff_accuracy': 0.9544203281402588}, '833dafe3': {'test_accuracy': 0.9644444584846497, 'test_diff_accuracy': 0.07334525883197784}, '845d6e51': {'test_accuracy': 0.9477777481079102, 'test_diff_accuracy': 0.0}, '84db8fc4': {'test_accuracy': 0.8888888955116272, 'test_diff_accuracy': 0.0}, '84f2aca1': {'test_accuracy': 0.9650000333786011, 'test_diff_accuracy': 0.0}, '8597cfd7': {'test_accuracy': 0.995555579662323, 'test_diff_accuracy': 0.8174242377281189}, '85b81ff1': {'test_accuracy': 0.875, 'test_diff_accuracy': 0.5}, '85fa5666': {'test_accuracy': 0.9622222185134888, 'test_diff_accuracy': 0.0}, '8719f442': {'test_accuracy': 0.9422221779823303, 'test_diff_accuracy': 0.0}, '88207623': {'test_accuracy': 0.9388889074325562, 'test_diff_accuracy': 0.0}, '891232d6': {'test_accuracy': 0.8897222280502319, 'test_diff_accuracy': 0.0}, '896d5239': {'test_accuracy': 0.8825926184654236, 'test_diff_accuracy': 0.0}, '8a371977': {'test_accuracy': 0.43888890743255615, 'test_diff_accuracy': 0.0}, '8b28cd80': {'test_accuracy': 0.948888897895813, 'test_diff_accuracy': 0.017298799008131027}, '8ba14f53': {'test_accuracy': 0.9938888549804688, 'test_diff_accuracy': 0.8179367184638977}, '8cb8642d': {'test_accuracy': 0.9296296238899231, 'test_diff_accuracy': 0.7093300819396973}, '8dae5dfc': {'test_accuracy': 0.8263888359069824, 'test_diff_accuracy': 0.0}, '8e2edd66': {'test_accuracy': 0.9814814925193787, 'test_diff_accuracy': 0.2586754262447357}, '8ee62060': {'test_accuracy': 0.9788889288902283, 'test_diff_accuracy': 0.5}, '8fbca751': {'test_accuracy': 0.9659258723258972, 'test_diff_accuracy': 0.0}, '90347967': {'test_accuracy': 0.9933333396911621, 'test_diff_accuracy': 0.5}, '903d1b4a': {'test_accuracy': 0.7155555486679077, 'test_diff_accuracy': 0.0}, '9110e3c5': {'test_accuracy': 0.9960317611694336, 'test_diff_accuracy': 0.8651400804519653}, '917bccba': {'test_accuracy': 0.9644444584846497, 'test_diff_accuracy': 0.6146110892295837}, '929ab4e9': {'test_accuracy': 0.3613888919353485, 'test_diff_accuracy': 0.0}, '92e50de0': {'test_accuracy': 0.6677777767181396, 'test_diff_accuracy': 0.0}, '9356391f': {'test_accuracy': 0.90666663646698, 'test_diff_accuracy': 0.0}, '93b4f4b3': {'test_accuracy': 0.9233333468437195, 'test_diff_accuracy': 0.40796583890914917}, '93c31fbe': {'test_accuracy': 0.9399999976158142, 'test_diff_accuracy': 0.3983488082885742}, '94133066': {'test_accuracy': 0.8922222256660461, 'test_diff_accuracy': 0.48462045192718506}, '94414823': {'test_accuracy': 0.9577777981758118, 'test_diff_accuracy': 0.0}, '94be5b80': {'test_accuracy': 0.9411110877990723, 'test_diff_accuracy': 0.2946428656578064}, '95a58926': {'test_accuracy': 0.8614814877510071, 'test_diff_accuracy': 0.5745627284049988}, '963f59bc': {'test_accuracy': 0.9786111116409302, 'test_diff_accuracy': 0.0}, '96a8c0cd': {'test_accuracy': 0.9350000023841858, 'test_diff_accuracy': 0.0}, '97239e3d': {'test_accuracy': 0.7988889217376709, 'test_diff_accuracy': 0.0}, '9772c176': {'test_accuracy': 0.7477777600288391, 'test_diff_accuracy': 0.0}, '981571dc': {'test_accuracy': 0.00027777778450399637, 'test_diff_accuracy': 0.0}, '992798f6': {'test_accuracy': 0.9863889217376709, 'test_diff_accuracy': 0.0}, '99306f82': {'test_accuracy': 0.9162963032722473, 'test_diff_accuracy': 0.0}, '9a4bb226': {'test_accuracy': 0.9888889193534851, 'test_diff_accuracy': 0.7706348896026611}, '9b2a60aa': {'test_accuracy': 0.965925931930542, 'test_diff_accuracy': 0.0}, '9b365c51': {'test_accuracy': 0.9670370221138, 'test_diff_accuracy': 0.444180965423584}, '9b4c17c4': {'test_accuracy': 0.8147222995758057, 'test_diff_accuracy': 0.0}, '9bebae7a': {'test_accuracy': 0.9786666631698608, 'test_diff_accuracy': 0.33641454577445984}, '9c1e755f': {'test_accuracy': 0.9461110830307007, 'test_diff_accuracy': 0.0}, '9c56f360': {'test_accuracy': 0.9737036824226379, 'test_diff_accuracy': 0.5}, '9caba7c3': {'test_accuracy': 0.7659258842468262, 'test_diff_accuracy': 0.0}, '9ddd00f0': {'test_accuracy': 0.9533333778381348, 'test_diff_accuracy': 0.0}, '9def23fe': {'test_accuracy': 0.8311111330986023, 'test_diff_accuracy': 0.0}, '9f27f097': {'test_accuracy': 0.8399999737739563, 'test_diff_accuracy': 0.0}, 'a04b2602': {'test_accuracy': 0.8177778124809265, 'test_diff_accuracy': 0.0}, 'a096bf4d': {'test_accuracy': 0.7333333492279053, 'test_diff_accuracy': 0.0}, 'a3f84088': {'test_accuracy': 0.8686110973358154, 'test_diff_accuracy': 0.0}, 'a406ac07': {'test_accuracy': 0.958148181438446, 'test_diff_accuracy': 0.0}, 'a57f2f04': {'test_accuracy': 0.6633333563804626, 'test_diff_accuracy': 0.0}, 'a59b95c0': {'test_accuracy': 0.9160000085830688, 'test_diff_accuracy': 0.0}, 'a680ac02': {'test_accuracy': 0.9644444584846497, 'test_diff_accuracy': 0.6501501202583313}, 'a8610ef7': {'test_accuracy': 0.9766666889190674, 'test_diff_accuracy': 0.0}, 'a934301b': {'test_accuracy': 0.9674074053764343, 'test_diff_accuracy': 1.0}, 'aa18de87': {'test_accuracy': 0.9791666269302368, 'test_diff_accuracy': 0.0}, 'aa300dc3': {'test_accuracy': 0.930555522441864, 'test_diff_accuracy': 0.0}, 'aa4ec2a5': {'test_accuracy': 0.43740740418434143, 'test_diff_accuracy': 0.0}, 'aab50785': {'test_accuracy': 0.9871110916137695, 'test_diff_accuracy': 0.9002954363822937}, 'ac0c5833': {'test_accuracy': 0.9518518447875977, 'test_diff_accuracy': 0.0}, 'ac2e8ecf': {'test_accuracy': 0.9529629349708557, 'test_diff_accuracy': 0.4784134328365326}, 'ac3e2b04': {'test_accuracy': 0.9386110901832581, 'test_diff_accuracy': 0.0}, 'ac605cbb': {'test_accuracy': 0.9875926375389099, 'test_diff_accuracy': 0.0}, 'ad7e01d0': {'test_accuracy': 0.9144444465637207, 'test_diff_accuracy': 0.08509097993373871}, 'ae58858e': {'test_accuracy': 0.9783333539962769, 'test_diff_accuracy': 0.0}, 'aee291af': {'test_accuracy': 0.9762962460517883, 'test_diff_accuracy': 0.9403367638587952}, 'af22c60d': {'test_accuracy': 0.0, 'test_diff_accuracy': 0.0}, 'af24b4cc': {'test_accuracy': 0.9929630160331726, 'test_diff_accuracy': 0.8559829592704773}, 'b0722778': {'test_accuracy': 0.9844444394111633, 'test_diff_accuracy': 0.7229965329170227}, 'b0f4d537': {'test_accuracy': 0.9722222089767456, 'test_diff_accuracy': 0.6134893894195557}, 'b15fca0b': {'test_accuracy': 0.9675555229187012, 'test_diff_accuracy': 0.0}, 'b1fc8b8e': {'test_accuracy': 0.9851110577583313, 'test_diff_accuracy': 0.48750001192092896}, 'b20f7c8b': {'test_accuracy': 0.7707407474517822, 'test_diff_accuracy': 0.0}, 'b457fec5': {'test_accuracy': 0.9137037396430969, 'test_diff_accuracy': 0.0}, 'b4a43f3b': {'test_accuracy': 0.9633333086967468, 'test_diff_accuracy': 0.46900829672813416}, 'b7999b51': {'test_accuracy': 0.9900000095367432, 'test_diff_accuracy': 0.8587267994880676}, 'b7cb93ac': {'test_accuracy': 0.9866666793823242, 'test_diff_accuracy': 0.4814814627170563}, 'b7f8a4d8': {'test_accuracy': 0.6399999856948853, 'test_diff_accuracy': 0.0}, 'b7fb29bc': {'test_accuracy': 0.9100000262260437, 'test_diff_accuracy': 0.0}, 'b942fd60': {'test_accuracy': 0.9666666984558105, 'test_diff_accuracy': 0.0}, 'b9630600': {'test_accuracy': 0.8437037467956543, 'test_diff_accuracy': 0.3881119191646576}, 'ba9d41b8': {'test_accuracy': 0.9162963032722473, 'test_diff_accuracy': 1.0}, 'baf41dbf': {'test_accuracy': 0.9592592716217041, 'test_diff_accuracy': 0.20501208305358887}, 'bb52a14b': {'test_accuracy': 0.9188888669013977, 'test_diff_accuracy': 0.0}, 'bbb1b8b6': {'test_accuracy': 0.9852380156517029, 'test_diff_accuracy': 0.5396488308906555}, 'bc4146bd': {'test_accuracy': 0.9111111164093018, 'test_diff_accuracy': 0.0}, 'bcb3040b': {'test_accuracy': 0.9196296334266663, 'test_diff_accuracy': 0.0}, 'bd14c3bf': {'test_accuracy': 0.9211111068725586, 'test_diff_accuracy': 0.0}, 'be03b35f': {'test_accuracy': 0.9970369935035706, 'test_diff_accuracy': 0.8111111521720886}, 'bf32578f': {'test_accuracy': 0.9881481528282166, 'test_diff_accuracy': 0.3821733891963959}, 'bf699163': {'test_accuracy': 0.9900000095367432, 'test_diff_accuracy': 0.9721251130104065}, 'bf89d739': {'test_accuracy': 0.9780555367469788, 'test_diff_accuracy': 0.0}, 'c074846d': {'test_accuracy': 0.9948889017105103, 'test_diff_accuracy': 0.0}, 'c1990cce': {'test_accuracy': 0.9785184860229492, 'test_diff_accuracy': 0.07402319461107254}, 'c3202e5a': {'test_accuracy': 0.9929630160331726, 'test_diff_accuracy': 0.9741120338439941}, 'c35c1b4c': {'test_accuracy': 0.9144444465637207, 'test_diff_accuracy': 0.0}, 'c48954c1': {'test_accuracy': 0.9100000262260437, 'test_diff_accuracy': 0.0}, 'c62e2108': {'test_accuracy': 0.8962963223457336, 'test_diff_accuracy': 0.04329491779208183}, 'c64f1187': {'test_accuracy': 0.9688888788223267, 'test_diff_accuracy': 0.6881044507026672}, 'c658a4bd': {'test_accuracy': 0.9194444417953491, 'test_diff_accuracy': 0.37494730949401855}, 'c663677b': {'test_accuracy': 0.1899999976158142, 'test_diff_accuracy': 0.0}, 'c6e1b8da': {'test_accuracy': 0.8537037372589111, 'test_diff_accuracy': 0.45049849152565}, 'c7d4e6ad': {'test_accuracy': 0.9777777791023254, 'test_diff_accuracy': 0.0}, 'c87289bb': {'test_accuracy': 0.9436111450195312, 'test_diff_accuracy': 0.0}, 'c8b7cc0f': {'test_accuracy': 0.995555579662323, 'test_diff_accuracy': 0.8881499767303467}, 'c92b942c': {'test_accuracy': 0.9175000190734863, 'test_diff_accuracy': 0.0}, 'c97c0139': {'test_accuracy': 0.9155555963516235, 'test_diff_accuracy': 0.0}, 'ca8de6ea': {'test_accuracy': 0.9900000095367432, 'test_diff_accuracy': 0.3333333432674408}, 'ca8f78db': {'test_accuracy': 0.0, 'test_diff_accuracy': 0.0}, 'cad67732': {'test_accuracy': 0.9740740656852722, 'test_diff_accuracy': 0.0}, 'cb227835': {'test_accuracy': 0.9792592525482178, 'test_diff_accuracy': 0.0}, 'ccd554ac': {'test_accuracy': 0.9307406544685364, 'test_diff_accuracy': 0.02556818164885044}, 'cd3c21df': {'test_accuracy': 0.9948148727416992, 'test_diff_accuracy': 0.8213383555412292}, 'ce039d91': {'test_accuracy': 0.9774999618530273, 'test_diff_accuracy': 0.0}, 'ce8d95cc': {'test_accuracy': 0.9802777767181396, 'test_diff_accuracy': 0.7194792032241821}, 'cf133acc': {'test_accuracy': 0.9370369911193848, 'test_diff_accuracy': 0.0}, 'cfb2ce5a': {'test_accuracy': 0.9325925707817078, 'test_diff_accuracy': 0.0}, 'd017b73f': {'test_accuracy': 0.9883332848548889, 'test_diff_accuracy': 0.5}, 'd19f7514': {'test_accuracy': 0.9808333516120911, 'test_diff_accuracy': 0.4937748610973358}, 'd282b262': {'test_accuracy': 0.9677777290344238, 'test_diff_accuracy': 0.4773857891559601}, 'd2acf2cb': {'test_accuracy': 0.9551851749420166, 'test_diff_accuracy': 0.095238097012043}, 'd304284e': {'test_accuracy': 0.8761111497879028, 'test_diff_accuracy': 0.0}, 'd37a1ef5': {'test_accuracy': 0.9344444274902344, 'test_diff_accuracy': 0.0}, 'd47aa2ff': {'test_accuracy': 0.9896295666694641, 'test_diff_accuracy': 0.7235023379325867}, 'd492a647': {'test_accuracy': 0.8811111450195312, 'test_diff_accuracy': 0.0}, 'd4b1c2b1': {'test_accuracy': 0.9442857503890991, 'test_diff_accuracy': 0.2857142984867096}, 'd4c90558': {'test_accuracy': 0.9829629063606262, 'test_diff_accuracy': 0.9063237309455872}, 'd56f2372': {'test_accuracy': 0.9866666793823242, 'test_diff_accuracy': 0.8060207962989807}, 'd5c634a2': {'test_accuracy': 0.9953967928886414, 'test_diff_accuracy': 0.7885443568229675}, 'd931c21c': {'test_accuracy': 0.9108333587646484, 'test_diff_accuracy': 0.25}, 'd94c3b52': {'test_accuracy': 0.8414815068244934, 'test_diff_accuracy': 0.0}, 'da2b0fe3': {'test_accuracy': 0.9707407355308533, 'test_diff_accuracy': 0.0}, 'da515329': {'test_accuracy': 0.8374074101448059, 'test_diff_accuracy': 0.0}, 'dc2aa30b': {'test_accuracy': 0.9100000262260437, 'test_diff_accuracy': 0.0}, 'dc2e9a9d': {'test_accuracy': 0.9233333468437195, 'test_diff_accuracy': 0.0}, 'dd2401ed': {'test_accuracy': 0.9811111092567444, 'test_diff_accuracy': 0.43627452850341797}, 'de493100': {'test_accuracy': 0.25111111998558044, 'test_diff_accuracy': 0.2521111071109772}, 'df8cc377': {'test_accuracy': 0.9492592811584473, 'test_diff_accuracy': 0.5}, 'e0fb7511': {'test_accuracy': 0.8314814567565918, 'test_diff_accuracy': 0.0}, 'e133d23d': {'test_accuracy': 0.9926666021347046, 'test_diff_accuracy': 0.5035164952278137}, 'e1baa8a4': {'test_accuracy': 0.9894444942474365, 'test_diff_accuracy': 0.9602466225624084}, 'e1d2900e': {'test_accuracy': 0.9777777194976807, 'test_diff_accuracy': 0.5}, 'e2092e0c': {'test_accuracy': 0.8866667151451111, 'test_diff_accuracy': 0.0}, 'e21a174a': {'test_accuracy': 0.9562962651252747, 'test_diff_accuracy': 0.254934161901474}, 'e345f17b': {'test_accuracy': 0.9961110949516296, 'test_diff_accuracy': 0.8137826919555664}, 'e4075551': {'test_accuracy': 0.9433333277702332, 'test_diff_accuracy': 0.0}, 'e41c6fd3': {'test_accuracy': 0.936296284198761, 'test_diff_accuracy': 0.5}, 'e57337a4': {'test_accuracy': 0.8762962818145752, 'test_diff_accuracy': 0.5169753432273865}, 'e5790162': {'test_accuracy': 0.988444447517395, 'test_diff_accuracy': 0.0}, 'e5c44e8f': {'test_accuracy': 0.9455555081367493, 'test_diff_accuracy': 0.0}, 'e619ca6e': {'test_accuracy': 0.8762962818145752, 'test_diff_accuracy': 0.0}, 'e633a9e5': {'test_accuracy': 0.9722221493721008, 'test_diff_accuracy': 0.0}, 'e66aafb8': {'test_accuracy': 0.9508889317512512, 'test_diff_accuracy': 0.9255886077880859}, 'e681b708': {'test_accuracy': 0.8870370388031006, 'test_diff_accuracy': 0.0}, 'e69241bd': {'test_accuracy': 0.9433333277702332, 'test_diff_accuracy': 0.0}, 'e6de6e8f': {'test_accuracy': 0.9877777695655823, 'test_diff_accuracy': 0.5444445013999939}, 'e74e1818': {'test_accuracy': 0.9674074053764343, 'test_diff_accuracy': 0.5}, 'e760a62e': {'test_accuracy': 0.618148148059845, 'test_diff_accuracy': 0.0}, 'e7639916': {'test_accuracy': 0.9644444584846497, 'test_diff_accuracy': 0.0}, 'e78887d1': {'test_accuracy': 0.9794444441795349, 'test_diff_accuracy': 0.6878482103347778}, 'e7a25a18': {'test_accuracy': 0.9244444370269775, 'test_diff_accuracy': 0.2172304391860962}, 'e7b06bea': {'test_accuracy': 0.9871110916137695, 'test_diff_accuracy': 0.7000000476837158}, 'e7dd8335': {'test_accuracy': 0.9785184860229492, 'test_diff_accuracy': 0.0}, 'e872b94a': {'test_accuracy': 1.0, 'test_diff_accuracy': 1.0}, 'e88171ec': {'test_accuracy': 0.8096296787261963, 'test_diff_accuracy': 0.0}, 'e95e3d8e': {'test_accuracy': 0.46222221851348877, 'test_diff_accuracy': 0.0}, 'e99362f0': {'test_accuracy': 0.978518545627594, 'test_diff_accuracy': 0.7147099375724792}, 'e9ac8c9e': {'test_accuracy': 0.9792592525482178, 'test_diff_accuracy': 0.2666666805744171}, 'e9b4f6fc': {'test_accuracy': 0.9619444012641907, 'test_diff_accuracy': 0.44486111402511597}, 'e9bb6954': {'test_accuracy': 0.9030555486679077, 'test_diff_accuracy': 0.0032051282469183207}, 'e9c9d9a1': {'test_accuracy': 0.8203703761100769, 'test_diff_accuracy': 0.0}, 'ea959feb': {'test_accuracy': 0.3888889253139496, 'test_diff_accuracy': 0.0}, 'ea9794b1': {'test_accuracy': 0.9729629158973694, 'test_diff_accuracy': 0.647230327129364}, 'ecaa0ec1': {'test_accuracy': 0.9894444346427917, 'test_diff_accuracy': 0.48773449659347534}, 'ed74f2f2': {'test_accuracy': 0.9935185313224792, 'test_diff_accuracy': 0.5953373312950134}, 'ed98d772': {'test_accuracy': 0.9777777791023254, 'test_diff_accuracy': 0.10508663952350616}, 'ef26cbf6': {'test_accuracy': 0.95333331823349, 'test_diff_accuracy': 0.0}, 'f0afb749': {'test_accuracy': 0.9822222590446472, 'test_diff_accuracy': 0.061728399246931076}, 'f0df5ff0': {'test_accuracy': 0.8670370578765869, 'test_diff_accuracy': 0.0}, 'f21745ec': {'test_accuracy': 0.8877778053283691, 'test_diff_accuracy': 0.4960607588291168}, 'f3b10344': {'test_accuracy': 0.711481511592865, 'test_diff_accuracy': 0.0}, 'f3cdc58f': {'test_accuracy': 0.9785184860229492, 'test_diff_accuracy': 0.44780412316322327}, 'f3e62deb': {'test_accuracy': 0.9911110997200012, 'test_diff_accuracy': 0.5}, 'f4081712': {'test_accuracy': 0.9235555529594421, 'test_diff_accuracy': 0.8869382739067078}, 'f45f5ca7': {'test_accuracy': 0.9918518662452698, 'test_diff_accuracy': 0.5}, 'f5aa3634': {'test_accuracy': 0.9911110997200012, 'test_diff_accuracy': 0.8053030371665955}, 'f5c89df1': {'test_accuracy': 0.9829629063606262, 'test_diff_accuracy': 0.437296062707901}, 'f823c43c': {'test_accuracy': 0.7616666555404663, 'test_diff_accuracy': 0.0}, 'f83cb3f6': {'test_accuracy': 0.9807407259941101, 'test_diff_accuracy': 0.6049907803535461}, 'f8be4b64': {'test_accuracy': 0.9094444513320923, 'test_diff_accuracy': 0.0}, 'f9a67cb5': {'test_accuracy': 0.9262962937355042, 'test_diff_accuracy': 0.0}, 'f9d67f8b': {'test_accuracy': 0.15777777135372162, 'test_diff_accuracy': 0.13529807329177856}, 'fafd9572': {'test_accuracy': 0.9700000286102295, 'test_diff_accuracy': 0.0}, 'fb791726': {'test_accuracy': 0.961017370223999, 'test_diff_accuracy': 0.03614457696676254}, 'fc754716': {'test_accuracy': 0.9844443798065186, 'test_diff_accuracy': 0.07361919432878494}, 'fd096ab6': {'test_accuracy': 0.41111111640930176, 'test_diff_accuracy': 0.0}, 'fd4b2b02': {'test_accuracy': 0.9122222065925598, 'test_diff_accuracy': 0.0}, 'fe9372f3': {'test_accuracy': 0.9600000977516174, 'test_diff_accuracy': 0.0}, 'fea12743': {'test_accuracy': 0.9288887977600098, 'test_diff_accuracy': 0.0}, 'ff72ca3e': {'test_accuracy': 0.9647221565246582, 'test_diff_accuracy': 0.0}, 'avg': {'test_accuracy': 0.904828667640686, 'test_diff_accuracy': 0.2692205607891083}}, 'model_summary': '   | Name                        | Type             | Params | Mode\\n-------------------------------------------------------------------------\\n0  | conv1                       | Conv2d           | 2.6 K  | eval\\n1  | blocks                      | ModuleList       | 1.6 M  | eval\\n2  | blocks.0                    | TransformerBlock | 789 K  | eval\\n3  | blocks.0.attention          | Attention        | 263 K  | eval\\n4  | blocks.0.attention.key      | Linear           | 65.8 K | eval\\n5  | blocks.0.attention.query    | Linear           | 65.8 K | eval\\n6  | blocks.0.attention.value    | Linear           | 65.8 K | eval\\n7  | blocks.0.attention.proj     | Linear           | 65.8 K | eval\\n8  | blocks.0.feed_forward       | FeedForward      | 525 K  | eval\\n9  | blocks.0.feed_forward.net   | Sequential       | 525 K  | eval\\n10 | blocks.0.feed_forward.net.0 | Linear           | 263 K  | eval\\n11 | blocks.0.feed_forward.net.1 | ReLU             | 0      | eval\\n12 | blocks.0.feed_forward.net.2 | Linear           | 262 K  | eval\\n13 | blocks.0.ln1                | LayerNorm        | 512    | eval\\n14 | blocks.0.ln2                | LayerNorm        | 512    | eval\\n15 | blocks.1                    | TransformerBlock | 789 K  | eval\\n16 | blocks.1.attention          | Attention        | 263 K  | eval\\n17 | blocks.1.attention.key      | Linear           | 65.8 K | eval\\n18 | blocks.1.attention.query    | Linear           | 65.8 K | eval\\n19 | blocks.1.attention.value    | Linear           | 65.8 K | eval\\n20 | blocks.1.attention.proj     | Linear           | 65.8 K | eval\\n21 | blocks.1.feed_forward       | FeedForward      | 525 K  | eval\\n22 | blocks.1.feed_forward.net   | Sequential       | 525 K  | eval\\n23 | blocks.1.feed_forward.net.0 | Linear           | 263 K  | eval\\n24 | blocks.1.feed_forward.net.1 | ReLU             | 0      | eval\\n25 | blocks.1.feed_forward.net.2 | Linear           | 262 K  | eval\\n26 | blocks.1.ln1                | LayerNorm        | 512    | eval\\n27 | blocks.1.ln2                | LayerNorm        | 512    | eval\\n28 | ln_f                        | LayerNorm        | 512    | eval\\n29 | fc_out                      | Linear           | 2.6 K  | eval\\n-------------------------------------------------------------------------\\n1.6 M     Trainable params\\n0         Non-trainable params\\n1.6 M     Total params\\n6.341     Total estimated model params size (MB)\\n0         Modules in train mode\\n30        Modules in eval mode'}\n",
            "INFO:__main__:Results saved to evaluation_results/arc_model-epoch_00-val_loss_0_eval_results_20240928_231928.json\n",
            "DEBUG:__main__:Creating wandb Artifact with name: arc_model-epoch_00-val_loss_0\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
            "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/11\" 200 None\n",
            "DEBUG:__main__:Artifact created and logged successfully.\n",
            "wandb: - 0.049 MB of 0.049 MB uploaded\n",
            "wandb: \\ 1.217 MB of 1.217 MB uploaded\n",
            "wandb: | 1.217 MB of 1.217 MB uploaded\n",
            "wandb: / 1.217 MB of 1.217 MB uploaded\n",
            "wandb: - 1.218 MB of 1.218 MB uploaded\n",
            "wandb:                                                                                \n",
            "wandb: \n",
            "wandb: Run history:\n",
            "wandb: eval/complete_task_accuracy ▁\n",
            "wandb:          eval/test_accuracy ▁\n",
            "wandb:     eval/test_diff_accuracy ▁\n",
            "wandb:              eval/test_loss ▁\n",
            "wandb: \n",
            "wandb: Run summary:\n",
            "wandb: eval/complete_task_accuracy 0.23441\n",
            "wandb:          eval/test_accuracy 0.90483\n",
            "wandb:     eval/test_diff_accuracy 0.26922\n",
            "wandb:              eval/test_loss 0.36649\n",
            "wandb: \n",
            "wandb: 🚀 View run scaling-test-evaluation-epoch00-val_loss0.37 at: https://wandb.ai/arc-abolition/arc-evaluation/runs/q0tv1k44\n",
            "wandb: ⭐️ View project at: https://wandb.ai/arc-abolition/arc-evaluation\n",
            "wandb: Synced 4 W&B file(s), 0 media file(s), 5 artifact file(s) and 0 other file(s)\n",
            "wandb: Find logs at: ./wandb/run-20240928_231726-q0tv1k44/logs\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): o151352.ingest.sentry.io:443\n",
            "DEBUG:urllib3.connectionpool:https://o151352.ingest.sentry.io:443 \"POST /api/4504800232407040/envelope/ HTTP/11\" 200 0\n",
            "\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: ['/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt']\n",
            "Current models: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "New models to evaluate: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "Skipping already evaluated model: arc_model-epoch=00-val_loss=0.37.ckpt\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: ['/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt']\n",
            "Current models: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "New models to evaluate: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "Skipping already evaluated model: arc_model-epoch=00-val_loss=0.37.ckpt\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: ['/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt']\n",
            "Current models: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "New models to evaluate: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "Skipping already evaluated model: arc_model-epoch=00-val_loss=0.37.ckpt\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: ['/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt']\n",
            "Current models: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "New models to evaluate: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "Skipping already evaluated model: arc_model-epoch=00-val_loss=0.37.ckpt\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: ['/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt']\n",
            "Current models: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "New models to evaluate: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "Skipping already evaluated model: arc_model-epoch=00-val_loss=0.37.ckpt\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: ['/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt']\n",
            "Current models: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "New models to evaluate: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "Skipping already evaluated model: arc_model-epoch=00-val_loss=0.37.ckpt\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: ['/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt']\n",
            "Current models: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "New models to evaluate: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "Skipping already evaluated model: arc_model-epoch=00-val_loss=0.37.ckpt\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: ['/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt']\n",
            "Current models: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "New models to evaluate: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "Skipping already evaluated model: arc_model-epoch=00-val_loss=0.37.ckpt\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: ['/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt']\n",
            "Current models: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "New models to evaluate: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "Skipping already evaluated model: arc_model-epoch=00-val_loss=0.37.ckpt\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: ['/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt']\n",
            "Current models: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "New models to evaluate: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "Skipping already evaluated model: arc_model-epoch=00-val_loss=0.37.ckpt\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: ['/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt']\n",
            "Current models: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "New models to evaluate: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "Skipping already evaluated model: arc_model-epoch=00-val_loss=0.37.ckpt\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: ['/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt']\n",
            "Current models: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "New models to evaluate: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "Skipping already evaluated model: arc_model-epoch=00-val_loss=0.37.ckpt\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: ['/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt']\n",
            "Current models: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "New models to evaluate: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "Skipping already evaluated model: arc_model-epoch=00-val_loss=0.37.ckpt\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: ['/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt']\n",
            "Current models: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "New models to evaluate: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "Skipping already evaluated model: arc_model-epoch=00-val_loss=0.37.ckpt\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: ['/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt']\n",
            "Current models: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "New models to evaluate: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "Skipping already evaluated model: arc_model-epoch=00-val_loss=0.37.ckpt\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: ['/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt']\n",
            "Current models: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "New models to evaluate: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "Skipping already evaluated model: arc_model-epoch=00-val_loss=0.37.ckpt\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: ['/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt']\n",
            "Current models: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "New models to evaluate: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "Skipping already evaluated model: arc_model-epoch=00-val_loss=0.37.ckpt\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: ['/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt']\n",
            "Current models: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "New models to evaluate: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "Skipping already evaluated model: arc_model-epoch=00-val_loss=0.37.ckpt\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: ['/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt']\n",
            "Current models: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "New models to evaluate: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "Skipping already evaluated model: arc_model-epoch=00-val_loss=0.37.ckpt\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: ['/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt']\n",
            "Current models: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "New models to evaluate: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "Skipping already evaluated model: arc_model-epoch=00-val_loss=0.37.ckpt\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: ['/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt']\n",
            "Current models: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "New models to evaluate: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "Skipping already evaluated model: arc_model-epoch=00-val_loss=0.37.ckpt\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: ['/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt']\n",
            "Current models: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "New models to evaluate: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "Skipping already evaluated model: arc_model-epoch=00-val_loss=0.37.ckpt\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: ['/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt']\n",
            "Current models: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "New models to evaluate: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "Skipping already evaluated model: arc_model-epoch=00-val_loss=0.37.ckpt\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: ['/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt']\n",
            "Current models: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "New models to evaluate: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "Skipping already evaluated model: arc_model-epoch=00-val_loss=0.37.ckpt\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: ['/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt']\n",
            "Current models: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "New models to evaluate: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "Skipping already evaluated model: arc_model-epoch=00-val_loss=0.37.ckpt\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: ['/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt']\n",
            "Current models: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "New models to evaluate: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "Skipping already evaluated model: arc_model-epoch=00-val_loss=0.37.ckpt\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: ['/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt']\n",
            "Current models: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "New models to evaluate: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "Skipping already evaluated model: arc_model-epoch=00-val_loss=0.37.ckpt\n",
            "Checking directory for .ckpt and .pth files: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints\n",
            "Found checkpoint files: ['/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt']\n",
            "Current models: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "New models to evaluate: {'/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt'}\n",
            "Skipping already evaluated model: arc_model-epoch=00-val_loss=0.37.ckpt\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import wandb\n",
        "import time\n",
        "from watchdog.observers import Observer\n",
        "from watchdog.events import FileSystemEventHandler\n",
        "import subprocess\n",
        "import threading\n",
        "from datetime import datetime\n",
        "\n",
        "# Set W&B API key (replace with your actual API key)\n",
        "wandb_api_key = \"2b06e99af167044b281668f6edd388c633aba1a0\"  # Replace with your W&B API key\n",
        "os.environ[\"WANDB_API_KEY\"] = wandb_api_key\n",
        "\n",
        "print(f\"arc_model_dir is set to: {arc_model_dir}\")\n",
        "\n",
        "# Directory containing the model files\n",
        "model_dir = os.path.join(date_folder, \"checkpoints\")\n",
        "print(f\"Watching for new models in directory: {model_dir}\")\n",
        "\n",
        "# Create the model_dir if it doesn't exist\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "output_dir = \"evaluation_results\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "wandb_project = \"arc-evaluation\"\n",
        "\n",
        "# Set of evaluated models\n",
        "evaluated_models = set()\n",
        "\n",
        "# Load previously evaluated models from a file\n",
        "evaluated_models_file = os.path.join(output_dir, \"evaluated_models.txt\")\n",
        "if os.path.exists(evaluated_models_file):\n",
        "    with open(evaluated_models_file, \"r\") as f:\n",
        "        evaluated_models.update(line.strip() for line in f)\n",
        "    print(f\"Loaded evaluated models from {evaluated_models_file}\")\n",
        "else:\n",
        "    print(f\"No previously evaluated models found. Starting fresh.\")\n",
        "\n",
        "class CheckpointHandler(FileSystemEventHandler):\n",
        "    def on_created(self, event):\n",
        "        if event.is_directory:\n",
        "            return\n",
        "        if event.src_path.endswith('.ckpt') or event.src_path.endswith('.pth'):\n",
        "            print(f\"New checkpoint detected: {event.src_path}\")\n",
        "            self.evaluate_model(event.src_path)\n",
        "\n",
        "    def evaluate_model(self, model_path):\n",
        "        model_file = os.path.basename(model_path)\n",
        "\n",
        "        if model_file in evaluated_models:\n",
        "            print(f\"Skipping already evaluated model: {model_file}\")\n",
        "            return  # Skip if the model was already evaluated\n",
        "\n",
        "        # Extract epoch and val_loss from the filename for run_name\n",
        "        try:\n",
        "            parts = model_file.replace('.ckpt', '').replace('.pth', '').split('-')\n",
        "            epoch = None\n",
        "            val_loss = None\n",
        "            for part in parts:\n",
        "                if part.startswith('epoch='):\n",
        "                    epoch = part.split('=')[1]\n",
        "                elif part.startswith('val_loss='):\n",
        "                    val_loss = part.split('=')[1]\n",
        "            if epoch is not None and val_loss is not None:\n",
        "                run_name = f\"scaling-test-evaluation-epoch{epoch}-val_loss{val_loss}\"\n",
        "            else:\n",
        "                run_name = f\"scaling-test-evaluation-{model_file}\"\n",
        "        except Exception as e:\n",
        "            print(f\"Error parsing run name from filename {model_file}: {e}\")\n",
        "            run_name = f\"scaling-test-evaluation-{model_file}\"\n",
        "\n",
        "        eval_command = [\n",
        "            \"python\", os.path.join(arc_model_dir, \"gpt2_arc/src/evaluate.py\"),\n",
        "            \"--model_checkpoint\", model_path,\n",
        "            \"--batch_size\", \"32\",\n",
        "            \"--output_dir\", output_dir,\n",
        "            \"--wandb_project\", wandb_project,\n",
        "            \"--wandb_run_name\", run_name\n",
        "        ]\n",
        "        print(f\"Evaluating model: {model_file} with command: {' '.join(eval_command)}\")\n",
        "\n",
        "        try:\n",
        "            # Run the evaluation command and capture stdout and stderr\n",
        "            result = subprocess.run(\n",
        "                eval_command,\n",
        "                check=True,\n",
        "                stdout=subprocess.PIPE,\n",
        "                stderr=subprocess.PIPE,\n",
        "                text=True  # Automatically decode bytes to string\n",
        "            )\n",
        "            print(f\"Successfully evaluated model: {model_file}\")\n",
        "            print(\"Evaluation Output:\")\n",
        "            print(result.stdout)  # Print the standard output from evaluate.py\n",
        "            if result.stderr:\n",
        "                print(\"Evaluation Errors/Warnings:\")\n",
        "                print(result.stderr)  # Print any errors or warnings from evaluate.py\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"Error during evaluation of {model_file}: {e}\")\n",
        "            print(\"Standard Output:\")\n",
        "            print(e.stdout)\n",
        "            print(\"Standard Error:\")\n",
        "            print(e.stderr)\n",
        "        except Exception as ex:\n",
        "            print(f\"An unexpected error occurred while evaluating {model_file}: {ex}\")\n",
        "\n",
        "        evaluated_models.add(model_file)\n",
        "\n",
        "        # Save the evaluated model to the file\n",
        "        with open(evaluated_models_file, \"a\") as f:\n",
        "            f.write(model_file + \"\\n\")\n",
        "\n",
        "def get_all_checkpoint_files(directory):\n",
        "    print(f\"Checking directory for .ckpt and .pth files: {directory}\")\n",
        "    checkpoint_files = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        checkpoint_files.extend([os.path.join(root, f) for f in files if f.endswith('.ckpt') or f.endswith('.pth')])\n",
        "    print(f\"Found checkpoint files: {checkpoint_files}\")\n",
        "    return checkpoint_files\n",
        "\n",
        "def start_observer():\n",
        "    # Set up and start the watchdog observer\n",
        "    event_handler = CheckpointHandler()\n",
        "    observer = Observer()\n",
        "    observer.schedule(event_handler, model_dir, recursive=True)\n",
        "    observer.start()\n",
        "\n",
        "    print(\"Watching for new checkpoints and final models in all subdirectories...\")\n",
        "    print(\"This script will continue running in the background.\")\n",
        "\n",
        "    try:\n",
        "        while True:\n",
        "            time.sleep(10)\n",
        "            # Check for any new models\n",
        "            current_models = set(get_all_checkpoint_files(model_dir))\n",
        "            new_models = current_models - evaluated_models\n",
        "\n",
        "            print(f\"Current models: {current_models}\")\n",
        "            print(f\"New models to evaluate: {new_models}\")\n",
        "\n",
        "            for model_path in new_models:\n",
        "                event_handler.evaluate_model(model_path)\n",
        "    except KeyboardInterrupt:\n",
        "        observer.stop()\n",
        "        print(\"Observer stopped by user.\")\n",
        "    except FileNotFoundError as fnf_error:\n",
        "        print(f\"FileNotFoundError: {fnf_error}\")\n",
        "        print(f\"Please ensure that the directory '{model_dir}' exists.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred in the observer: {e}\")\n",
        "    finally:\n",
        "        observer.join()\n",
        "        print(\"Checkpoint and final model evaluation completed.\")\n",
        "\n",
        "# Function to start the observer in a background thread\n",
        "def run_observer():\n",
        "    observer_thread = threading.Thread(target=start_observer)\n",
        "    observer_thread.daemon = True  # Ensures the thread will exit when the main program exits\n",
        "    observer_thread.start()\n",
        "    print(\"Background checkpoint observer started.\")\n",
        "\n",
        "# Start the observer\n",
        "run_observer()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2ba232c",
      "metadata": {
        "id": "f2ba232c"
      },
      "source": [
        "### 5. Use the best hyperparameters for longer training (manually set max epochs!):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "BWmLkQeNsxiX",
      "metadata": {
        "id": "BWmLkQeNsxiX"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import subprocess\n",
        "import os\n",
        "import math\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "m8uLi0U5l6QL",
      "metadata": {
        "id": "m8uLi0U5l6QL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded best hyperparameters from JSON.\n",
            "Converted n_head_exp: 2 to n_head: 4\n",
            "Converted n_embd_multiplier: 91 to n_embd: 256\n",
            "Final Parameters for Training: {'n_embd': 256, 'n_head': 4, 'n_layer': 2, 'batch_size': 21, 'learning_rate': 0.0044446551952796705, 'max_epochs': 50}\n"
          ]
        }
      ],
      "source": [
        "# Load best hyperparameters from the JSON file if use_best_params is True\n",
        "if use_best_params:\n",
        "    try:\n",
        "        with open(f\"{date_folder}/best_hyperparameters.json\", \"r\") as f:\n",
        "            best_params = json.load(f)\n",
        "        print(\"Loaded best hyperparameters from JSON.\")\n",
        "\n",
        "        # Check if 'n_head_exp' and 'n_embd_multiplier' are present\n",
        "        if 'n_head_exp' in best_params and 'n_embd_multiplier' in best_params:\n",
        "            # Convert exponent to actual n_head\n",
        "            n_head_exp = best_params['n_head_exp']\n",
        "            n_head = 2 ** n_head_exp\n",
        "            # Convert multiplier to actual n_embd\n",
        "            n_embd_multiplier = best_params['n_embd_multiplier']\n",
        "            n_embd = n_head * n_embd_multiplier\n",
        "            # Ensure n_embd is a power of 2\n",
        "            n_embd = 2 ** int(math.log2(n_embd))\n",
        "            print(f\"Converted n_head_exp: {n_head_exp} to n_head: {n_head}\")\n",
        "            print(f\"Converted n_embd_multiplier: {n_embd_multiplier} to n_embd: {n_embd}\")\n",
        "        else:\n",
        "            # If conversion parameters are not present, use manual values or existing best_params\n",
        "            n_head = best_params.get(\"n_head\", manual_params[\"n_head\"])\n",
        "            n_embd = best_params.get(\"n_embd\", manual_params[\"n_embd\"])\n",
        "            print(\"n_head_exp and/or n_embd_multiplier not found in best_params. Using existing n_head and n_embd.\")\n",
        "\n",
        "        # Extract other hyperparameters but OVERRIDE max_epochs with manual setting\n",
        "        params = {\n",
        "            \"n_embd\": n_embd,\n",
        "            \"n_head\": n_head,\n",
        "            \"n_layer\": best_params.get(\"n_layer\", manual_params[\"n_layer\"]),\n",
        "            \"batch_size\": best_params.get(\"batch_size\", manual_params[\"batch_size\"]),\n",
        "            \"learning_rate\": best_params.get(\"learning_rate\", manual_params[\"learning_rate\"]),\n",
        "            \"max_epochs\": manual_params[\"max_epochs\"]  # Override max_epochs with manual setting\n",
        "        }\n",
        "        print(f\"Final Parameters for Training: {params}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Warning: {date_folder}/best_hyperparameters.json not found. Using manual parameters.\")\n",
        "        params = manual_params\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while loading best hyperparameters: {str(e)}. Using manual parameters.\")\n",
        "        params = manual_params\n",
        "else:\n",
        "    # Use manually defined parameters\n",
        "    params = manual_params\n",
        "    print(\"Using manual hyperparameters.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "ysTJm45AtuzN",
      "metadata": {
        "id": "ysTJm45AtuzN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training process...\n",
            "2024-09-28 23:13:06.863574: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-09-28 23:13:06.868340: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-09-28 23:13:06.882232: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-09-28 23:13:06.906143: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-09-28 23:13:06.918630: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-09-28 23:13:06.943731: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "DEBUG:tensorflow:Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n",
            "2024-09-28 23:13:09.826436: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DEBUG:h5py._conv:Creating converter from 7 to 5\n",
            "DEBUG:h5py._conv:Creating converter from 5 to 7\n",
            "DEBUG:h5py._conv:Creating converter from 7 to 5\n",
            "DEBUG:h5py._conv:Creating converter from 5 to 7\n",
            "DEBUG:git.cmd:Popen(['git', 'version'], cwd=/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928, stdin=None, shell=False, universal_newlines=False)\n",
            "DEBUG:git.cmd:Popen(['git', 'version'], cwd=/workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928, stdin=None, shell=False, universal_newlines=False)\n",
            "DEBUG:wandb.docker.auth:Trying paths: ['/home/codespace/.docker/config.json', '/home/codespace/.dockercfg']\n",
            "DEBUG:wandb.docker.auth:Found file at path: /home/codespace/.docker/config.json\n",
            "DEBUG:wandb.docker.auth:Found 'auths' section\n",
            "DEBUG:wandb.docker.auth:Found entry (registry='docker.pkg.github.com', username='USERNAME')\n",
            "DEBUG:wandb.docker.auth:Found entry (registry='ghcr.io', username='ImmortalDemonGod')\n",
            "DEBUG:wandb.docker.auth:Found entry (registry='https://index.docker.io/v1/', username='codespacesdev')\n",
            "INFO:__main__:Starting main function\n",
            "DEBUG:__main__:Command line arguments: Namespace(use_optuna=False, optuna_study_name='gpt2_arc_optimization', optuna_storage='sqlite:///optuna_results.db', n_embd=256, n_head=4, n_layer=2, batch_size=21, learning_rate=0.0044446551952796705, max_epochs=50, use_gpu=True, no_logging=False, no_checkpointing=False, no_progress_bar=False, fast_dev_run=False, model_checkpoint=None, project='arc-scaling-test', results_dir='./results', run_name='default_run', use_synthetic_data=False, synthetic_data_path=None, log_level='INFO')\n",
            "INFO:__main__:Using provided or default hyperparameters\n",
            "DEBUG:__main__:Configuration: Config(model=ModelConfig(n_embd=256, n_head=4, n_layer=2, dropout=0.1), training=TrainingConfig(batch_size=21, learning_rate=0.0044446551952796705, max_epochs=50, use_gpu=True, log_level='INFO', use_synthetic_data=False, synthetic_data_path=None), evaluation=EvaluationConfig(perfect_accuracy_threshold=98))\n",
            "INFO:__main__:Loading data\n",
            "INFO:__main__:Loading ARC dataset\n",
            "DEBUG:__main__:Train data size: 1302, Validation data size: 1363\n",
            "INFO:__main__:Determining number of classes\n",
            "INFO:__main__:Number of classes determined: 10\n",
            "DEBUG:__main__:num_classes (type: <class 'int'>): 10\n",
            "INFO:__main__:Creating DataLoader instances\n",
            "/home/codespace/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 7 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "DEBUG:__main__:DataLoaders created with batch size 21\n",
            "INFO:__main__:Initializing model\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Initialized Attention with n_embd=256, n_head=4\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Initialized FeedForward with n_embd=256\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Initialized TransformerBlock with n_embd=256, n_head=4\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Initialized Attention with n_embd=256, n_head=4\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Initialized FeedForward with n_embd=256\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Initialized TransformerBlock with n_embd=256, n_head=4\n",
            "DEBUG:__main__:Model initialized with config: ModelConfig(n_embd=256, n_head=4, n_layer=2, dropout=0.1)\n",
            "DEBUG: Initialized self.results['train'] as <class 'dict'>\n",
            "ExperimentTracker initialized with config: {\n",
            "  \"model\": {\n",
            "    \"n_embd\": 256,\n",
            "    \"n_head\": 4,\n",
            "    \"n_layer\": 2,\n",
            "    \"dropout\": 0.1\n",
            "  },\n",
            "  \"training\": {\n",
            "    \"batch_size\": 21,\n",
            "    \"learning_rate\": 0.0044446551952796705,\n",
            "    \"max_epochs\": 50,\n",
            "    \"use_gpu\": true,\n",
            "    \"log_level\": \"INFO\",\n",
            "    \"use_synthetic_data\": false,\n",
            "    \"synthetic_data_path\": null\n",
            "  },\n",
            "  \"evaluation\": {\n",
            "    \"perfect_accuracy_threshold\": 98\n",
            "  }\n",
            "}\n",
            "Project: arc-scaling-test, Entity: None\n",
            "use_wandb: False\n",
            "DEBUG:__main__:Initializing ExperimentTracker\n",
            "ExperimentTracker initialized with config: {\n",
            "  \"model\": {\n",
            "    \"n_embd\": 256,\n",
            "    \"n_head\": 4,\n",
            "    \"n_layer\": 2,\n",
            "    \"dropout\": 0.1\n",
            "  },\n",
            "  \"training\": {\n",
            "    \"batch_size\": 21,\n",
            "    \"learning_rate\": 0.0044446551952796705,\n",
            "    \"max_epochs\": 50,\n",
            "    \"use_gpu\": true,\n",
            "    \"log_level\": \"INFO\",\n",
            "    \"use_synthetic_data\": false,\n",
            "    \"synthetic_data_path\": null\n",
            "  },\n",
            "  \"evaluation\": {\n",
            "    \"perfect_accuracy_threshold\": 98\n",
            "  }\n",
            "}\n",
            "Project: arc-scaling-test, Entity: None\n",
            "use_wandb: False\n",
            "DEBUG:__main__:Initializing ARCTrainer\n",
            "DEBUG: Initialized self.results['train'] as <class 'dict'>\n",
            "DEBUG: Successfully logged hyperparameters: {'learning_rate': 0.0044446551952796705, 'batch_size': 21, 'n_embd': 256, 'n_head': 4, 'n_layer': 2}\n",
            "INFO:__main__:Setting up PyTorch Lightning trainer\n",
            "DEBUG:__main__:TensorBoard logger initialized. Log dir: runs/experiment_fdc03d51-e11d-4abb-ad23-f8c9297e71da/version_0\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "DEBUG: Set TensorBoard log path in ResultsCollector: runs/experiment_fdc03d51-e11d-4abb-ad23-f8c9297e71da/version_0\n",
            "DEBUG:__main__:TensorBoard log path set in results collector: runs/experiment_fdc03d51-e11d-4abb-ad23-f8c9297e71da/version_0\n",
            "INFO:__main__:Starting model training\n",
            "\n",
            "  | Name  | Type    | Params | Mode \n",
            "------------------------------------------\n",
            "0 | model | GPT2ARC | 1.6 M  | train\n",
            "------------------------------------------\n",
            "1.6 M     Trainable params\n",
            "0         Non-trainable params\n",
            "1.6 M     Total params\n",
            "6.341     Total estimated model params size (MB)\n",
            "31        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "DEBUG:fsspec.local:open file: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/runs/experiment_fdc03d51-e11d-4abb-ad23-f8c9297e71da/version_0/hparams.yaml\n",
            "\n",
            "Sanity Checking: |          | 0/? [00:00<?, ?it/s]DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test dataloader created with 65 batches\n",
            "\n",
            "Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]\n",
            "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]DEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "/usr/local/python/3.12.1/lib/python3.12/site-packages/pytorch_lightning/utilities/data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 21. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "DEBUG: Logged validation loss: 3.498927354812622 for epoch 0\n",
            "\n",
            "Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:02<00:02,  0.36it/s]DEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 3.2593655586242676 for epoch 0\n",
            "\n",
            "Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:05<00:00,  0.37it/s]\n",
            "                                                                           \n",
            "\n",
            "Training: |          | 0/? [00:00<?, ?it/s]\n",
            "Training:   0%|          | 0/62 [00:00<?, ?it/s]\n",
            "Epoch 0:   0%|          | 0/62 [00:00<?, ?it/s] DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 3.5868005752563477 at step 0\n",
            "\n",
            "Epoch 0:   2%|▏         | 1/62 [00:07<07:28,  0.14it/s]\n",
            "Epoch 0:   2%|▏         | 1/62 [00:07<07:28,  0.14it/s, v_num=0, train_loss_step=3.590]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 1.1740692853927612 at step 1\n",
            "\n",
            "Epoch 0:   3%|▎         | 2/62 [00:11<05:46,  0.17it/s, v_num=0, train_loss_step=3.590]\n",
            "Epoch 0:   3%|▎         | 2/62 [00:11<05:46,  0.17it/s, v_num=0, train_loss_step=1.170]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 8.660600662231445 at step 2\n",
            "\n",
            "Epoch 0:   5%|▍         | 3/62 [00:15<05:07,  0.19it/s, v_num=0, train_loss_step=1.170]\n",
            "Epoch 0:   5%|▍         | 3/62 [00:15<05:07,  0.19it/s, v_num=0, train_loss_step=8.660]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 2.9627604484558105 at step 3\n",
            "\n",
            "Epoch 0:   6%|▋         | 4/62 [00:19<04:43,  0.20it/s, v_num=0, train_loss_step=8.660]\n",
            "Epoch 0:   6%|▋         | 4/62 [00:19<04:43,  0.20it/s, v_num=0, train_loss_step=2.960]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.23227523267269135 at step 4\n",
            "\n",
            "Epoch 0:   8%|▊         | 5/62 [00:23<04:32,  0.21it/s, v_num=0, train_loss_step=2.960]\n",
            "Epoch 0:   8%|▊         | 5/62 [00:23<04:32,  0.21it/s, v_num=0, train_loss_step=0.232]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.5341600775718689 at step 5\n",
            "\n",
            "Epoch 0:  10%|▉         | 6/62 [00:28<04:24,  0.21it/s, v_num=0, train_loss_step=0.232]\n",
            "Epoch 0:  10%|▉         | 6/62 [00:28<04:24,  0.21it/s, v_num=0, train_loss_step=0.534]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.19722996652126312 at step 6\n",
            "\n",
            "Epoch 0:  11%|█▏        | 7/62 [00:32<04:16,  0.21it/s, v_num=0, train_loss_step=0.534]\n",
            "Epoch 0:  11%|█▏        | 7/62 [00:32<04:16,  0.21it/s, v_num=0, train_loss_step=0.197]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.22524328529834747 at step 7\n",
            "\n",
            "Epoch 0:  13%|█▎        | 8/62 [00:36<04:03,  0.22it/s, v_num=0, train_loss_step=0.197]\n",
            "Epoch 0:  13%|█▎        | 8/62 [00:36<04:03,  0.22it/s, v_num=0, train_loss_step=0.225]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.2460905760526657 at step 8\n",
            "\n",
            "Epoch 0:  15%|█▍        | 9/62 [00:39<03:50,  0.23it/s, v_num=0, train_loss_step=0.225]\n",
            "Epoch 0:  15%|█▍        | 9/62 [00:39<03:50,  0.23it/s, v_num=0, train_loss_step=0.246]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.3360733985900879 at step 9\n",
            "\n",
            "Epoch 0:  16%|█▌        | 10/62 [00:41<03:35,  0.24it/s, v_num=0, train_loss_step=0.246]\n",
            "Epoch 0:  16%|█▌        | 10/62 [00:41<03:35,  0.24it/s, v_num=0, train_loss_step=0.336]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.2112272083759308 at step 10\n",
            "\n",
            "Epoch 0:  18%|█▊        | 11/62 [00:43<03:22,  0.25it/s, v_num=0, train_loss_step=0.336]\n",
            "Epoch 0:  18%|█▊        | 11/62 [00:43<03:22,  0.25it/s, v_num=0, train_loss_step=0.211]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.16597208380699158 at step 11\n",
            "\n",
            "Epoch 0:  19%|█▉        | 12/62 [00:46<03:11,  0.26it/s, v_num=0, train_loss_step=0.211]\n",
            "Epoch 0:  19%|█▉        | 12/62 [00:46<03:11,  0.26it/s, v_num=0, train_loss_step=0.166]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.3399660289287567 at step 12\n",
            "\n",
            "Epoch 0:  21%|██        | 13/62 [00:48<03:02,  0.27it/s, v_num=0, train_loss_step=0.166]\n",
            "Epoch 0:  21%|██        | 13/62 [00:48<03:02,  0.27it/s, v_num=0, train_loss_step=0.340]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.30292439460754395 at step 13\n",
            "\n",
            "Epoch 0:  23%|██▎       | 14/62 [00:50<02:53,  0.28it/s, v_num=0, train_loss_step=0.340]\n",
            "Epoch 0:  23%|██▎       | 14/62 [00:50<02:53,  0.28it/s, v_num=0, train_loss_step=0.303]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.24320997297763824 at step 14\n",
            "\n",
            "Epoch 0:  24%|██▍       | 15/62 [00:52<02:46,  0.28it/s, v_num=0, train_loss_step=0.303]\n",
            "Epoch 0:  24%|██▍       | 15/62 [00:52<02:46,  0.28it/s, v_num=0, train_loss_step=0.243]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.1717522144317627 at step 15\n",
            "\n",
            "Epoch 0:  26%|██▌       | 16/62 [00:55<02:38,  0.29it/s, v_num=0, train_loss_step=0.243]\n",
            "Epoch 0:  26%|██▌       | 16/62 [00:55<02:38,  0.29it/s, v_num=0, train_loss_step=0.172]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.15192927420139313 at step 16\n",
            "\n",
            "Epoch 0:  27%|██▋       | 17/62 [00:57<02:32,  0.30it/s, v_num=0, train_loss_step=0.172]\n",
            "Epoch 0:  27%|██▋       | 17/62 [00:57<02:32,  0.30it/s, v_num=0, train_loss_step=0.152]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.33295926451683044 at step 17\n",
            "\n",
            "Epoch 0:  29%|██▉       | 18/62 [00:59<02:26,  0.30it/s, v_num=0, train_loss_step=0.152]\n",
            "Epoch 0:  29%|██▉       | 18/62 [00:59<02:26,  0.30it/s, v_num=0, train_loss_step=0.333]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.2534906566143036 at step 18\n",
            "\n",
            "Epoch 0:  31%|███       | 19/62 [01:02<02:20,  0.31it/s, v_num=0, train_loss_step=0.333]\n",
            "Epoch 0:  31%|███       | 19/62 [01:02<02:20,  0.31it/s, v_num=0, train_loss_step=0.253]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.2589254379272461 at step 19\n",
            "\n",
            "Epoch 0:  32%|███▏      | 20/62 [01:04<02:15,  0.31it/s, v_num=0, train_loss_step=0.253]\n",
            "Epoch 0:  32%|███▏      | 20/62 [01:04<02:15,  0.31it/s, v_num=0, train_loss_step=0.259]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.1809847056865692 at step 20\n",
            "\n",
            "Epoch 0:  34%|███▍      | 21/62 [01:06<02:10,  0.31it/s, v_num=0, train_loss_step=0.259]\n",
            "Epoch 0:  34%|███▍      | 21/62 [01:06<02:10,  0.31it/s, v_num=0, train_loss_step=0.181]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.18601453304290771 at step 21\n",
            "\n",
            "Epoch 0:  35%|███▌      | 22/62 [01:09<02:05,  0.32it/s, v_num=0, train_loss_step=0.181]\n",
            "Epoch 0:  35%|███▌      | 22/62 [01:09<02:05,  0.32it/s, v_num=0, train_loss_step=0.186]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.1522039771080017 at step 22\n",
            "\n",
            "Epoch 0:  37%|███▋      | 23/62 [01:11<02:01,  0.32it/s, v_num=0, train_loss_step=0.186]\n",
            "Epoch 0:  37%|███▋      | 23/62 [01:11<02:01,  0.32it/s, v_num=0, train_loss_step=0.152]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.16686801612377167 at step 23\n",
            "\n",
            "Epoch 0:  39%|███▊      | 24/62 [01:13<01:56,  0.33it/s, v_num=0, train_loss_step=0.152]\n",
            "Epoch 0:  39%|███▊      | 24/62 [01:13<01:56,  0.33it/s, v_num=0, train_loss_step=0.167]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.2743879556655884 at step 24\n",
            "\n",
            "Epoch 0:  40%|████      | 25/62 [01:16<01:52,  0.33it/s, v_num=0, train_loss_step=0.167]\n",
            "Epoch 0:  40%|████      | 25/62 [01:16<01:52,  0.33it/s, v_num=0, train_loss_step=0.274]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.17645606398582458 at step 25\n",
            "\n",
            "Epoch 0:  42%|████▏     | 26/62 [01:18<01:48,  0.33it/s, v_num=0, train_loss_step=0.274]\n",
            "Epoch 0:  42%|████▏     | 26/62 [01:18<01:48,  0.33it/s, v_num=0, train_loss_step=0.176]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.11147703975439072 at step 26\n",
            "\n",
            "Epoch 0:  44%|████▎     | 27/62 [01:20<01:44,  0.33it/s, v_num=0, train_loss_step=0.176]\n",
            "Epoch 0:  44%|████▎     | 27/62 [01:20<01:44,  0.33it/s, v_num=0, train_loss_step=0.111]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.2434578835964203 at step 27\n",
            "\n",
            "Epoch 0:  45%|████▌     | 28/62 [01:23<01:40,  0.34it/s, v_num=0, train_loss_step=0.111]\n",
            "Epoch 0:  45%|████▌     | 28/62 [01:23<01:40,  0.34it/s, v_num=0, train_loss_step=0.243]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.1068345159292221 at step 28\n",
            "\n",
            "Epoch 0:  47%|████▋     | 29/62 [01:25<01:37,  0.34it/s, v_num=0, train_loss_step=0.243]\n",
            "Epoch 0:  47%|████▋     | 29/62 [01:25<01:37,  0.34it/s, v_num=0, train_loss_step=0.107]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.45692387223243713 at step 29\n",
            "\n",
            "Epoch 0:  48%|████▊     | 30/62 [01:27<01:33,  0.34it/s, v_num=0, train_loss_step=0.107]\n",
            "Epoch 0:  48%|████▊     | 30/62 [01:27<01:33,  0.34it/s, v_num=0, train_loss_step=0.457]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.18990108370780945 at step 30\n",
            "\n",
            "Epoch 0:  50%|█████     | 31/62 [01:29<01:29,  0.34it/s, v_num=0, train_loss_step=0.457]\n",
            "Epoch 0:  50%|█████     | 31/62 [01:29<01:29,  0.34it/s, v_num=0, train_loss_step=0.190]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.31998229026794434 at step 31\n",
            "\n",
            "Epoch 0:  52%|█████▏    | 32/62 [01:32<01:26,  0.35it/s, v_num=0, train_loss_step=0.190]\n",
            "Epoch 0:  52%|█████▏    | 32/62 [01:32<01:26,  0.35it/s, v_num=0, train_loss_step=0.320]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.23416292667388916 at step 32\n",
            "\n",
            "Epoch 0:  53%|█████▎    | 33/62 [01:34<01:23,  0.35it/s, v_num=0, train_loss_step=0.320]\n",
            "Epoch 0:  53%|█████▎    | 33/62 [01:34<01:23,  0.35it/s, v_num=0, train_loss_step=0.234]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.33986854553222656 at step 33\n",
            "\n",
            "Epoch 0:  55%|█████▍    | 34/62 [01:37<01:19,  0.35it/s, v_num=0, train_loss_step=0.234]\n",
            "Epoch 0:  55%|█████▍    | 34/62 [01:37<01:19,  0.35it/s, v_num=0, train_loss_step=0.340]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.22533011436462402 at step 34\n",
            "\n",
            "Epoch 0:  56%|█████▋    | 35/62 [01:39<01:16,  0.35it/s, v_num=0, train_loss_step=0.340]\n",
            "Epoch 0:  56%|█████▋    | 35/62 [01:39<01:16,  0.35it/s, v_num=0, train_loss_step=0.225]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.2588897943496704 at step 35\n",
            "\n",
            "Epoch 0:  58%|█████▊    | 36/62 [01:41<01:13,  0.35it/s, v_num=0, train_loss_step=0.225]\n",
            "Epoch 0:  58%|█████▊    | 36/62 [01:41<01:13,  0.35it/s, v_num=0, train_loss_step=0.259]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.28213784098625183 at step 36\n",
            "\n",
            "Epoch 0:  60%|█████▉    | 37/62 [01:44<01:10,  0.36it/s, v_num=0, train_loss_step=0.259]\n",
            "Epoch 0:  60%|█████▉    | 37/62 [01:44<01:10,  0.36it/s, v_num=0, train_loss_step=0.282]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.11042992025613785 at step 37\n",
            "\n",
            "Epoch 0:  61%|██████▏   | 38/62 [01:46<01:07,  0.36it/s, v_num=0, train_loss_step=0.282]\n",
            "Epoch 0:  61%|██████▏   | 38/62 [01:46<01:07,  0.36it/s, v_num=0, train_loss_step=0.110]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.19917193055152893 at step 38\n",
            "\n",
            "Epoch 0:  63%|██████▎   | 39/62 [01:48<01:04,  0.36it/s, v_num=0, train_loss_step=0.110]\n",
            "Epoch 0:  63%|██████▎   | 39/62 [01:48<01:04,  0.36it/s, v_num=0, train_loss_step=0.199]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.26327061653137207 at step 39\n",
            "\n",
            "Epoch 0:  65%|██████▍   | 40/62 [01:51<01:01,  0.36it/s, v_num=0, train_loss_step=0.199]\n",
            "Epoch 0:  65%|██████▍   | 40/62 [01:51<01:01,  0.36it/s, v_num=0, train_loss_step=0.263]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.30612412095069885 at step 40\n",
            "\n",
            "Epoch 0:  66%|██████▌   | 41/62 [01:53<00:58,  0.36it/s, v_num=0, train_loss_step=0.263]\n",
            "Epoch 0:  66%|██████▌   | 41/62 [01:53<00:58,  0.36it/s, v_num=0, train_loss_step=0.306]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.20192040503025055 at step 41\n",
            "\n",
            "Epoch 0:  68%|██████▊   | 42/62 [01:55<00:55,  0.36it/s, v_num=0, train_loss_step=0.306]\n",
            "Epoch 0:  68%|██████▊   | 42/62 [01:55<00:55,  0.36it/s, v_num=0, train_loss_step=0.202]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.30694878101348877 at step 42\n",
            "\n",
            "Epoch 0:  69%|██████▉   | 43/62 [01:57<00:52,  0.36it/s, v_num=0, train_loss_step=0.202]\n",
            "Epoch 0:  69%|██████▉   | 43/62 [01:57<00:52,  0.36it/s, v_num=0, train_loss_step=0.307]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.43409356474876404 at step 43\n",
            "\n",
            "Epoch 0:  71%|███████   | 44/62 [02:00<00:49,  0.37it/s, v_num=0, train_loss_step=0.307]\n",
            "Epoch 0:  71%|███████   | 44/62 [02:00<00:49,  0.37it/s, v_num=0, train_loss_step=0.434]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.14731186628341675 at step 44\n",
            "\n",
            "Epoch 0:  73%|███████▎  | 45/62 [02:02<00:46,  0.37it/s, v_num=0, train_loss_step=0.434]\n",
            "Epoch 0:  73%|███████▎  | 45/62 [02:02<00:46,  0.37it/s, v_num=0, train_loss_step=0.147]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.11080197244882584 at step 45\n",
            "\n",
            "Epoch 0:  74%|███████▍  | 46/62 [02:04<00:43,  0.37it/s, v_num=0, train_loss_step=0.147]\n",
            "Epoch 0:  74%|███████▍  | 46/62 [02:04<00:43,  0.37it/s, v_num=0, train_loss_step=0.111]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.22261284291744232 at step 46\n",
            "\n",
            "Epoch 0:  76%|███████▌  | 47/62 [02:07<00:40,  0.37it/s, v_num=0, train_loss_step=0.111]\n",
            "Epoch 0:  76%|███████▌  | 47/62 [02:07<00:40,  0.37it/s, v_num=0, train_loss_step=0.223]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.21658384799957275 at step 47\n",
            "\n",
            "Epoch 0:  77%|███████▋  | 48/62 [02:09<00:37,  0.37it/s, v_num=0, train_loss_step=0.223]\n",
            "Epoch 0:  77%|███████▋  | 48/62 [02:09<00:37,  0.37it/s, v_num=0, train_loss_step=0.217]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.2120898962020874 at step 48\n",
            "\n",
            "Epoch 0:  79%|███████▉  | 49/62 [02:11<00:34,  0.37it/s, v_num=0, train_loss_step=0.217]\n",
            "Epoch 0:  79%|███████▉  | 49/62 [02:11<00:34,  0.37it/s, v_num=0, train_loss_step=0.212]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.22084374725818634 at step 49\n",
            "\n",
            "Epoch 0:  81%|████████  | 50/62 [02:14<00:32,  0.37it/s, v_num=0, train_loss_step=0.212]\n",
            "Epoch 0:  81%|████████  | 50/62 [02:14<00:32,  0.37it/s, v_num=0, train_loss_step=0.221]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.14949452877044678 at step 50\n",
            "\n",
            "Epoch 0:  82%|████████▏ | 51/62 [02:16<00:29,  0.37it/s, v_num=0, train_loss_step=0.221]\n",
            "Epoch 0:  82%|████████▏ | 51/62 [02:16<00:29,  0.37it/s, v_num=0, train_loss_step=0.149]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.20260389149188995 at step 51\n",
            "\n",
            "Epoch 0:  84%|████████▍ | 52/62 [02:18<00:26,  0.37it/s, v_num=0, train_loss_step=0.149]\n",
            "Epoch 0:  84%|████████▍ | 52/62 [02:18<00:26,  0.37it/s, v_num=0, train_loss_step=0.203]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.26433297991752625 at step 52\n",
            "\n",
            "Epoch 0:  85%|████████▌ | 53/62 [02:21<00:23,  0.38it/s, v_num=0, train_loss_step=0.203]\n",
            "Epoch 0:  85%|████████▌ | 53/62 [02:21<00:23,  0.38it/s, v_num=0, train_loss_step=0.264]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.41045862436294556 at step 53\n",
            "\n",
            "Epoch 0:  87%|████████▋ | 54/62 [02:23<00:21,  0.38it/s, v_num=0, train_loss_step=0.264]\n",
            "Epoch 0:  87%|████████▋ | 54/62 [02:23<00:21,  0.38it/s, v_num=0, train_loss_step=0.410]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.2152954787015915 at step 54\n",
            "\n",
            "Epoch 0:  89%|████████▊ | 55/62 [02:25<00:18,  0.38it/s, v_num=0, train_loss_step=0.410]\n",
            "Epoch 0:  89%|████████▊ | 55/62 [02:25<00:18,  0.38it/s, v_num=0, train_loss_step=0.215]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.38179728388786316 at step 55\n",
            "\n",
            "Epoch 0:  90%|█████████ | 56/62 [02:27<00:15,  0.38it/s, v_num=0, train_loss_step=0.215]\n",
            "Epoch 0:  90%|█████████ | 56/62 [02:27<00:15,  0.38it/s, v_num=0, train_loss_step=0.382]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.394046425819397 at step 56\n",
            "\n",
            "Epoch 0:  92%|█████████▏| 57/62 [02:30<00:13,  0.38it/s, v_num=0, train_loss_step=0.382]\n",
            "Epoch 0:  92%|█████████▏| 57/62 [02:30<00:13,  0.38it/s, v_num=0, train_loss_step=0.394]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.2168666273355484 at step 57\n",
            "\n",
            "Epoch 0:  94%|█████████▎| 58/62 [02:32<00:10,  0.38it/s, v_num=0, train_loss_step=0.394]\n",
            "Epoch 0:  94%|█████████▎| 58/62 [02:32<00:10,  0.38it/s, v_num=0, train_loss_step=0.217]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.2539941072463989 at step 58\n",
            "\n",
            "Epoch 0:  95%|█████████▌| 59/62 [02:34<00:07,  0.38it/s, v_num=0, train_loss_step=0.217]\n",
            "Epoch 0:  95%|█████████▌| 59/62 [02:34<00:07,  0.38it/s, v_num=0, train_loss_step=0.254]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.228926420211792 at step 59\n",
            "\n",
            "Epoch 0:  97%|█████████▋| 60/62 [02:36<00:05,  0.38it/s, v_num=0, train_loss_step=0.254]\n",
            "Epoch 0:  97%|█████████▋| 60/62 [02:36<00:05,  0.38it/s, v_num=0, train_loss_step=0.229]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.24903441965579987 at step 60\n",
            "\n",
            "Epoch 0:  98%|█████████▊| 61/62 [02:39<00:02,  0.38it/s, v_num=0, train_loss_step=0.229]\n",
            "Epoch 0:  98%|█████████▊| 61/62 [02:39<00:02,  0.38it/s, v_num=0, train_loss_step=0.249]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.15768924355506897 at step 61\n",
            "\n",
            "Epoch 0: 100%|██████████| 62/62 [02:41<00:00,  0.38it/s, v_num=0, train_loss_step=0.249]\n",
            "Epoch 0: 100%|██████████| 62/62 [02:41<00:00,  0.38it/s, v_num=0, train_loss_step=0.158]\n",
            "\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation:   0%|          | 0/65 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0:   0%|          | 0/65 [00:00<?, ?it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.47380906343460083 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:   2%|▏         | 1/65 [00:01<01:36,  0.66it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.6025872230529785 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:   3%|▎         | 2/65 [00:02<01:14,  0.85it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.1634376049041748 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:   5%|▍         | 3/65 [00:03<01:06,  0.94it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.23836244642734528 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:   6%|▌         | 4/65 [00:04<01:01,  1.00it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.4701901376247406 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:   8%|▊         | 5/65 [00:04<00:58,  1.03it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.25016528367996216 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:   9%|▉         | 6/65 [00:05<00:56,  1.05it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.15116280317306519 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  11%|█         | 7/65 [00:06<00:54,  1.07it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.49169766902923584 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  12%|█▏        | 8/65 [00:07<00:52,  1.09it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.44831931591033936 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  14%|█▍        | 9/65 [00:08<00:50,  1.10it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.6581388115882874 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  15%|█▌        | 10/65 [00:09<00:49,  1.11it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.1809493899345398 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  17%|█▋        | 11/65 [00:09<00:48,  1.11it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.29773032665252686 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  18%|█▊        | 12/65 [00:10<00:47,  1.11it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.3531131148338318 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  20%|██        | 13/65 [00:11<00:46,  1.12it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.24887725710868835 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  22%|██▏       | 14/65 [00:12<00:45,  1.13it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.2869816720485687 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  23%|██▎       | 15/65 [00:13<00:44,  1.13it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.49009057879447937 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  25%|██▍       | 16/65 [00:14<00:43,  1.13it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.5285606384277344 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  26%|██▌       | 17/65 [00:14<00:42,  1.14it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.8642153739929199 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  28%|██▊       | 18/65 [00:15<00:41,  1.14it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.27678918838500977 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  29%|██▉       | 19/65 [00:16<00:40,  1.15it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.3403497636318207 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  31%|███       | 20/65 [00:17<00:39,  1.15it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.42870375514030457 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  32%|███▏      | 21/65 [00:18<00:38,  1.15it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.38913941383361816 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  34%|███▍      | 22/65 [00:19<00:37,  1.15it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.3473120927810669 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  35%|███▌      | 23/65 [00:19<00:36,  1.15it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.12752245366573334 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  37%|███▋      | 24/65 [00:20<00:35,  1.16it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.21507161855697632 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  38%|███▊      | 25/65 [00:21<00:34,  1.16it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.28376349806785583 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  40%|████      | 26/65 [00:22<00:33,  1.16it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.07844100147485733 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  42%|████▏     | 27/65 [00:23<00:32,  1.16it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.2095094621181488 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  43%|████▎     | 28/65 [00:24<00:31,  1.16it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.3477773666381836 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  45%|████▍     | 29/65 [00:24<00:30,  1.17it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.29768094420433044 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  46%|████▌     | 30/65 [00:25<00:30,  1.17it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.32991889119148254 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  48%|████▊     | 31/65 [00:26<00:29,  1.17it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.18755392730236053 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  49%|████▉     | 32/65 [00:27<00:28,  1.17it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.29861220717430115 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  51%|█████     | 33/65 [00:28<00:27,  1.17it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.4161645174026489 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  52%|█████▏    | 34/65 [00:29<00:26,  1.17it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.2952934205532074 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  54%|█████▍    | 35/65 [00:29<00:25,  1.17it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.6109200716018677 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  55%|█████▌    | 36/65 [00:30<00:24,  1.17it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.3142905533313751 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  57%|█████▋    | 37/65 [00:31<00:23,  1.17it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.8107244968414307 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  58%|█████▊    | 38/65 [00:32<00:23,  1.17it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.2588026523590088 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  60%|██████    | 39/65 [00:33<00:22,  1.17it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.5691624879837036 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  62%|██████▏   | 40/65 [00:34<00:21,  1.17it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.35844293236732483 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  63%|██████▎   | 41/65 [00:34<00:20,  1.18it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.38105958700180054 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  65%|██████▍   | 42/65 [00:35<00:19,  1.18it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.39452260732650757 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  66%|██████▌   | 43/65 [00:36<00:18,  1.18it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.5207206010818481 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  68%|██████▊   | 44/65 [00:37<00:17,  1.18it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.3550329804420471 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  69%|██████▉   | 45/65 [00:38<00:16,  1.18it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.2711259722709656 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  71%|███████   | 46/65 [00:39<00:16,  1.18it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.1852722018957138 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  72%|███████▏  | 47/65 [00:39<00:15,  1.18it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.17686806619167328 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  74%|███████▍  | 48/65 [00:40<00:14,  1.18it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.7263253331184387 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  75%|███████▌  | 49/65 [00:41<00:13,  1.18it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.5966437458992004 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  77%|███████▋  | 50/65 [00:42<00:12,  1.18it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.23536518216133118 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  78%|███████▊  | 51/65 [00:43<00:11,  1.18it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.2367303967475891 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  80%|████████  | 52/65 [00:44<00:11,  1.18it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.2465173900127411 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  82%|████████▏ | 53/65 [00:44<00:10,  1.18it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.32896241545677185 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  83%|████████▎ | 54/65 [00:45<00:09,  1.18it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.534004807472229 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  85%|████████▍ | 55/65 [00:46<00:08,  1.18it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.20665626227855682 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  86%|████████▌ | 56/65 [00:47<00:07,  1.18it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.33415141701698303 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  88%|████████▊ | 57/65 [00:48<00:06,  1.18it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.4210454821586609 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  89%|████████▉ | 58/65 [00:48<00:05,  1.18it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.15418291091918945 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  91%|█████████ | 59/65 [00:49<00:05,  1.19it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.45397764444351196 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  92%|█████████▏| 60/65 [00:50<00:04,  1.19it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.443539023399353 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  94%|█████████▍| 61/65 [00:51<00:03,  1.19it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.32585033774375916 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  95%|█████████▌| 62/65 [00:52<00:02,  1.19it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.2532985508441925 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  97%|█████████▋| 63/65 [00:52<00:01,  1.19it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: Logged validation loss: 0.7110154628753662 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0:  98%|█████████▊| 64/65 [00:53<00:00,  1.19it/s]\u001b[ADEBUG:gpt2_arc.src.training.trainer:Validation step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([19, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([19, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([19, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([19, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([19, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([19, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([19, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([19, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([19, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([19, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([19, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([19, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([19, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([19, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([19, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([19, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([19, 900, 256])\n",
            "/usr/local/python/3.12.1/lib/python3.12/site-packages/pytorch_lightning/utilities/data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 19. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "DEBUG: Logged validation loss: 0.348099023103714 for epoch 0\n",
            "\n",
            "\n",
            "Validation DataLoader 0: 100%|██████████| 65/65 [00:54<00:00,  1.19it/s]\u001b[A\n",
            "\n",
            "                                                                        \u001b[A\n",
            "Epoch 0: 100%|██████████| 62/62 [03:36<00:00,  0.29it/s, v_num=0, train_loss_step=0.158, val_loss=0.367]\n",
            "Epoch 0: 100%|██████████| 62/62 [03:36<00:00,  0.29it/s, v_num=0, train_loss_step=0.158, val_loss=0.367, train_loss_epoch=0.493]DEBUG:fsspec.local:open file: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt\n",
            "New checkpoint detected: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt\n",
            "Evaluating model: arc_model-epoch=00-val_loss=0.37.ckpt with command: python /workspaces/arc-neural-reasoning-model/gpt2_arc/src/evaluate.py --model_checkpoint /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/checkpoints/arc_model-epoch=00-val_loss=0.37.ckpt --batch_size 32 --output_dir evaluation_results --wandb_project arc-evaluation --wandb_run_name scaling-test-evaluation-epoch00-val_loss0.37\n",
            "\n",
            "Epoch 0:   0%|          | 0/62 [00:00<?, ?it/s, v_num=0, train_loss_step=0.158, val_loss=0.367, train_loss_epoch=0.493]         \n",
            "Epoch 1:   0%|          | 0/62 [00:00<?, ?it/s, v_num=0, train_loss_step=0.158, val_loss=0.367, train_loss_epoch=0.493]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.197772815823555 at step 62\n",
            "\n",
            "Epoch 1:   2%|▏         | 1/62 [00:04<04:26,  0.23it/s, v_num=0, train_loss_step=0.158, val_loss=0.367, train_loss_epoch=0.493]\n",
            "Epoch 1:   2%|▏         | 1/62 [00:04<04:26,  0.23it/s, v_num=0, train_loss_step=0.198, val_loss=0.367, train_loss_epoch=0.493]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.13002318143844604 at step 63\n",
            "\n",
            "Epoch 1:   3%|▎         | 2/62 [00:07<03:52,  0.26it/s, v_num=0, train_loss_step=0.198, val_loss=0.367, train_loss_epoch=0.493]\n",
            "Epoch 1:   3%|▎         | 2/62 [00:07<03:52,  0.26it/s, v_num=0, train_loss_step=0.130, val_loss=0.367, train_loss_epoch=0.493]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.2411908358335495 at step 64\n",
            "\n",
            "Epoch 1:   5%|▍         | 3/62 [00:10<03:32,  0.28it/s, v_num=0, train_loss_step=0.130, val_loss=0.367, train_loss_epoch=0.493]\n",
            "Epoch 1:   5%|▍         | 3/62 [00:10<03:32,  0.28it/s, v_num=0, train_loss_step=0.241, val_loss=0.367, train_loss_epoch=0.493]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.24733392894268036 at step 65\n",
            "\n",
            "Epoch 1:   6%|▋         | 4/62 [00:13<03:18,  0.29it/s, v_num=0, train_loss_step=0.241, val_loss=0.367, train_loss_epoch=0.493]\n",
            "Epoch 1:   6%|▋         | 4/62 [00:13<03:18,  0.29it/s, v_num=0, train_loss_step=0.247, val_loss=0.367, train_loss_epoch=0.493]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.37195202708244324 at step 66\n",
            "\n",
            "Epoch 1:   8%|▊         | 5/62 [00:18<03:36,  0.26it/s, v_num=0, train_loss_step=0.247, val_loss=0.367, train_loss_epoch=0.493]\n",
            "Epoch 1:   8%|▊         | 5/62 [00:18<03:36,  0.26it/s, v_num=0, train_loss_step=0.372, val_loss=0.367, train_loss_epoch=0.493]DEBUG:gpt2_arc.src.training.trainer:Training step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([21, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([21, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([21, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([21, 900, 256])\n",
            "DEBUG: self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Before setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: After setting default, self.results['train'] is of type <class 'dict'>\n",
            "DEBUG: Logged training loss: 0.21500061452388763 at step 67\n",
            "[rank: 0] Received SIGTERM: 15\n",
            "\n",
            "Epoch 1:  10%|▉         | 6/62 [00:26<04:04,  0.23it/s, v_num=0, train_loss_step=0.372, val_loss=0.367, train_loss_epoch=0.493]\n",
            "Epoch 1:  10%|▉         | 6/62 [00:26<04:04,  0.23it/s, v_num=0, train_loss_step=0.215, val_loss=0.367, train_loss_epoch=0.493]Experiment finished. Metrics: {}\n",
            "\n",
            "Epoch 1:  10%|▉         | 6/62 [00:27<04:13,  0.22it/s, v_num=0, train_loss_step=0.215, val_loss=0.367, train_loss_epoch=0.493]\n",
            "Training completed successfully.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully evaluated model: arc_model-epoch=00-val_loss=0.37.ckpt\n",
            "Evaluation Output:\n",
            "DEBUG: Attempting to generate model summary\n",
            "DEBUG: Model summary generated successfully\n",
            "DEBUG: Model summary:\n",
            "   | Name                        | Type             | Params | Mode\n",
            "-------------------------------------------------------------------------\n",
            "0  | conv1                       | Conv2d           | 2.6 K  | eval\n",
            "1  | blocks                      | ModuleList       | 1.6 M  | eval\n",
            "2  | blocks.0                    | TransformerBlock | 789 K  | eval\n",
            "3  | blocks.0.attention          | Attention        | 263 K  | eval\n",
            "4  | blocks.0.attention.key      | Linear           | 65.8 K | eval\n",
            "5  | blocks.0.attention.query    | Linear           | 65.8 K | eval\n",
            "6  | blocks.0.attention.value    | Linear           | 65.8 K | eval\n",
            "7  | blocks.0.attention.proj     | Linear           | 65.8 K | eval\n",
            "8  | blocks.0.feed_forward       | FeedForward      | 525 K  | eval\n",
            "9  | blocks.0.feed_forward.net   | Sequential       | 525 K  | eval\n",
            "10 | blocks.0.feed_forward.net.0 | Linear           | 263 K  | eval\n",
            "11 | blocks.0.feed_forward.net.1 | ReLU             | 0      | eval\n",
            "12 | blocks.0.feed_forward.net.2 | Linear           | 262 K  | eval\n",
            "13 | blocks.0.ln1                | LayerNorm        | 512    | eval\n",
            "14 | blocks.0.ln2                | LayerNorm        | 512    | eval\n",
            "15 | blocks.1                    | TransformerBlock | 789 K  | eval\n",
            "16 | blocks.1.attention          | Attention        | 263 K  | eval\n",
            "17 | blocks.1.attention.key      | Linear           | 65.8 K | eval\n",
            "18 | blocks.1.attention.query    | Linear           | 65.8 K | eval\n",
            "19 | blocks.1.attention.value    | Linear           | 65.8 K | eval\n",
            "20 | blocks.1.attention.proj     | Linear           | 65.8 K | eval\n",
            "21 | blocks.1.feed_forward       | FeedForward      | 525 K  | eval\n",
            "22 | blocks.1.feed_forward.net   | Sequential       | 525 K  | eval\n",
            "23 | blocks.1.feed_forward.net.0 | Linear           | 263 K  | eval\n",
            "24 | blocks.1.feed_forward.net.1 | ReLU             | 0      | eval\n",
            "25 | blocks.1.feed_forward.net.2 | Linear           | 262 K  | eval\n",
            "26 | blocks.1.ln1                | LayerNorm        | 512    | eval\n",
            "27 | blocks.1.ln2                | LayerNorm        | 512    | eval\n",
            "28 | ln_f                        | LayerNorm        | 512    | eval\n",
            "29 | fc_out                      | Linear           | 2.6 K  | eval\n",
            "-------------------------------------------------------------------------\n",
            "1.6 M     Trainable params\n",
            "0         Non-trainable params\n",
            "1.6 M     Total params\n",
            "6.341     Total estimated model params size (MB)\n",
            "0         Modules in train mode\n",
            "30        Modules in eval mode\n",
            "DEBUG: Sanitized model_name: arc_model-epoch_00-val_loss_0\n",
            "DEBUG: Model name contains only valid characters.\n",
            "DEBUG: Initialized self.results['train'] as <class 'dict'>\n",
            "\n",
            "Testing: |          | 0/? [00:00<?, ?it/s]\n",
            "Testing:   0%|          | 0/43 [00:00<?, ?it/s]\n",
            "Testing DataLoader 0:   0%|          | 0/43 [00:00<?, ?it/s]DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9666666388511658\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 35\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.14285714285714285\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9844444394111633\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.3\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9733333587646484\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 29\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.1724137931034483\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9655555486679077\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 37\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.16216216216216217\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 22\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.2727272727272727\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9722222089767456\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.945555567741394\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8822222352027893\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 56\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9177777767181396\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 32\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9833333492279053\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 33\n",
            "Correctly predicted different pixels: 18\n",
            "Calculated accuracy: 0.5454545454545454\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 42\n",
            "Correctly predicted different pixels: 22\n",
            "Calculated accuracy: 0.5238095238095238\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 39\n",
            "Correctly predicted different pixels: 19\n",
            "Calculated accuracy: 0.48717948717948717\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6611111164093018\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 247\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6922222375869751\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 208\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6166666746139526\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 285\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.800000011920929\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 39\n",
            "Correctly predicted different pixels: 26\n",
            "Calculated accuracy: 0.6666666666666666\n",
            "DEBUG: compute_accuracy - Accuracy: 0.75\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 52\n",
            "Correctly predicted different pixels: 32\n",
            "Calculated accuracy: 0.6153846153846154\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8399999737739563\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 43\n",
            "Correctly predicted different pixels: 30\n",
            "Calculated accuracy: 0.6976744186046512\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 25\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.2\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 3\n",
            "Calculated accuracy: 0.14285714285714285\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.16666666666666666\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9544444680213928\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 31\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9677777886390686\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 19\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 2\n",
            "Calculated accuracy: 0.09523809523809523\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 28\n",
            "Correctly predicted different pixels: 2\n",
            "Calculated accuracy: 0.07142857142857142\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9399999976158142\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 55\n",
            "Correctly predicted different pixels: 2\n",
            "Calculated accuracy: 0.03636363636363636\n",
            "DEBUG: compute_accuracy - Accuracy: 0.47777777910232544\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 897\n",
            "Correctly predicted different pixels: 429\n",
            "Calculated accuracy: 0.4782608695652174\n",
            "DEBUG: compute_accuracy - Accuracy: 0.4333333373069763\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 896\n",
            "Correctly predicted different pixels: 390\n",
            "Calculated accuracy: 0.43526785714285715\n",
            "DEBUG: compute_accuracy - Accuracy: 0.2988888919353485\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 896\n",
            "Correctly predicted different pixels: 269\n",
            "Calculated accuracy: 0.3002232142857143\n",
            "DEBUG: compute_accuracy - Accuracy: 0.29555556178092957\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 895\n",
            "Correctly predicted different pixels: 266\n",
            "Calculated accuracy: 0.29720670391061454\n",
            "\n",
            "Testing DataLoader 0:   2%|▏         | 1/43 [00:05<03:36,  0.19it/s]DEBUG: compute_accuracy - Accuracy: 0.652222216129303\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 77\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8622221946716309\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8488888740539551\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 22\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9677777886390686\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 536\n",
            "Correctly predicted different pixels: 509\n",
            "Calculated accuracy: 0.9496268656716418\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9666666388511658\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 477\n",
            "Correctly predicted different pixels: 447\n",
            "Calculated accuracy: 0.9371069182389937\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9188888669013977\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 536\n",
            "Correctly predicted different pixels: 463\n",
            "Calculated accuracy: 0.8638059701492538\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9655555486679077\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 31\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9366666674613953\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 57\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9388889074325562\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 55\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9166666865348816\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 75\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 4\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 1\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 52\n",
            "Correctly predicted different pixels: 35\n",
            "Calculated accuracy: 0.6730769230769231\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9788888692855835\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 60\n",
            "Correctly predicted different pixels: 41\n",
            "Calculated accuracy: 0.6833333333333333\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 64\n",
            "Correctly predicted different pixels: 44\n",
            "Calculated accuracy: 0.6875\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9722222089767456\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 23\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 13\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9466666579246521\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 44\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9466666579246521\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 41\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9466666579246521\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 47\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 33\n",
            "Correctly predicted different pixels: 25\n",
            "Calculated accuracy: 0.7575757575757576\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 29\n",
            "Correctly predicted different pixels: 23\n",
            "Calculated accuracy: 0.7931034482758621\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 30\n",
            "Correctly predicted different pixels: 21\n",
            "Calculated accuracy: 0.7\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 27\n",
            "Correctly predicted different pixels: 20\n",
            "Calculated accuracy: 0.7407407407407407\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8833333253860474\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 67\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9344444274902344\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.898888885974884\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 58\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9711111187934875\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 23\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9744444489479065\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9744444489479065\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "\n",
            "Testing DataLoader 0:   5%|▍         | 2/43 [00:09<03:22,  0.20it/s]DEBUG: compute_accuracy - Accuracy: 0.894444465637207\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 92\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8799999952316284\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 104\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.894444465637207\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 92\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.894444465637207\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 92\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.949999988079071\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9333333373069763\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 54\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 4\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 4\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9877777695655823\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 4\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 5\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9666666388511658\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9833333492279053\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 27\n",
            "Correctly predicted different pixels: 9\n",
            "Calculated accuracy: 0.3333333333333333\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 7\n",
            "Calculated accuracy: 0.2916666666666667\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 19\n",
            "Correctly predicted different pixels: 7\n",
            "Calculated accuracy: 0.3684210526315789\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 13\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.38461538461538464\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9711111187934875\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9544444680213928\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9711111187934875\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 11\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 3\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 37\n",
            "Correctly predicted different pixels: 26\n",
            "Calculated accuracy: 0.7027027027027027\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 68\n",
            "Correctly predicted different pixels: 48\n",
            "Calculated accuracy: 0.7058823529411765\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9844444394111633\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 51\n",
            "Correctly predicted different pixels: 37\n",
            "Calculated accuracy: 0.7254901960784313\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8766666650772095\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 84\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8755555748939514\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 86\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8255555629730225\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 124\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9200000166893005\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9333333373069763\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.902222216129303\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 52\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8122222423553467\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 104\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "\n",
            "Testing DataLoader 0:   7%|▋         | 3/43 [00:12<02:52,  0.23it/s]DEBUG: compute_accuracy - Accuracy: 0.8655555844306946\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 69\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8266666531562805\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8411111235618591\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8888888955116272\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 7\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8955555558204651\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.653333306312561\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6222222447395325\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.601111114025116\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9511111378669739\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9399999976158142\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 22\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9355555772781372\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 9\n",
            "Calculated accuracy: 0.25\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 9\n",
            "Calculated accuracy: 0.25\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 9\n",
            "Calculated accuracy: 0.25\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8022222518920898\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 54\n",
            "Correctly predicted different pixels: 27\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7811111211776733\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 111\n",
            "Correctly predicted different pixels: 52\n",
            "Calculated accuracy: 0.46846846846846846\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9211111068725586\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9577777981758118\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 19\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9733333587646484\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 5\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 27\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 27\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 27\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 27\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9144444465637207\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9511111378669739\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 5\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9377777576446533\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8122222423553467\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 96\n",
            "Correctly predicted different pixels: 51\n",
            "Calculated accuracy: 0.53125\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8644444346427917\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 55\n",
            "Correctly predicted different pixels: 32\n",
            "Calculated accuracy: 0.5818181818181818\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8799999952316284\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 49\n",
            "Correctly predicted different pixels: 30\n",
            "Calculated accuracy: 0.6122448979591837\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9766666889190674\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 44\n",
            "Correctly predicted different pixels: 23\n",
            "Calculated accuracy: 0.5227272727272727\n",
            "\n",
            "Testing DataLoader 0:   9%|▉         | 4/43 [00:15<02:32,  0.26it/s]DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 46\n",
            "Correctly predicted different pixels: 24\n",
            "Calculated accuracy: 0.5217391304347826\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9766666889190674\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 42\n",
            "Correctly predicted different pixels: 21\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9744444489479065\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 44\n",
            "Correctly predicted different pixels: 21\n",
            "Calculated accuracy: 0.4772727272727273\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 54\n",
            "Correctly predicted different pixels: 27\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9733333587646484\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 32\n",
            "Correctly predicted different pixels: 16\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9788888692855835\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 38\n",
            "Correctly predicted different pixels: 19\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9733333587646484\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 63\n",
            "Correctly predicted different pixels: 40\n",
            "Calculated accuracy: 0.6349206349206349\n",
            "DEBUG: compute_accuracy - Accuracy: 0.996666669845581\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 129\n",
            "Correctly predicted different pixels: 127\n",
            "Calculated accuracy: 0.9844961240310077\n",
            "DEBUG: compute_accuracy - Accuracy: 0.948888897895813\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 108\n",
            "Correctly predicted different pixels: 62\n",
            "Calculated accuracy: 0.5740740740740741\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9988889098167419\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 51\n",
            "Correctly predicted different pixels: 50\n",
            "Calculated accuracy: 0.9803921568627451\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9977777600288391\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 52\n",
            "Correctly predicted different pixels: 50\n",
            "Calculated accuracy: 0.9615384615384616\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9988889098167419\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 86\n",
            "Correctly predicted different pixels: 85\n",
            "Calculated accuracy: 0.9883720930232558\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9988889098167419\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 78\n",
            "Correctly predicted different pixels: 77\n",
            "Calculated accuracy: 0.9871794871794872\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9988889098167419\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 4\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9844444394111633\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 120\n",
            "Correctly predicted different pixels: 106\n",
            "Calculated accuracy: 0.8833333333333333\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9711111187934875\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 231\n",
            "Correctly predicted different pixels: 206\n",
            "Calculated accuracy: 0.8917748917748918\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 167\n",
            "Correctly predicted different pixels: 161\n",
            "Calculated accuracy: 0.9640718562874252\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9744444489479065\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 4\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9677777886390686\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9566666483879089\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 15\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8888888955116272\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 43\n",
            "Correctly predicted different pixels: 2\n",
            "Calculated accuracy: 0.046511627906976744\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8655555844306946\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 67\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.05970149253731343\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8266666531562805\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 75\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.08\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 27\n",
            "Correctly predicted different pixels: 17\n",
            "Calculated accuracy: 0.6296296296296297\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 54\n",
            "Correctly predicted different pixels: 34\n",
            "Calculated accuracy: 0.6296296296296297\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 19\n",
            "Calculated accuracy: 0.5277777777777778\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9566666483879089\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 7\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9666666388511658\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 10\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9377777576446533\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 22\n",
            "Correctly predicted different pixels: 11\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9555555582046509\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 32\n",
            "Correctly predicted different pixels: 16\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.3055555522441864\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 81\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "\n",
            "Testing DataLoader 0:  12%|█▏        | 5/43 [00:18<02:18,  0.27it/s]DEBUG: compute_accuracy - Accuracy: 0.3055555522441864\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 80\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.3055555522441864\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 52\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9477777481079102\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 38\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9622222185134888\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 25\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9288889169692993\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 55\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8922222256660461\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 43\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9288889169692993\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 28\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9766666889190674\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 3\n",
            "Correctly predicted different pixels: 3\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9666666388511658\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 5\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9611111283302307\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 5\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.4122222363948822\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 66\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.4122222363948822\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 50\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.4144444465637207\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 62\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 187\n",
            "Correctly predicted different pixels: 179\n",
            "Calculated accuracy: 0.9572192513368984\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 152\n",
            "Correctly predicted different pixels: 139\n",
            "Calculated accuracy: 0.9144736842105263\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 84\n",
            "Correctly predicted different pixels: 78\n",
            "Calculated accuracy: 0.9285714285714286\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.047619047619047616\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9466666579246521\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 199\n",
            "Correctly predicted different pixels: 162\n",
            "Calculated accuracy: 0.8140703517587939\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9399999976158142\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 214\n",
            "Correctly predicted different pixels: 186\n",
            "Calculated accuracy: 0.8691588785046729\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9288889169692993\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 72\n",
            "Correctly predicted different pixels: 35\n",
            "Calculated accuracy: 0.4861111111111111\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9655555486679077\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 22\n",
            "Correctly predicted different pixels: 11\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9688888788223267\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 10\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9066666960716248\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 52\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9266666769981384\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 35\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9255555272102356\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 31\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9244444370269775\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 66\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9233333468437195\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 67\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9577777981758118\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 15\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9311110973358154\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "\n",
            "Testing DataLoader 0:  14%|█▍        | 6/43 [00:20<02:09,  0.29it/s]DEBUG: compute_accuracy - Accuracy: 0.9344444274902344\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 26\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.949999988079071\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.1599999964237213\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 145\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.20555555820465088\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 87\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8677777647972107\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 5\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8422222137451172\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7099999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 242\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6644444465637207\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 270\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6255555748939514\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 311\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9644444584846497\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 1\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9544444680213928\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9711111187934875\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 4\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9555555582046509\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9744444489479065\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 2\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9333333373069763\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 69\n",
            "Correctly predicted different pixels: 12\n",
            "Calculated accuracy: 0.17391304347826086\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9688888788223267\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 33\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.18181818181818182\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9644444584846497\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 34\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.14705882352941177\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9377777576446533\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 62\n",
            "Correctly predicted different pixels: 10\n",
            "Calculated accuracy: 0.16129032258064516\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 77\n",
            "Correctly predicted different pixels: 71\n",
            "Calculated accuracy: 0.922077922077922\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 84\n",
            "Correctly predicted different pixels: 74\n",
            "Calculated accuracy: 0.8809523809523809\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9877777695655823\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 105\n",
            "Correctly predicted different pixels: 94\n",
            "Calculated accuracy: 0.8952380952380953\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 1\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 1\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9677777886390686\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 1\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 9\n",
            "Calculated accuracy: 0.25\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 27\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 45\n",
            "Correctly predicted different pixels: 9\n",
            "Calculated accuracy: 0.2\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 51\n",
            "Correctly predicted different pixels: 37\n",
            "Calculated accuracy: 0.7254901960784313\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 49\n",
            "Correctly predicted different pixels: 34\n",
            "Calculated accuracy: 0.6938775510204082\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9844444394111633\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 52\n",
            "Correctly predicted different pixels: 39\n",
            "Calculated accuracy: 0.75\n",
            "\n",
            "Testing DataLoader 0:  16%|█▋        | 7/43 [00:23<02:01,  0.30it/s]DEBUG: compute_accuracy - Accuracy: 0.9844444394111633\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 46\n",
            "Correctly predicted different pixels: 33\n",
            "Calculated accuracy: 0.717391304347826\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 43\n",
            "Correctly predicted different pixels: 28\n",
            "Calculated accuracy: 0.6511627906976745\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9844444394111633\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 48\n",
            "Correctly predicted different pixels: 36\n",
            "Calculated accuracy: 0.75\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9044444561004639\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 13\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9300000071525574\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 7\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8899999856948853\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 13\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9611111283302307\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 30\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9622222185134888\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 28\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9622222185134888\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 28\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 5\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 11\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9666666388511658\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 15\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9744444489479065\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9722222089767456\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9655555486679077\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9311110973358154\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 235\n",
            "Correctly predicted different pixels: 189\n",
            "Calculated accuracy: 0.8042553191489362\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 326\n",
            "Correctly predicted different pixels: 269\n",
            "Calculated accuracy: 0.8251533742331288\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9088888764381409\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 208\n",
            "Correctly predicted different pixels: 148\n",
            "Calculated accuracy: 0.7115384615384616\n",
            "DEBUG: compute_accuracy - Accuracy: 0.897777795791626\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 200\n",
            "Correctly predicted different pixels: 138\n",
            "Calculated accuracy: 0.69\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9788888692855835\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.1\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9877777695655823\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.16666666666666666\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 7\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.14285714285714285\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9544444680213928\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 352\n",
            "Correctly predicted different pixels: 311\n",
            "Calculated accuracy: 0.8835227272727273\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9622222185134888\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 422\n",
            "Correctly predicted different pixels: 388\n",
            "Calculated accuracy: 0.919431279620853\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 276\n",
            "Correctly predicted different pixels: 263\n",
            "Calculated accuracy: 0.9528985507246377\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 25\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 34\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 34\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 221\n",
            "Correctly predicted different pixels: 201\n",
            "Calculated accuracy: 0.9095022624434389\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9788888692855835\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 251\n",
            "Correctly predicted different pixels: 238\n",
            "Calculated accuracy: 0.9482071713147411\n",
            "\n",
            "Testing DataLoader 0:  19%|█▊        | 8/43 [00:26<01:54,  0.30it/s]DEBUG: compute_accuracy - Accuracy: 0.9744444489479065\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 255\n",
            "Correctly predicted different pixels: 232\n",
            "Calculated accuracy: 0.9098039215686274\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6277777552604675\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 64\n",
            "Correctly predicted different pixels: 61\n",
            "Calculated accuracy: 0.953125\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6266666650772095\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 62\n",
            "Correctly predicted different pixels: 60\n",
            "Calculated accuracy: 0.967741935483871\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6288889050483704\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 61\n",
            "Correctly predicted different pixels: 61\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9300000071525574\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 22\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9344444274902344\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9277777671813965\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 30\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9944444298744202\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 15\n",
            "Calculated accuracy: 0.75\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 19\n",
            "Correctly predicted different pixels: 12\n",
            "Calculated accuracy: 0.631578947368421\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 12\n",
            "Calculated accuracy: 0.6666666666666666\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 11\n",
            "Calculated accuracy: 0.6111111111111112\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 11\n",
            "Calculated accuracy: 0.6111111111111112\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 7\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9288889169692993\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 60\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.945555567741394\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9555555582046509\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9766666889190674\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9277777671813965\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 65\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9733333587646484\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 12\n",
            "Calculated accuracy: 0.3333333333333333\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9833333492279053\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.25\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9844444394111633\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 7\n",
            "Calculated accuracy: 0.3333333333333333\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 10\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8500000238418579\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 120\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8577777743339539\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 112\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9200000166893005\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 48\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8600000143051147\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 78\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8644444346427917\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 78\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 29\n",
            "Correctly predicted different pixels: 19\n",
            "Calculated accuracy: 0.6551724137931034\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 25\n",
            "Correctly predicted different pixels: 16\n",
            "Calculated accuracy: 0.64\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 28\n",
            "Correctly predicted different pixels: 18\n",
            "Calculated accuracy: 0.6428571428571429\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 31\n",
            "Correctly predicted different pixels: 18\n",
            "Calculated accuracy: 0.5806451612903226\n",
            "\n",
            "Testing DataLoader 0:  21%|██        | 9/43 [00:28<01:48,  0.31it/s]DEBUG: compute_accuracy - Accuracy: 0.996666669845581\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 51\n",
            "Correctly predicted different pixels: 48\n",
            "Calculated accuracy: 0.9411764705882353\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 59\n",
            "Correctly predicted different pixels: 49\n",
            "Calculated accuracy: 0.8305084745762712\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 97\n",
            "Correctly predicted different pixels: 83\n",
            "Calculated accuracy: 0.8556701030927835\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9733333587646484\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 118\n",
            "Correctly predicted different pixels: 100\n",
            "Calculated accuracy: 0.847457627118644\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 108\n",
            "Correctly predicted different pixels: 100\n",
            "Calculated accuracy: 0.9259259259259259\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9733333587646484\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 140\n",
            "Correctly predicted different pixels: 116\n",
            "Calculated accuracy: 0.8285714285714286\n",
            "DEBUG: compute_accuracy - Accuracy: 0.894444465637207\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 95\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8666666746139526\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 120\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8755555748939514\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 112\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8888888955116272\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 97\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8888888955116272\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 97\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8533333539962769\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 76\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.945555567741394\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9288889169692993\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 48\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8122222423553467\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 120\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9722222089767456\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9977777600288391\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 27\n",
            "Correctly predicted different pixels: 25\n",
            "Calculated accuracy: 0.9259259259259259\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9988889098167419\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 13\n",
            "Calculated accuracy: 0.9285714285714286\n",
            "DEBUG: compute_accuracy - Accuracy: 0.996666669845581\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 17\n",
            "Calculated accuracy: 0.85\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9977777600288391\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 13\n",
            "Correctly predicted different pixels: 11\n",
            "Calculated accuracy: 0.8461538461538461\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9988889098167419\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 13\n",
            "Correctly predicted different pixels: 12\n",
            "Calculated accuracy: 0.9230769230769231\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9833333492279053\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 38\n",
            "Correctly predicted different pixels: 23\n",
            "Calculated accuracy: 0.6052631578947368\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9766666889190674\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 45\n",
            "Correctly predicted different pixels: 26\n",
            "Calculated accuracy: 0.5777777777777777\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 44\n",
            "Correctly predicted different pixels: 26\n",
            "Calculated accuracy: 0.5909090909090909\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9788888692855835\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 50\n",
            "Correctly predicted different pixels: 32\n",
            "Calculated accuracy: 0.64\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 25\n",
            "Calculated accuracy: 0.625\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 46\n",
            "Correctly predicted different pixels: 28\n",
            "Calculated accuracy: 0.6086956521739131\n",
            "DEBUG: compute_accuracy - Accuracy: 0.596666693687439\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 75\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6155555844306946\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 77\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7022222280502319\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 30\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9722222089767456\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 34\n",
            "Correctly predicted different pixels: 9\n",
            "Calculated accuracy: 0.2647058823529412\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 46\n",
            "Correctly predicted different pixels: 10\n",
            "Calculated accuracy: 0.21739130434782608\n",
            "\n",
            "Testing DataLoader 0:  23%|██▎       | 10/43 [00:31<01:43,  0.32it/s]DEBUG: compute_accuracy - Accuracy: 0.9288889169692993\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 73\n",
            "Correctly predicted different pixels: 10\n",
            "Calculated accuracy: 0.136986301369863\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9355555772781372\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 56\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9744444489479065\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 22\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6544444561004639\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 77\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6100000143051147\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 70\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6166666746139526\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 102\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8533333539962769\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 175\n",
            "Correctly predicted different pixels: 90\n",
            "Calculated accuracy: 0.5142857142857142\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9144444465637207\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 116\n",
            "Correctly predicted different pixels: 41\n",
            "Calculated accuracy: 0.35344827586206895\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9200000166893005\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 122\n",
            "Correctly predicted different pixels: 66\n",
            "Calculated accuracy: 0.5409836065573771\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 10\n",
            "Calculated accuracy: 0.5882352941176471\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 10\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9788888692855835\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 25\n",
            "Correctly predicted different pixels: 13\n",
            "Calculated accuracy: 0.52\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9944444298744202\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 2\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8822222352027893\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 5\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8244444727897644\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 7\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7488889098167419\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8077777624130249\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9366666674613953\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 3\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8911111354827881\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8911111354827881\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 3\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7866666913032532\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8399999737739563\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8266666531562805\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 84\n",
            "Correctly predicted different pixels: 67\n",
            "Calculated accuracy: 0.7976190476190477\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9722222089767456\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 37\n",
            "Correctly predicted different pixels: 28\n",
            "Calculated accuracy: 0.7567567567567568\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9722222089767456\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 37\n",
            "Correctly predicted different pixels: 28\n",
            "Calculated accuracy: 0.7567567567567568\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 27\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9333333373069763\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 58\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9422222375869751\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 50\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "\n",
            "Testing DataLoader 0:  26%|██▌       | 11/43 [00:33<01:38,  0.32it/s]DEBUG: compute_accuracy - Accuracy: 0.9233333468437195\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 66\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8122222423553467\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 166\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8122222423553467\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 163\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8122222423553467\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 162\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.1088888868689537\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 39\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.02564102564102564\n",
            "DEBUG: compute_accuracy - Accuracy: 0.08666666597127914\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 45\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.08888888888888889\n",
            "DEBUG: compute_accuracy - Accuracy: 0.15000000596046448\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 95\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.08421052631578947\n",
            "DEBUG: compute_accuracy - Accuracy: 0.20777778327465057\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 115\n",
            "Correctly predicted different pixels: 26\n",
            "Calculated accuracy: 0.22608695652173913\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9733333587646484\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 23\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.043478260869565216\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 2\n",
            "Calculated accuracy: 0.2\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9555555582046509\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 42\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.09523809523809523\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 19\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.3157894736842105\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9944444298744202\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 11\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.5454545454545454\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.35294117647058826\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 23\n",
            "Correctly predicted different pixels: 7\n",
            "Calculated accuracy: 0.30434782608695654\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 28\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.2857142857142857\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.4444444444444444\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 27\n",
            "Correctly predicted different pixels: 9\n",
            "Calculated accuracy: 0.3333333333333333\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 9\n",
            "Calculated accuracy: 0.25\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 9\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 9\n",
            "Calculated accuracy: 0.25\n",
            "DEBUG: compute_accuracy - Accuracy: 0.12888889014720917\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 123\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.12888889014720917\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 82\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.12888889014720917\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 99\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 29\n",
            "Correctly predicted different pixels: 14\n",
            "Calculated accuracy: 0.4827586206896552\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9766666889190674\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 34\n",
            "Correctly predicted different pixels: 17\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 18\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9711111187934875\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 47\n",
            "Correctly predicted different pixels: 21\n",
            "Calculated accuracy: 0.44680851063829785\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8666666746139526\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 44\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.022727272727272728\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8500000238418579\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 66\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.09090909090909091\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8700000047683716\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 68\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "\n",
            "Testing DataLoader 0:  28%|██▊       | 12/43 [00:36<01:34,  0.33it/s]DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 53\n",
            "Correctly predicted different pixels: 40\n",
            "Calculated accuracy: 0.7547169811320755\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 46\n",
            "Correctly predicted different pixels: 34\n",
            "Calculated accuracy: 0.7391304347826086\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 42\n",
            "Correctly predicted different pixels: 30\n",
            "Calculated accuracy: 0.7142857142857143\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 41\n",
            "Correctly predicted different pixels: 32\n",
            "Calculated accuracy: 0.7804878048780488\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 5\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 5\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.75\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 54\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.75\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 28\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7522222399711609\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 48\n",
            "Correctly predicted different pixels: 2\n",
            "Calculated accuracy: 0.041666666666666664\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9766666889190674\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9711111187934875\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 13\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9511111378669739\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7822222113609314\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 48\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8122222423553467\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 44\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6211110949516296\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 15\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.5233333110809326\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7333333492279053\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 15\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 89\n",
            "Correctly predicted different pixels: 77\n",
            "Calculated accuracy: 0.8651685393258427\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9977777600288391\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 15\n",
            "Calculated accuracy: 0.8823529411764706\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9977777600288391\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 27\n",
            "Correctly predicted different pixels: 25\n",
            "Calculated accuracy: 0.9259259259259259\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 43\n",
            "Correctly predicted different pixels: 38\n",
            "Calculated accuracy: 0.8837209302325582\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 49\n",
            "Correctly predicted different pixels: 44\n",
            "Calculated accuracy: 0.8979591836734694\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 32\n",
            "Correctly predicted different pixels: 16\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 34\n",
            "Correctly predicted different pixels: 17\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 28\n",
            "Correctly predicted different pixels: 11\n",
            "Calculated accuracy: 0.39285714285714285\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9844444394111633\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 29\n",
            "Correctly predicted different pixels: 15\n",
            "Calculated accuracy: 0.5172413793103449\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9288889169692993\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 64\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6088888645172119\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 400\n",
            "Correctly predicted different pixels: 48\n",
            "Calculated accuracy: 0.12\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 81\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 30\n",
            "Correctly predicted different pixels: 14\n",
            "Calculated accuracy: 0.4666666666666667\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 30\n",
            "Correctly predicted different pixels: 15\n",
            "Calculated accuracy: 0.5\n",
            "\n",
            "Testing DataLoader 0:  30%|███       | 13/43 [00:39<01:31,  0.33it/s]DEBUG: compute_accuracy - Accuracy: 0.9711111187934875\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 46\n",
            "Correctly predicted different pixels: 20\n",
            "Calculated accuracy: 0.43478260869565216\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8544444441795349\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 5\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.804444432258606\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7911111116409302\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.757777750492096\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9388889074325562\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9277777671813965\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 31\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8899999856948853\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 51\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 31\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9300000071525574\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 56\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 190\n",
            "Correctly predicted different pixels: 180\n",
            "Calculated accuracy: 0.9473684210526315\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 100\n",
            "Correctly predicted different pixels: 96\n",
            "Calculated accuracy: 0.96\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9944444298744202\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 140\n",
            "Correctly predicted different pixels: 135\n",
            "Calculated accuracy: 0.9642857142857143\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9233333468437195\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 193\n",
            "Correctly predicted different pixels: 126\n",
            "Calculated accuracy: 0.6528497409326425\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7022222280502319\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 184\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7988888621330261\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 130\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6399999856948853\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 228\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.897777795791626\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.902222216129303\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 25\n",
            "Correctly predicted different pixels: 25\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 15\n",
            "Correctly predicted different pixels: 15\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9166666865348816\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 35\n",
            "Correctly predicted different pixels: 35\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 7\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9722222089767456\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 5\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 2\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7555555701255798\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 113\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7733333110809326\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 103\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 4\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9077777862548828\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8799999952316284\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 5\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.800000011920929\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 22\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7333333492279053\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "\n",
            "Testing DataLoader 0:  33%|███▎      | 14/43 [00:42<01:27,  0.33it/s]DEBUG: compute_accuracy - Accuracy: 0.8888888955116272\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 15\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8888888955116272\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8888888955116272\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 7\n",
            "Calculated accuracy: 0.4375\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.47058823529411764\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 15\n",
            "Correctly predicted different pixels: 7\n",
            "Calculated accuracy: 0.4666666666666667\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8577777743339539\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 100\n",
            "Correctly predicted different pixels: 64\n",
            "Calculated accuracy: 0.64\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8500000238418579\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 89\n",
            "Correctly predicted different pixels: 46\n",
            "Calculated accuracy: 0.5168539325842697\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9399999976158142\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 65\n",
            "Correctly predicted different pixels: 42\n",
            "Calculated accuracy: 0.6461538461538462\n",
            "DEBUG: compute_accuracy - Accuracy: 0.948888897895813\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.945555567741394\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 11\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 67\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9211111068725586\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 61\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9200000166893005\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 63\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 31\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 30\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9611111283302307\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 30\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 31\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8622221946716309\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 66\n",
            "Correctly predicted different pixels: 3\n",
            "Calculated accuracy: 0.045454545454545456\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7766666412353516\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 88\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.045454545454545456\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9744444489479065\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9766666889190674\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9200000166893005\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 32\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8933333158493042\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 48\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.898888885974884\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 22\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.22727272727272727\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9277777671813965\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 3\n",
            "Calculated accuracy: 0.25\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8888888955116272\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 106\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.07547169811320754\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 3\n",
            "Calculated accuracy: 0.16666666666666666\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9288889169692993\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 64\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.0625\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 90\n",
            "Correctly predicted different pixels: 9\n",
            "Calculated accuracy: 0.1\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8888888955116272\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 100\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.05\n",
            "\n",
            "Testing DataLoader 0:  35%|███▍      | 15/43 [00:45<01:24,  0.33it/s]DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 34\n",
            "Correctly predicted different pixels: 16\n",
            "Calculated accuracy: 0.47058823529411764\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9788888692855835\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 38\n",
            "Correctly predicted different pixels: 19\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 20\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 16\n",
            "Calculated accuracy: 0.4444444444444444\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 38\n",
            "Correctly predicted different pixels: 18\n",
            "Calculated accuracy: 0.47368421052631576\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 26\n",
            "Correctly predicted different pixels: 13\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.47058823529411764\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 9\n",
            "Calculated accuracy: 0.25\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 11\n",
            "Correctly predicted different pixels: 3\n",
            "Calculated accuracy: 0.2727272727272727\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9833333492279053\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.2857142857142857\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9833333492279053\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.2857142857142857\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 5\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 7\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9644444584846497\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.05555555555555555\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 13\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9511111378669739\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 11\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9355555772781372\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9233333468437195\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 27\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9666666388511658\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9466666579246521\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9544444680213928\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 30\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7955555319786072\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 184\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7599999904632568\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 216\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.95333331823349\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9577777981758118\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8855555653572083\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 493\n",
            "Correctly predicted different pixels: 390\n",
            "Calculated accuracy: 0.7910750507099391\n",
            "\n",
            "Testing DataLoader 0:  37%|███▋      | 16/43 [00:47<01:20,  0.33it/s]DEBUG: compute_accuracy - Accuracy: 0.9988889098167419\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 344\n",
            "Correctly predicted different pixels: 343\n",
            "Calculated accuracy: 0.997093023255814\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9988889098167419\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 336\n",
            "Correctly predicted different pixels: 335\n",
            "Calculated accuracy: 0.9970238095238095\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 9\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 32\n",
            "Correctly predicted different pixels: 16\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 28\n",
            "Correctly predicted different pixels: 18\n",
            "Calculated accuracy: 0.6428571428571429\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 32\n",
            "Correctly predicted different pixels: 26\n",
            "Calculated accuracy: 0.8125\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9944444298744202\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 29\n",
            "Correctly predicted different pixels: 24\n",
            "Calculated accuracy: 0.8275862068965517\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 31\n",
            "Correctly predicted different pixels: 23\n",
            "Calculated accuracy: 0.7419354838709677\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9833333492279053\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 25\n",
            "Correctly predicted different pixels: 10\n",
            "Calculated accuracy: 0.4\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9733333587646484\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 249\n",
            "Correctly predicted different pixels: 232\n",
            "Calculated accuracy: 0.9317269076305221\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9766666889190674\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 248\n",
            "Correctly predicted different pixels: 235\n",
            "Calculated accuracy: 0.9475806451612904\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9588888883590698\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 254\n",
            "Correctly predicted different pixels: 219\n",
            "Calculated accuracy: 0.8622047244094488\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9833333492279053\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9766666889190674\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 10\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9877777695655823\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 4\n",
            "Correctly predicted different pixels: 2\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9666666388511658\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 12\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9944444298744202\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 3\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9177777767181396\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 58\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9288889169692993\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 48\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.855555534362793\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 114\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 80\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.05\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8611111044883728\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 123\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.008130081300813009\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 83\n",
            "Correctly predicted different pixels: 9\n",
            "Calculated accuracy: 0.10843373493975904\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9588888883590698\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 22\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9688888788223267\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "\n",
            "Testing DataLoader 0:  40%|███▉      | 17/43 [00:50<01:17,  0.34it/s]DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9844444394111633\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 13\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9733333587646484\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 46\n",
            "Correctly predicted different pixels: 27\n",
            "Calculated accuracy: 0.5869565217391305\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9788888692855835\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 42\n",
            "Correctly predicted different pixels: 24\n",
            "Calculated accuracy: 0.5714285714285714\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9744444489479065\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 45\n",
            "Correctly predicted different pixels: 25\n",
            "Calculated accuracy: 0.5555555555555556\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 43\n",
            "Correctly predicted different pixels: 25\n",
            "Calculated accuracy: 0.5813953488372093\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9766666889190674\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 47\n",
            "Correctly predicted different pixels: 28\n",
            "Calculated accuracy: 0.5957446808510638\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 23\n",
            "Correctly predicted different pixels: 11\n",
            "Calculated accuracy: 0.4782608695652174\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 19\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.42105263157894735\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9833333492279053\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 19\n",
            "Correctly predicted different pixels: 9\n",
            "Calculated accuracy: 0.47368421052631576\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 11\n",
            "Calculated accuracy: 0.4583333333333333\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 11\n",
            "Calculated accuracy: 0.55\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9944444298744202\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 19\n",
            "Correctly predicted different pixels: 14\n",
            "Calculated accuracy: 0.7368421052631579\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 15\n",
            "Correctly predicted different pixels: 11\n",
            "Calculated accuracy: 0.7333333333333333\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 2\n",
            "Calculated accuracy: 0.25\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 2\n",
            "Calculated accuracy: 0.2222222222222222\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 3\n",
            "Calculated accuracy: 0.3333333333333333\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9944444298744202\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.4444444444444444\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9944444298744202\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.4444444444444444\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 3\n",
            "Calculated accuracy: 0.3333333333333333\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9944444298744202\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.4444444444444444\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9444444179534912\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 52\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.09615384615384616\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9466666579246521\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 56\n",
            "Correctly predicted different pixels: 10\n",
            "Calculated accuracy: 0.17857142857142858\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 11\n",
            "Correctly predicted different pixels: 3\n",
            "Calculated accuracy: 0.2727272727272727\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 13\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.3076923076923077\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 433\n",
            "Correctly predicted different pixels: 429\n",
            "Calculated accuracy: 0.9907621247113164\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9722222089767456\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 709\n",
            "Correctly predicted different pixels: 704\n",
            "Calculated accuracy: 0.9929478138222849\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 97\n",
            "Correctly predicted different pixels: 94\n",
            "Calculated accuracy: 0.9690721649484536\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "\n",
            "Testing DataLoader 0:  42%|████▏     | 18/43 [00:53<01:13,  0.34it/s]DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 7\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9311110973358154\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 34\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9211111068725586\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 33\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.898888885974884\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 43\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 3\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 4\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 7\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9877777695655823\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 4\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 3\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9788888692855835\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 37\n",
            "Correctly predicted different pixels: 32\n",
            "Calculated accuracy: 0.8648648648648649\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9877777695655823\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 42\n",
            "Correctly predicted different pixels: 33\n",
            "Calculated accuracy: 0.7857142857142857\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 36\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.16666666666666666\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 2\n",
            "Calculated accuracy: 0.2222222222222222\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.29411764705882354\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 2\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 57\n",
            "Correctly predicted different pixels: 48\n",
            "Calculated accuracy: 0.8421052631578947\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 68\n",
            "Correctly predicted different pixels: 60\n",
            "Calculated accuracy: 0.8823529411764706\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9844444394111633\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 65\n",
            "Correctly predicted different pixels: 51\n",
            "Calculated accuracy: 0.7846153846153846\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7522222399711609\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 184\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9333333373069763\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 41\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9066666960716248\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 80\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9066666960716248\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 80\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6222222447395325\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 336\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 3\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 15\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9766666889190674\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9744444489479065\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "\n",
            "Testing DataLoader 0:  44%|████▍     | 19/43 [00:56<01:10,  0.34it/s]DEBUG: compute_accuracy - Accuracy: 0.9322222471237183\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 21\n",
            "Calculated accuracy: 0.525\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9222221970558167\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 55\n",
            "Correctly predicted different pixels: 20\n",
            "Calculated accuracy: 0.36363636363636365\n",
            "DEBUG: compute_accuracy - Accuracy: 0.948888897895813\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 37\n",
            "Correctly predicted different pixels: 19\n",
            "Calculated accuracy: 0.5135135135135135\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8322222232818604\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7644444704055786\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 4\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8155555725097656\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 3\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9288889169692993\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 62\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9288889169692993\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 60\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9288889169692993\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 59\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9288889169692993\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 61\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9288889169692993\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 60\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8100000023841858\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 103\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.949999988079071\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 31\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9877777695655823\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 7\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9177777767181396\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 45\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9788888692855835\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9722222089767456\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 176\n",
            "Correctly predicted different pixels: 159\n",
            "Calculated accuracy: 0.9034090909090909\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9833333492279053\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 157\n",
            "Correctly predicted different pixels: 146\n",
            "Calculated accuracy: 0.9299363057324841\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 227\n",
            "Correctly predicted different pixels: 219\n",
            "Calculated accuracy: 0.9647577092511013\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9733333587646484\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 41\n",
            "Correctly predicted different pixels: 26\n",
            "Calculated accuracy: 0.6341463414634146\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9611111283302307\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 163\n",
            "Correctly predicted different pixels: 131\n",
            "Calculated accuracy: 0.803680981595092\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8888888955116272\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 56\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8888888955116272\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 56\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8888888955116272\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 48\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 218\n",
            "Correctly predicted different pixels: 208\n",
            "Calculated accuracy: 0.9541284403669725\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8866666555404663\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 217\n",
            "Correctly predicted different pixels: 115\n",
            "Calculated accuracy: 0.5299539170506913\n",
            "DEBUG: compute_accuracy - Accuracy: 0.846666693687439\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 227\n",
            "Correctly predicted different pixels: 90\n",
            "Calculated accuracy: 0.3964757709251101\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9788888692855835\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 83\n",
            "Correctly predicted different pixels: 64\n",
            "Calculated accuracy: 0.7710843373493976\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9744444489479065\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 97\n",
            "Correctly predicted different pixels: 74\n",
            "Calculated accuracy: 0.7628865979381443\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 96\n",
            "Correctly predicted different pixels: 76\n",
            "Calculated accuracy: 0.7916666666666666\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7955555319786072\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 60\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "\n",
            "Testing DataLoader 0:  47%|████▋     | 20/43 [00:58<01:07,  0.34it/s]DEBUG: compute_accuracy - Accuracy: 0.7888888716697693\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 78\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9133333563804626\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 32\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8822222352027893\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 44\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8766666650772095\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 59\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7944444417953491\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 90\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9122222065925598\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9088888764381409\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8788889050483704\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9244444370269775\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9077777862548828\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 30\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9077777862548828\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 28\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9733333587646484\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9688888788223267\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 4\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 123\n",
            "Correctly predicted different pixels: 117\n",
            "Calculated accuracy: 0.9512195121951219\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9944444298744202\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 126\n",
            "Correctly predicted different pixels: 121\n",
            "Calculated accuracy: 0.9603174603174603\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 145\n",
            "Correctly predicted different pixels: 138\n",
            "Calculated accuracy: 0.9517241379310345\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9733333587646484\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 26\n",
            "Correctly predicted different pixels: 2\n",
            "Calculated accuracy: 0.07692307692307693\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9555555582046509\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 43\n",
            "Correctly predicted different pixels: 3\n",
            "Calculated accuracy: 0.06976744186046512\n",
            "DEBUG: compute_accuracy - Accuracy: 0.948888897895813\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 28\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9344444274902344\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 15\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8888888955116272\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 39\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8888888955116272\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 37\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8888888955116272\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 43\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8888888955116272\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 46\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9433333277702332\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 7\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 1\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 2\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9399999976158142\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "\n",
            "Testing DataLoader 0:  49%|████▉     | 21/43 [01:01<01:04,  0.34it/s]DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 16\n",
            "Calculated accuracy: 0.8\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 22\n",
            "Correctly predicted different pixels: 18\n",
            "Calculated accuracy: 0.8181818181818182\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 20\n",
            "Calculated accuracy: 0.8333333333333334\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 22\n",
            "Correctly predicted different pixels: 18\n",
            "Calculated accuracy: 0.8181818181818182\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8777777552604675\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 7\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8722222447395325\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 7\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8755555748939514\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8744444251060486\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 13\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9466666579246521\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9422222375869751\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9788888692855835\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 11\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9277777671813965\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 60\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9422222375869751\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 48\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9566666483879089\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9444444179534912\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9333333373069763\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 23\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8733333349227905\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 48\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8222222328186035\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 45\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8899999856948853\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 72\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9733333587646484\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9188888669013977\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 15\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8811110854148865\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 15\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.847777783870697\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 19\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.5988888740539551\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 144\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.4122222363948822\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 121\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.3055555522441864\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 324\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.945555567741394\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 48\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.948888897895813\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 47\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.02127659574468085\n",
            "DEBUG: compute_accuracy - Accuracy: 0.949999988079071\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 46\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.021739130434782608\n",
            "DEBUG: compute_accuracy - Accuracy: 0.949999988079071\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 46\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.021739130434782608\n",
            "DEBUG: compute_accuracy - Accuracy: 0.949999988079071\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 46\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.021739130434782608\n",
            "\n",
            "Testing DataLoader 0:  51%|█████     | 22/43 [01:03<01:01,  0.34it/s]DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 17\n",
            "Calculated accuracy: 0.8095238095238095\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9944444298744202\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 26\n",
            "Correctly predicted different pixels: 21\n",
            "Calculated accuracy: 0.8076923076923077\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 18\n",
            "Calculated accuracy: 0.75\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 22\n",
            "Correctly predicted different pixels: 18\n",
            "Calculated accuracy: 0.8181818181818182\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9977777600288391\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 16\n",
            "Calculated accuracy: 0.8888888888888888\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9944444298744202\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 20\n",
            "Calculated accuracy: 0.8333333333333334\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 29\n",
            "Correctly predicted different pixels: 20\n",
            "Calculated accuracy: 0.6896551724137931\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9466666579246521\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 55\n",
            "Correctly predicted different pixels: 42\n",
            "Calculated accuracy: 0.7636363636363637\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8822222352027893\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 83\n",
            "Correctly predicted different pixels: 56\n",
            "Calculated accuracy: 0.6746987951807228\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8155555725097656\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 154\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8399999737739563\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 144\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8266666531562805\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 120\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8233333230018616\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 147\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9722222089767456\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 29\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.13793103448275862\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.23809523809523808\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 15\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.4\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 18\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9733333587646484\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 48\n",
            "Correctly predicted different pixels: 24\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9833333492279053\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 12\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9677777886390686\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9477777481079102\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9944444298744202\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7155555486679077\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7155555486679077\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7155555486679077\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7155555486679077\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 26\n",
            "Correctly predicted different pixels: 22\n",
            "Calculated accuracy: 0.8461538461538461\n",
            "DEBUG: compute_accuracy - Accuracy: 0.996666669845581\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 17\n",
            "Calculated accuracy: 0.85\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 31\n",
            "Correctly predicted different pixels: 27\n",
            "Calculated accuracy: 0.8709677419354839\n",
            "\n",
            "Testing DataLoader 0:  53%|█████▎    | 23/43 [01:06<00:57,  0.35it/s]DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 26\n",
            "Correctly predicted different pixels: 22\n",
            "Calculated accuracy: 0.8461538461538461\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 26\n",
            "Correctly predicted different pixels: 22\n",
            "Calculated accuracy: 0.8461538461538461\n",
            "DEBUG: compute_accuracy - Accuracy: 0.996666669845581\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 29\n",
            "Correctly predicted different pixels: 26\n",
            "Calculated accuracy: 0.896551724137931\n",
            "DEBUG: compute_accuracy - Accuracy: 0.996666669845581\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 30\n",
            "Correctly predicted different pixels: 27\n",
            "Calculated accuracy: 0.9\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9644444584846497\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 31\n",
            "Correctly predicted different pixels: 19\n",
            "Calculated accuracy: 0.6129032258064516\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9622222185134888\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 29\n",
            "Correctly predicted different pixels: 19\n",
            "Calculated accuracy: 0.6551724137931034\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9666666388511658\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 33\n",
            "Correctly predicted different pixels: 19\n",
            "Calculated accuracy: 0.5757575757575758\n",
            "DEBUG: compute_accuracy - Accuracy: 0.3655555546283722\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 58\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.36000001430511475\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.36000001430511475\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 96\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.36000001430511475\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 35\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6200000047683716\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 48\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7322221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 32\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6511111259460449\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 46\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9233333468437195\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 48\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8899999856948853\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 78\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9333333373069763\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 74\n",
            "Correctly predicted different pixels: 30\n",
            "Calculated accuracy: 0.40540540540540543\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9133333563804626\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 95\n",
            "Correctly predicted different pixels: 39\n",
            "Calculated accuracy: 0.4105263157894737\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9355555772781372\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.35294117647058826\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9333333373069763\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 19\n",
            "Correctly predicted different pixels: 7\n",
            "Calculated accuracy: 0.3684210526315789\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9511111378669739\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 19\n",
            "Correctly predicted different pixels: 9\n",
            "Calculated accuracy: 0.47368421052631576\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8999999761581421\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 144\n",
            "Correctly predicted different pixels: 71\n",
            "Calculated accuracy: 0.4930555555555556\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 130\n",
            "Correctly predicted different pixels: 63\n",
            "Calculated accuracy: 0.4846153846153846\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8666666746139526\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 189\n",
            "Correctly predicted different pixels: 90\n",
            "Calculated accuracy: 0.47619047619047616\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9577777981758118\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9577777981758118\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9577777981758118\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9266666769981384\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 28\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.21428571428571427\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9555555582046509\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 32\n",
            "Correctly predicted different pixels: 12\n",
            "Calculated accuracy: 0.375\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9211111068725586\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 14\n",
            "Calculated accuracy: 0.5833333333333334\n",
            "DEBUG: compute_accuracy - Accuracy: 0.903333306312561\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 61\n",
            "Correctly predicted different pixels: 47\n",
            "Calculated accuracy: 0.7704918032786885\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7599999904632568\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 73\n",
            "Correctly predicted different pixels: 27\n",
            "Calculated accuracy: 0.3698630136986301\n",
            "\n",
            "Testing DataLoader 0:  56%|█████▌    | 24/43 [01:09<00:54,  0.35it/s]DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9844444394111633\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9477777481079102\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 31\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9266666769981384\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9111111164093018\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 38\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9544444680213928\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 28\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8066666722297668\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 44\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7900000214576721\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 57\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.800000011920929\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 48\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6688888669013977\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 38\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8266666531562805\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 39\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.0\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 82\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.0\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 114\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.0\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 93\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.0011111111380159855\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 84\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9877777695655823\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 11\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 11\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9577777981758118\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9066666960716248\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 49\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8844444155693054\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 64\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 42\n",
            "Correctly predicted different pixels: 32\n",
            "Calculated accuracy: 0.7619047619047619\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9877777695655823\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 44\n",
            "Correctly predicted different pixels: 33\n",
            "Calculated accuracy: 0.75\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 45\n",
            "Correctly predicted different pixels: 36\n",
            "Calculated accuracy: 0.8\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9644444584846497\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9688888788223267\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9644444584846497\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9555555582046509\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 64\n",
            "Correctly predicted different pixels: 24\n",
            "Calculated accuracy: 0.375\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9744444489479065\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 41\n",
            "Correctly predicted different pixels: 18\n",
            "Calculated accuracy: 0.43902439024390244\n",
            "\n",
            "Testing DataLoader 0:  58%|█████▊    | 25/43 [01:12<00:51,  0.35it/s]DEBUG: compute_accuracy - Accuracy: 0.9711111187934875\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 54\n",
            "Correctly predicted different pixels: 28\n",
            "Calculated accuracy: 0.5185185185185185\n",
            "DEBUG: compute_accuracy - Accuracy: 0.75\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 34\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8411111235618591\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 32\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8144444227218628\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 42\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8533333539962769\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 30\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9733333587646484\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 2\n",
            "Calculated accuracy: 0.14285714285714285\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.35294117647058826\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9844444394111633\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.4166666666666667\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9844444394111633\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.4166666666666667\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.35294117647058826\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9688888788223267\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9377777576446533\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.95333331823349\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 30\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9244444370269775\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 42\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 3\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 4\n",
            "Correctly predicted different pixels: 2\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9611111283302307\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7888888716697693\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 23\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7688888907432556\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7400000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9200000166893005\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 32\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7733333110809326\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 132\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8811110854148865\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 74\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8388888835906982\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 101\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8399999737739563\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8399999737739563\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 25\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8399999737739563\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.79666668176651\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 64\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7233333587646484\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 96\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9333333373069763\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 26\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7155555486679077\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 4\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "\n",
            "Testing DataLoader 0:  60%|██████    | 26/43 [01:14<00:48,  0.35it/s]DEBUG: compute_accuracy - Accuracy: 0.644444465637207\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8399999737739563\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 2\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9200000166893005\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8622221946716309\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 80\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7322221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 177\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9577777981758118\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 19\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9566666483879089\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7599999904632568\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 49\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.5477777719497681\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 63\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6822222471237183\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 99\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 72\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 33\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8399999737739563\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 139\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 31\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 72\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9688888788223267\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 74\n",
            "Correctly predicted different pixels: 46\n",
            "Calculated accuracy: 0.6216216216216216\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9688888788223267\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 74\n",
            "Correctly predicted different pixels: 49\n",
            "Calculated accuracy: 0.6621621621621622\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9555555582046509\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 120\n",
            "Correctly predicted different pixels: 80\n",
            "Calculated accuracy: 0.6666666666666666\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 22\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9744444489479065\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 23\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9766666889190674\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9722222089767456\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 27\n",
            "Correctly predicted different pixels: 27\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 44\n",
            "Correctly predicted different pixels: 44\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 47\n",
            "Correctly predicted different pixels: 47\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 4\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9633333086967468\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9300000071525574\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "\n",
            "Testing DataLoader 0:  63%|██████▎   | 27/43 [01:17<00:45,  0.35it/s]DEBUG: compute_accuracy - Accuracy: 0.9333333373069763\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 7\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9333333373069763\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9255555272102356\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.2844444513320923\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 202\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.3611111044883728\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 171\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6666666865348816\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 76\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9833333492279053\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 121\n",
            "Correctly predicted different pixels: 106\n",
            "Calculated accuracy: 0.8760330578512396\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 71\n",
            "Correctly predicted different pixels: 65\n",
            "Calculated accuracy: 0.9154929577464789\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9877777695655823\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 50\n",
            "Correctly predicted different pixels: 47\n",
            "Calculated accuracy: 0.94\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 122\n",
            "Correctly predicted different pixels: 106\n",
            "Calculated accuracy: 0.8688524590163934\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 91\n",
            "Correctly predicted different pixels: 82\n",
            "Calculated accuracy: 0.9010989010989011\n",
            "DEBUG: compute_accuracy - Accuracy: 0.945555567741394\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.949999988079071\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9666666388511658\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 54\n",
            "Correctly predicted different pixels: 27\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.95333331823349\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 71\n",
            "Correctly predicted different pixels: 32\n",
            "Calculated accuracy: 0.4507042253521127\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9388889074325562\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 97\n",
            "Correctly predicted different pixels: 47\n",
            "Calculated accuracy: 0.4845360824742268\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9266666769981384\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 28\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.897777795791626\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 46\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 7\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 15\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9611111283302307\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 42\n",
            "Correctly predicted different pixels: 7\n",
            "Calculated accuracy: 0.16666666666666666\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9766666889190674\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9333333373069763\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 62\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.0967741935483871\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7866666913032532\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 208\n",
            "Correctly predicted different pixels: 16\n",
            "Calculated accuracy: 0.07692307692307693\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "\n",
            "Testing DataLoader 0:  65%|██████▌   | 28/43 [01:20<00:42,  0.35it/s]DEBUG: compute_accuracy - Accuracy: 0.9666666388511658\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 4\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 254\n",
            "Correctly predicted different pixels: 240\n",
            "Calculated accuracy: 0.9448818897637795\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9766666889190674\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 251\n",
            "Correctly predicted different pixels: 235\n",
            "Calculated accuracy: 0.9362549800796812\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 316\n",
            "Correctly predicted different pixels: 297\n",
            "Calculated accuracy: 0.939873417721519\n",
            "DEBUG: compute_accuracy - Accuracy: 0.0\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 100\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.0\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 117\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.0\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 34\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.0\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 59\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 34\n",
            "Calculated accuracy: 0.85\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 39\n",
            "Correctly predicted different pixels: 33\n",
            "Calculated accuracy: 0.8461538461538461\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 39\n",
            "Correctly predicted different pixels: 34\n",
            "Calculated accuracy: 0.8717948717948718\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 56\n",
            "Correctly predicted different pixels: 40\n",
            "Calculated accuracy: 0.7142857142857143\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 41\n",
            "Correctly predicted different pixels: 30\n",
            "Calculated accuracy: 0.7317073170731707\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9766666889190674\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 52\n",
            "Correctly predicted different pixels: 31\n",
            "Calculated accuracy: 0.5961538461538461\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9688888788223267\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 69\n",
            "Correctly predicted different pixels: 43\n",
            "Calculated accuracy: 0.6231884057971014\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9644444584846497\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 80\n",
            "Correctly predicted different pixels: 48\n",
            "Calculated accuracy: 0.6\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9788888692855835\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 52\n",
            "Correctly predicted different pixels: 33\n",
            "Calculated accuracy: 0.6346153846153846\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 11\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9788888692855835\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 11\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9766666889190674\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9666666388511658\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9399999976158142\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 25\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9844444394111633\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 10\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 7\n",
            "Calculated accuracy: 0.4375\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7688888907432556\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 100\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7688888907432556\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 79\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7744444608688354\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 94\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "\n",
            "Testing DataLoader 0:  67%|██████▋   | 29/43 [01:22<00:39,  0.35it/s]DEBUG: compute_accuracy - Accuracy: 0.8922222256660461\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 93\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9422222375869751\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 49\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9066666960716248\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 81\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9666666388511658\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 57\n",
            "Correctly predicted different pixels: 28\n",
            "Calculated accuracy: 0.49122807017543857\n",
            "DEBUG: compute_accuracy - Accuracy: 0.95333331823349\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 77\n",
            "Correctly predicted different pixels: 37\n",
            "Calculated accuracy: 0.4805194805194805\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9666666388511658\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 50\n",
            "Correctly predicted different pixels: 22\n",
            "Calculated accuracy: 0.44\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9666666388511658\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 56\n",
            "Correctly predicted different pixels: 26\n",
            "Calculated accuracy: 0.4642857142857143\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 71\n",
            "Correctly predicted different pixels: 62\n",
            "Calculated accuracy: 0.8732394366197183\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 34\n",
            "Correctly predicted different pixels: 29\n",
            "Calculated accuracy: 0.8529411764705882\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 34\n",
            "Calculated accuracy: 0.85\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 12\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.4444444444444444\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 22\n",
            "Correctly predicted different pixels: 11\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.699999988079071\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 32\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.4699999988079071\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.75\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 30\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 48\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 48\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 48\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9622222185134888\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 19\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9177777767181396\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 54\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9844444394111633\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9722222089767456\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9722222089767456\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 19\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.851111114025116\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 44\n",
            "Correctly predicted different pixels: 20\n",
            "Calculated accuracy: 0.45454545454545453\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8266666531562805\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 52\n",
            "Correctly predicted different pixels: 18\n",
            "Calculated accuracy: 0.34615384615384615\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8533333539962769\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 44\n",
            "Correctly predicted different pixels: 16\n",
            "Calculated accuracy: 0.36363636363636365\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9377777576446533\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 24\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9288889169692993\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 21\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8822222352027893\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 36\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9655555486679077\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 23\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.2608695652173913\n",
            "\n",
            "Testing DataLoader 0:  70%|██████▉   | 30/43 [01:25<00:37,  0.35it/s]DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 3\n",
            "Calculated accuracy: 0.16666666666666666\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9366666674613953\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 48\n",
            "Correctly predicted different pixels: 9\n",
            "Calculated accuracy: 0.1875\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9266666769981384\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 5\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9122222065925598\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9177777767181396\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 26\n",
            "Correctly predicted different pixels: 12\n",
            "Calculated accuracy: 0.46153846153846156\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 23\n",
            "Correctly predicted different pixels: 16\n",
            "Calculated accuracy: 0.6956521739130435\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 26\n",
            "Correctly predicted different pixels: 12\n",
            "Calculated accuracy: 0.46153846153846156\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 22\n",
            "Correctly predicted different pixels: 10\n",
            "Calculated accuracy: 0.45454545454545453\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 19\n",
            "Correctly predicted different pixels: 11\n",
            "Calculated accuracy: 0.5789473684210527\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 11\n",
            "Calculated accuracy: 0.6470588235294118\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 23\n",
            "Correctly predicted different pixels: 11\n",
            "Calculated accuracy: 0.4782608695652174\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9111111164093018\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 64\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9111111164093018\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 64\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9111111164093018\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 64\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9111111164093018\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 64\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8822222352027893\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9366666674613953\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9399999976158142\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9322222471237183\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 26\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9166666865348816\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 42\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9144444465637207\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.996666669845581\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 15\n",
            "Correctly predicted different pixels: 12\n",
            "Calculated accuracy: 0.8\n",
            "DEBUG: compute_accuracy - Accuracy: 0.996666669845581\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 15\n",
            "Correctly predicted different pixels: 12\n",
            "Calculated accuracy: 0.8\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9977777600288391\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 10\n",
            "Calculated accuracy: 0.8333333333333334\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.3333333333333333\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 9\n",
            "Calculated accuracy: 0.42857142857142855\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 13\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.38461538461538464\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 271\n",
            "Correctly predicted different pixels: 263\n",
            "Calculated accuracy: 0.9704797047970479\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 305\n",
            "Correctly predicted different pixels: 297\n",
            "Calculated accuracy: 0.9737704918032787\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 15\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "\n",
            "Testing DataLoader 0:  72%|███████▏  | 31/43 [01:28<00:34,  0.35it/s]DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9700000286102295\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9944444298744202\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 4\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.996666669845581\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 2\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.996666669845581\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 2\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9944444298744202\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 4\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9577777981758118\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 39\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.02564102564102564\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.125\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.07142857142857142\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 252\n",
            "Correctly predicted different pixels: 243\n",
            "Calculated accuracy: 0.9642857142857143\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 211\n",
            "Correctly predicted different pixels: 205\n",
            "Calculated accuracy: 0.9715639810426541\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 296\n",
            "Correctly predicted different pixels: 292\n",
            "Calculated accuracy: 0.9864864864864865\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9155555367469788\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9144444465637207\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9133333563804626\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 72\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 72\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 72\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9111111164093018\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 70\n",
            "Correctly predicted different pixels: 2\n",
            "Calculated accuracy: 0.02857142857142857\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8844444155693054\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 82\n",
            "Correctly predicted different pixels: 2\n",
            "Calculated accuracy: 0.024390243902439025\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8933333158493042\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 78\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.07692307692307693\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 77\n",
            "Correctly predicted different pixels: 56\n",
            "Calculated accuracy: 0.7272727272727273\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9622222185134888\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 94\n",
            "Correctly predicted different pixels: 61\n",
            "Calculated accuracy: 0.648936170212766\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9288889169692993\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 84\n",
            "Correctly predicted different pixels: 34\n",
            "Calculated accuracy: 0.40476190476190477\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 113\n",
            "Correctly predicted different pixels: 39\n",
            "Calculated accuracy: 0.34513274336283184\n",
            "DEBUG: compute_accuracy - Accuracy: 0.1899999976158142\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 79\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.1899999976158142\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 84\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.1899999976158142\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 60\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8311111330986023\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 47\n",
            "Correctly predicted different pixels: 14\n",
            "Calculated accuracy: 0.2978723404255319\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8377777934074402\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 60\n",
            "Correctly predicted different pixels: 28\n",
            "Calculated accuracy: 0.4666666666666667\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8922222256660461\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 46\n",
            "Correctly predicted different pixels: 27\n",
            "Calculated accuracy: 0.5869565217391305\n",
            "\n",
            "Testing DataLoader 0:  74%|███████▍  | 32/43 [01:30<00:31,  0.35it/s]DEBUG: compute_accuracy - Accuracy: 0.9788888692855835\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9766666889190674\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 13\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9644444584846497\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9277777671813965\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 38\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9466666579246521\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 27\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9355555772781372\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 33\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.996666669845581\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 22\n",
            "Calculated accuracy: 0.9166666666666666\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9944444298744202\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 29\n",
            "Correctly predicted different pixels: 25\n",
            "Calculated accuracy: 0.8620689655172413\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 35\n",
            "Correctly predicted different pixels: 31\n",
            "Calculated accuracy: 0.8857142857142857\n",
            "DEBUG: compute_accuracy - Accuracy: 0.949999988079071\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 44\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9433333277702332\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 50\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.846666693687439\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 135\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9300000071525574\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 62\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8911111354827881\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 84\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9399999976158142\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.3333333333333333\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.3333333333333333\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.3333333333333333\n",
            "DEBUG: compute_accuracy - Accuracy: 0.0\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 68\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.0\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 92\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.0\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 46\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9622222185134888\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 11\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9399999976158142\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 48\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 11\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.09090909090909091\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9511111378669739\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8577777743339539\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 128\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.03125\n",
            "\n",
            "Testing DataLoader 0:  77%|███████▋  | 33/43 [01:33<00:28,  0.35it/s]DEBUG: compute_accuracy - Accuracy: 0.8577777743339539\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 128\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.03125\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 20\n",
            "Calculated accuracy: 0.8333333333333334\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 22\n",
            "Correctly predicted different pixels: 18\n",
            "Calculated accuracy: 0.8181818181818182\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 32\n",
            "Correctly predicted different pixels: 26\n",
            "Calculated accuracy: 0.8125\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9844444394111633\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9711111187934875\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9788888692855835\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 50\n",
            "Correctly predicted different pixels: 34\n",
            "Calculated accuracy: 0.68\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9744444489479065\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 52\n",
            "Correctly predicted different pixels: 39\n",
            "Calculated accuracy: 0.75\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 32\n",
            "Correctly predicted different pixels: 25\n",
            "Calculated accuracy: 0.78125\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9744444489479065\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 69\n",
            "Correctly predicted different pixels: 46\n",
            "Calculated accuracy: 0.6666666666666666\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9522222280502319\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 23\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9366666674613953\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9222221970558167\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 28\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9399999976158142\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 33\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9288889169692993\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 42\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9288889169692993\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 42\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9877777695655823\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 10\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9877777695655823\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9877777695655823\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 7\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 28\n",
            "Correctly predicted different pixels: 16\n",
            "Calculated accuracy: 0.5714285714285714\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 35\n",
            "Correctly predicted different pixels: 17\n",
            "Calculated accuracy: 0.4857142857142857\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 34\n",
            "Correctly predicted different pixels: 16\n",
            "Calculated accuracy: 0.47058823529411764\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9766666889190674\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 38\n",
            "Correctly predicted different pixels: 17\n",
            "Calculated accuracy: 0.4473684210526316\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 67\n",
            "Correctly predicted different pixels: 32\n",
            "Calculated accuracy: 0.47761194029850745\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 20\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9655555486679077\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 55\n",
            "Correctly predicted different pixels: 25\n",
            "Calculated accuracy: 0.45454545454545453\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9566666483879089\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 7\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9466666579246521\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.2857142857142857\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9622222185134888\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "\n",
            "Testing DataLoader 0:  79%|███████▉  | 34/43 [01:36<00:25,  0.35it/s]DEBUG: compute_accuracy - Accuracy: 0.8733333349227905\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 103\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8788889050483704\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 101\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9522222280502319\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9311110973358154\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 32\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9200000166893005\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 31\n",
            "Correctly predicted different pixels: 23\n",
            "Calculated accuracy: 0.7419354838709677\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 35\n",
            "Correctly predicted different pixels: 25\n",
            "Calculated accuracy: 0.7142857142857143\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 35\n",
            "Correctly predicted different pixels: 25\n",
            "Calculated accuracy: 0.7142857142857143\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8688889145851135\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 23\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8933333158493042\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 26\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 28\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 78\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8399999737739563\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 141\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 0\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 0\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 29\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 30\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 183\n",
            "Correctly predicted different pixels: 161\n",
            "Calculated accuracy: 0.8797814207650273\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 101\n",
            "Correctly predicted different pixels: 94\n",
            "Calculated accuracy: 0.9306930693069307\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 153\n",
            "Correctly predicted different pixels: 139\n",
            "Calculated accuracy: 0.9084967320261438\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 58\n",
            "Correctly predicted different pixels: 48\n",
            "Calculated accuracy: 0.8275862068965517\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 70\n",
            "Correctly predicted different pixels: 53\n",
            "Calculated accuracy: 0.7571428571428571\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 54\n",
            "Correctly predicted different pixels: 45\n",
            "Calculated accuracy: 0.8333333333333334\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 34\n",
            "Correctly predicted different pixels: 27\n",
            "Calculated accuracy: 0.7941176470588235\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9977777600288391\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.8\n",
            "DEBUG: compute_accuracy - Accuracy: 0.996666669845581\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 11\n",
            "Calculated accuracy: 0.7857142857142857\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 14\n",
            "Calculated accuracy: 0.7777777777777778\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 16\n",
            "Calculated accuracy: 0.8\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 19\n",
            "Correctly predicted different pixels: 15\n",
            "Calculated accuracy: 0.7894736842105263\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9944444298744202\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 22\n",
            "Correctly predicted different pixels: 17\n",
            "Calculated accuracy: 0.7727272727272727\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9466666579246521\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 30\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 0\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 1.0\n",
            "\n",
            "Testing DataLoader 0:  81%|████████▏ | 35/43 [01:38<00:22,  0.35it/s]DEBUG: compute_accuracy - Accuracy: 0.8688889145851135\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 69\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.846666693687439\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 72\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8377777934074402\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 67\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8411111235618591\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 75\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8455555438995361\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 28\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9688888788223267\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9677777886390686\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7344444394111633\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 227\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9188888669013977\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 69\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8588888645172119\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 119\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9100000262260437\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 46\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9422222375869751\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 26\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9144444465637207\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 38\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9133333563804626\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 39\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9833333492279053\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 7\n",
            "Calculated accuracy: 0.4117647058823529\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 7\n",
            "Calculated accuracy: 0.3333333333333333\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9844444394111633\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 7\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 7\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.2244444489479065\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 888\n",
            "Correctly predicted different pixels: 201\n",
            "Calculated accuracy: 0.22635135135135134\n",
            "DEBUG: compute_accuracy - Accuracy: 0.4300000071525574\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 896\n",
            "Correctly predicted different pixels: 387\n",
            "Calculated accuracy: 0.43191964285714285\n",
            "DEBUG: compute_accuracy - Accuracy: 0.1922222226858139\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 881\n",
            "Correctly predicted different pixels: 171\n",
            "Calculated accuracy: 0.19409761634506242\n",
            "DEBUG: compute_accuracy - Accuracy: 0.15777777135372162\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 897\n",
            "Correctly predicted different pixels: 140\n",
            "Calculated accuracy: 0.15607580824972128\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9288889169692993\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 20\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9444444179534912\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 12\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9744444489479065\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 6\n",
            "Correctly predicted different pixels: 3\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8266666531562805\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8388888835906982\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8288888931274414\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.5714285714285714\n",
            "\n",
            "Testing DataLoader 0:  84%|████████▎ | 36/43 [01:41<00:19,  0.36it/s]DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 13\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.38461538461538464\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 13\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.46153846153846156\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 6\n",
            "Calculated accuracy: 0.6\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 194\n",
            "Correctly predicted different pixels: 191\n",
            "Calculated accuracy: 0.9845360824742269\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 167\n",
            "Correctly predicted different pixels: 162\n",
            "Calculated accuracy: 0.9700598802395209\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 209\n",
            "Correctly predicted different pixels: 204\n",
            "Calculated accuracy: 0.9760765550239234\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 223\n",
            "Correctly predicted different pixels: 203\n",
            "Calculated accuracy: 0.9103139013452914\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9666666388511658\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 12\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9788888692855835\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 7\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9877777695655823\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 4\n",
            "Correctly predicted different pixels: 2\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8911111354827881\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8799999952316284\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8888888955116272\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9466666579246521\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 53\n",
            "Correctly predicted different pixels: 13\n",
            "Calculated accuracy: 0.24528301886792453\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9411110877990723\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 74\n",
            "Correctly predicted different pixels: 22\n",
            "Calculated accuracy: 0.2972972972972973\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.2222222222222222\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9944444298744202\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 12\n",
            "Calculated accuracy: 0.7058823529411765\n",
            "DEBUG: compute_accuracy - Accuracy: 0.996666669845581\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 17\n",
            "Calculated accuracy: 0.85\n",
            "DEBUG: compute_accuracy - Accuracy: 0.996666669845581\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 19\n",
            "Correctly predicted different pixels: 16\n",
            "Calculated accuracy: 0.8421052631578947\n",
            "DEBUG: compute_accuracy - Accuracy: 0.996666669845581\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 18\n",
            "Calculated accuracy: 0.8571428571428571\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9466666579246521\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 43\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9466666579246521\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 43\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9366666674613953\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 52\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9466666579246521\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 48\n",
            "Correctly predicted different pixels: 24\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9288889169692993\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 88\n",
            "Correctly predicted different pixels: 44\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9333333373069763\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 80\n",
            "Correctly predicted different pixels: 40\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8166666626930237\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 216\n",
            "Correctly predicted different pixels: 59\n",
            "Calculated accuracy: 0.27314814814814814\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8188889026641846\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 216\n",
            "Correctly predicted different pixels: 60\n",
            "Calculated accuracy: 0.2777777777777778\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 216\n",
            "Correctly predicted different pixels: 216\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 5\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 7\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "\n",
            "Testing DataLoader 0:  86%|████████▌ | 37/43 [01:43<00:16,  0.36it/s]DEBUG: compute_accuracy - Accuracy: 0.9833333492279053\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 11\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 5\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9333333373069763\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 59\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9388889074325562\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 45\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9644444584846497\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.800000011920929\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 157\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9511111378669739\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 34\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8777777552604675\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 96\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9722222089767456\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9722222089767456\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9722222089767456\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9333333373069763\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 533\n",
            "Correctly predicted different pixels: 477\n",
            "Calculated accuracy: 0.8949343339587242\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9333333373069763\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 561\n",
            "Correctly predicted different pixels: 504\n",
            "Calculated accuracy: 0.8983957219251337\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9622222185134888\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 543\n",
            "Correctly predicted different pixels: 512\n",
            "Calculated accuracy: 0.9429097605893186\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9733333587646484\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 546\n",
            "Correctly predicted different pixels: 528\n",
            "Calculated accuracy: 0.967032967032967\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9522222280502319\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 531\n",
            "Correctly predicted different pixels: 491\n",
            "Calculated accuracy: 0.9246704331450094\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8633333444595337\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 32\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8866666555404663\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 26\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9111111164093018\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9344444274902344\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9399999976158142\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 19\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9555555582046509\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9877777695655823\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 13\n",
            "Calculated accuracy: 0.5416666666666666\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9877777695655823\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 11\n",
            "Calculated accuracy: 0.55\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9877777695655823\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 13\n",
            "Calculated accuracy: 0.5416666666666666\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9577777981758118\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 32\n",
            "Correctly predicted different pixels: 16\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9611111283302307\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 7\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9833333492279053\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6933333277702332\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 77\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.5688889026641846\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 62\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.5922222137451172\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 171\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "\n",
            "Testing DataLoader 0:  88%|████████▊ | 38/43 [01:46<00:14,  0.36it/s]DEBUG: compute_accuracy - Accuracy: 0.9555555582046509\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 37\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9733333587646484\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9644444584846497\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 29\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 52\n",
            "Correctly predicted different pixels: 44\n",
            "Calculated accuracy: 0.8461538461538461\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9833333492279053\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 33\n",
            "Correctly predicted different pixels: 24\n",
            "Calculated accuracy: 0.7272727272727273\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 9\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9766666889190674\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 59\n",
            "Correctly predicted different pixels: 40\n",
            "Calculated accuracy: 0.6779661016949152\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8888888955116272\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 86\n",
            "Correctly predicted different pixels: 10\n",
            "Calculated accuracy: 0.11627906976744186\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 44\n",
            "Correctly predicted different pixels: 14\n",
            "Calculated accuracy: 0.3181818181818182\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 15\n",
            "Correctly predicted different pixels: 10\n",
            "Calculated accuracy: 0.6666666666666666\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 14\n",
            "Calculated accuracy: 0.6666666666666666\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9877777695655823\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 27\n",
            "Calculated accuracy: 0.75\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 24\n",
            "Calculated accuracy: 0.6666666666666666\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9833333492279053\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 56\n",
            "Correctly predicted different pixels: 42\n",
            "Calculated accuracy: 0.75\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 11\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 10\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 1.0\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 46\n",
            "Correctly predicted different pixels: 46\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 1.0\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 4\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 1.0\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 16\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 1.0\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 38\n",
            "Correctly predicted different pixels: 38\n",
            "Calculated accuracy: 1.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7311111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8566666841506958\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 4\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8411111235618591\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.46222221851348877\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 56\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.46222221851348877\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 56\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.46222221851348877\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 65\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 53\n",
            "Correctly predicted different pixels: 37\n",
            "Calculated accuracy: 0.6981132075471698\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 62\n",
            "Correctly predicted different pixels: 45\n",
            "Calculated accuracy: 0.7258064516129032\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9744444489479065\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 66\n",
            "Correctly predicted different pixels: 45\n",
            "Calculated accuracy: 0.6818181818181818\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9800000190734863\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 59\n",
            "Correctly predicted different pixels: 44\n",
            "Calculated accuracy: 0.7457627118644068\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9766666889190674\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 69\n",
            "Correctly predicted different pixels: 50\n",
            "Calculated accuracy: 0.7246376811594203\n",
            "\n",
            "Testing DataLoader 0:  91%|█████████ | 39/43 [01:49<00:11,  0.36it/s]DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 66\n",
            "Correctly predicted different pixels: 47\n",
            "Calculated accuracy: 0.7121212121212122\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.2\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9599999785423279\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.1\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9588888883590698\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 15\n",
            "Calculated accuracy: 0.375\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9444444179534912\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 75\n",
            "Correctly predicted different pixels: 32\n",
            "Calculated accuracy: 0.4266666666666667\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9633333086967468\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 60\n",
            "Correctly predicted different pixels: 27\n",
            "Calculated accuracy: 0.45\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 19\n",
            "Calculated accuracy: 0.5277777777777778\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9066666960716248\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 53\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.945555567741394\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.897777795791626\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 47\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8622221946716309\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 78\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.01282051282051282\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8222222328186035\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 92\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8700000047683716\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 67\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7688888907432556\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 88\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.3888888955116272\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 65\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.3888888955116272\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 60\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.3888888955116272\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 41\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9733333587646484\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 60\n",
            "Correctly predicted different pixels: 38\n",
            "Calculated accuracy: 0.6333333333333333\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9711111187934875\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 59\n",
            "Correctly predicted different pixels: 37\n",
            "Calculated accuracy: 0.6271186440677966\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9733333587646484\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 55\n",
            "Correctly predicted different pixels: 39\n",
            "Calculated accuracy: 0.7090909090909091\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9744444489479065\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 53\n",
            "Correctly predicted different pixels: 36\n",
            "Calculated accuracy: 0.6792452830188679\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9766666889190674\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 51\n",
            "Correctly predicted different pixels: 32\n",
            "Calculated accuracy: 0.6274509803921569\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9688888788223267\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 56\n",
            "Correctly predicted different pixels: 34\n",
            "Calculated accuracy: 0.6071428571428571\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 7\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.5714285714285714\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 11\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.36363636363636365\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.4444444444444444\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 7\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.5714285714285714\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 15\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.5333333333333333\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.5714285714285714\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.5714285714285714\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 9\n",
            "Calculated accuracy: 0.5625\n",
            "\n",
            "Testing DataLoader 0:  93%|█████████▎| 40/43 [01:51<00:08,  0.36it/s]DEBUG: compute_accuracy - Accuracy: 0.9944444298744202\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 15\n",
            "Correctly predicted different pixels: 10\n",
            "Calculated accuracy: 0.6666666666666666\n",
            "DEBUG: compute_accuracy - Accuracy: 0.995555579662323\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 12\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.6666666666666666\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 19\n",
            "Correctly predicted different pixels: 2\n",
            "Calculated accuracy: 0.10526315789473684\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9688888788223267\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 23\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.043478260869565216\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 19\n",
            "Correctly predicted different pixels: 2\n",
            "Calculated accuracy: 0.10526315789473684\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 20\n",
            "Correctly predicted different pixels: 4\n",
            "Calculated accuracy: 0.2\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.07142857142857142\n",
            "DEBUG: compute_accuracy - Accuracy: 0.95333331823349\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.95333331823349\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9711111187934875\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 27\n",
            "Correctly predicted different pixels: 2\n",
            "Calculated accuracy: 0.07407407407407407\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9933333396911621\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 5\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 18\n",
            "Correctly predicted different pixels: 2\n",
            "Calculated accuracy: 0.1111111111111111\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8722222447395325\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 25\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8833333253860474\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 30\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8455555438995361\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 37\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8766666650772095\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 38\n",
            "Correctly predicted different pixels: 16\n",
            "Calculated accuracy: 0.42105263157894735\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8933333158493042\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 32\n",
            "Correctly predicted different pixels: 14\n",
            "Calculated accuracy: 0.4375\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8933333158493042\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 54\n",
            "Correctly predicted different pixels: 34\n",
            "Calculated accuracy: 0.6296296296296297\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7288888692855835\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 80\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6777777671813965\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 79\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.7277777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 56\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 30\n",
            "Correctly predicted different pixels: 13\n",
            "Calculated accuracy: 0.43333333333333335\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9722222089767456\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 44\n",
            "Correctly predicted different pixels: 19\n",
            "Calculated accuracy: 0.4318181818181818\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 23\n",
            "Correctly predicted different pixels: 11\n",
            "Calculated accuracy: 0.4782608695652174\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 574\n",
            "Correctly predicted different pixels: 567\n",
            "Calculated accuracy: 0.9878048780487805\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8322222232818604\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 572\n",
            "Correctly predicted different pixels: 425\n",
            "Calculated accuracy: 0.743006993006993\n",
            "\n",
            "Testing DataLoader 0:  95%|█████████▌| 41/43 [01:54<00:05,  0.36it/s]DEBUG: compute_accuracy - Accuracy: 0.9244444370269775\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 571\n",
            "Correctly predicted different pixels: 507\n",
            "Calculated accuracy: 0.8879159369527145\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9355555772781372\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 569\n",
            "Correctly predicted different pixels: 518\n",
            "Calculated accuracy: 0.9103690685413005\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9355555772781372\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 572\n",
            "Correctly predicted different pixels: 518\n",
            "Calculated accuracy: 0.9055944055944056\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 7\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 14\n",
            "Correctly predicted different pixels: 7\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 16\n",
            "Correctly predicted different pixels: 8\n",
            "Calculated accuracy: 0.5\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9900000095367432\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 31\n",
            "Calculated accuracy: 0.775\n",
            "DEBUG: compute_accuracy - Accuracy: 0.992222249507904\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 44\n",
            "Correctly predicted different pixels: 37\n",
            "Calculated accuracy: 0.8409090909090909\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 32\n",
            "Calculated accuracy: 0.8\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 13\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.38461538461538464\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 33\n",
            "Correctly predicted different pixels: 13\n",
            "Calculated accuracy: 0.3939393939393939\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9844444394111633\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 30\n",
            "Correctly predicted different pixels: 16\n",
            "Calculated accuracy: 0.5333333333333333\n",
            "DEBUG: compute_accuracy - Accuracy: 0.6833333373069763\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 51\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8399999737739563\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 23\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9755555391311646\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 23\n",
            "Correctly predicted different pixels: 12\n",
            "Calculated accuracy: 0.5217391304347826\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9811111092567444\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 19\n",
            "Correctly predicted different pixels: 11\n",
            "Calculated accuracy: 0.5789473684210527\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9855555295944214\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 15\n",
            "Calculated accuracy: 0.7142857142857143\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8233333230018616\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 140\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9466666579246521\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 33\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.898888885974884\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 72\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9688888788223267\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 19\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8999999761581421\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 43\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9355555772781372\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 29\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9433333277702332\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 26\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.1388888955116272\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.027777777777777776\n",
            "DEBUG: compute_accuracy - Accuracy: 0.13777777552604675\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 72\n",
            "Correctly predicted different pixels: 7\n",
            "Calculated accuracy: 0.09722222222222222\n",
            "DEBUG: compute_accuracy - Accuracy: 0.15777777135372162\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 51\n",
            "Correctly predicted different pixels: 13\n",
            "Calculated accuracy: 0.2549019607843137\n",
            "DEBUG: compute_accuracy - Accuracy: 0.1966666728258133\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 31\n",
            "Correctly predicted different pixels: 5\n",
            "Calculated accuracy: 0.16129032258064516\n",
            "DEBUG: compute_accuracy - Accuracy: 0.95333331823349\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 36\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9377777576446533\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 52\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.058823529411764705\n",
            "\n",
            "Testing DataLoader 0:  98%|█████████▊| 42/43 [01:56<00:02,  0.36it/s]DEBUG: compute_accuracy - Accuracy: 0.9644444584846497\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 34\n",
            "Correctly predicted different pixels: 2\n",
            "Calculated accuracy: 0.058823529411764705\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9911110997200012\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 9\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.1111111111111111\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9866666793823242\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 13\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.07692307692307693\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9777777791023254\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.047619047619047616\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9822221994400024\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 17\n",
            "Correctly predicted different pixels: 1\n",
            "Calculated accuracy: 0.058823529411764705\n",
            "DEBUG: compute_accuracy - Accuracy: 0.46222221851348877\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 11\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.36000001430511475\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 21\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8999999761581421\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 82\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.95333331823349\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 39\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.8833333253860474\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 95\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9577777981758118\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 33\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9622222185134888\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 29\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9311110973358154\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 32\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9122222065925598\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 40\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9433333277702332\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 27\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9544444680213928\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 32\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9711111187934875\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 24\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9888888597488403\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 8\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "DEBUG: compute_accuracy - Accuracy: 0.9444444179534912\n",
            "Differential pixel accuracy - Input shape: torch.Size([1, 1, 30, 30]), Target shape: torch.Size([1, 1, 30, 30]), Prediction shape: torch.Size([1, 900])\n",
            "Reshaped - Input: torch.Size([1, 1, 30, 30]), Target: torch.Size([1, 1, 30, 30]), Prediction: torch.Size([1, 1, 30, 30])\n",
            "Total different pixels: 48\n",
            "Correctly predicted different pixels: 0\n",
            "Calculated accuracy: 0.0\n",
            "\n",
            "Testing DataLoader 0: 100%|██████████| 43/43 [01:58<00:00,  0.36it/s]DEBUG: Test epoch end - Avg loss: 0.3664872646331787, Avg accuracy: 0.9048286856023982, Avg diff accuracy: 0.26922056889637347\n",
            "\n",
            "Testing DataLoader 0: 100%|██████████| 43/43 [01:58<00:00,  0.36it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m        Test metric        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       DataLoader 0        \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m  00576224_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9599999785423279     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m00576224_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  009d5c81_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9744443893432617     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m009d5c81_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.21003207564353943    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  00dbd492_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.929444432258606     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m00dbd492_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  03560426_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9796295762062073     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m03560426_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.5188145637512207     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  05a7bcf2_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6566666960716248     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m05a7bcf2_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  0607ce86_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7966666221618652     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m0607ce86_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6599085927009583     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  0692e18c_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9785184860229492     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m0692e18c_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.16984127461910248    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  070dd51e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9611111283302307     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m070dd51e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  08573cc6_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.962592601776123     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m08573cc6_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.06767676770687103    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  0934a4d8_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.37638890743255615    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m0934a4d8_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.37773966789245605    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  09c534e7_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7877777218818665     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m09c534e7_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  0a1d4ef5_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9511110782623291     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m0a1d4ef5_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9168465733528137     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  0a2355a6_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9394444823265076     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m0a2355a6_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  0b17323b_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9938889145851135     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m0b17323b_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  0bb8deee_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9788889288902283     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m0bb8deee_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6813034415245056     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  0becf7df_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9744444489479065     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m0becf7df_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  0c786b71_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9466666579246521     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m0c786b71_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  0c9aba6e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9916666746139526     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m0c9aba6e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.747855007648468     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  0d87d2a6_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9055555462837219     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m0d87d2a6_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  0e671a1a_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9724999666213989     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m0e671a1a_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  0f63c0b9_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8908333778381348     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m0f63c0b9_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  103eff5b_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9416666626930237     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m103eff5b_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  11e1fe23_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.992222249507904     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m11e1fe23_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  12422b43_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9788888692855835     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m12422b43_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  12997ef3_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9844444394111633     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m12997ef3_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.3445091247558594     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  12eac192_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9725000262260437     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m12eac192_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  136b0064_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9822222590446472     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m136b0064_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.711358368396759     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  13713586_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.859259307384491     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m13713586_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  137f0df0_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9185185432434082     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m137f0df0_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  140c817e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8625926375389099     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m140c817e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  14754a24_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8630555272102356     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m14754a24_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  15113be4_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6255555748939514     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m15113be4_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  15663ba9_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9422222971916199     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m15663ba9_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  15696249_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9700000286102295     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m15696249_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m          0.1875           \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  16b78196_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7916666865348816     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m16b78196_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.4842342138290405     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  17b80ad2_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9611111283302307     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m17b80ad2_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  17cae0c1_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9700000286102295     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m17cae0c1_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  18419cfa_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9344444274902344     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m18419cfa_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  184a9768_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8522222638130188     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m184a9768_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.575104296207428     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  195ba7dc_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9758332967758179     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m195ba7dc_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.5054347515106201     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  1990f7a8_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9740740656852722     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m1990f7a8_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.5            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  19bb5feb_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9729630351066589     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m19bb5feb_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7311635613441467     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  1a2e2828_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9986666440963745     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m1a2e2828_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9834964871406555     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  1a6449f1_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9829629063606262     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m1a6449f1_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9130600094795227     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  1acc24af_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.964722216129303     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m1acc24af_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  1c02dbbe_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.860370397567749     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m1c02dbbe_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.06207104027271271    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  1c0d0a4b_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9825925827026367     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m1c0d0a4b_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.595678985118866     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  1c56ad9f_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9541666507720947     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m1c56ad9f_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.5            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  1d0a4b61_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.3055555522441864     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m1d0a4b61_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  1d398264_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9462962746620178     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m1d398264_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  1da012fc_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9105556011199951     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m1da012fc_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  1e81d6f9_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9681481719017029     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m1e81d6f9_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            1.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  1e97544e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.41296300292015076    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m1e97544e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  2037f2c7_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9900000095367432     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m2037f2c7_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9334214329719543     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  2072aba6_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9807407259941101     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m2072aba6_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.01587301678955555    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  20818e16_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9385185241699219     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m20818e16_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.723113477230072     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  20981f0e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9681481719017029     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m20981f0e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.5            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  212895b5_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9196296334266663     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m212895b5_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  21f83797_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9238889217376709     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m21f83797_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  22a4bbc2_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9433333277702332     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m22a4bbc2_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  25094a63_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.1827777773141861     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m25094a63_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  2546ccf6_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8550000190734863     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m2546ccf6_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  256b0a75_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6666666865348816     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m256b0a75_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  2685904e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.965925931930542     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m2685904e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  2697da3f_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9511110782623291     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m2697da3f_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.16602009534835815    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  2753e76c_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9900000095367432     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m2753e76c_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.899422824382782     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  27a77e38_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9807407259941101     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m27a77e38_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  27f8ce4f_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9650000333786011     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m27f8ce4f_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.11249999701976776    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  281123b4_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9829630255699158     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m281123b4_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7146536707878113     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  292dd178_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9081481099128723     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m292dd178_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  29700607_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9618518948554993     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m29700607_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  2a5f8217_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9774073958396912     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m2a5f8217_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  2b01abd0_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.970740795135498     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m2b01abd0_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  2c0b0aff_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9119444489479065     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m2c0b0aff_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7577368021011353     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  2c737e39_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9840741157531738     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m2c737e39_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.13650794327259064    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  2f0c5170_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9674074053764343     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m2f0c5170_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9186174869537354     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  310f3251_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9700000882148743     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m310f3251_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  3194b014_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9770370125770569     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m3194b014_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9225044250488281     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  319f2597_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6277777552604675     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m319f2597_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9736223220825195     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  31adaf00_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9307407736778259     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m31adaf00_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  31d5ba1a_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9928889274597168     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m31d5ba1a_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6540936231613159     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  32e9702f_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9548148512840271     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m32e9702f_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  332efdb3_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9533333778381348     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m332efdb3_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  3391f8c0_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9824999570846558     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m3391f8c0_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.3541666865348816     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  33b52de3_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8538888692855835     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m33b52de3_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  3490cc26_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9061111211776733     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m3490cc26_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  34b99a2b_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9883333444595337     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m34b99a2b_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.629668653011322     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  351d6448_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9927777647972107     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m351d6448_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8858424425125122     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  358ba94e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9744444489479065     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m358ba94e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8644062280654907     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  37d3e8b2_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8788889050483704     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m37d3e8b2_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  3979b1a8_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8888888955116272     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m3979b1a8_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  3a301edc_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9024444818496704     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m3a301edc_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  3b4c2228_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9979999661445618     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m3b4c2228_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8947456479072571     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  3d31c5b3_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9794444441795349     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m3d31c5b3_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6079409122467041     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  3ed85e70_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6381481885910034     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m3ed85e70_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  3ee1011a_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9537037014961243     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m3ee1011a_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.20636117458343506    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  3f23242b_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9550000429153442     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m3f23242b_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  40f6cd08_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6270370483398438     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m40f6cd08_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  414297c0_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8959259390830994     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m414297c0_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.4695725440979004     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  423a55dc_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9855555295944214     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m423a55dc_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.5216470956802368     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  42918530_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.815833330154419     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m42918530_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  42a15761_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9062963128089905     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m42a15761_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.5            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  4364c1c4_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8177778124809265     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m4364c1c4_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  456873bc_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9514815211296082     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m456873bc_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7703775763511658     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  45737921_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9733333587646484     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m45737921_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  45bbe264_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.932962954044342     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m45bbe264_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  477d2879_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8122222423553467     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m477d2879_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  47996f11_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.13833333551883698    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m47996f11_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.10620684921741486    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  48131b3c_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9733333587646484     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m48131b3c_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.11290545016527176    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  4852f2fa_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9853333234786987     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m4852f2fa_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.36084944009780884    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  48f8583b_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9798148274421692     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m48f8583b_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.29629629850387573    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  4aab4007_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.12888889014720917    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m4aab4007_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  4acc7107_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9758333563804626     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m4acc7107_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.4823917746543884     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  4b6b68e5_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8622221946716309     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m4b6b68e5_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.03787878900766373    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  4c177718_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9872222542762756     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m4c177718_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7471552491188049     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  4cd1b7b2_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9822222590446472     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m4cd1b7b2_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  4e45f183_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7507407665252686     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m4e45f183_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.013888888992369175    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  4e469f39_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9662962555885315     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m4e469f39_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  4f537728_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7972222566604614     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m4f537728_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  4ff4c9da_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6259259581565857     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m4ff4c9da_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  505fff84_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9913333654403687     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m505fff84_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8910254240036011     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  506d28a5_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9822221994400024     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m506d28a5_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.47752460837364197    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  50a16a69_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8159258961677551     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m50a16a69_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.03999999910593033    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  50aad11f_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9785184860229492     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m50aad11f_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.4671497642993927     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  50f325b5_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.801944375038147     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m50f325b5_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  516b51b7_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9188888669013977     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m516b51b7_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  5207a7b5_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9559259414672852     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m5207a7b5_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  5289ad53_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9755555391311646     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m5289ad53_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8811259269714355     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  52fd389e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7137036323547363     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m52fd389e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  54db823b_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9066666960716248     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m54db823b_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            1.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  55059096_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9744443893432617     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m55059096_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  551d5bf1_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7644444704055786     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m551d5bf1_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  55783887_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8462222218513489     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m55783887_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.10000000149011612    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  575b1a71_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8888888955116272     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m575b1a71_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  5783df64_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9900000095367432     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m5783df64_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.45825162529945374    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  5833af48_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8825926184654236     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m5833af48_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6010026335716248     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  58743b76_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9472222328186035     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m58743b76_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  58e15b12_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9170370697975159     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m58e15b12_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  59341089_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.960277795791626     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m59341089_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  5a5a2103_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8194444179534912     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m5a5a2103_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.04545454680919647    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  5af49b42_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9737036824226379     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m5af49b42_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  5b526a93_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.90666663646698      \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m5b526a93_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  5b692c0f_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9133332967758179     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m5b692c0f_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.23863637447357178    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  5b6cbef5_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9197778701782227     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m5b6cbef5_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.09092767536640167    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  5d2a5c43_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9784444570541382     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m5d2a5c43_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.47774338722229004    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  5ffb2104_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.987407386302948     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m5ffb2104_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.4901960790157318     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  604001fa_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9819444417953491     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m604001fa_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.2735389471054077     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  60a26a3e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9718518257141113     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m60a26a3e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  60c09cac_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9822221994400024     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m60c09cac_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.02777777798473835    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  626c0bcc_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9825925827026367     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m626c0bcc_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  62ab2642_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.93666672706604      \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m62ab2642_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  62b74c02_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9559259414672852     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m62b74c02_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  639f5a19_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7777777910232544     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m639f5a19_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  642248e4_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9570370316505432     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m642248e4_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  642d658d_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9611111283302307     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m642d658d_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9283973574638367     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  64a7c07e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9892592430114746     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m64a7c07e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.5            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  66e6c45b_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.995555579662323     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m66e6c45b_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.5            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  66f2d22f_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.991944432258606     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m66f2d22f_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7562196850776672     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  67636eac_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9862963557243347     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m67636eac_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.46666666865348816    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  67b4a34d_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9696295857429504     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m67b4a34d_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9138374328613281     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  67c52801_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9786111116409302     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m67c52801_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.5            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  68b67ca3_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9944444298744202     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m68b67ca3_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.5            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  692cd3b6_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9007408022880554     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m692cd3b6_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  695367ec_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8937036991119385     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m695367ec_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.05552127584815025    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  696d4842_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.962592601776123     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m696d4842_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  69889d6e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.980555534362793     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m69889d6e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  6a11f6da_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.975777804851532     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m6a11f6da_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.5782161355018616     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  6ad5bdfd_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9814814925193787     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m6ad5bdfd_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.45766592025756836    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  6df30ad6_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.991777777671814     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m6df30ad6_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.5457017421722412     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  6ea4a07e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9937036633491516     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m6ea4a07e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.37037038803100586    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  6f473927_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9677777886390686     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m6f473927_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.21378621459007263    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  7039b2d7_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9840741157531738     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m7039b2d7_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9842607378959656     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  705a3229_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9844444394111633     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m705a3229_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  712bf12e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9170370101928711     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m712bf12e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  72207abc_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9925925731658936     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m72207abc_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  72a961c9_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9844444990158081     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m72a961c9_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  73182012_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9881481528282166     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m73182012_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8835263848304749     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  73c3b0d8_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9869444370269775     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m73c3b0d8_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.2957516312599182     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  73ccf9c2_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9881481528282166     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m73ccf9c2_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8363578915596008     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  759f3fd3_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8427777886390686     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m759f3fd3_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  762cd429_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8118519186973572     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m762cd429_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  770cc55f_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9769444465637207     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m770cc55f_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  782b5218_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9344444274902344     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m782b5218_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.4673832952976227     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  79369cc6_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8040741086006165     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m79369cc6_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  7953d61e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9288889169692993     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m7953d61e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  79fb03f4_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.93833327293396      \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m79fb03f4_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  7bb29440_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9735555648803711     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m7bb29440_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8471860885620117     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  7c8af763_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8888888955116272     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m7c8af763_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  7c9b52a0_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9074074625968933     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m7c9b52a0_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6268526911735535     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  7d18a6fb_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9770370125770569     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m7d18a6fb_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7752125263214111     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  7d1f7ee8_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8325925469398499     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m7d1f7ee8_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  7d419a02_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.851111114025116     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m7d419a02_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  7e02026e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9000000357627869     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m7e02026e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  7ee1c6ea_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9133333563804626     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m7ee1c6ea_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  817e6c09_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9760000109672546     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m817e6c09_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  81c0276b_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9933333396911621     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m81c0276b_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9544203281402588     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  833dafe3_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9644444584846497     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m833dafe3_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.07334525883197784    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  845d6e51_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9477777481079102     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m845d6e51_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  84db8fc4_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8888888955116272     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m84db8fc4_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  84f2aca1_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9650000333786011     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m84f2aca1_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  8597cfd7_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.995555579662323     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m8597cfd7_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8174242377281189     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  85b81ff1_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.875           \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m85b81ff1_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.5            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  85fa5666_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9622222185134888     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m85fa5666_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  8719f442_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9422221779823303     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m8719f442_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  88207623_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9388889074325562     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m88207623_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  891232d6_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8897222280502319     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m891232d6_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  896d5239_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8825926184654236     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m896d5239_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  8a371977_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.43888890743255615    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m8a371977_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  8b28cd80_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.948888897895813     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m8b28cd80_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.017298799008131027    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  8ba14f53_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9938888549804688     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m8ba14f53_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8179367184638977     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  8cb8642d_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9296296238899231     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m8cb8642d_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7093300819396973     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  8dae5dfc_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8263888359069824     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m8dae5dfc_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  8e2edd66_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9814814925193787     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m8e2edd66_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.2586754262447357     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  8ee62060_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9788889288902283     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m8ee62060_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.5            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  8fbca751_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9659258723258972     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m8fbca751_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  90347967_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9933333396911621     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m90347967_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.5            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  903d1b4a_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7155555486679077     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m903d1b4a_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  9110e3c5_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9960317611694336     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m9110e3c5_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8651400804519653     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  917bccba_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9644444584846497     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m917bccba_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6146110892295837     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  929ab4e9_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.3613888919353485     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m929ab4e9_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  92e50de0_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6677777767181396     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m92e50de0_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  9356391f_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.90666663646698      \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m9356391f_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  93b4f4b3_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9233333468437195     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m93b4f4b3_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.40796583890914917    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  93c31fbe_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9399999976158142     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m93c31fbe_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.3983488082885742     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  94133066_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8922222256660461     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m94133066_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.48462045192718506    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  94414823_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9577777981758118     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m94414823_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  94be5b80_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9411110877990723     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m94be5b80_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.2946428656578064     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  95a58926_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8614814877510071     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m95a58926_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.5745627284049988     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  963f59bc_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9786111116409302     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m963f59bc_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  96a8c0cd_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9350000023841858     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m96a8c0cd_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  97239e3d_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7988889217376709     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m97239e3d_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  9772c176_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7477777600288391     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m9772c176_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  981571dc_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.00027777778450399637   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m981571dc_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  992798f6_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9863889217376709     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m992798f6_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  99306f82_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9162963032722473     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m99306f82_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  9a4bb226_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9888889193534851     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m9a4bb226_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7706348896026611     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  9b2a60aa_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.965925931930542     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m9b2a60aa_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  9b365c51_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      0.9670370221138      \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m9b365c51_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.444180965423584     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  9b4c17c4_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8147222995758057     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m9b4c17c4_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  9bebae7a_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9786666631698608     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m9bebae7a_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.33641454577445984    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  9c1e755f_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9461110830307007     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m9c1e755f_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  9c56f360_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9737036824226379     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m9c56f360_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.5            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  9caba7c3_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7659258842468262     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m9caba7c3_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  9ddd00f0_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9533333778381348     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m9ddd00f0_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  9def23fe_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8311111330986023     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m9def23fe_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  9f27f097_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8399999737739563     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m9f27f097_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  a04b2602_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8177778124809265     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36ma04b2602_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  a096bf4d_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7333333492279053     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36ma096bf4d_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  a3f84088_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8686110973358154     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36ma3f84088_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  a406ac07_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.958148181438446     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36ma406ac07_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  a57f2f04_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6633333563804626     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36ma57f2f04_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  a59b95c0_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9160000085830688     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36ma59b95c0_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  a680ac02_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9644444584846497     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36ma680ac02_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6501501202583313     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  a8610ef7_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9766666889190674     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36ma8610ef7_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  a934301b_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9674074053764343     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36ma934301b_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            1.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  aa18de87_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9791666269302368     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36maa18de87_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  aa300dc3_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.930555522441864     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36maa300dc3_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  aa4ec2a5_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.43740740418434143    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36maa4ec2a5_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  aab50785_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9871110916137695     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36maab50785_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9002954363822937     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  ac0c5833_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9518518447875977     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mac0c5833_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  ac2e8ecf_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9529629349708557     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mac2e8ecf_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.4784134328365326     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  ac3e2b04_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9386110901832581     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mac3e2b04_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  ac605cbb_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9875926375389099     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mac605cbb_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  ad7e01d0_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9144444465637207     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mad7e01d0_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.08509097993373871    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  ae58858e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9783333539962769     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mae58858e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  aee291af_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9762962460517883     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36maee291af_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9403367638587952     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  af22c60d_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36maf22c60d_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  af24b4cc_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9929630160331726     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36maf24b4cc_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8559829592704773     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m     avg_test_accuracy     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.904828667640686     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  avg_test_diff_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.2692205607891083     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m       avg_test_loss       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.3664872646331787     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  b0722778_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9844444394111633     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mb0722778_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7229965329170227     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  b0f4d537_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9722222089767456     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mb0f4d537_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6134893894195557     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  b15fca0b_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9675555229187012     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mb15fca0b_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  b1fc8b8e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9851110577583313     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mb1fc8b8e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.48750001192092896    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  b20f7c8b_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7707407474517822     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mb20f7c8b_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  b457fec5_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9137037396430969     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mb457fec5_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  b4a43f3b_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9633333086967468     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mb4a43f3b_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.46900829672813416    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  b7999b51_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9900000095367432     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mb7999b51_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8587267994880676     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  b7cb93ac_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9866666793823242     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mb7cb93ac_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.4814814627170563     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  b7f8a4d8_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6399999856948853     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mb7f8a4d8_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  b7fb29bc_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9100000262260437     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mb7fb29bc_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  b942fd60_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9666666984558105     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mb942fd60_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  b9630600_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8437037467956543     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mb9630600_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.3881119191646576     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  ba9d41b8_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9162963032722473     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mba9d41b8_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            1.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  baf41dbf_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9592592716217041     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mbaf41dbf_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.20501208305358887    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  bb52a14b_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9188888669013977     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mbb52a14b_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  bbb1b8b6_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9852380156517029     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mbbb1b8b6_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.5396488308906555     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  bc4146bd_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9111111164093018     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mbc4146bd_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  bcb3040b_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9196296334266663     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mbcb3040b_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  bd14c3bf_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9211111068725586     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mbd14c3bf_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  be03b35f_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9970369935035706     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mbe03b35f_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8111111521720886     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  bf32578f_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9881481528282166     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mbf32578f_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.3821733891963959     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  bf699163_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9900000095367432     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mbf699163_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9721251130104065     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  bf89d739_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9780555367469788     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mbf89d739_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  c074846d_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9948889017105103     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mc074846d_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  c1990cce_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9785184860229492     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mc1990cce_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.07402319461107254    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  c3202e5a_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9929630160331726     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mc3202e5a_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9741120338439941     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  c35c1b4c_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9144444465637207     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mc35c1b4c_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  c48954c1_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9100000262260437     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mc48954c1_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  c62e2108_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8962963223457336     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mc62e2108_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.04329491779208183    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  c64f1187_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9688888788223267     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mc64f1187_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6881044507026672     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  c658a4bd_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9194444417953491     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mc658a4bd_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.37494730949401855    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  c663677b_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.1899999976158142     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mc663677b_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  c6e1b8da_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8537037372589111     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mc6e1b8da_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.45049849152565      \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  c7d4e6ad_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9777777791023254     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mc7d4e6ad_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  c87289bb_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9436111450195312     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mc87289bb_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  c8b7cc0f_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.995555579662323     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mc8b7cc0f_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8881499767303467     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  c92b942c_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9175000190734863     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mc92b942c_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  c97c0139_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9155555963516235     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mc97c0139_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  ca8de6ea_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9900000095367432     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mca8de6ea_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.3333333432674408     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  ca8f78db_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mca8f78db_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  cad67732_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9740740656852722     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mcad67732_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  cb227835_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9792592525482178     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mcb227835_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  ccd554ac_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9307406544685364     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mccd554ac_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.02556818164885044    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  cd3c21df_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9948148727416992     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mcd3c21df_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8213383555412292     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  ce039d91_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9774999618530273     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mce039d91_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  ce8d95cc_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9802777767181396     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mce8d95cc_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7194792032241821     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  cf133acc_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9370369911193848     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mcf133acc_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  cfb2ce5a_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9325925707817078     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mcfb2ce5a_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  d017b73f_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9883332848548889     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36md017b73f_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.5            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  d19f7514_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9808333516120911     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36md19f7514_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.4937748610973358     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  d282b262_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9677777290344238     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36md282b262_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.4773857891559601     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  d2acf2cb_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9551851749420166     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36md2acf2cb_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.095238097012043     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  d304284e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8761111497879028     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36md304284e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  d37a1ef5_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9344444274902344     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36md37a1ef5_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  d47aa2ff_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9896295666694641     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36md47aa2ff_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7235023379325867     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  d492a647_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8811111450195312     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36md492a647_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  d4b1c2b1_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9442857503890991     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36md4b1c2b1_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.2857142984867096     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  d4c90558_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9829629063606262     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36md4c90558_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9063237309455872     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  d56f2372_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9866666793823242     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36md56f2372_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8060207962989807     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  d5c634a2_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9953967928886414     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36md5c634a2_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7885443568229675     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  d931c21c_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9108333587646484     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36md931c21c_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.25            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  d94c3b52_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8414815068244934     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36md94c3b52_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  da2b0fe3_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9707407355308533     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mda2b0fe3_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  da515329_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8374074101448059     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mda515329_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  dc2aa30b_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9100000262260437     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mdc2aa30b_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  dc2e9a9d_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9233333468437195     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mdc2e9a9d_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  dd2401ed_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9811111092567444     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mdd2401ed_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.43627452850341797    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  de493100_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.25111111998558044    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mde493100_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.2521111071109772     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  df8cc377_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9492592811584473     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mdf8cc377_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.5            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e0fb7511_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8314814567565918     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me0fb7511_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e133d23d_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9926666021347046     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me133d23d_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.5035164952278137     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e1baa8a4_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9894444942474365     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me1baa8a4_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9602466225624084     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e1d2900e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9777777194976807     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me1d2900e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.5            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e2092e0c_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8866667151451111     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me2092e0c_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e21a174a_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9562962651252747     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me21a174a_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.254934161901474     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e345f17b_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9961110949516296     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me345f17b_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8137826919555664     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e4075551_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9433333277702332     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me4075551_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e41c6fd3_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.936296284198761     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me41c6fd3_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.5            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e57337a4_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8762962818145752     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me57337a4_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.5169753432273865     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e5790162_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.988444447517395     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me5790162_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e5c44e8f_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9455555081367493     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me5c44e8f_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e619ca6e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8762962818145752     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me619ca6e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e633a9e5_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9722221493721008     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me633a9e5_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e66aafb8_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9508889317512512     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me66aafb8_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9255886077880859     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e681b708_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8870370388031006     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me681b708_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e69241bd_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9433333277702332     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me69241bd_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e6de6e8f_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9877777695655823     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me6de6e8f_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.5444445013999939     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e74e1818_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9674074053764343     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me74e1818_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.5            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e760a62e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.618148148059845     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me760a62e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e7639916_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9644444584846497     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me7639916_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e78887d1_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9794444441795349     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me78887d1_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6878482103347778     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e7a25a18_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9244444370269775     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me7a25a18_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.2172304391860962     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e7b06bea_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9871110916137695     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me7b06bea_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7000000476837158     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e7dd8335_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9785184860229492     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me7dd8335_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e872b94a_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            1.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me872b94a_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            1.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e88171ec_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8096296787261963     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me88171ec_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e95e3d8e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.46222221851348877    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me95e3d8e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e99362f0_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.978518545627594     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me99362f0_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7147099375724792     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e9ac8c9e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9792592525482178     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me9ac8c9e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.2666666805744171     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e9b4f6fc_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9619444012641907     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me9b4f6fc_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.44486111402511597    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e9bb6954_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9030555486679077     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me9bb6954_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0032051282469183207   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  e9c9d9a1_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8203703761100769     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36me9c9d9a1_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  ea959feb_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.3888889253139496     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mea959feb_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  ea9794b1_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9729629158973694     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mea9794b1_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.647230327129364     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  ecaa0ec1_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9894444346427917     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mecaa0ec1_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.48773449659347534    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  ed74f2f2_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9935185313224792     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36med74f2f2_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.5953373312950134     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  ed98d772_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9777777791023254     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36med98d772_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.10508663952350616    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  ef26cbf6_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.95333331823349      \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mef26cbf6_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  f0afb749_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9822222590446472     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mf0afb749_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.061728399246931076    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  f0df5ff0_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8670370578765869     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mf0df5ff0_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  f21745ec_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8877778053283691     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mf21745ec_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.4960607588291168     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  f3b10344_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.711481511592865     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mf3b10344_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  f3cdc58f_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9785184860229492     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mf3cdc58f_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.44780412316322327    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  f3e62deb_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9911110997200012     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mf3e62deb_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.5            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  f4081712_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9235555529594421     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mf4081712_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8869382739067078     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  f45f5ca7_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9918518662452698     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mf45f5ca7_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.5            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  f5aa3634_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9911110997200012     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mf5aa3634_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8053030371665955     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  f5c89df1_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9829629063606262     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mf5c89df1_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.437296062707901     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  f823c43c_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7616666555404663     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mf823c43c_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  f83cb3f6_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9807407259941101     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mf83cb3f6_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6049907803535461     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  f8be4b64_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9094444513320923     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mf8be4b64_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  f9a67cb5_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9262962937355042     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mf9a67cb5_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  f9d67f8b_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.15777777135372162    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mf9d67f8b_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.13529807329177856    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  fafd9572_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9700000286102295     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mfafd9572_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  fb791726_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.961017370223999     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mfb791726_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.03614457696676254    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  fc754716_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9844443798065186     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mfc754716_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.07361919432878494    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  fd096ab6_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.41111111640930176    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mfd096ab6_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  fd4b2b02_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9122222065925598     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mfd4b2b02_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  fe9372f3_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9600000977516174     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mfe9372f3_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  fea12743_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9288887977600098     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mfea12743_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m  ff72ca3e_test_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9647221565246582     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mff72ca3e_test_diff_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            0.0            \u001b[0m\u001b[35m \u001b[0m│\n",
            "└─────────────────────────────┴─────────────────────────────┘\n",
            "DEBUG: Logged metrics - Avg test loss: 0.3664872646331787, Avg test accuracy: 0.904828667640686, Avg diff accuracy: 0.2692205607891083\n",
            "DEBUG: Computed complete task accuracy: 0.2344139650872818\n",
            "test_loss: 0.3664872646331787\n",
            "test_accuracy: 0.904828667640686\n",
            "test_diff_accuracy: 0.2692205607891083\n",
            "complete_task_accuracy: 0.2344139650872818\n",
            "DEBUG: Creating wandb Artifact with name: arc_model-epoch_00-val_loss_0\n",
            "DEBUG: Artifact created and logged successfully.\n",
            "\n",
            "Evaluation Errors/Warnings:\n",
            "2024-09-28 23:17:21.343716: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-09-28 23:17:21.348011: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-09-28 23:17:21.362557: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-09-28 23:17:21.387342: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-09-28 23:17:21.394517: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-09-28 23:17:21.412236: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "DEBUG:tensorflow:Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n",
            "2024-09-28 23:17:23.851220: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DEBUG:h5py._conv:Creating converter from 7 to 5\n",
            "DEBUG:h5py._conv:Creating converter from 5 to 7\n",
            "DEBUG:h5py._conv:Creating converter from 7 to 5\n",
            "DEBUG:h5py._conv:Creating converter from 5 to 7\n",
            "DEBUG:git.util:Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'No such file or directory')\n",
            "DEBUG:git.cmd:Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/workspaces/arc-neural-reasoning-model, stdin=None, shell=False, universal_newlines=False)\n",
            "DEBUG:git.cmd:Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/workspaces/arc-neural-reasoning-model, stdin=None, shell=False, universal_newlines=False)\n",
            "wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
            "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/11\" 200 None\n",
            "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/11\" 200 None\n",
            "wandb: Currently logged in as: military-ingram (arc-abolition). Use `wandb login --relogin` to force relogin\n",
            "DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/workspaces/arc-neural-reasoning-model, stdin=<valid stream>, shell=False, universal_newlines=False)\n",
            "wandb: Tracking run with wandb version 0.18.1\n",
            "wandb: Run data is saved locally in /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/wandb/run-20240928_231726-rn92ouio\n",
            "wandb: Run `wandb offline` to turn off syncing.\n",
            "wandb: Syncing run scaling-test-evaluation-epoch00-val_loss0.37\n",
            "wandb: ⭐️ View project at https://wandb.ai/arc-abolition/arc-evaluation\n",
            "wandb: 🚀 View run at https://wandb.ai/arc-abolition/arc-evaluation/runs/rn92ouio\n",
            "/workspaces/arc-neural-reasoning-model/gpt2_arc/src/evaluate.py:118: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(args.model_checkpoint, map_location='cpu')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Initialized Attention with n_embd=256, n_head=4\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Initialized FeedForward with n_embd=256\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Initialized TransformerBlock with n_embd=256, n_head=4\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Initialized Attention with n_embd=256, n_head=4\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Initialized FeedForward with n_embd=256\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Initialized TransformerBlock with n_embd=256, n_head=4\n",
            "INFO:__main__:Model moved to device: cpu\n",
            "INFO:__main__:Defined input_size for summary: (1, 1, 100)\n",
            "DEBUG:__main__:Sanitized model_name: arc_model-epoch_00-val_loss_0\n",
            "DEBUG:__main__:Model name contains only valid characters.\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "DEBUG:fsspec.local:open file: /workspaces/arc-neural-reasoning-model/EXPERIMENTAL/20240928/lightning_logs/version_1/hparams.yaml\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[9, 9, 2,  ..., 4, 3, 2],\n",
            "          [7, 9, 3,  ..., 4, 5, 3],\n",
            "          [3, 2, 9,  ..., 7, 9, 9],\n",
            "          ...,\n",
            "          [7, 7, 9,  ..., 9, 3, 9],\n",
            "          [2, 3, 7,  ..., 5, 9, 7],\n",
            "          [3, 2, 9,  ..., 7, 9, 9]]],\n",
            "\n",
            "\n",
            "        [[[3, 5, 3,  ..., 6, 3, 3],\n",
            "          [5, 3, 3,  ..., 6, 3, 3],\n",
            "          [1, 1, 3,  ..., 5, 5, 3],\n",
            "          ...,\n",
            "          [6, 9, 9,  ..., 3, 9, 9],\n",
            "          [1, 1, 5,  ..., 4, 3, 5],\n",
            "          [1, 1, 3,  ..., 5, 5, 3]]],\n",
            "\n",
            "\n",
            "        [[[1, 9, 4,  ..., 9, 4, 4],\n",
            "          [7, 1, 4,  ..., 9, 4, 4],\n",
            "          [2, 7, 1,  ..., 2, 9, 1],\n",
            "          ...,\n",
            "          [9, 6, 7,  ..., 1, 2, 7],\n",
            "          [7, 2, 7,  ..., 7, 1, 7],\n",
            "          [2, 7, 1,  ..., 2, 9, 1]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('00576224', '00576224', '009d5c81', '009d5c81', '009d5c81', '009d5c81', '009d5c81', '00dbd492', '00dbd492', '00dbd492', '00dbd492', '03560426', '03560426', '03560426', '05a7bcf2', '05a7bcf2', '05a7bcf2', '0607ce86', '0607ce86', '0607ce86', '0692e18c', '0692e18c', '0692e18c', '070dd51e', '070dd51e', '08573cc6', '08573cc6', '08573cc6', '0934a4d8', '0934a4d8', '0934a4d8', '0934a4d8')], batch_idx: 0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('00576224', '00576224', '009d5c81', '009d5c81', '009d5c81', '009d5c81', '009d5c81', '00dbd492', '00dbd492', '00dbd492', '00dbd492', '03560426', '03560426', '03560426', '05a7bcf2', '05a7bcf2', '05a7bcf2', '0607ce86', '0607ce86', '0607ce86', '0692e18c', '0692e18c', '0692e18c', '070dd51e', '070dd51e', '08573cc6', '08573cc6', '08573cc6', '0934a4d8', '0934a4d8', '0934a4d8', '0934a4d8')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.14285714285714285\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.1724137931034483\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.16216216216216217\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.2727272727272727\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5454545454545454\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5238095238095238\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.48717948717948717\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6666666666666666\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6153846153846154\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6976744186046512\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.2\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.14285714285714285\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.16666666666666666\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.09523809523809523\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.07142857142857142\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.03636363636363636\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4782608695652174\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.43526785714285715\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.3002232142857143\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.29720670391061454\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.5816769003868103, Avg accuracy: 0.845625001937151, Avg diff accuracy: 0.21280757454400098\n",
            "/usr/local/python/3.12.1/lib/python3.12/site-packages/pytorch_lightning/utilities/data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 32. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.5816769003868103, avg_accuracy=0.845625001937151, diff_accuracy=0.21280757454400098\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.5816769003868103, 'task_ids': ('00576224', '00576224', '009d5c81', '009d5c81', '009d5c81', '009d5c81', '009d5c81', '00dbd492', '00dbd492', '00dbd492', '00dbd492', '03560426', '03560426', '03560426', '05a7bcf2', '05a7bcf2', '05a7bcf2', '0607ce86', '0607ce86', '0607ce86', '0692e18c', '0692e18c', '0692e18c', '070dd51e', '070dd51e', '08573cc6', '08573cc6', '08573cc6', '0934a4d8', '0934a4d8', '0934a4d8', '0934a4d8'), 'test_accuracy': 0.845625001937151, 'test_diff_accuracy': 0.21280757454400098, '00576224_test_accuracy': 0.9599999785423279, '00576224_test_diff_accuracy': 0.0, '009d5c81_test_accuracy': 0.9822221994400024, '009d5c81_test_diff_accuracy': 0.2727272727272727, '00dbd492_test_accuracy': 0.9177777767181396, '00dbd492_test_diff_accuracy': 0.0, '03560426_test_accuracy': 0.9777777791023254, '03560426_test_diff_accuracy': 0.48717948717948717, '05a7bcf2_test_accuracy': 0.6166666746139526, '05a7bcf2_test_diff_accuracy': 0.0, '0607ce86_test_accuracy': 0.8399999737739563, '0607ce86_test_diff_accuracy': 0.6976744186046512, '0692e18c_test_accuracy': 0.9777777791023254, '0692e18c_test_diff_accuracy': 0.16666666666666666, '070dd51e_test_accuracy': 0.9677777886390686, '070dd51e_test_diff_accuracy': 0.0, '08573cc6_test_accuracy': 0.9399999976158142, '08573cc6_test_diff_accuracy': 0.03636363636363636, '0934a4d8_test_accuracy': 0.29555556178092957, '0934a4d8_test_diff_accuracy': 0.29720670391061454}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.5816769003868103, 'task_ids': ('00576224', '00576224', '009d5c81', '009d5c81', '009d5c81', '009d5c81', '009d5c81', '00dbd492', '00dbd492', '00dbd492', '00dbd492', '03560426', '03560426', '03560426', '05a7bcf2', '05a7bcf2', '05a7bcf2', '0607ce86', '0607ce86', '0607ce86', '0692e18c', '0692e18c', '0692e18c', '070dd51e', '070dd51e', '08573cc6', '08573cc6', '08573cc6', '0934a4d8', '0934a4d8', '0934a4d8', '0934a4d8'), 'test_accuracy': 0.845625001937151, 'test_diff_accuracy': 0.21280757454400098, '00576224_test_accuracy': 0.9599999785423279, '00576224_test_diff_accuracy': 0.0, '009d5c81_test_accuracy': 0.9822221994400024, '009d5c81_test_diff_accuracy': 0.2727272727272727, '00dbd492_test_accuracy': 0.9177777767181396, '00dbd492_test_diff_accuracy': 0.0, '03560426_test_accuracy': 0.9777777791023254, '03560426_test_diff_accuracy': 0.48717948717948717, '05a7bcf2_test_accuracy': 0.6166666746139526, '05a7bcf2_test_diff_accuracy': 0.0, '0607ce86_test_accuracy': 0.8399999737739563, '0607ce86_test_diff_accuracy': 0.6976744186046512, '0692e18c_test_accuracy': 0.9777777791023254, '0692e18c_test_diff_accuracy': 0.16666666666666666, '070dd51e_test_accuracy': 0.9677777886390686, '070dd51e_test_diff_accuracy': 0.0, '08573cc6_test_accuracy': 0.9399999976158142, '08573cc6_test_diff_accuracy': 0.03636363636363636, '0934a4d8_test_accuracy': 0.29555556178092957, '0934a4d8_test_diff_accuracy': 0.29720670391061454}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('09c534e7', '09c534e7', '09c534e7', '0a1d4ef5', '0a1d4ef5', '0a1d4ef5', '0a2355a6', '0a2355a6', '0a2355a6', '0a2355a6', '0b17323b', '0b17323b', '0bb8deee', '0bb8deee', '0bb8deee', '0becf7df', '0becf7df', '0becf7df', '0c786b71', '0c786b71', '0c786b71', '0c9aba6e', '0c9aba6e', '0c9aba6e', '0c9aba6e', '0d87d2a6', '0d87d2a6', '0d87d2a6', '0e671a1a', '0e671a1a', '0e671a1a', '0e671a1a')], batch_idx: 1\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('09c534e7', '09c534e7', '09c534e7', '0a1d4ef5', '0a1d4ef5', '0a1d4ef5', '0a2355a6', '0a2355a6', '0a2355a6', '0a2355a6', '0b17323b', '0b17323b', '0bb8deee', '0bb8deee', '0bb8deee', '0becf7df', '0becf7df', '0becf7df', '0c786b71', '0c786b71', '0c786b71', '0c9aba6e', '0c9aba6e', '0c9aba6e', '0c9aba6e', '0d87d2a6', '0d87d2a6', '0d87d2a6', '0e671a1a', '0e671a1a', '0e671a1a', '0e671a1a')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9496268656716418\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9371069182389937\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8638059701492538\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6730769230769231\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6833333333333333\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6875\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7575757575757576\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7931034482758621\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7407407407407407\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.23821046948432922, Avg accuracy: 0.9448611121624708, Avg diff accuracy: 0.2433084361582033\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.23821046948432922, avg_accuracy=0.9448611121624708, diff_accuracy=0.2433084361582033\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.23821046948432922, 'task_ids': ('09c534e7', '09c534e7', '09c534e7', '0a1d4ef5', '0a1d4ef5', '0a1d4ef5', '0a2355a6', '0a2355a6', '0a2355a6', '0a2355a6', '0b17323b', '0b17323b', '0bb8deee', '0bb8deee', '0bb8deee', '0becf7df', '0becf7df', '0becf7df', '0c786b71', '0c786b71', '0c786b71', '0c9aba6e', '0c9aba6e', '0c9aba6e', '0c9aba6e', '0d87d2a6', '0d87d2a6', '0d87d2a6', '0e671a1a', '0e671a1a', '0e671a1a', '0e671a1a'), 'test_accuracy': 0.9448611121624708, 'test_diff_accuracy': 0.2433084361582033, '09c534e7_test_accuracy': 0.8488888740539551, '09c534e7_test_diff_accuracy': 0.0, '0a1d4ef5_test_accuracy': 0.9188888669013977, '0a1d4ef5_test_diff_accuracy': 0.8638059701492538, '0a2355a6_test_accuracy': 0.9166666865348816, '0a2355a6_test_diff_accuracy': 0.0, '0b17323b_test_accuracy': 0.995555579662323, '0b17323b_test_diff_accuracy': 0.0, '0bb8deee_test_accuracy': 0.9777777791023254, '0bb8deee_test_diff_accuracy': 0.6875, '0becf7df_test_accuracy': 0.9811111092567444, '0becf7df_test_diff_accuracy': 0.0, '0c786b71_test_accuracy': 0.9466666579246521, '0c786b71_test_diff_accuracy': 0.0, '0c9aba6e_test_accuracy': 0.992222249507904, '0c9aba6e_test_diff_accuracy': 0.7407407407407407, '0d87d2a6_test_accuracy': 0.898888885974884, '0d87d2a6_test_diff_accuracy': 0.0, '0e671a1a_test_accuracy': 0.9744444489479065, '0e671a1a_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.23821046948432922, 'task_ids': ('09c534e7', '09c534e7', '09c534e7', '0a1d4ef5', '0a1d4ef5', '0a1d4ef5', '0a2355a6', '0a2355a6', '0a2355a6', '0a2355a6', '0b17323b', '0b17323b', '0bb8deee', '0bb8deee', '0bb8deee', '0becf7df', '0becf7df', '0becf7df', '0c786b71', '0c786b71', '0c786b71', '0c9aba6e', '0c9aba6e', '0c9aba6e', '0c9aba6e', '0d87d2a6', '0d87d2a6', '0d87d2a6', '0e671a1a', '0e671a1a', '0e671a1a', '0e671a1a'), 'test_accuracy': 0.9448611121624708, 'test_diff_accuracy': 0.2433084361582033, '09c534e7_test_accuracy': 0.8488888740539551, '09c534e7_test_diff_accuracy': 0.0, '0a1d4ef5_test_accuracy': 0.9188888669013977, '0a1d4ef5_test_diff_accuracy': 0.8638059701492538, '0a2355a6_test_accuracy': 0.9166666865348816, '0a2355a6_test_diff_accuracy': 0.0, '0b17323b_test_accuracy': 0.995555579662323, '0b17323b_test_diff_accuracy': 0.0, '0bb8deee_test_accuracy': 0.9777777791023254, '0bb8deee_test_diff_accuracy': 0.6875, '0becf7df_test_accuracy': 0.9811111092567444, '0becf7df_test_diff_accuracy': 0.0, '0c786b71_test_accuracy': 0.9466666579246521, '0c786b71_test_diff_accuracy': 0.0, '0c9aba6e_test_accuracy': 0.992222249507904, '0c9aba6e_test_diff_accuracy': 0.7407407407407407, '0d87d2a6_test_accuracy': 0.898888885974884, '0d87d2a6_test_diff_accuracy': 0.0, '0e671a1a_test_accuracy': 0.9744444489479065, '0e671a1a_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('0f63c0b9', '0f63c0b9', '0f63c0b9', '0f63c0b9', '103eff5b', '103eff5b', '11e1fe23', '11e1fe23', '12422b43', '12422b43', '12422b43', '12422b43', '12422b43', '12997ef3', '12997ef3', '12997ef3', '12997ef3', '12eac192', '12eac192', '12eac192', '12eac192', '136b0064', '136b0064', '136b0064', '13713586', '13713586', '13713586', '137f0df0', '137f0df0', '137f0df0', '140c817e', '140c817e')], batch_idx: 2\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('0f63c0b9', '0f63c0b9', '0f63c0b9', '0f63c0b9', '103eff5b', '103eff5b', '11e1fe23', '11e1fe23', '12422b43', '12422b43', '12422b43', '12422b43', '12422b43', '12997ef3', '12997ef3', '12997ef3', '12997ef3', '12eac192', '12eac192', '12eac192', '12eac192', '136b0064', '136b0064', '136b0064', '13713586', '13713586', '13713586', '137f0df0', '137f0df0', '137f0df0', '140c817e', '140c817e')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.3333333333333333\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.2916666666666667\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.3684210526315789\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.38461538461538464\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7027027027027027\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7058823529411765\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7254901960784313\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.29349371790885925, Avg accuracy: 0.9423611182719469, Avg diff accuracy: 0.10975349028028981\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.29349371790885925, avg_accuracy=0.9423611182719469, diff_accuracy=0.10975349028028981\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.29349371790885925, 'task_ids': ('0f63c0b9', '0f63c0b9', '0f63c0b9', '0f63c0b9', '103eff5b', '103eff5b', '11e1fe23', '11e1fe23', '12422b43', '12422b43', '12422b43', '12422b43', '12422b43', '12997ef3', '12997ef3', '12997ef3', '12997ef3', '12eac192', '12eac192', '12eac192', '12eac192', '136b0064', '136b0064', '136b0064', '13713586', '13713586', '13713586', '137f0df0', '137f0df0', '137f0df0', '140c817e', '140c817e'), 'test_accuracy': 0.9423611182719469, 'test_diff_accuracy': 0.10975349028028981, '0f63c0b9_test_accuracy': 0.894444465637207, '0f63c0b9_test_diff_accuracy': 0.0, '103eff5b_test_accuracy': 0.9333333373069763, '103eff5b_test_diff_accuracy': 0.0, '11e1fe23_test_accuracy': 0.992222249507904, '11e1fe23_test_diff_accuracy': 0.0, '12422b43_test_accuracy': 0.9833333492279053, '12422b43_test_diff_accuracy': 0.0, '12997ef3_test_accuracy': 0.9911110997200012, '12997ef3_test_diff_accuracy': 0.38461538461538464, '12eac192_test_accuracy': 0.9933333396911621, '12eac192_test_diff_accuracy': 0.0, '136b0064_test_accuracy': 0.9844444394111633, '136b0064_test_diff_accuracy': 0.7254901960784313, '13713586_test_accuracy': 0.8255555629730225, '13713586_test_diff_accuracy': 0.0, '137f0df0_test_accuracy': 0.902222216129303, '137f0df0_test_diff_accuracy': 0.0, '140c817e_test_accuracy': 0.9100000262260437, '140c817e_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.29349371790885925, 'task_ids': ('0f63c0b9', '0f63c0b9', '0f63c0b9', '0f63c0b9', '103eff5b', '103eff5b', '11e1fe23', '11e1fe23', '12422b43', '12422b43', '12422b43', '12422b43', '12422b43', '12997ef3', '12997ef3', '12997ef3', '12997ef3', '12eac192', '12eac192', '12eac192', '12eac192', '136b0064', '136b0064', '136b0064', '13713586', '13713586', '13713586', '137f0df0', '137f0df0', '137f0df0', '140c817e', '140c817e'), 'test_accuracy': 0.9423611182719469, 'test_diff_accuracy': 0.10975349028028981, '0f63c0b9_test_accuracy': 0.894444465637207, '0f63c0b9_test_diff_accuracy': 0.0, '103eff5b_test_accuracy': 0.9333333373069763, '103eff5b_test_diff_accuracy': 0.0, '11e1fe23_test_accuracy': 0.992222249507904, '11e1fe23_test_diff_accuracy': 0.0, '12422b43_test_accuracy': 0.9833333492279053, '12422b43_test_diff_accuracy': 0.0, '12997ef3_test_accuracy': 0.9911110997200012, '12997ef3_test_diff_accuracy': 0.38461538461538464, '12eac192_test_accuracy': 0.9933333396911621, '12eac192_test_diff_accuracy': 0.0, '136b0064_test_accuracy': 0.9844444394111633, '136b0064_test_diff_accuracy': 0.7254901960784313, '13713586_test_accuracy': 0.8255555629730225, '13713586_test_diff_accuracy': 0.0, '137f0df0_test_accuracy': 0.902222216129303, '137f0df0_test_diff_accuracy': 0.0, '140c817e_test_accuracy': 0.9100000262260437, '140c817e_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('140c817e', '14754a24', '14754a24', '14754a24', '14754a24', '15113be4', '15113be4', '15113be4', '15663ba9', '15663ba9', '15663ba9', '15696249', '15696249', '15696249', '15696249', '16b78196', '16b78196', '17b80ad2', '17b80ad2', '17b80ad2', '17b80ad2', '17cae0c1', '17cae0c1', '17cae0c1', '17cae0c1', '18419cfa', '18419cfa', '18419cfa', '184a9768', '184a9768', '184a9768', '195ba7dc')], batch_idx: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('140c817e', '14754a24', '14754a24', '14754a24', '14754a24', '15113be4', '15113be4', '15113be4', '15663ba9', '15663ba9', '15663ba9', '15696249', '15696249', '15696249', '15696249', '16b78196', '16b78196', '17b80ad2', '17b80ad2', '17b80ad2', '17b80ad2', '17cae0c1', '17cae0c1', '17cae0c1', '17cae0c1', '18419cfa', '18419cfa', '18419cfa', '184a9768', '184a9768', '184a9768', '195ba7dc')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.25\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.25\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.25\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.46846846846846846\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.53125\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5818181818181818\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6122448979591837\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5227272727272727\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.3418425917625427, Avg accuracy: 0.8920486252754927, Avg diff accuracy: 0.12395340065540958\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.3418425917625427, avg_accuracy=0.8920486252754927, diff_accuracy=0.12395340065540958\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.3418425917625427, 'task_ids': ('140c817e', '14754a24', '14754a24', '14754a24', '14754a24', '15113be4', '15113be4', '15113be4', '15663ba9', '15663ba9', '15663ba9', '15696249', '15696249', '15696249', '15696249', '16b78196', '16b78196', '17b80ad2', '17b80ad2', '17b80ad2', '17b80ad2', '17cae0c1', '17cae0c1', '17cae0c1', '17cae0c1', '18419cfa', '18419cfa', '18419cfa', '184a9768', '184a9768', '184a9768', '195ba7dc'), 'test_accuracy': 0.8920486252754927, 'test_diff_accuracy': 0.12395340065540958, '140c817e_test_accuracy': 0.8655555844306946, '140c817e_test_diff_accuracy': 0.0, '14754a24_test_accuracy': 0.8955555558204651, '14754a24_test_diff_accuracy': 0.0, '15113be4_test_accuracy': 0.601111114025116, '15113be4_test_diff_accuracy': 0.0, '15663ba9_test_accuracy': 0.9355555772781372, '15663ba9_test_diff_accuracy': 0.0, '15696249_test_accuracy': 0.9700000286102295, '15696249_test_diff_accuracy': 0.25, '16b78196_test_accuracy': 0.7811111211776733, '16b78196_test_diff_accuracy': 0.46846846846846846, '17b80ad2_test_accuracy': 0.992222249507904, '17b80ad2_test_diff_accuracy': 0.0, '17cae0c1_test_accuracy': 0.9700000286102295, '17cae0c1_test_diff_accuracy': 0.0, '18419cfa_test_accuracy': 0.9377777576446533, '18419cfa_test_diff_accuracy': 0.0, '184a9768_test_accuracy': 0.8799999952316284, '184a9768_test_diff_accuracy': 0.6122448979591837, '195ba7dc_test_accuracy': 0.9766666889190674, '195ba7dc_test_diff_accuracy': 0.5227272727272727}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.3418425917625427, 'task_ids': ('140c817e', '14754a24', '14754a24', '14754a24', '14754a24', '15113be4', '15113be4', '15113be4', '15663ba9', '15663ba9', '15663ba9', '15696249', '15696249', '15696249', '15696249', '16b78196', '16b78196', '17b80ad2', '17b80ad2', '17b80ad2', '17b80ad2', '17cae0c1', '17cae0c1', '17cae0c1', '17cae0c1', '18419cfa', '18419cfa', '18419cfa', '184a9768', '184a9768', '184a9768', '195ba7dc'), 'test_accuracy': 0.8920486252754927, 'test_diff_accuracy': 0.12395340065540958, '140c817e_test_accuracy': 0.8655555844306946, '140c817e_test_diff_accuracy': 0.0, '14754a24_test_accuracy': 0.8955555558204651, '14754a24_test_diff_accuracy': 0.0, '15113be4_test_accuracy': 0.601111114025116, '15113be4_test_diff_accuracy': 0.0, '15663ba9_test_accuracy': 0.9355555772781372, '15663ba9_test_diff_accuracy': 0.0, '15696249_test_accuracy': 0.9700000286102295, '15696249_test_diff_accuracy': 0.25, '16b78196_test_accuracy': 0.7811111211776733, '16b78196_test_diff_accuracy': 0.46846846846846846, '17b80ad2_test_accuracy': 0.992222249507904, '17b80ad2_test_diff_accuracy': 0.0, '17cae0c1_test_accuracy': 0.9700000286102295, '17cae0c1_test_diff_accuracy': 0.0, '18419cfa_test_accuracy': 0.9377777576446533, '18419cfa_test_diff_accuracy': 0.0, '184a9768_test_accuracy': 0.8799999952316284, '184a9768_test_diff_accuracy': 0.6122448979591837, '195ba7dc_test_accuracy': 0.9766666889190674, '195ba7dc_test_diff_accuracy': 0.5227272727272727}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 1,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 1,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('195ba7dc', '195ba7dc', '195ba7dc', '1990f7a8', '1990f7a8', '1990f7a8', '19bb5feb', '19bb5feb', '19bb5feb', '1a2e2828', '1a2e2828', '1a2e2828', '1a2e2828', '1a2e2828', '1a6449f1', '1a6449f1', '1a6449f1', '1acc24af', '1acc24af', '1acc24af', '1acc24af', '1c02dbbe', '1c02dbbe', '1c02dbbe', '1c0d0a4b', '1c0d0a4b', '1c0d0a4b', '1c56ad9f', '1c56ad9f', '1c56ad9f', '1c56ad9f', '1d0a4b61')], batch_idx: 4\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('195ba7dc', '195ba7dc', '195ba7dc', '1990f7a8', '1990f7a8', '1990f7a8', '19bb5feb', '19bb5feb', '19bb5feb', '1a2e2828', '1a2e2828', '1a2e2828', '1a2e2828', '1a2e2828', '1a6449f1', '1a6449f1', '1a6449f1', '1acc24af', '1acc24af', '1acc24af', '1acc24af', '1c02dbbe', '1c02dbbe', '1c02dbbe', '1c0d0a4b', '1c0d0a4b', '1c0d0a4b', '1c56ad9f', '1c56ad9f', '1c56ad9f', '1c56ad9f', '1d0a4b61')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5217391304347826\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4772727272727273\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6349206349206349\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9844961240310077\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5740740740740741\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9803921568627451\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9615384615384616\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9883720930232558\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9871794871794872\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8833333333333333\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8917748917748918\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9640718562874252\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.046511627906976744\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.05970149253731343\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.08\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6296296296296297\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6296296296296297\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5277777777777778\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.23224544525146484, Avg accuracy: 0.9443750018253922, Avg diff accuracy: 0.5257004727566923\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.23224544525146484, avg_accuracy=0.9443750018253922, diff_accuracy=0.5257004727566923\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.23224544525146484, 'task_ids': ('195ba7dc', '195ba7dc', '195ba7dc', '1990f7a8', '1990f7a8', '1990f7a8', '19bb5feb', '19bb5feb', '19bb5feb', '1a2e2828', '1a2e2828', '1a2e2828', '1a2e2828', '1a2e2828', '1a6449f1', '1a6449f1', '1a6449f1', '1acc24af', '1acc24af', '1acc24af', '1acc24af', '1c02dbbe', '1c02dbbe', '1c02dbbe', '1c0d0a4b', '1c0d0a4b', '1c0d0a4b', '1c56ad9f', '1c56ad9f', '1c56ad9f', '1c56ad9f', '1d0a4b61'), 'test_accuracy': 0.9443750018253922, 'test_diff_accuracy': 0.5257004727566923, '195ba7dc_test_accuracy': 0.9744444489479065, '195ba7dc_test_diff_accuracy': 0.4772727272727273, '1990f7a8_test_accuracy': 0.9788888692855835, '1990f7a8_test_diff_accuracy': 0.5, '19bb5feb_test_accuracy': 0.948888897895813, '19bb5feb_test_diff_accuracy': 0.5740740740740741, '1a2e2828_test_accuracy': 0.9988889098167419, '1a2e2828_test_diff_accuracy': 1.0, '1a6449f1_test_accuracy': 0.9933333396911621, '1a6449f1_test_diff_accuracy': 0.9640718562874252, '1acc24af_test_accuracy': 0.9599999785423279, '1acc24af_test_diff_accuracy': 0.0, '1c02dbbe_test_accuracy': 0.8266666531562805, '1c02dbbe_test_diff_accuracy': 0.08, '1c0d0a4b_test_accuracy': 0.9811111092567444, '1c0d0a4b_test_diff_accuracy': 0.5277777777777778, '1c56ad9f_test_accuracy': 0.9555555582046509, '1c56ad9f_test_diff_accuracy': 0.5, '1d0a4b61_test_accuracy': 0.3055555522441864, '1d0a4b61_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.23224544525146484, 'task_ids': ('195ba7dc', '195ba7dc', '195ba7dc', '1990f7a8', '1990f7a8', '1990f7a8', '19bb5feb', '19bb5feb', '19bb5feb', '1a2e2828', '1a2e2828', '1a2e2828', '1a2e2828', '1a2e2828', '1a6449f1', '1a6449f1', '1a6449f1', '1acc24af', '1acc24af', '1acc24af', '1acc24af', '1c02dbbe', '1c02dbbe', '1c02dbbe', '1c0d0a4b', '1c0d0a4b', '1c0d0a4b', '1c56ad9f', '1c56ad9f', '1c56ad9f', '1c56ad9f', '1d0a4b61'), 'test_accuracy': 0.9443750018253922, 'test_diff_accuracy': 0.5257004727566923, '195ba7dc_test_accuracy': 0.9744444489479065, '195ba7dc_test_diff_accuracy': 0.4772727272727273, '1990f7a8_test_accuracy': 0.9788888692855835, '1990f7a8_test_diff_accuracy': 0.5, '19bb5feb_test_accuracy': 0.948888897895813, '19bb5feb_test_diff_accuracy': 0.5740740740740741, '1a2e2828_test_accuracy': 0.9988889098167419, '1a2e2828_test_diff_accuracy': 1.0, '1a6449f1_test_accuracy': 0.9933333396911621, '1a6449f1_test_diff_accuracy': 0.9640718562874252, '1acc24af_test_accuracy': 0.9599999785423279, '1acc24af_test_diff_accuracy': 0.0, '1c02dbbe_test_accuracy': 0.8266666531562805, '1c02dbbe_test_diff_accuracy': 0.08, '1c0d0a4b_test_accuracy': 0.9811111092567444, '1c0d0a4b_test_diff_accuracy': 0.5277777777777778, '1c56ad9f_test_accuracy': 0.9555555582046509, '1c56ad9f_test_diff_accuracy': 0.5, '1d0a4b61_test_accuracy': 0.3055555522441864, '1d0a4b61_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 1,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 1,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 1,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 1,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('1d0a4b61', '1d0a4b61', '1d398264', '1d398264', '1d398264', '1da012fc', '1da012fc', '1e81d6f9', '1e81d6f9', '1e81d6f9', '1e97544e', '1e97544e', '1e97544e', '2037f2c7', '2037f2c7', '2037f2c7', '2072aba6', '2072aba6', '2072aba6', '20818e16', '20818e16', '20818e16', '20981f0e', '20981f0e', '20981f0e', '212895b5', '212895b5', '212895b5', '21f83797', '21f83797', '22a4bbc2', '22a4bbc2')], batch_idx: 5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('1d0a4b61', '1d0a4b61', '1d398264', '1d398264', '1d398264', '1da012fc', '1da012fc', '1e81d6f9', '1e81d6f9', '1e81d6f9', '1e97544e', '1e97544e', '1e97544e', '2037f2c7', '2037f2c7', '2037f2c7', '2072aba6', '2072aba6', '2072aba6', '20818e16', '20818e16', '20818e16', '20981f0e', '20981f0e', '20981f0e', '212895b5', '212895b5', '212895b5', '21f83797', '21f83797', '22a4bbc2', '22a4bbc2')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9572192513368984\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9144736842105263\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9285714285714286\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.047619047619047616\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8140703517587939\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8691588785046729\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4861111111111111\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.4968261420726776, Avg accuracy: 0.8606944475322962, Avg diff accuracy: 0.29741324228476496\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.4968261420726776, avg_accuracy=0.8606944475322962, diff_accuracy=0.29741324228476496\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.4968261420726776, 'task_ids': ('1d0a4b61', '1d0a4b61', '1d398264', '1d398264', '1d398264', '1da012fc', '1da012fc', '1e81d6f9', '1e81d6f9', '1e81d6f9', '1e97544e', '1e97544e', '1e97544e', '2037f2c7', '2037f2c7', '2037f2c7', '2072aba6', '2072aba6', '2072aba6', '20818e16', '20818e16', '20818e16', '20981f0e', '20981f0e', '20981f0e', '212895b5', '212895b5', '212895b5', '21f83797', '21f83797', '22a4bbc2', '22a4bbc2'), 'test_accuracy': 0.8606944475322962, 'test_diff_accuracy': 0.29741324228476496, '1d0a4b61_test_accuracy': 0.3055555522441864, '1d0a4b61_test_diff_accuracy': 0.0, '1d398264_test_accuracy': 0.9288889169692993, '1d398264_test_diff_accuracy': 0.0, '1da012fc_test_accuracy': 0.9288889169692993, '1da012fc_test_diff_accuracy': 0.0, '1e81d6f9_test_accuracy': 0.9611111283302307, '1e81d6f9_test_diff_accuracy': 1.0, '1e97544e_test_accuracy': 0.4144444465637207, '1e97544e_test_diff_accuracy': 0.0, '2037f2c7_test_accuracy': 0.9933333396911621, '2037f2c7_test_diff_accuracy': 0.9285714285714286, '2072aba6_test_accuracy': 0.9777777791023254, '2072aba6_test_diff_accuracy': 0.047619047619047616, '20818e16_test_accuracy': 0.9288889169692993, '20818e16_test_diff_accuracy': 0.4861111111111111, '20981f0e_test_accuracy': 0.9700000286102295, '20981f0e_test_diff_accuracy': 0.5, '212895b5_test_accuracy': 0.9255555272102356, '212895b5_test_diff_accuracy': 0.0, '21f83797_test_accuracy': 0.9233333468437195, '21f83797_test_diff_accuracy': 0.0, '22a4bbc2_test_accuracy': 0.9311110973358154, '22a4bbc2_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.4968261420726776, 'task_ids': ('1d0a4b61', '1d0a4b61', '1d398264', '1d398264', '1d398264', '1da012fc', '1da012fc', '1e81d6f9', '1e81d6f9', '1e81d6f9', '1e97544e', '1e97544e', '1e97544e', '2037f2c7', '2037f2c7', '2037f2c7', '2072aba6', '2072aba6', '2072aba6', '20818e16', '20818e16', '20818e16', '20981f0e', '20981f0e', '20981f0e', '212895b5', '212895b5', '212895b5', '21f83797', '21f83797', '22a4bbc2', '22a4bbc2'), 'test_accuracy': 0.8606944475322962, 'test_diff_accuracy': 0.29741324228476496, '1d0a4b61_test_accuracy': 0.3055555522441864, '1d0a4b61_test_diff_accuracy': 0.0, '1d398264_test_accuracy': 0.9288889169692993, '1d398264_test_diff_accuracy': 0.0, '1da012fc_test_accuracy': 0.9288889169692993, '1da012fc_test_diff_accuracy': 0.0, '1e81d6f9_test_accuracy': 0.9611111283302307, '1e81d6f9_test_diff_accuracy': 1.0, '1e97544e_test_accuracy': 0.4144444465637207, '1e97544e_test_diff_accuracy': 0.0, '2037f2c7_test_accuracy': 0.9933333396911621, '2037f2c7_test_diff_accuracy': 0.9285714285714286, '2072aba6_test_accuracy': 0.9777777791023254, '2072aba6_test_diff_accuracy': 0.047619047619047616, '20818e16_test_accuracy': 0.9288889169692993, '20818e16_test_diff_accuracy': 0.4861111111111111, '20981f0e_test_accuracy': 0.9700000286102295, '20981f0e_test_diff_accuracy': 0.5, '212895b5_test_accuracy': 0.9255555272102356, '212895b5_test_diff_accuracy': 0.0, '21f83797_test_accuracy': 0.9233333468437195, '21f83797_test_diff_accuracy': 0.0, '22a4bbc2_test_accuracy': 0.9311110973358154, '22a4bbc2_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[3, 3, 2,  ..., 8, 1, 1],\n",
            "          [8, 2, 1,  ..., 6, 2, 6],\n",
            "          [1, 8, 3,  ..., 3, 2, 3],\n",
            "          ...,\n",
            "          [2, 3, 2,  ..., 2, 3, 2],\n",
            "          [2, 1, 8,  ..., 1, 8, 3],\n",
            "          [1, 6, 3,  ..., 1, 1, 8]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[3, 3, 2,  ..., 8, 1, 1],\n",
            "          [8, 2, 1,  ..., 6, 2, 6],\n",
            "          [1, 8, 3,  ..., 3, 2, 3],\n",
            "          ...,\n",
            "          [2, 3, 2,  ..., 2, 3, 2],\n",
            "          [2, 1, 8,  ..., 1, 8, 3],\n",
            "          [1, 6, 3,  ..., 1, 1, 8]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('22a4bbc2', '22a4bbc2', '25094a63', '25094a63', '2546ccf6', '2546ccf6', '256b0a75', '256b0a75', '256b0a75', '2685904e', '2685904e', '2685904e', '2685904e', '2685904e', '2685904e', '2697da3f', '2697da3f', '2697da3f', '2697da3f', '2753e76c', '2753e76c', '2753e76c', '27a77e38', '27a77e38', '27a77e38', '27f8ce4f', '27f8ce4f', '27f8ce4f', '27f8ce4f', '281123b4', '281123b4', '281123b4')], batch_idx: 6\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('22a4bbc2', '22a4bbc2', '25094a63', '25094a63', '2546ccf6', '2546ccf6', '256b0a75', '256b0a75', '256b0a75', '2685904e', '2685904e', '2685904e', '2685904e', '2685904e', '2685904e', '2697da3f', '2697da3f', '2697da3f', '2697da3f', '2753e76c', '2753e76c', '2753e76c', '27a77e38', '27a77e38', '27a77e38', '27f8ce4f', '27f8ce4f', '27f8ce4f', '27f8ce4f', '281123b4', '281123b4', '281123b4')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.17391304347826086\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.18181818181818182\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.14705882352941177\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.16129032258064516\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.922077922077922\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8809523809523809\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8952380952380953\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.25\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.2\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7254901960784313\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6938775510204082\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.75\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.47957876324653625, Avg accuracy: 0.8837499981746078, Avg diff accuracy: 0.1869286411491793\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.47957876324653625, avg_accuracy=0.8837499981746078, diff_accuracy=0.1869286411491793\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.47957876324653625, 'task_ids': ('22a4bbc2', '22a4bbc2', '25094a63', '25094a63', '2546ccf6', '2546ccf6', '256b0a75', '256b0a75', '256b0a75', '2685904e', '2685904e', '2685904e', '2685904e', '2685904e', '2685904e', '2697da3f', '2697da3f', '2697da3f', '2697da3f', '2753e76c', '2753e76c', '2753e76c', '27a77e38', '27a77e38', '27a77e38', '27f8ce4f', '27f8ce4f', '27f8ce4f', '27f8ce4f', '281123b4', '281123b4', '281123b4'), 'test_accuracy': 0.8837499981746078, 'test_diff_accuracy': 0.1869286411491793, '22a4bbc2_test_accuracy': 0.949999988079071, '22a4bbc2_test_diff_accuracy': 0.0, '25094a63_test_accuracy': 0.20555555820465088, '25094a63_test_diff_accuracy': 0.0, '2546ccf6_test_accuracy': 0.8422222137451172, '2546ccf6_test_diff_accuracy': 0.0, '256b0a75_test_accuracy': 0.6255555748939514, '256b0a75_test_diff_accuracy': 0.0, '2685904e_test_accuracy': 0.9744444489479065, '2685904e_test_diff_accuracy': 0.0, '2697da3f_test_accuracy': 0.9377777576446533, '2697da3f_test_diff_accuracy': 0.16129032258064516, '2753e76c_test_accuracy': 0.9877777695655823, '2753e76c_test_diff_accuracy': 0.8952380952380953, '27a77e38_test_accuracy': 0.9677777886390686, '27a77e38_test_diff_accuracy': 0.0, '27f8ce4f_test_accuracy': 0.9700000286102295, '27f8ce4f_test_diff_accuracy': 0.0, '281123b4_test_accuracy': 0.9844444394111633, '281123b4_test_diff_accuracy': 0.75}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.47957876324653625, 'task_ids': ('22a4bbc2', '22a4bbc2', '25094a63', '25094a63', '2546ccf6', '2546ccf6', '256b0a75', '256b0a75', '256b0a75', '2685904e', '2685904e', '2685904e', '2685904e', '2685904e', '2685904e', '2697da3f', '2697da3f', '2697da3f', '2697da3f', '2753e76c', '2753e76c', '2753e76c', '27a77e38', '27a77e38', '27a77e38', '27f8ce4f', '27f8ce4f', '27f8ce4f', '27f8ce4f', '281123b4', '281123b4', '281123b4'), 'test_accuracy': 0.8837499981746078, 'test_diff_accuracy': 0.1869286411491793, '22a4bbc2_test_accuracy': 0.949999988079071, '22a4bbc2_test_diff_accuracy': 0.0, '25094a63_test_accuracy': 0.20555555820465088, '25094a63_test_diff_accuracy': 0.0, '2546ccf6_test_accuracy': 0.8422222137451172, '2546ccf6_test_diff_accuracy': 0.0, '256b0a75_test_accuracy': 0.6255555748939514, '256b0a75_test_diff_accuracy': 0.0, '2685904e_test_accuracy': 0.9744444489479065, '2685904e_test_diff_accuracy': 0.0, '2697da3f_test_accuracy': 0.9377777576446533, '2697da3f_test_diff_accuracy': 0.16129032258064516, '2753e76c_test_accuracy': 0.9877777695655823, '2753e76c_test_diff_accuracy': 0.8952380952380953, '27a77e38_test_accuracy': 0.9677777886390686, '27a77e38_test_diff_accuracy': 0.0, '27f8ce4f_test_accuracy': 0.9700000286102295, '27f8ce4f_test_diff_accuracy': 0.0, '281123b4_test_accuracy': 0.9844444394111633, '281123b4_test_diff_accuracy': 0.75}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('281123b4', '281123b4', '281123b4', '292dd178', '292dd178', '292dd178', '29700607', '29700607', '29700607', '2a5f8217', '2a5f8217', '2a5f8217', '2b01abd0', '2b01abd0', '2b01abd0', '2c0b0aff', '2c0b0aff', '2c0b0aff', '2c0b0aff', '2c737e39', '2c737e39', '2c737e39', '2f0c5170', '2f0c5170', '2f0c5170', '310f3251', '310f3251', '310f3251', '310f3251', '310f3251', '3194b014', '3194b014')], batch_idx: 7\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('281123b4', '281123b4', '281123b4', '292dd178', '292dd178', '292dd178', '29700607', '29700607', '29700607', '2a5f8217', '2a5f8217', '2a5f8217', '2b01abd0', '2b01abd0', '2b01abd0', '2c0b0aff', '2c0b0aff', '2c0b0aff', '2c0b0aff', '2c737e39', '2c737e39', '2c737e39', '2f0c5170', '2f0c5170', '2f0c5170', '310f3251', '310f3251', '310f3251', '310f3251', '310f3251', '3194b014', '3194b014')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.717391304347826\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6511627906976745\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.75\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8042553191489362\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8251533742331288\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7115384615384616\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.69\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.1\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.16666666666666666\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.14285714285714285\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8835227272727273\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.919431279620853\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9528985507246377\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9095022624434389\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9482071713147411\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.2770877480506897, Avg accuracy: 0.9597916640341282, Avg diff accuracy: 0.3178933453395698\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.2770877480506897, avg_accuracy=0.9597916640341282, diff_accuracy=0.3178933453395698\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.2770877480506897, 'task_ids': ('281123b4', '281123b4', '281123b4', '292dd178', '292dd178', '292dd178', '29700607', '29700607', '29700607', '2a5f8217', '2a5f8217', '2a5f8217', '2b01abd0', '2b01abd0', '2b01abd0', '2c0b0aff', '2c0b0aff', '2c0b0aff', '2c0b0aff', '2c737e39', '2c737e39', '2c737e39', '2f0c5170', '2f0c5170', '2f0c5170', '310f3251', '310f3251', '310f3251', '310f3251', '310f3251', '3194b014', '3194b014'), 'test_accuracy': 0.9597916640341282, 'test_diff_accuracy': 0.3178933453395698, '281123b4_test_accuracy': 0.9844444394111633, '281123b4_test_diff_accuracy': 0.75, '292dd178_test_accuracy': 0.8899999856948853, '292dd178_test_diff_accuracy': 0.0, '29700607_test_accuracy': 0.9622222185134888, '29700607_test_diff_accuracy': 0.0, '2a5f8217_test_accuracy': 0.9666666388511658, '2a5f8217_test_diff_accuracy': 0.0, '2b01abd0_test_accuracy': 0.9655555486679077, '2b01abd0_test_diff_accuracy': 0.0, '2c0b0aff_test_accuracy': 0.897777795791626, '2c0b0aff_test_diff_accuracy': 0.69, '2c737e39_test_accuracy': 0.9855555295944214, '2c737e39_test_diff_accuracy': 0.14285714285714285, '2f0c5170_test_accuracy': 0.9855555295944214, '2f0c5170_test_diff_accuracy': 0.9528985507246377, '310f3251_test_accuracy': 0.9800000190734863, '310f3251_test_diff_accuracy': 0.0, '3194b014_test_accuracy': 0.9788888692855835, '3194b014_test_diff_accuracy': 0.9482071713147411}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.2770877480506897, 'task_ids': ('281123b4', '281123b4', '281123b4', '292dd178', '292dd178', '292dd178', '29700607', '29700607', '29700607', '2a5f8217', '2a5f8217', '2a5f8217', '2b01abd0', '2b01abd0', '2b01abd0', '2c0b0aff', '2c0b0aff', '2c0b0aff', '2c0b0aff', '2c737e39', '2c737e39', '2c737e39', '2f0c5170', '2f0c5170', '2f0c5170', '310f3251', '310f3251', '310f3251', '310f3251', '310f3251', '3194b014', '3194b014'), 'test_accuracy': 0.9597916640341282, 'test_diff_accuracy': 0.3178933453395698, '281123b4_test_accuracy': 0.9844444394111633, '281123b4_test_diff_accuracy': 0.75, '292dd178_test_accuracy': 0.8899999856948853, '292dd178_test_diff_accuracy': 0.0, '29700607_test_accuracy': 0.9622222185134888, '29700607_test_diff_accuracy': 0.0, '2a5f8217_test_accuracy': 0.9666666388511658, '2a5f8217_test_diff_accuracy': 0.0, '2b01abd0_test_accuracy': 0.9655555486679077, '2b01abd0_test_diff_accuracy': 0.0, '2c0b0aff_test_accuracy': 0.897777795791626, '2c0b0aff_test_diff_accuracy': 0.69, '2c737e39_test_accuracy': 0.9855555295944214, '2c737e39_test_diff_accuracy': 0.14285714285714285, '2f0c5170_test_accuracy': 0.9855555295944214, '2f0c5170_test_diff_accuracy': 0.9528985507246377, '310f3251_test_accuracy': 0.9800000190734863, '310f3251_test_diff_accuracy': 0.0, '3194b014_test_accuracy': 0.9788888692855835, '3194b014_test_diff_accuracy': 0.9482071713147411}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('3194b014', '319f2597', '319f2597', '319f2597', '31adaf00', '31adaf00', '31adaf00', '31d5ba1a', '31d5ba1a', '31d5ba1a', '31d5ba1a', '31d5ba1a', '32e9702f', '32e9702f', '32e9702f', '332efdb3', '332efdb3', '332efdb3', '3391f8c0', '3391f8c0', '3391f8c0', '3391f8c0', '33b52de3', '33b52de3', '3490cc26', '3490cc26', '3490cc26', '3490cc26', '34b99a2b', '34b99a2b', '34b99a2b', '34b99a2b')], batch_idx: 8\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('3194b014', '319f2597', '319f2597', '319f2597', '31adaf00', '31adaf00', '31adaf00', '31d5ba1a', '31d5ba1a', '31d5ba1a', '31d5ba1a', '31d5ba1a', '32e9702f', '32e9702f', '32e9702f', '332efdb3', '332efdb3', '332efdb3', '3391f8c0', '3391f8c0', '3391f8c0', '3391f8c0', '33b52de3', '33b52de3', '3490cc26', '3490cc26', '3490cc26', '3490cc26', '34b99a2b', '34b99a2b', '34b99a2b', '34b99a2b')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9098039215686274\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.953125\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.967741935483871\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.75\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.631578947368421\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6666666666666666\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6111111111111112\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6111111111111112\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.3333333333333333\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.25\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.3333333333333333\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6551724137931034\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.64\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6428571428571429\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5806451612903226\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.3190476894378662, Avg accuracy: 0.9235763922333717, Avg diff accuracy: 0.34489000243490764\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.3190476894378662, avg_accuracy=0.9235763922333717, diff_accuracy=0.34489000243490764\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.3190476894378662, 'task_ids': ('3194b014', '319f2597', '319f2597', '319f2597', '31adaf00', '31adaf00', '31adaf00', '31d5ba1a', '31d5ba1a', '31d5ba1a', '31d5ba1a', '31d5ba1a', '32e9702f', '32e9702f', '32e9702f', '332efdb3', '332efdb3', '332efdb3', '3391f8c0', '3391f8c0', '3391f8c0', '3391f8c0', '33b52de3', '33b52de3', '3490cc26', '3490cc26', '3490cc26', '3490cc26', '34b99a2b', '34b99a2b', '34b99a2b', '34b99a2b'), 'test_accuracy': 0.9235763922333717, 'test_diff_accuracy': 0.34489000243490764, '3194b014_test_accuracy': 0.9744444489479065, '3194b014_test_diff_accuracy': 0.9098039215686274, '319f2597_test_accuracy': 0.6288889050483704, '319f2597_test_diff_accuracy': 1.0, '31adaf00_test_accuracy': 0.9277777671813965, '31adaf00_test_diff_accuracy': 0.0, '31d5ba1a_test_accuracy': 0.992222249507904, '31d5ba1a_test_diff_accuracy': 0.6111111111111112, '32e9702f_test_accuracy': 0.945555567741394, '32e9702f_test_diff_accuracy': 0.0, '332efdb3_test_accuracy': 0.9277777671813965, '332efdb3_test_diff_accuracy': 0.0, '3391f8c0_test_accuracy': 0.9888888597488403, '3391f8c0_test_diff_accuracy': 0.5, '33b52de3_test_accuracy': 0.8577777743339539, '33b52de3_test_diff_accuracy': 0.0, '3490cc26_test_accuracy': 0.8644444346427917, '3490cc26_test_diff_accuracy': 0.0, '34b99a2b_test_accuracy': 0.9855555295944214, '34b99a2b_test_diff_accuracy': 0.5806451612903226}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.3190476894378662, 'task_ids': ('3194b014', '319f2597', '319f2597', '319f2597', '31adaf00', '31adaf00', '31adaf00', '31d5ba1a', '31d5ba1a', '31d5ba1a', '31d5ba1a', '31d5ba1a', '32e9702f', '32e9702f', '32e9702f', '332efdb3', '332efdb3', '332efdb3', '3391f8c0', '3391f8c0', '3391f8c0', '3391f8c0', '33b52de3', '33b52de3', '3490cc26', '3490cc26', '3490cc26', '3490cc26', '34b99a2b', '34b99a2b', '34b99a2b', '34b99a2b'), 'test_accuracy': 0.9235763922333717, 'test_diff_accuracy': 0.34489000243490764, '3194b014_test_accuracy': 0.9744444489479065, '3194b014_test_diff_accuracy': 0.9098039215686274, '319f2597_test_accuracy': 0.6288889050483704, '319f2597_test_diff_accuracy': 1.0, '31adaf00_test_accuracy': 0.9277777671813965, '31adaf00_test_diff_accuracy': 0.0, '31d5ba1a_test_accuracy': 0.992222249507904, '31d5ba1a_test_diff_accuracy': 0.6111111111111112, '32e9702f_test_accuracy': 0.945555567741394, '32e9702f_test_diff_accuracy': 0.0, '332efdb3_test_accuracy': 0.9277777671813965, '332efdb3_test_diff_accuracy': 0.0, '3391f8c0_test_accuracy': 0.9888888597488403, '3391f8c0_test_diff_accuracy': 0.5, '33b52de3_test_accuracy': 0.8577777743339539, '33b52de3_test_diff_accuracy': 0.0, '3490cc26_test_accuracy': 0.8644444346427917, '3490cc26_test_diff_accuracy': 0.0, '34b99a2b_test_accuracy': 0.9855555295944214, '34b99a2b_test_diff_accuracy': 0.5806451612903226}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[3, 3, 3,  ..., 3, 3, 3],\n",
            "          [3, 3, 1,  ..., 3, 3, 3],\n",
            "          [3, 3, 1,  ..., 3, 3, 3],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[3, 3, 3,  ..., 3, 3, 3],\n",
            "          [3, 3, 1,  ..., 3, 3, 3],\n",
            "          [3, 3, 1,  ..., 3, 3, 3],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('351d6448', '351d6448', '358ba94e', '358ba94e', '358ba94e', '358ba94e', '37d3e8b2', '37d3e8b2', '37d3e8b2', '3979b1a8', '3979b1a8', '3a301edc', '3a301edc', '3a301edc', '3a301edc', '3a301edc', '3b4c2228', '3b4c2228', '3b4c2228', '3b4c2228', '3b4c2228', '3d31c5b3', '3d31c5b3', '3d31c5b3', '3d31c5b3', '3d31c5b3', '3d31c5b3', '3ed85e70', '3ed85e70', '3ed85e70', '3ee1011a', '3ee1011a')], batch_idx: 9\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('351d6448', '351d6448', '358ba94e', '358ba94e', '358ba94e', '358ba94e', '37d3e8b2', '37d3e8b2', '37d3e8b2', '3979b1a8', '3979b1a8', '3a301edc', '3a301edc', '3a301edc', '3a301edc', '3a301edc', '3b4c2228', '3b4c2228', '3b4c2228', '3b4c2228', '3b4c2228', '3d31c5b3', '3d31c5b3', '3d31c5b3', '3d31c5b3', '3d31c5b3', '3d31c5b3', '3ed85e70', '3ed85e70', '3ed85e70', '3ee1011a', '3ee1011a')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9411764705882353\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8305084745762712\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8556701030927835\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.847457627118644\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9259259259259259\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8285714285714286\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9259259259259259\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9285714285714286\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.85\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8461538461538461\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9230769230769231\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6052631578947368\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5777777777777777\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5909090909090909\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.64\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.625\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6086956521739131\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.2647058823529412\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.21739130434782608\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.34507545828819275, Avg accuracy: 0.9226041734218597, Avg diff accuracy: 0.43227440684555307\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.34507545828819275, avg_accuracy=0.9226041734218597, diff_accuracy=0.43227440684555307\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.34507545828819275, 'task_ids': ('351d6448', '351d6448', '358ba94e', '358ba94e', '358ba94e', '358ba94e', '37d3e8b2', '37d3e8b2', '37d3e8b2', '3979b1a8', '3979b1a8', '3a301edc', '3a301edc', '3a301edc', '3a301edc', '3a301edc', '3b4c2228', '3b4c2228', '3b4c2228', '3b4c2228', '3b4c2228', '3d31c5b3', '3d31c5b3', '3d31c5b3', '3d31c5b3', '3d31c5b3', '3d31c5b3', '3ed85e70', '3ed85e70', '3ed85e70', '3ee1011a', '3ee1011a'), 'test_accuracy': 0.9226041734218597, 'test_diff_accuracy': 0.43227440684555307, '351d6448_test_accuracy': 0.9888888597488403, '351d6448_test_diff_accuracy': 0.8305084745762712, '358ba94e_test_accuracy': 0.9733333587646484, '358ba94e_test_diff_accuracy': 0.8285714285714286, '37d3e8b2_test_accuracy': 0.8755555748939514, '37d3e8b2_test_diff_accuracy': 0.0, '3979b1a8_test_accuracy': 0.8888888955116272, '3979b1a8_test_diff_accuracy': 0.0, '3a301edc_test_accuracy': 0.9722222089767456, '3a301edc_test_diff_accuracy': 0.0, '3b4c2228_test_accuracy': 0.9988889098167419, '3b4c2228_test_diff_accuracy': 0.9230769230769231, '3d31c5b3_test_accuracy': 0.9800000190734863, '3d31c5b3_test_diff_accuracy': 0.6086956521739131, '3ed85e70_test_accuracy': 0.7022222280502319, '3ed85e70_test_diff_accuracy': 0.0, '3ee1011a_test_accuracy': 0.9599999785423279, '3ee1011a_test_diff_accuracy': 0.21739130434782608}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.34507545828819275, 'task_ids': ('351d6448', '351d6448', '358ba94e', '358ba94e', '358ba94e', '358ba94e', '37d3e8b2', '37d3e8b2', '37d3e8b2', '3979b1a8', '3979b1a8', '3a301edc', '3a301edc', '3a301edc', '3a301edc', '3a301edc', '3b4c2228', '3b4c2228', '3b4c2228', '3b4c2228', '3b4c2228', '3d31c5b3', '3d31c5b3', '3d31c5b3', '3d31c5b3', '3d31c5b3', '3d31c5b3', '3ed85e70', '3ed85e70', '3ed85e70', '3ee1011a', '3ee1011a'), 'test_accuracy': 0.9226041734218597, 'test_diff_accuracy': 0.43227440684555307, '351d6448_test_accuracy': 0.9888888597488403, '351d6448_test_diff_accuracy': 0.8305084745762712, '358ba94e_test_accuracy': 0.9733333587646484, '358ba94e_test_diff_accuracy': 0.8285714285714286, '37d3e8b2_test_accuracy': 0.8755555748939514, '37d3e8b2_test_diff_accuracy': 0.0, '3979b1a8_test_accuracy': 0.8888888955116272, '3979b1a8_test_diff_accuracy': 0.0, '3a301edc_test_accuracy': 0.9722222089767456, '3a301edc_test_diff_accuracy': 0.0, '3b4c2228_test_accuracy': 0.9988889098167419, '3b4c2228_test_diff_accuracy': 0.9230769230769231, '3d31c5b3_test_accuracy': 0.9800000190734863, '3d31c5b3_test_diff_accuracy': 0.6086956521739131, '3ed85e70_test_accuracy': 0.7022222280502319, '3ed85e70_test_diff_accuracy': 0.0, '3ee1011a_test_accuracy': 0.9599999785423279, '3ee1011a_test_diff_accuracy': 0.21739130434782608}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('3ee1011a', '3f23242b', '3f23242b', '40f6cd08', '40f6cd08', '40f6cd08', '414297c0', '414297c0', '414297c0', '423a55dc', '423a55dc', '423a55dc', '423a55dc', '423a55dc', '42918530', '42918530', '42918530', '42918530', '42a15761', '42a15761', '42a15761', '4364c1c4', '4364c1c4', '4364c1c4', '456873bc', '456873bc', '456873bc', '45737921', '45737921', '45737921', '45bbe264', '45bbe264')], batch_idx: 10\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('3ee1011a', '3f23242b', '3f23242b', '40f6cd08', '40f6cd08', '40f6cd08', '414297c0', '414297c0', '414297c0', '423a55dc', '423a55dc', '423a55dc', '423a55dc', '423a55dc', '42918530', '42918530', '42918530', '42918530', '42a15761', '42a15761', '42a15761', '4364c1c4', '4364c1c4', '4364c1c4', '456873bc', '456873bc', '456873bc', '45737921', '45737921', '45737921', '45bbe264', '45bbe264')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.136986301369863\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5142857142857142\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.35344827586206895\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5409836065573771\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5882352941176471\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.52\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7976190476190477\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7567567567567568\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7567567567567568\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.35555434226989746, Avg accuracy: 0.8881597276777029, Avg diff accuracy: 0.24890849229141349\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.35555434226989746, avg_accuracy=0.8881597276777029, diff_accuracy=0.24890849229141349\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.35555434226989746, 'task_ids': ('3ee1011a', '3f23242b', '3f23242b', '40f6cd08', '40f6cd08', '40f6cd08', '414297c0', '414297c0', '414297c0', '423a55dc', '423a55dc', '423a55dc', '423a55dc', '423a55dc', '42918530', '42918530', '42918530', '42918530', '42a15761', '42a15761', '42a15761', '4364c1c4', '4364c1c4', '4364c1c4', '456873bc', '456873bc', '456873bc', '45737921', '45737921', '45737921', '45bbe264', '45bbe264'), 'test_accuracy': 0.8881597276777029, 'test_diff_accuracy': 0.24890849229141349, '3ee1011a_test_accuracy': 0.9288889169692993, '3ee1011a_test_diff_accuracy': 0.136986301369863, '3f23242b_test_accuracy': 0.9744444489479065, '3f23242b_test_diff_accuracy': 0.0, '40f6cd08_test_accuracy': 0.6166666746139526, '40f6cd08_test_diff_accuracy': 0.0, '414297c0_test_accuracy': 0.9200000166893005, '414297c0_test_diff_accuracy': 0.5409836065573771, '423a55dc_test_accuracy': 0.9944444298744202, '423a55dc_test_diff_accuracy': 0.5, '42918530_test_accuracy': 0.8077777624130249, '42918530_test_diff_accuracy': 0.0, '42a15761_test_accuracy': 0.8911111354827881, '42a15761_test_diff_accuracy': 0.5, '4364c1c4_test_accuracy': 0.8266666531562805, '4364c1c4_test_diff_accuracy': 0.0, '456873bc_test_accuracy': 0.9722222089767456, '456873bc_test_diff_accuracy': 0.7567567567567568, '45737921_test_accuracy': 0.9599999785423279, '45737921_test_diff_accuracy': 0.0, '45bbe264_test_accuracy': 0.9422222375869751, '45bbe264_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.35555434226989746, 'task_ids': ('3ee1011a', '3f23242b', '3f23242b', '40f6cd08', '40f6cd08', '40f6cd08', '414297c0', '414297c0', '414297c0', '423a55dc', '423a55dc', '423a55dc', '423a55dc', '423a55dc', '42918530', '42918530', '42918530', '42918530', '42a15761', '42a15761', '42a15761', '4364c1c4', '4364c1c4', '4364c1c4', '456873bc', '456873bc', '456873bc', '45737921', '45737921', '45737921', '45bbe264', '45bbe264'), 'test_accuracy': 0.8881597276777029, 'test_diff_accuracy': 0.24890849229141349, '3ee1011a_test_accuracy': 0.9288889169692993, '3ee1011a_test_diff_accuracy': 0.136986301369863, '3f23242b_test_accuracy': 0.9744444489479065, '3f23242b_test_diff_accuracy': 0.0, '40f6cd08_test_accuracy': 0.6166666746139526, '40f6cd08_test_diff_accuracy': 0.0, '414297c0_test_accuracy': 0.9200000166893005, '414297c0_test_diff_accuracy': 0.5409836065573771, '423a55dc_test_accuracy': 0.9944444298744202, '423a55dc_test_diff_accuracy': 0.5, '42918530_test_accuracy': 0.8077777624130249, '42918530_test_diff_accuracy': 0.0, '42a15761_test_accuracy': 0.8911111354827881, '42a15761_test_diff_accuracy': 0.5, '4364c1c4_test_accuracy': 0.8266666531562805, '4364c1c4_test_diff_accuracy': 0.0, '456873bc_test_accuracy': 0.9722222089767456, '456873bc_test_diff_accuracy': 0.7567567567567568, '45737921_test_accuracy': 0.9599999785423279, '45737921_test_diff_accuracy': 0.0, '45bbe264_test_accuracy': 0.9422222375869751, '45bbe264_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('45bbe264', '477d2879', '477d2879', '477d2879', '47996f11', '47996f11', '47996f11', '47996f11', '48131b3c', '48131b3c', '48131b3c', '4852f2fa', '4852f2fa', '4852f2fa', '4852f2fa', '4852f2fa', '48f8583b', '48f8583b', '48f8583b', '48f8583b', '48f8583b', '48f8583b', '4aab4007', '4aab4007', '4aab4007', '4acc7107', '4acc7107', '4acc7107', '4acc7107', '4b6b68e5', '4b6b68e5', '4b6b68e5')], batch_idx: 11\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('45bbe264', '477d2879', '477d2879', '477d2879', '47996f11', '47996f11', '47996f11', '47996f11', '48131b3c', '48131b3c', '48131b3c', '4852f2fa', '4852f2fa', '4852f2fa', '4852f2fa', '4852f2fa', '48f8583b', '48f8583b', '48f8583b', '48f8583b', '48f8583b', '48f8583b', '4aab4007', '4aab4007', '4aab4007', '4acc7107', '4acc7107', '4acc7107', '4acc7107', '4b6b68e5', '4b6b68e5', '4b6b68e5')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.02564102564102564\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.08888888888888889\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.08421052631578947\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.22608695652173913\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.043478260869565216\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.2\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.09523809523809523\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.3157894736842105\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5454545454545454\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.35294117647058826\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.30434782608695654\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.2857142857142857\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4444444444444444\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.3333333333333333\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.25\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.25\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4827586206896552\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.44680851063829785\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.022727272727272728\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.09090909090909091\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.8300538063049316, Avg accuracy: 0.7661111173219979, Avg diff accuracy: 0.19964913542586826\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.8300538063049316, avg_accuracy=0.7661111173219979, diff_accuracy=0.19964913542586826\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.8300538063049316, 'task_ids': ('45bbe264', '477d2879', '477d2879', '477d2879', '47996f11', '47996f11', '47996f11', '47996f11', '48131b3c', '48131b3c', '48131b3c', '4852f2fa', '4852f2fa', '4852f2fa', '4852f2fa', '4852f2fa', '48f8583b', '48f8583b', '48f8583b', '48f8583b', '48f8583b', '48f8583b', '4aab4007', '4aab4007', '4aab4007', '4acc7107', '4acc7107', '4acc7107', '4acc7107', '4b6b68e5', '4b6b68e5', '4b6b68e5'), 'test_accuracy': 0.7661111173219979, 'test_diff_accuracy': 0.19964913542586826, '45bbe264_test_accuracy': 0.9233333468437195, '45bbe264_test_diff_accuracy': 0.0, '477d2879_test_accuracy': 0.8122222423553467, '477d2879_test_diff_accuracy': 0.0, '47996f11_test_accuracy': 0.20777778327465057, '47996f11_test_diff_accuracy': 0.22608695652173913, '48131b3c_test_accuracy': 0.9555555582046509, '48131b3c_test_diff_accuracy': 0.09523809523809523, '4852f2fa_test_accuracy': 0.9777777791023254, '4852f2fa_test_diff_accuracy': 0.2857142857142857, '48f8583b_test_accuracy': 0.9700000286102295, '48f8583b_test_diff_accuracy': 0.25, '4aab4007_test_accuracy': 0.12888889014720917, '4aab4007_test_diff_accuracy': 0.0, '4acc7107_test_accuracy': 0.9711111187934875, '4acc7107_test_diff_accuracy': 0.44680851063829785, '4b6b68e5_test_accuracy': 0.8700000047683716, '4b6b68e5_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.8300538063049316, 'task_ids': ('45bbe264', '477d2879', '477d2879', '477d2879', '47996f11', '47996f11', '47996f11', '47996f11', '48131b3c', '48131b3c', '48131b3c', '4852f2fa', '4852f2fa', '4852f2fa', '4852f2fa', '4852f2fa', '48f8583b', '48f8583b', '48f8583b', '48f8583b', '48f8583b', '48f8583b', '4aab4007', '4aab4007', '4aab4007', '4acc7107', '4acc7107', '4acc7107', '4acc7107', '4b6b68e5', '4b6b68e5', '4b6b68e5'), 'test_accuracy': 0.7661111173219979, 'test_diff_accuracy': 0.19964913542586826, '45bbe264_test_accuracy': 0.9233333468437195, '45bbe264_test_diff_accuracy': 0.0, '477d2879_test_accuracy': 0.8122222423553467, '477d2879_test_diff_accuracy': 0.0, '47996f11_test_accuracy': 0.20777778327465057, '47996f11_test_diff_accuracy': 0.22608695652173913, '48131b3c_test_accuracy': 0.9555555582046509, '48131b3c_test_diff_accuracy': 0.09523809523809523, '4852f2fa_test_accuracy': 0.9777777791023254, '4852f2fa_test_diff_accuracy': 0.2857142857142857, '48f8583b_test_accuracy': 0.9700000286102295, '48f8583b_test_diff_accuracy': 0.25, '4aab4007_test_accuracy': 0.12888889014720917, '4aab4007_test_diff_accuracy': 0.0, '4acc7107_test_accuracy': 0.9711111187934875, '4acc7107_test_diff_accuracy': 0.44680851063829785, '4b6b68e5_test_accuracy': 0.8700000047683716, '4b6b68e5_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('4c177718', '4c177718', '4c177718', '4c177718', '4cd1b7b2', '4cd1b7b2', '4cd1b7b2', '4e45f183', '4e45f183', '4e45f183', '4e469f39', '4e469f39', '4e469f39', '4f537728', '4f537728', '4ff4c9da', '4ff4c9da', '4ff4c9da', '505fff84', '505fff84', '505fff84', '505fff84', '505fff84', '506d28a5', '506d28a5', '506d28a5', '506d28a5', '50a16a69', '50a16a69', '50a16a69', '50aad11f', '50aad11f')], batch_idx: 12\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('4c177718', '4c177718', '4c177718', '4c177718', '4cd1b7b2', '4cd1b7b2', '4cd1b7b2', '4e45f183', '4e45f183', '4e45f183', '4e469f39', '4e469f39', '4e469f39', '4f537728', '4f537728', '4ff4c9da', '4ff4c9da', '4ff4c9da', '505fff84', '505fff84', '505fff84', '505fff84', '505fff84', '506d28a5', '506d28a5', '506d28a5', '506d28a5', '50a16a69', '50a16a69', '50a16a69', '50aad11f', '50aad11f')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7547169811320755\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7391304347826086\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7142857142857143\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7804878048780488\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.041666666666666664\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8651685393258427\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8823529411764706\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9259259259259259\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8837209302325582\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8979591836734694\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.39285714285714285\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5172413793103449\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.12\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4666666666666667\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.27849647402763367, Avg accuracy: 0.9005208313465118, Avg diff accuracy: 0.32756813471604795\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.27849647402763367, avg_accuracy=0.9005208313465118, diff_accuracy=0.32756813471604795\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.27849647402763367, 'task_ids': ('4c177718', '4c177718', '4c177718', '4c177718', '4cd1b7b2', '4cd1b7b2', '4cd1b7b2', '4e45f183', '4e45f183', '4e45f183', '4e469f39', '4e469f39', '4e469f39', '4f537728', '4f537728', '4ff4c9da', '4ff4c9da', '4ff4c9da', '505fff84', '505fff84', '505fff84', '505fff84', '505fff84', '506d28a5', '506d28a5', '506d28a5', '506d28a5', '50a16a69', '50a16a69', '50a16a69', '50aad11f', '50aad11f'), 'test_accuracy': 0.9005208313465118, 'test_diff_accuracy': 0.32756813471604795, '4c177718_test_accuracy': 0.9900000095367432, '4c177718_test_diff_accuracy': 0.7804878048780488, '4cd1b7b2_test_accuracy': 0.9822221994400024, '4cd1b7b2_test_diff_accuracy': 0.0, '4e45f183_test_accuracy': 0.7522222399711609, '4e45f183_test_diff_accuracy': 0.041666666666666664, '4e469f39_test_accuracy': 0.9511111378669739, '4e469f39_test_diff_accuracy': 0.0, '4f537728_test_accuracy': 0.8122222423553467, '4f537728_test_diff_accuracy': 0.0, '4ff4c9da_test_accuracy': 0.7333333492279053, '4ff4c9da_test_diff_accuracy': 0.0, '505fff84_test_accuracy': 0.9900000095367432, '505fff84_test_diff_accuracy': 0.8979591836734694, '506d28a5_test_accuracy': 0.9844444394111633, '506d28a5_test_diff_accuracy': 0.5172413793103449, '50a16a69_test_accuracy': 0.9100000262260437, '50a16a69_test_diff_accuracy': 0.0, '50aad11f_test_accuracy': 0.9822221994400024, '50aad11f_test_diff_accuracy': 0.5}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.27849647402763367, 'task_ids': ('4c177718', '4c177718', '4c177718', '4c177718', '4cd1b7b2', '4cd1b7b2', '4cd1b7b2', '4e45f183', '4e45f183', '4e45f183', '4e469f39', '4e469f39', '4e469f39', '4f537728', '4f537728', '4ff4c9da', '4ff4c9da', '4ff4c9da', '505fff84', '505fff84', '505fff84', '505fff84', '505fff84', '506d28a5', '506d28a5', '506d28a5', '506d28a5', '50a16a69', '50a16a69', '50a16a69', '50aad11f', '50aad11f'), 'test_accuracy': 0.9005208313465118, 'test_diff_accuracy': 0.32756813471604795, '4c177718_test_accuracy': 0.9900000095367432, '4c177718_test_diff_accuracy': 0.7804878048780488, '4cd1b7b2_test_accuracy': 0.9822221994400024, '4cd1b7b2_test_diff_accuracy': 0.0, '4e45f183_test_accuracy': 0.7522222399711609, '4e45f183_test_diff_accuracy': 0.041666666666666664, '4e469f39_test_accuracy': 0.9511111378669739, '4e469f39_test_diff_accuracy': 0.0, '4f537728_test_accuracy': 0.8122222423553467, '4f537728_test_diff_accuracy': 0.0, '4ff4c9da_test_accuracy': 0.7333333492279053, '4ff4c9da_test_diff_accuracy': 0.0, '505fff84_test_accuracy': 0.9900000095367432, '505fff84_test_diff_accuracy': 0.8979591836734694, '506d28a5_test_accuracy': 0.9844444394111633, '506d28a5_test_diff_accuracy': 0.5172413793103449, '50a16a69_test_accuracy': 0.9100000262260437, '50a16a69_test_diff_accuracy': 0.0, '50aad11f_test_accuracy': 0.9822221994400024, '50aad11f_test_diff_accuracy': 0.5}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('50aad11f', '50f325b5', '50f325b5', '50f325b5', '50f325b5', '516b51b7', '516b51b7', '516b51b7', '5207a7b5', '5207a7b5', '5207a7b5', '5289ad53', '5289ad53', '5289ad53', '5289ad53', '52fd389e', '52fd389e', '52fd389e', '54db823b', '54db823b', '54db823b', '54db823b', '55059096', '55059096', '55059096', '551d5bf1', '551d5bf1', '55783887', '55783887', '55783887', '55783887', '55783887')], batch_idx: 13\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('50aad11f', '50f325b5', '50f325b5', '50f325b5', '50f325b5', '516b51b7', '516b51b7', '516b51b7', '5207a7b5', '5207a7b5', '5207a7b5', '5289ad53', '5289ad53', '5289ad53', '5289ad53', '52fd389e', '52fd389e', '52fd389e', '54db823b', '54db823b', '54db823b', '54db823b', '55059096', '55059096', '55059096', '551d5bf1', '551d5bf1', '55783887', '55783887', '55783887', '55783887', '55783887')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.43478260869565216\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9473684210526315\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.96\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9642857142857143\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6528497409326425\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.4569234848022461, Avg accuracy: 0.8798958323895931, Avg diff accuracy: 0.2643527026552075\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.4569234848022461, avg_accuracy=0.8798958323895931, diff_accuracy=0.2643527026552075\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.4569234848022461, 'task_ids': ('50aad11f', '50f325b5', '50f325b5', '50f325b5', '50f325b5', '516b51b7', '516b51b7', '516b51b7', '5207a7b5', '5207a7b5', '5207a7b5', '5289ad53', '5289ad53', '5289ad53', '5289ad53', '52fd389e', '52fd389e', '52fd389e', '54db823b', '54db823b', '54db823b', '54db823b', '55059096', '55059096', '55059096', '551d5bf1', '551d5bf1', '55783887', '55783887', '55783887', '55783887', '55783887'), 'test_accuracy': 0.8798958323895931, 'test_diff_accuracy': 0.2643527026552075, '50aad11f_test_accuracy': 0.9711111187934875, '50aad11f_test_diff_accuracy': 0.43478260869565216, '50f325b5_test_accuracy': 0.757777750492096, '50f325b5_test_diff_accuracy': 0.0, '516b51b7_test_accuracy': 0.8899999856948853, '516b51b7_test_diff_accuracy': 0.0, '5207a7b5_test_accuracy': 0.9300000071525574, '5207a7b5_test_diff_accuracy': 0.0, '5289ad53_test_accuracy': 0.9233333468437195, '5289ad53_test_diff_accuracy': 0.6528497409326425, '52fd389e_test_accuracy': 0.6399999856948853, '52fd389e_test_diff_accuracy': 0.0, '54db823b_test_accuracy': 0.9166666865348816, '54db823b_test_diff_accuracy': 1.0, '55059096_test_accuracy': 0.9755555391311646, '55059096_test_diff_accuracy': 0.0, '551d5bf1_test_accuracy': 0.7733333110809326, '551d5bf1_test_diff_accuracy': 0.0, '55783887_test_accuracy': 0.7333333492279053, '55783887_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.4569234848022461, 'task_ids': ('50aad11f', '50f325b5', '50f325b5', '50f325b5', '50f325b5', '516b51b7', '516b51b7', '516b51b7', '5207a7b5', '5207a7b5', '5207a7b5', '5289ad53', '5289ad53', '5289ad53', '5289ad53', '52fd389e', '52fd389e', '52fd389e', '54db823b', '54db823b', '54db823b', '54db823b', '55059096', '55059096', '55059096', '551d5bf1', '551d5bf1', '55783887', '55783887', '55783887', '55783887', '55783887'), 'test_accuracy': 0.8798958323895931, 'test_diff_accuracy': 0.2643527026552075, '50aad11f_test_accuracy': 0.9711111187934875, '50aad11f_test_diff_accuracy': 0.43478260869565216, '50f325b5_test_accuracy': 0.757777750492096, '50f325b5_test_diff_accuracy': 0.0, '516b51b7_test_accuracy': 0.8899999856948853, '516b51b7_test_diff_accuracy': 0.0, '5207a7b5_test_accuracy': 0.9300000071525574, '5207a7b5_test_diff_accuracy': 0.0, '5289ad53_test_accuracy': 0.9233333468437195, '5289ad53_test_diff_accuracy': 0.6528497409326425, '52fd389e_test_accuracy': 0.6399999856948853, '52fd389e_test_diff_accuracy': 0.0, '54db823b_test_accuracy': 0.9166666865348816, '54db823b_test_diff_accuracy': 1.0, '55059096_test_accuracy': 0.9755555391311646, '55059096_test_diff_accuracy': 0.0, '551d5bf1_test_accuracy': 0.7733333110809326, '551d5bf1_test_diff_accuracy': 0.0, '55783887_test_accuracy': 0.7333333492279053, '55783887_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('575b1a71', '575b1a71', '575b1a71', '5783df64', '5783df64', '5783df64', '5833af48', '5833af48', '5833af48', '58743b76', '58743b76', '58e15b12', '58e15b12', '58e15b12', '59341089', '59341089', '59341089', '59341089', '5a5a2103', '5a5a2103', '5af49b42', '5af49b42', '5af49b42', '5b526a93', '5b526a93', '5b692c0f', '5b692c0f', '5b6cbef5', '5b6cbef5', '5b6cbef5', '5b6cbef5', '5b6cbef5')], batch_idx: 14\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('575b1a71', '575b1a71', '575b1a71', '5783df64', '5783df64', '5783df64', '5833af48', '5833af48', '5833af48', '58743b76', '58743b76', '58e15b12', '58e15b12', '58e15b12', '59341089', '59341089', '59341089', '59341089', '5a5a2103', '5a5a2103', '5af49b42', '5af49b42', '5af49b42', '5b526a93', '5b526a93', '5b692c0f', '5b692c0f', '5b6cbef5', '5b6cbef5', '5b6cbef5', '5b6cbef5', '5b6cbef5')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4375\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.47058823529411764\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4666666666666667\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.64\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5168539325842697\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6461538461538462\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.045454545454545456\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.045454545454545456\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.22727272727272727\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.25\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.07547169811320754\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.16666666666666666\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0625\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.1\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.05\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.35447943210601807, Avg accuracy: 0.9240625035017729, Avg diff accuracy: 0.13126821448939352\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.35447943210601807, avg_accuracy=0.9240625035017729, diff_accuracy=0.13126821448939352\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.35447943210601807, 'task_ids': ('575b1a71', '575b1a71', '575b1a71', '5783df64', '5783df64', '5783df64', '5833af48', '5833af48', '5833af48', '58743b76', '58743b76', '58e15b12', '58e15b12', '58e15b12', '59341089', '59341089', '59341089', '59341089', '5a5a2103', '5a5a2103', '5af49b42', '5af49b42', '5af49b42', '5b526a93', '5b526a93', '5b692c0f', '5b692c0f', '5b6cbef5', '5b6cbef5', '5b6cbef5', '5b6cbef5', '5b6cbef5'), 'test_accuracy': 0.9240625035017729, 'test_diff_accuracy': 0.13126821448939352, '575b1a71_test_accuracy': 0.8888888955116272, '575b1a71_test_diff_accuracy': 0.0, '5783df64_test_accuracy': 0.9900000095367432, '5783df64_test_diff_accuracy': 0.4666666666666667, '5833af48_test_accuracy': 0.9399999976158142, '5833af48_test_diff_accuracy': 0.6461538461538462, '58743b76_test_accuracy': 0.945555567741394, '58743b76_test_diff_accuracy': 0.0, '58e15b12_test_accuracy': 0.9200000166893005, '58e15b12_test_diff_accuracy': 0.0, '59341089_test_accuracy': 0.9599999785423279, '59341089_test_diff_accuracy': 0.0, '5a5a2103_test_accuracy': 0.7766666412353516, '5a5a2103_test_diff_accuracy': 0.045454545454545456, '5af49b42_test_accuracy': 0.9766666889190674, '5af49b42_test_diff_accuracy': 0.0, '5b526a93_test_accuracy': 0.8933333158493042, '5b526a93_test_diff_accuracy': 0.0, '5b692c0f_test_accuracy': 0.9277777671813965, '5b692c0f_test_diff_accuracy': 0.25, '5b6cbef5_test_accuracy': 0.8888888955116272, '5b6cbef5_test_diff_accuracy': 0.05}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.35447943210601807, 'task_ids': ('575b1a71', '575b1a71', '575b1a71', '5783df64', '5783df64', '5783df64', '5833af48', '5833af48', '5833af48', '58743b76', '58743b76', '58e15b12', '58e15b12', '58e15b12', '59341089', '59341089', '59341089', '59341089', '5a5a2103', '5a5a2103', '5af49b42', '5af49b42', '5af49b42', '5b526a93', '5b526a93', '5b692c0f', '5b692c0f', '5b6cbef5', '5b6cbef5', '5b6cbef5', '5b6cbef5', '5b6cbef5'), 'test_accuracy': 0.9240625035017729, 'test_diff_accuracy': 0.13126821448939352, '575b1a71_test_accuracy': 0.8888888955116272, '575b1a71_test_diff_accuracy': 0.0, '5783df64_test_accuracy': 0.9900000095367432, '5783df64_test_diff_accuracy': 0.4666666666666667, '5833af48_test_accuracy': 0.9399999976158142, '5833af48_test_diff_accuracy': 0.6461538461538462, '58743b76_test_accuracy': 0.945555567741394, '58743b76_test_diff_accuracy': 0.0, '58e15b12_test_accuracy': 0.9200000166893005, '58e15b12_test_diff_accuracy': 0.0, '59341089_test_accuracy': 0.9599999785423279, '59341089_test_diff_accuracy': 0.0, '5a5a2103_test_accuracy': 0.7766666412353516, '5a5a2103_test_diff_accuracy': 0.045454545454545456, '5af49b42_test_accuracy': 0.9766666889190674, '5af49b42_test_diff_accuracy': 0.0, '5b526a93_test_accuracy': 0.8933333158493042, '5b526a93_test_diff_accuracy': 0.0, '5b692c0f_test_accuracy': 0.9277777671813965, '5b692c0f_test_diff_accuracy': 0.25, '5b6cbef5_test_accuracy': 0.8888888955116272, '5b6cbef5_test_diff_accuracy': 0.05}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('5d2a5c43', '5d2a5c43', '5d2a5c43', '5d2a5c43', '5d2a5c43', '5ffb2104', '5ffb2104', '5ffb2104', '604001fa', '604001fa', '604001fa', '604001fa', '60a26a3e', '60a26a3e', '60a26a3e', '60c09cac', '60c09cac', '626c0bcc', '626c0bcc', '626c0bcc', '62ab2642', '62ab2642', '62ab2642', '62b74c02', '62b74c02', '62b74c02', '639f5a19', '639f5a19', '642248e4', '642248e4', '642248e4', '642d658d')], batch_idx: 15\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('5d2a5c43', '5d2a5c43', '5d2a5c43', '5d2a5c43', '5d2a5c43', '5ffb2104', '5ffb2104', '5ffb2104', '604001fa', '604001fa', '604001fa', '604001fa', '60a26a3e', '60a26a3e', '60a26a3e', '60c09cac', '60c09cac', '626c0bcc', '626c0bcc', '626c0bcc', '62ab2642', '62ab2642', '62ab2642', '62b74c02', '62b74c02', '62b74c02', '639f5a19', '639f5a19', '642248e4', '642248e4', '642248e4', '642d658d')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.47058823529411764\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4444444444444444\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.47368421052631576\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.47058823529411764\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.25\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.2727272727272727\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.2857142857142857\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.2857142857142857\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.05555555555555555\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7910750507099391\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.18470335006713867, Avg accuracy: 0.9562500026077032, Avg diff accuracy: 0.18125286174938546\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.18470335006713867, avg_accuracy=0.9562500026077032, diff_accuracy=0.18125286174938546\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.18470335006713867, 'task_ids': ('5d2a5c43', '5d2a5c43', '5d2a5c43', '5d2a5c43', '5d2a5c43', '5ffb2104', '5ffb2104', '5ffb2104', '604001fa', '604001fa', '604001fa', '604001fa', '60a26a3e', '60a26a3e', '60a26a3e', '60c09cac', '60c09cac', '626c0bcc', '626c0bcc', '626c0bcc', '62ab2642', '62ab2642', '62ab2642', '62b74c02', '62b74c02', '62b74c02', '639f5a19', '639f5a19', '642248e4', '642248e4', '642248e4', '642d658d'), 'test_accuracy': 0.9562500026077032, 'test_diff_accuracy': 0.18125286174938546, '5d2a5c43_test_accuracy': 0.9777777791023254, '5d2a5c43_test_diff_accuracy': 0.47368421052631576, '5ffb2104_test_accuracy': 0.9900000095367432, '5ffb2104_test_diff_accuracy': 0.47058823529411764, '604001fa_test_accuracy': 0.9833333492279053, '604001fa_test_diff_accuracy': 0.2857142857142857, '60a26a3e_test_accuracy': 0.9644444584846497, '60a26a3e_test_diff_accuracy': 0.0, '60c09cac_test_accuracy': 0.9777777791023254, '60c09cac_test_diff_accuracy': 0.05555555555555555, '626c0bcc_test_accuracy': 0.9855555295944214, '626c0bcc_test_diff_accuracy': 0.0, '62ab2642_test_accuracy': 0.9233333468437195, '62ab2642_test_diff_accuracy': 0.0, '62b74c02_test_accuracy': 0.9544444680213928, '62b74c02_test_diff_accuracy': 0.0, '639f5a19_test_accuracy': 0.7599999904632568, '639f5a19_test_diff_accuracy': 0.0, '642248e4_test_accuracy': 0.9599999785423279, '642248e4_test_diff_accuracy': 0.0, '642d658d_test_accuracy': 0.8855555653572083, '642d658d_test_diff_accuracy': 0.7910750507099391}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.18470335006713867, 'task_ids': ('5d2a5c43', '5d2a5c43', '5d2a5c43', '5d2a5c43', '5d2a5c43', '5ffb2104', '5ffb2104', '5ffb2104', '604001fa', '604001fa', '604001fa', '604001fa', '60a26a3e', '60a26a3e', '60a26a3e', '60c09cac', '60c09cac', '626c0bcc', '626c0bcc', '626c0bcc', '62ab2642', '62ab2642', '62ab2642', '62b74c02', '62b74c02', '62b74c02', '639f5a19', '639f5a19', '642248e4', '642248e4', '642248e4', '642d658d'), 'test_accuracy': 0.9562500026077032, 'test_diff_accuracy': 0.18125286174938546, '5d2a5c43_test_accuracy': 0.9777777791023254, '5d2a5c43_test_diff_accuracy': 0.47368421052631576, '5ffb2104_test_accuracy': 0.9900000095367432, '5ffb2104_test_diff_accuracy': 0.47058823529411764, '604001fa_test_accuracy': 0.9833333492279053, '604001fa_test_diff_accuracy': 0.2857142857142857, '60a26a3e_test_accuracy': 0.9644444584846497, '60a26a3e_test_diff_accuracy': 0.0, '60c09cac_test_accuracy': 0.9777777791023254, '60c09cac_test_diff_accuracy': 0.05555555555555555, '626c0bcc_test_accuracy': 0.9855555295944214, '626c0bcc_test_diff_accuracy': 0.0, '62ab2642_test_accuracy': 0.9233333468437195, '62ab2642_test_diff_accuracy': 0.0, '62b74c02_test_accuracy': 0.9544444680213928, '62b74c02_test_diff_accuracy': 0.0, '639f5a19_test_accuracy': 0.7599999904632568, '639f5a19_test_diff_accuracy': 0.0, '642248e4_test_accuracy': 0.9599999785423279, '642248e4_test_diff_accuracy': 0.0, '642d658d_test_accuracy': 0.8855555653572083, '642d658d_test_diff_accuracy': 0.7910750507099391}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('642d658d', '642d658d', '64a7c07e', '64a7c07e', '64a7c07e', '66e6c45b', '66e6c45b', '66f2d22f', '66f2d22f', '66f2d22f', '66f2d22f', '67636eac', '67636eac', '67636eac', '67b4a34d', '67b4a34d', '67b4a34d', '67c52801', '67c52801', '67c52801', '67c52801', '68b67ca3', '68b67ca3', '68b67ca3', '692cd3b6', '692cd3b6', '692cd3b6', '695367ec', '695367ec', '695367ec', '696d4842', '696d4842')], batch_idx: 16\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('642d658d', '642d658d', '64a7c07e', '64a7c07e', '64a7c07e', '66e6c45b', '66e6c45b', '66f2d22f', '66f2d22f', '66f2d22f', '66f2d22f', '67636eac', '67636eac', '67636eac', '67b4a34d', '67b4a34d', '67b4a34d', '67c52801', '67c52801', '67c52801', '67c52801', '68b67ca3', '68b67ca3', '68b67ca3', '692cd3b6', '692cd3b6', '692cd3b6', '695367ec', '695367ec', '695367ec', '696d4842', '696d4842')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.997093023255814\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9970238095238095\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6428571428571429\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8125\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8275862068965517\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7419354838709677\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9317269076305221\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9475806451612904\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8622047244094488\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.05\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.008130081300813009\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.10843373493975904\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.23099343478679657, Avg accuracy: 0.9687847271561623, Avg diff accuracy: 0.4789709924951912\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.23099343478679657, avg_accuracy=0.9687847271561623, diff_accuracy=0.4789709924951912\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.23099343478679657, 'task_ids': ('642d658d', '642d658d', '64a7c07e', '64a7c07e', '64a7c07e', '66e6c45b', '66e6c45b', '66f2d22f', '66f2d22f', '66f2d22f', '66f2d22f', '67636eac', '67636eac', '67636eac', '67b4a34d', '67b4a34d', '67b4a34d', '67c52801', '67c52801', '67c52801', '67c52801', '68b67ca3', '68b67ca3', '68b67ca3', '692cd3b6', '692cd3b6', '692cd3b6', '695367ec', '695367ec', '695367ec', '696d4842', '696d4842'), 'test_accuracy': 0.9687847271561623, 'test_diff_accuracy': 0.4789709924951912, '642d658d_test_accuracy': 0.9988889098167419, '642d658d_test_diff_accuracy': 0.9970238095238095, '64a7c07e_test_accuracy': 0.9822221994400024, '64a7c07e_test_diff_accuracy': 0.5, '66e6c45b_test_accuracy': 0.995555579662323, '66e6c45b_test_diff_accuracy': 0.5, '66f2d22f_test_accuracy': 0.9911110997200012, '66f2d22f_test_diff_accuracy': 0.7419354838709677, '67636eac_test_accuracy': 0.9888888597488403, '67636eac_test_diff_accuracy': 0.5, '67b4a34d_test_accuracy': 0.9588888883590698, '67b4a34d_test_diff_accuracy': 0.8622047244094488, '67c52801_test_accuracy': 0.9666666388511658, '67c52801_test_diff_accuracy': 0.5, '68b67ca3_test_accuracy': 0.995555579662323, '68b67ca3_test_diff_accuracy': 0.5, '692cd3b6_test_accuracy': 0.855555534362793, '692cd3b6_test_diff_accuracy': 0.0, '695367ec_test_accuracy': 0.9100000262260437, '695367ec_test_diff_accuracy': 0.10843373493975904, '696d4842_test_accuracy': 0.9688888788223267, '696d4842_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.23099343478679657, 'task_ids': ('642d658d', '642d658d', '64a7c07e', '64a7c07e', '64a7c07e', '66e6c45b', '66e6c45b', '66f2d22f', '66f2d22f', '66f2d22f', '66f2d22f', '67636eac', '67636eac', '67636eac', '67b4a34d', '67b4a34d', '67b4a34d', '67c52801', '67c52801', '67c52801', '67c52801', '68b67ca3', '68b67ca3', '68b67ca3', '692cd3b6', '692cd3b6', '692cd3b6', '695367ec', '695367ec', '695367ec', '696d4842', '696d4842'), 'test_accuracy': 0.9687847271561623, 'test_diff_accuracy': 0.4789709924951912, '642d658d_test_accuracy': 0.9988889098167419, '642d658d_test_diff_accuracy': 0.9970238095238095, '64a7c07e_test_accuracy': 0.9822221994400024, '64a7c07e_test_diff_accuracy': 0.5, '66e6c45b_test_accuracy': 0.995555579662323, '66e6c45b_test_diff_accuracy': 0.5, '66f2d22f_test_accuracy': 0.9911110997200012, '66f2d22f_test_diff_accuracy': 0.7419354838709677, '67636eac_test_accuracy': 0.9888888597488403, '67636eac_test_diff_accuracy': 0.5, '67b4a34d_test_accuracy': 0.9588888883590698, '67b4a34d_test_diff_accuracy': 0.8622047244094488, '67c52801_test_accuracy': 0.9666666388511658, '67c52801_test_diff_accuracy': 0.5, '68b67ca3_test_accuracy': 0.995555579662323, '68b67ca3_test_diff_accuracy': 0.5, '692cd3b6_test_accuracy': 0.855555534362793, '692cd3b6_test_diff_accuracy': 0.0, '695367ec_test_accuracy': 0.9100000262260437, '695367ec_test_diff_accuracy': 0.10843373493975904, '696d4842_test_accuracy': 0.9688888788223267, '696d4842_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 5, 5,  ..., 5, 0, 0],\n",
            "          [0, 5, 5,  ..., 5, 0, 0],\n",
            "          ...,\n",
            "          [0, 5, 5,  ..., 5, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('696d4842', '69889d6e', '69889d6e', '69889d6e', '69889d6e', '6a11f6da', '6a11f6da', '6a11f6da', '6a11f6da', '6a11f6da', '6ad5bdfd', '6ad5bdfd', '6ad5bdfd', '6df30ad6', '6df30ad6', '6df30ad6', '6df30ad6', '6df30ad6', '6ea4a07e', '6ea4a07e', '6ea4a07e', '6ea4a07e', '6ea4a07e', '6ea4a07e', '6f473927', '6f473927', '6f473927', '6f473927', '7039b2d7', '7039b2d7', '7039b2d7', '705a3229')], batch_idx: 17\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('696d4842', '69889d6e', '69889d6e', '69889d6e', '69889d6e', '6a11f6da', '6a11f6da', '6a11f6da', '6a11f6da', '6a11f6da', '6ad5bdfd', '6ad5bdfd', '6ad5bdfd', '6df30ad6', '6df30ad6', '6df30ad6', '6df30ad6', '6df30ad6', '6ea4a07e', '6ea4a07e', '6ea4a07e', '6ea4a07e', '6ea4a07e', '6ea4a07e', '6f473927', '6f473927', '6f473927', '6f473927', '7039b2d7', '7039b2d7', '7039b2d7', '705a3229')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5869565217391305\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5714285714285714\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5555555555555556\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5813953488372093\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5957446808510638\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4782608695652174\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.42105263157894735\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.47368421052631576\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4583333333333333\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.55\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7368421052631579\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7333333333333333\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.25\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.2222222222222222\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.3333333333333333\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4444444444444444\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4444444444444444\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.3333333333333333\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4444444444444444\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.09615384615384616\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.17857142857142858\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.2727272727272727\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.3076923076923077\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9907621247113164\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9929478138222849\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9690721649484536\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.14405301213264465, Avg accuracy: 0.9824652783572674, Avg diff accuracy: 0.40696051071440525\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.14405301213264465, avg_accuracy=0.9824652783572674, diff_accuracy=0.40696051071440525\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.14405301213264465, 'task_ids': ('696d4842', '69889d6e', '69889d6e', '69889d6e', '69889d6e', '6a11f6da', '6a11f6da', '6a11f6da', '6a11f6da', '6a11f6da', '6ad5bdfd', '6ad5bdfd', '6ad5bdfd', '6df30ad6', '6df30ad6', '6df30ad6', '6df30ad6', '6df30ad6', '6ea4a07e', '6ea4a07e', '6ea4a07e', '6ea4a07e', '6ea4a07e', '6ea4a07e', '6f473927', '6f473927', '6f473927', '6f473927', '7039b2d7', '7039b2d7', '7039b2d7', '705a3229'), 'test_accuracy': 0.9824652783572674, 'test_diff_accuracy': 0.40696051071440525, '696d4842_test_accuracy': 0.9599999785423279, '696d4842_test_diff_accuracy': 0.0, '69889d6e_test_accuracy': 0.9777777791023254, '69889d6e_test_diff_accuracy': 0.0, '6a11f6da_test_accuracy': 0.9766666889190674, '6a11f6da_test_diff_accuracy': 0.5957446808510638, '6ad5bdfd_test_accuracy': 0.9833333492279053, '6ad5bdfd_test_diff_accuracy': 0.47368421052631576, '6df30ad6_test_accuracy': 0.9933333396911621, '6df30ad6_test_diff_accuracy': 0.25, '6ea4a07e_test_accuracy': 0.9944444298744202, '6ea4a07e_test_diff_accuracy': 0.4444444444444444, '6f473927_test_accuracy': 0.9900000095367432, '6f473927_test_diff_accuracy': 0.3076923076923077, '7039b2d7_test_accuracy': 0.9933333396911621, '7039b2d7_test_diff_accuracy': 0.9690721649484536, '705a3229_test_accuracy': 0.9888888597488403, '705a3229_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.14405301213264465, 'task_ids': ('696d4842', '69889d6e', '69889d6e', '69889d6e', '69889d6e', '6a11f6da', '6a11f6da', '6a11f6da', '6a11f6da', '6a11f6da', '6ad5bdfd', '6ad5bdfd', '6ad5bdfd', '6df30ad6', '6df30ad6', '6df30ad6', '6df30ad6', '6df30ad6', '6ea4a07e', '6ea4a07e', '6ea4a07e', '6ea4a07e', '6ea4a07e', '6ea4a07e', '6f473927', '6f473927', '6f473927', '6f473927', '7039b2d7', '7039b2d7', '7039b2d7', '705a3229'), 'test_accuracy': 0.9824652783572674, 'test_diff_accuracy': 0.40696051071440525, '696d4842_test_accuracy': 0.9599999785423279, '696d4842_test_diff_accuracy': 0.0, '69889d6e_test_accuracy': 0.9777777791023254, '69889d6e_test_diff_accuracy': 0.0, '6a11f6da_test_accuracy': 0.9766666889190674, '6a11f6da_test_diff_accuracy': 0.5957446808510638, '6ad5bdfd_test_accuracy': 0.9833333492279053, '6ad5bdfd_test_diff_accuracy': 0.47368421052631576, '6df30ad6_test_accuracy': 0.9933333396911621, '6df30ad6_test_diff_accuracy': 0.25, '6ea4a07e_test_accuracy': 0.9944444298744202, '6ea4a07e_test_diff_accuracy': 0.4444444444444444, '6f473927_test_accuracy': 0.9900000095367432, '6f473927_test_diff_accuracy': 0.3076923076923077, '7039b2d7_test_accuracy': 0.9933333396911621, '7039b2d7_test_diff_accuracy': 0.9690721649484536, '705a3229_test_accuracy': 0.9888888597488403, '705a3229_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('705a3229', '705a3229', '705a3229', '712bf12e', '712bf12e', '712bf12e', '72207abc', '72207abc', '72207abc', '72a961c9', '72a961c9', '72a961c9', '72a961c9', '73182012', '73182012', '73182012', '73c3b0d8', '73c3b0d8', '73c3b0d8', '73c3b0d8', '73ccf9c2', '73ccf9c2', '73ccf9c2', '759f3fd3', '759f3fd3', '762cd429', '762cd429', '762cd429', '770cc55f', '770cc55f', '770cc55f', '770cc55f')], batch_idx: 18\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('705a3229', '705a3229', '705a3229', '712bf12e', '712bf12e', '712bf12e', '72207abc', '72207abc', '72207abc', '72a961c9', '72a961c9', '72a961c9', '72a961c9', '73182012', '73182012', '73182012', '73c3b0d8', '73c3b0d8', '73c3b0d8', '73c3b0d8', '73ccf9c2', '73ccf9c2', '73ccf9c2', '759f3fd3', '759f3fd3', '762cd429', '762cd429', '762cd429', '770cc55f', '770cc55f', '770cc55f', '770cc55f')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8648648648648649\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7857142857142857\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.16666666666666666\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.2222222222222222\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.29411764705882354\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8421052631578947\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8823529411764706\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7846153846153846\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.2715076804161072, Avg accuracy: 0.9537847265601158, Avg diff accuracy: 0.19820810235864414\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.2715076804161072, avg_accuracy=0.9537847265601158, diff_accuracy=0.19820810235864414\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.2715076804161072, 'task_ids': ('705a3229', '705a3229', '705a3229', '712bf12e', '712bf12e', '712bf12e', '72207abc', '72207abc', '72207abc', '72a961c9', '72a961c9', '72a961c9', '72a961c9', '73182012', '73182012', '73182012', '73c3b0d8', '73c3b0d8', '73c3b0d8', '73c3b0d8', '73ccf9c2', '73ccf9c2', '73ccf9c2', '759f3fd3', '759f3fd3', '762cd429', '762cd429', '762cd429', '770cc55f', '770cc55f', '770cc55f', '770cc55f'), 'test_accuracy': 0.9537847265601158, 'test_diff_accuracy': 0.19820810235864414, '705a3229_test_accuracy': 0.9911110997200012, '705a3229_test_diff_accuracy': 0.0, '712bf12e_test_accuracy': 0.898888885974884, '712bf12e_test_diff_accuracy': 0.0, '72207abc_test_accuracy': 0.9933333396911621, '72207abc_test_diff_accuracy': 0.0, '72a961c9_test_accuracy': 0.9788888692855835, '72a961c9_test_diff_accuracy': 0.0, '73182012_test_accuracy': 0.9866666793823242, '73182012_test_diff_accuracy': 1.0, '73c3b0d8_test_accuracy': 0.995555579662323, '73c3b0d8_test_diff_accuracy': 0.5, '73ccf9c2_test_accuracy': 0.9844444394111633, '73ccf9c2_test_diff_accuracy': 0.7846153846153846, '759f3fd3_test_accuracy': 0.9333333373069763, '759f3fd3_test_diff_accuracy': 0.0, '762cd429_test_accuracy': 0.6222222447395325, '762cd429_test_diff_accuracy': 0.0, '770cc55f_test_accuracy': 0.9744444489479065, '770cc55f_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.2715076804161072, 'task_ids': ('705a3229', '705a3229', '705a3229', '712bf12e', '712bf12e', '712bf12e', '72207abc', '72207abc', '72207abc', '72a961c9', '72a961c9', '72a961c9', '72a961c9', '73182012', '73182012', '73182012', '73c3b0d8', '73c3b0d8', '73c3b0d8', '73c3b0d8', '73ccf9c2', '73ccf9c2', '73ccf9c2', '759f3fd3', '759f3fd3', '762cd429', '762cd429', '762cd429', '770cc55f', '770cc55f', '770cc55f', '770cc55f'), 'test_accuracy': 0.9537847265601158, 'test_diff_accuracy': 0.19820810235864414, '705a3229_test_accuracy': 0.9911110997200012, '705a3229_test_diff_accuracy': 0.0, '712bf12e_test_accuracy': 0.898888885974884, '712bf12e_test_diff_accuracy': 0.0, '72207abc_test_accuracy': 0.9933333396911621, '72207abc_test_diff_accuracy': 0.0, '72a961c9_test_accuracy': 0.9788888692855835, '72a961c9_test_diff_accuracy': 0.0, '73182012_test_accuracy': 0.9866666793823242, '73182012_test_diff_accuracy': 1.0, '73c3b0d8_test_accuracy': 0.995555579662323, '73c3b0d8_test_diff_accuracy': 0.5, '73ccf9c2_test_accuracy': 0.9844444394111633, '73ccf9c2_test_diff_accuracy': 0.7846153846153846, '759f3fd3_test_accuracy': 0.9333333373069763, '759f3fd3_test_diff_accuracy': 0.0, '762cd429_test_accuracy': 0.6222222447395325, '762cd429_test_diff_accuracy': 0.0, '770cc55f_test_accuracy': 0.9744444489479065, '770cc55f_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('782b5218', '782b5218', '782b5218', '79369cc6', '79369cc6', '79369cc6', '7953d61e', '7953d61e', '7953d61e', '7953d61e', '7953d61e', '79fb03f4', '79fb03f4', '79fb03f4', '79fb03f4', '79fb03f4', '79fb03f4', '7bb29440', '7bb29440', '7bb29440', '7bb29440', '7bb29440', '7c8af763', '7c8af763', '7c8af763', '7c9b52a0', '7c9b52a0', '7c9b52a0', '7d18a6fb', '7d18a6fb', '7d18a6fb', '7d1f7ee8')], batch_idx: 19\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('782b5218', '782b5218', '782b5218', '79369cc6', '79369cc6', '79369cc6', '7953d61e', '7953d61e', '7953d61e', '7953d61e', '7953d61e', '79fb03f4', '79fb03f4', '79fb03f4', '79fb03f4', '79fb03f4', '79fb03f4', '7bb29440', '7bb29440', '7bb29440', '7bb29440', '7bb29440', '7c8af763', '7c8af763', '7c8af763', '7c9b52a0', '7c9b52a0', '7c9b52a0', '7d18a6fb', '7d18a6fb', '7d18a6fb', '7d1f7ee8')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.525\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.36363636363636365\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5135135135135135\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9034090909090909\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9299363057324841\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9647577092511013\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6341463414634146\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.803680981595092\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9541284403669725\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5299539170506913\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.3964757709251101\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7710843373493976\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7628865979381443\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7916666666666666\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.32043546438217163, Avg accuracy: 0.9210416711866856, Avg diff accuracy: 0.30763362613743883\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.32043546438217163, avg_accuracy=0.9210416711866856, diff_accuracy=0.30763362613743883\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.32043546438217163, 'task_ids': ('782b5218', '782b5218', '782b5218', '79369cc6', '79369cc6', '79369cc6', '7953d61e', '7953d61e', '7953d61e', '7953d61e', '7953d61e', '79fb03f4', '79fb03f4', '79fb03f4', '79fb03f4', '79fb03f4', '79fb03f4', '7bb29440', '7bb29440', '7bb29440', '7bb29440', '7bb29440', '7c8af763', '7c8af763', '7c8af763', '7c9b52a0', '7c9b52a0', '7c9b52a0', '7d18a6fb', '7d18a6fb', '7d18a6fb', '7d1f7ee8'), 'test_accuracy': 0.9210416711866856, 'test_diff_accuracy': 0.30763362613743883, '782b5218_test_accuracy': 0.948888897895813, '782b5218_test_diff_accuracy': 0.5135135135135135, '79369cc6_test_accuracy': 0.8155555725097656, '79369cc6_test_diff_accuracy': 0.0, '7953d61e_test_accuracy': 0.9288889169692993, '7953d61e_test_diff_accuracy': 0.0, '79fb03f4_test_accuracy': 0.9788888692855835, '79fb03f4_test_diff_accuracy': 0.0, '7bb29440_test_accuracy': 0.9611111283302307, '7bb29440_test_diff_accuracy': 0.803680981595092, '7c8af763_test_accuracy': 0.8888888955116272, '7c8af763_test_diff_accuracy': 0.0, '7c9b52a0_test_accuracy': 0.846666693687439, '7c9b52a0_test_diff_accuracy': 0.3964757709251101, '7d18a6fb_test_accuracy': 0.9777777791023254, '7d18a6fb_test_diff_accuracy': 0.7916666666666666, '7d1f7ee8_test_accuracy': 0.7955555319786072, '7d1f7ee8_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.32043546438217163, 'task_ids': ('782b5218', '782b5218', '782b5218', '79369cc6', '79369cc6', '79369cc6', '7953d61e', '7953d61e', '7953d61e', '7953d61e', '7953d61e', '79fb03f4', '79fb03f4', '79fb03f4', '79fb03f4', '79fb03f4', '79fb03f4', '7bb29440', '7bb29440', '7bb29440', '7bb29440', '7bb29440', '7c8af763', '7c8af763', '7c8af763', '7c9b52a0', '7c9b52a0', '7c9b52a0', '7d18a6fb', '7d18a6fb', '7d18a6fb', '7d1f7ee8'), 'test_accuracy': 0.9210416711866856, 'test_diff_accuracy': 0.30763362613743883, '782b5218_test_accuracy': 0.948888897895813, '782b5218_test_diff_accuracy': 0.5135135135135135, '79369cc6_test_accuracy': 0.8155555725097656, '79369cc6_test_diff_accuracy': 0.0, '7953d61e_test_accuracy': 0.9288889169692993, '7953d61e_test_diff_accuracy': 0.0, '79fb03f4_test_accuracy': 0.9788888692855835, '79fb03f4_test_diff_accuracy': 0.0, '7bb29440_test_accuracy': 0.9611111283302307, '7bb29440_test_diff_accuracy': 0.803680981595092, '7c8af763_test_accuracy': 0.8888888955116272, '7c8af763_test_diff_accuracy': 0.0, '7c9b52a0_test_accuracy': 0.846666693687439, '7c9b52a0_test_diff_accuracy': 0.3964757709251101, '7d18a6fb_test_accuracy': 0.9777777791023254, '7d18a6fb_test_diff_accuracy': 0.7916666666666666, '7d1f7ee8_test_accuracy': 0.7955555319786072, '7d1f7ee8_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('7d1f7ee8', '7d1f7ee8', '7d419a02', '7d419a02', '7d419a02', '7e02026e', '7e02026e', '7e02026e', '7ee1c6ea', '7ee1c6ea', '7ee1c6ea', '817e6c09', '817e6c09', '817e6c09', '817e6c09', '817e6c09', '81c0276b', '81c0276b', '81c0276b', '833dafe3', '833dafe3', '845d6e51', '845d6e51', '845d6e51', '84db8fc4', '84db8fc4', '84db8fc4', '84db8fc4', '84f2aca1', '84f2aca1', '84f2aca1', '84f2aca1')], batch_idx: 20\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('7d1f7ee8', '7d1f7ee8', '7d419a02', '7d419a02', '7d419a02', '7e02026e', '7e02026e', '7e02026e', '7ee1c6ea', '7ee1c6ea', '7ee1c6ea', '817e6c09', '817e6c09', '817e6c09', '817e6c09', '817e6c09', '81c0276b', '81c0276b', '81c0276b', '833dafe3', '833dafe3', '845d6e51', '845d6e51', '845d6e51', '84db8fc4', '84db8fc4', '84db8fc4', '84db8fc4', '84f2aca1', '84f2aca1', '84f2aca1', '84f2aca1')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9512195121951219\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9603174603174603\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9517241379310345\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.07692307692307693\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.06976744186046512\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.22447605431079865, Avg accuracy: 0.929479168727994, Avg diff accuracy: 0.09406098841334871\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.22447605431079865, avg_accuracy=0.929479168727994, diff_accuracy=0.09406098841334871\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.22447605431079865, 'task_ids': ('7d1f7ee8', '7d1f7ee8', '7d419a02', '7d419a02', '7d419a02', '7e02026e', '7e02026e', '7e02026e', '7ee1c6ea', '7ee1c6ea', '7ee1c6ea', '817e6c09', '817e6c09', '817e6c09', '817e6c09', '817e6c09', '81c0276b', '81c0276b', '81c0276b', '833dafe3', '833dafe3', '845d6e51', '845d6e51', '845d6e51', '84db8fc4', '84db8fc4', '84db8fc4', '84db8fc4', '84f2aca1', '84f2aca1', '84f2aca1', '84f2aca1'), 'test_accuracy': 0.929479168727994, 'test_diff_accuracy': 0.09406098841334871, '7d1f7ee8_test_accuracy': 0.9133333563804626, '7d1f7ee8_test_diff_accuracy': 0.0, '7d419a02_test_accuracy': 0.7944444417953491, '7d419a02_test_diff_accuracy': 0.0, '7e02026e_test_accuracy': 0.8788889050483704, '7e02026e_test_diff_accuracy': 0.0, '7ee1c6ea_test_accuracy': 0.9077777862548828, '7ee1c6ea_test_diff_accuracy': 0.0, '817e6c09_test_accuracy': 0.9911110997200012, '817e6c09_test_diff_accuracy': 0.0, '81c0276b_test_accuracy': 0.992222249507904, '81c0276b_test_diff_accuracy': 0.9517241379310345, '833dafe3_test_accuracy': 0.9555555582046509, '833dafe3_test_diff_accuracy': 0.06976744186046512, '845d6e51_test_accuracy': 0.9599999785423279, '845d6e51_test_diff_accuracy': 0.0, '84db8fc4_test_accuracy': 0.8888888955116272, '84db8fc4_test_diff_accuracy': 0.0, '84f2aca1_test_accuracy': 0.9399999976158142, '84f2aca1_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.22447605431079865, 'task_ids': ('7d1f7ee8', '7d1f7ee8', '7d419a02', '7d419a02', '7d419a02', '7e02026e', '7e02026e', '7e02026e', '7ee1c6ea', '7ee1c6ea', '7ee1c6ea', '817e6c09', '817e6c09', '817e6c09', '817e6c09', '817e6c09', '81c0276b', '81c0276b', '81c0276b', '833dafe3', '833dafe3', '845d6e51', '845d6e51', '845d6e51', '84db8fc4', '84db8fc4', '84db8fc4', '84db8fc4', '84f2aca1', '84f2aca1', '84f2aca1', '84f2aca1'), 'test_accuracy': 0.929479168727994, 'test_diff_accuracy': 0.09406098841334871, '7d1f7ee8_test_accuracy': 0.9133333563804626, '7d1f7ee8_test_diff_accuracy': 0.0, '7d419a02_test_accuracy': 0.7944444417953491, '7d419a02_test_diff_accuracy': 0.0, '7e02026e_test_accuracy': 0.8788889050483704, '7e02026e_test_diff_accuracy': 0.0, '7ee1c6ea_test_accuracy': 0.9077777862548828, '7ee1c6ea_test_diff_accuracy': 0.0, '817e6c09_test_accuracy': 0.9911110997200012, '817e6c09_test_diff_accuracy': 0.0, '81c0276b_test_accuracy': 0.992222249507904, '81c0276b_test_diff_accuracy': 0.9517241379310345, '833dafe3_test_accuracy': 0.9555555582046509, '833dafe3_test_diff_accuracy': 0.06976744186046512, '845d6e51_test_accuracy': 0.9599999785423279, '845d6e51_test_diff_accuracy': 0.0, '84db8fc4_test_accuracy': 0.8888888955116272, '84db8fc4_test_diff_accuracy': 0.0, '84f2aca1_test_accuracy': 0.9399999976158142, '84f2aca1_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('8597cfd7', '8597cfd7', '8597cfd7', '8597cfd7', '85b81ff1', '85b81ff1', '85b81ff1', '85b81ff1', '85fa5666', '85fa5666', '85fa5666', '85fa5666', '8719f442', '8719f442', '8719f442', '88207623', '88207623', '891232d6', '891232d6', '891232d6', '891232d6', '896d5239', '896d5239', '896d5239', '8a371977', '8a371977', '8a371977', '8b28cd80', '8b28cd80', '8b28cd80', '8b28cd80', '8b28cd80')], batch_idx: 21\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('8597cfd7', '8597cfd7', '8597cfd7', '8597cfd7', '85b81ff1', '85b81ff1', '85b81ff1', '85b81ff1', '85fa5666', '85fa5666', '85fa5666', '85fa5666', '8719f442', '8719f442', '8719f442', '88207623', '88207623', '891232d6', '891232d6', '891232d6', '891232d6', '896d5239', '896d5239', '896d5239', '8a371977', '8a371977', '8a371977', '8b28cd80', '8b28cd80', '8b28cd80', '8b28cd80', '8b28cd80')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8181818181818182\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8333333333333334\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8181818181818182\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.02127659574468085\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.021739130434782608\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.021739130434782608\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.021739130434782608\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.42091232538223267, Avg accuracy: 0.8844791669398546, Avg diff accuracy: 0.16738096739831246\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.42091232538223267, avg_accuracy=0.8844791669398546, diff_accuracy=0.16738096739831246\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.42091232538223267, 'task_ids': ('8597cfd7', '8597cfd7', '8597cfd7', '8597cfd7', '85b81ff1', '85b81ff1', '85b81ff1', '85b81ff1', '85fa5666', '85fa5666', '85fa5666', '85fa5666', '8719f442', '8719f442', '8719f442', '88207623', '88207623', '891232d6', '891232d6', '891232d6', '891232d6', '896d5239', '896d5239', '896d5239', '8a371977', '8a371977', '8a371977', '8b28cd80', '8b28cd80', '8b28cd80', '8b28cd80', '8b28cd80'), 'test_accuracy': 0.8844791669398546, 'test_diff_accuracy': 0.16738096739831246, '8597cfd7_test_accuracy': 0.995555579662323, '8597cfd7_test_diff_accuracy': 0.8181818181818182, '85b81ff1_test_accuracy': 0.8744444251060486, '85b81ff1_test_diff_accuracy': 0.5, '85fa5666_test_accuracy': 0.9788888692855835, '85fa5666_test_diff_accuracy': 0.0, '8719f442_test_accuracy': 0.9566666483879089, '8719f442_test_diff_accuracy': 0.0, '88207623_test_accuracy': 0.9333333373069763, '88207623_test_diff_accuracy': 0.0, '891232d6_test_accuracy': 0.9733333587646484, '891232d6_test_diff_accuracy': 0.0, '896d5239_test_accuracy': 0.847777783870697, '896d5239_test_diff_accuracy': 0.0, '8a371977_test_accuracy': 0.3055555522441864, '8a371977_test_diff_accuracy': 0.0, '8b28cd80_test_accuracy': 0.949999988079071, '8b28cd80_test_diff_accuracy': 0.021739130434782608}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.42091232538223267, 'task_ids': ('8597cfd7', '8597cfd7', '8597cfd7', '8597cfd7', '85b81ff1', '85b81ff1', '85b81ff1', '85b81ff1', '85fa5666', '85fa5666', '85fa5666', '85fa5666', '8719f442', '8719f442', '8719f442', '88207623', '88207623', '891232d6', '891232d6', '891232d6', '891232d6', '896d5239', '896d5239', '896d5239', '8a371977', '8a371977', '8a371977', '8b28cd80', '8b28cd80', '8b28cd80', '8b28cd80', '8b28cd80'), 'test_accuracy': 0.8844791669398546, 'test_diff_accuracy': 0.16738096739831246, '8597cfd7_test_accuracy': 0.995555579662323, '8597cfd7_test_diff_accuracy': 0.8181818181818182, '85b81ff1_test_accuracy': 0.8744444251060486, '85b81ff1_test_diff_accuracy': 0.5, '85fa5666_test_accuracy': 0.9788888692855835, '85fa5666_test_diff_accuracy': 0.0, '8719f442_test_accuracy': 0.9566666483879089, '8719f442_test_diff_accuracy': 0.0, '88207623_test_accuracy': 0.9333333373069763, '88207623_test_diff_accuracy': 0.0, '891232d6_test_accuracy': 0.9733333587646484, '891232d6_test_diff_accuracy': 0.0, '896d5239_test_accuracy': 0.847777783870697, '896d5239_test_diff_accuracy': 0.0, '8a371977_test_accuracy': 0.3055555522441864, '8a371977_test_diff_accuracy': 0.0, '8b28cd80_test_accuracy': 0.949999988079071, '8b28cd80_test_diff_accuracy': 0.021739130434782608}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('8ba14f53', '8ba14f53', '8ba14f53', '8ba14f53', '8ba14f53', '8ba14f53', '8cb8642d', '8cb8642d', '8cb8642d', '8dae5dfc', '8dae5dfc', '8dae5dfc', '8dae5dfc', '8e2edd66', '8e2edd66', '8e2edd66', '8ee62060', '8ee62060', '8ee62060', '8fbca751', '8fbca751', '8fbca751', '90347967', '90347967', '90347967', '903d1b4a', '903d1b4a', '903d1b4a', '903d1b4a', '9110e3c5', '9110e3c5', '9110e3c5')], batch_idx: 22\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('8ba14f53', '8ba14f53', '8ba14f53', '8ba14f53', '8ba14f53', '8ba14f53', '8cb8642d', '8cb8642d', '8cb8642d', '8dae5dfc', '8dae5dfc', '8dae5dfc', '8dae5dfc', '8e2edd66', '8e2edd66', '8e2edd66', '8ee62060', '8ee62060', '8ee62060', '8fbca751', '8fbca751', '8fbca751', '90347967', '90347967', '90347967', '903d1b4a', '903d1b4a', '903d1b4a', '903d1b4a', '9110e3c5', '9110e3c5', '9110e3c5')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8095238095238095\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8076923076923077\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.75\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8181818181818182\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8888888888888888\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8333333333333334\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6896551724137931\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7636363636363637\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6746987951807228\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.13793103448275862\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.23809523809523808\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8461538461538461\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.85\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8709677419354839\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.24392108619213104, Avg accuracy: 0.9270833320915699, Avg diff accuracy: 0.4180861984224489\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.24392108619213104, avg_accuracy=0.9270833320915699, diff_accuracy=0.4180861984224489\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.24392108619213104, 'task_ids': ('8ba14f53', '8ba14f53', '8ba14f53', '8ba14f53', '8ba14f53', '8ba14f53', '8cb8642d', '8cb8642d', '8cb8642d', '8dae5dfc', '8dae5dfc', '8dae5dfc', '8dae5dfc', '8e2edd66', '8e2edd66', '8e2edd66', '8ee62060', '8ee62060', '8ee62060', '8fbca751', '8fbca751', '8fbca751', '90347967', '90347967', '90347967', '903d1b4a', '903d1b4a', '903d1b4a', '903d1b4a', '9110e3c5', '9110e3c5', '9110e3c5'), 'test_accuracy': 0.9270833320915699, 'test_diff_accuracy': 0.4180861984224489, '8ba14f53_test_accuracy': 0.9944444298744202, '8ba14f53_test_diff_accuracy': 0.8333333333333334, '8cb8642d_test_accuracy': 0.8822222352027893, '8cb8642d_test_diff_accuracy': 0.6746987951807228, '8dae5dfc_test_accuracy': 0.8233333230018616, '8dae5dfc_test_diff_accuracy': 0.0, '8e2edd66_test_accuracy': 0.9900000095367432, '8e2edd66_test_diff_accuracy': 0.4, '8ee62060_test_accuracy': 0.9833333492279053, '8ee62060_test_diff_accuracy': 0.5, '8fbca751_test_accuracy': 0.9822221994400024, '8fbca751_test_diff_accuracy': 0.0, '90347967_test_accuracy': 0.9933333396911621, '90347967_test_diff_accuracy': 0.5, '903d1b4a_test_accuracy': 0.7155555486679077, '903d1b4a_test_diff_accuracy': 0.0, '9110e3c5_test_accuracy': 0.995555579662323, '9110e3c5_test_diff_accuracy': 0.8709677419354839}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.24392108619213104, 'task_ids': ('8ba14f53', '8ba14f53', '8ba14f53', '8ba14f53', '8ba14f53', '8ba14f53', '8cb8642d', '8cb8642d', '8cb8642d', '8dae5dfc', '8dae5dfc', '8dae5dfc', '8dae5dfc', '8e2edd66', '8e2edd66', '8e2edd66', '8ee62060', '8ee62060', '8ee62060', '8fbca751', '8fbca751', '8fbca751', '90347967', '90347967', '90347967', '903d1b4a', '903d1b4a', '903d1b4a', '903d1b4a', '9110e3c5', '9110e3c5', '9110e3c5'), 'test_accuracy': 0.9270833320915699, 'test_diff_accuracy': 0.4180861984224489, '8ba14f53_test_accuracy': 0.9944444298744202, '8ba14f53_test_diff_accuracy': 0.8333333333333334, '8cb8642d_test_accuracy': 0.8822222352027893, '8cb8642d_test_diff_accuracy': 0.6746987951807228, '8dae5dfc_test_accuracy': 0.8233333230018616, '8dae5dfc_test_diff_accuracy': 0.0, '8e2edd66_test_accuracy': 0.9900000095367432, '8e2edd66_test_diff_accuracy': 0.4, '8ee62060_test_accuracy': 0.9833333492279053, '8ee62060_test_diff_accuracy': 0.5, '8fbca751_test_accuracy': 0.9822221994400024, '8fbca751_test_diff_accuracy': 0.0, '90347967_test_accuracy': 0.9933333396911621, '90347967_test_diff_accuracy': 0.5, '903d1b4a_test_accuracy': 0.7155555486679077, '903d1b4a_test_diff_accuracy': 0.0, '9110e3c5_test_accuracy': 0.995555579662323, '9110e3c5_test_diff_accuracy': 0.8709677419354839}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('9110e3c5', '9110e3c5', '9110e3c5', '9110e3c5', '917bccba', '917bccba', '917bccba', '929ab4e9', '929ab4e9', '929ab4e9', '929ab4e9', '92e50de0', '92e50de0', '92e50de0', '9356391f', '9356391f', '93b4f4b3', '93b4f4b3', '93c31fbe', '93c31fbe', '93c31fbe', '94133066', '94133066', '94133066', '94414823', '94414823', '94414823', '94be5b80', '94be5b80', '95a58926', '95a58926', '95a58926')], batch_idx: 23\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('9110e3c5', '9110e3c5', '9110e3c5', '9110e3c5', '917bccba', '917bccba', '917bccba', '929ab4e9', '929ab4e9', '929ab4e9', '929ab4e9', '92e50de0', '92e50de0', '92e50de0', '9356391f', '9356391f', '93b4f4b3', '93b4f4b3', '93c31fbe', '93c31fbe', '93c31fbe', '94133066', '94133066', '94133066', '94414823', '94414823', '94414823', '94be5b80', '94be5b80', '95a58926', '95a58926', '95a58926')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8461538461538461\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8461538461538461\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.896551724137931\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6129032258064516\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6551724137931034\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5757575757575758\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.40540540540540543\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4105263157894737\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.35294117647058826\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.3684210526315789\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.47368421052631576\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4930555555555556\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4846153846153846\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.47619047619047616\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.21428571428571427\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.375\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5833333333333334\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7704918032786885\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.3698630136986301\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.544943630695343, Avg accuracy: 0.8382291728630662, Avg diff accuracy: 0.34720331479949684\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.544943630695343, avg_accuracy=0.8382291728630662, diff_accuracy=0.34720331479949684\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.544943630695343, 'task_ids': ('9110e3c5', '9110e3c5', '9110e3c5', '9110e3c5', '917bccba', '917bccba', '917bccba', '929ab4e9', '929ab4e9', '929ab4e9', '929ab4e9', '92e50de0', '92e50de0', '92e50de0', '9356391f', '9356391f', '93b4f4b3', '93b4f4b3', '93c31fbe', '93c31fbe', '93c31fbe', '94133066', '94133066', '94133066', '94414823', '94414823', '94414823', '94be5b80', '94be5b80', '95a58926', '95a58926', '95a58926'), 'test_accuracy': 0.8382291728630662, 'test_diff_accuracy': 0.34720331479949684, '9110e3c5_test_accuracy': 0.996666669845581, '9110e3c5_test_diff_accuracy': 0.9, '917bccba_test_accuracy': 0.9666666388511658, '917bccba_test_diff_accuracy': 0.5757575757575758, '929ab4e9_test_accuracy': 0.36000001430511475, '929ab4e9_test_diff_accuracy': 0.0, '92e50de0_test_accuracy': 0.6511111259460449, '92e50de0_test_diff_accuracy': 0.0, '9356391f_test_accuracy': 0.8899999856948853, '9356391f_test_diff_accuracy': 0.0, '93b4f4b3_test_accuracy': 0.9133333563804626, '93b4f4b3_test_diff_accuracy': 0.4105263157894737, '93c31fbe_test_accuracy': 0.9511111378669739, '93c31fbe_test_diff_accuracy': 0.47368421052631576, '94133066_test_accuracy': 0.8666666746139526, '94133066_test_diff_accuracy': 0.47619047619047616, '94414823_test_accuracy': 0.9577777981758118, '94414823_test_diff_accuracy': 0.0, '94be5b80_test_accuracy': 0.9555555582046509, '94be5b80_test_diff_accuracy': 0.375, '95a58926_test_accuracy': 0.7599999904632568, '95a58926_test_diff_accuracy': 0.3698630136986301}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.544943630695343, 'task_ids': ('9110e3c5', '9110e3c5', '9110e3c5', '9110e3c5', '917bccba', '917bccba', '917bccba', '929ab4e9', '929ab4e9', '929ab4e9', '929ab4e9', '92e50de0', '92e50de0', '92e50de0', '9356391f', '9356391f', '93b4f4b3', '93b4f4b3', '93c31fbe', '93c31fbe', '93c31fbe', '94133066', '94133066', '94133066', '94414823', '94414823', '94414823', '94be5b80', '94be5b80', '95a58926', '95a58926', '95a58926'), 'test_accuracy': 0.8382291728630662, 'test_diff_accuracy': 0.34720331479949684, '9110e3c5_test_accuracy': 0.996666669845581, '9110e3c5_test_diff_accuracy': 0.9, '917bccba_test_accuracy': 0.9666666388511658, '917bccba_test_diff_accuracy': 0.5757575757575758, '929ab4e9_test_accuracy': 0.36000001430511475, '929ab4e9_test_diff_accuracy': 0.0, '92e50de0_test_accuracy': 0.6511111259460449, '92e50de0_test_diff_accuracy': 0.0, '9356391f_test_accuracy': 0.8899999856948853, '9356391f_test_diff_accuracy': 0.0, '93b4f4b3_test_accuracy': 0.9133333563804626, '93b4f4b3_test_diff_accuracy': 0.4105263157894737, '93c31fbe_test_accuracy': 0.9511111378669739, '93c31fbe_test_diff_accuracy': 0.47368421052631576, '94133066_test_accuracy': 0.8666666746139526, '94133066_test_diff_accuracy': 0.47619047619047616, '94414823_test_accuracy': 0.9577777981758118, '94414823_test_diff_accuracy': 0.0, '94be5b80_test_accuracy': 0.9555555582046509, '94be5b80_test_diff_accuracy': 0.375, '95a58926_test_accuracy': 0.7599999904632568, '95a58926_test_diff_accuracy': 0.3698630136986301}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('963f59bc', '963f59bc', '963f59bc', '963f59bc', '96a8c0cd', '96a8c0cd', '96a8c0cd', '96a8c0cd', '97239e3d', '97239e3d', '97239e3d', '9772c176', '9772c176', '981571dc', '981571dc', '981571dc', '981571dc', '992798f6', '992798f6', '992798f6', '992798f6', '99306f82', '99306f82', '99306f82', '9a4bb226', '9a4bb226', '9a4bb226', '9b2a60aa', '9b2a60aa', '9b2a60aa', '9b365c51', '9b365c51')], batch_idx: 24\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('963f59bc', '963f59bc', '963f59bc', '963f59bc', '96a8c0cd', '96a8c0cd', '96a8c0cd', '96a8c0cd', '97239e3d', '97239e3d', '97239e3d', '9772c176', '9772c176', '981571dc', '981571dc', '981571dc', '981571dc', '992798f6', '992798f6', '992798f6', '992798f6', '99306f82', '99306f82', '99306f82', '9a4bb226', '9a4bb226', '9a4bb226', '9b2a60aa', '9b2a60aa', '9b2a60aa', '9b365c51', '9b365c51')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7619047619047619\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.75\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.375\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.43902439024390244\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.600387692451477, Avg accuracy: 0.8136458347580628, Avg diff accuracy: 0.09768528600464577\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.600387692451477, avg_accuracy=0.8136458347580628, diff_accuracy=0.09768528600464577\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.600387692451477, 'task_ids': ('963f59bc', '963f59bc', '963f59bc', '963f59bc', '96a8c0cd', '96a8c0cd', '96a8c0cd', '96a8c0cd', '97239e3d', '97239e3d', '97239e3d', '9772c176', '9772c176', '981571dc', '981571dc', '981571dc', '981571dc', '992798f6', '992798f6', '992798f6', '992798f6', '99306f82', '99306f82', '99306f82', '9a4bb226', '9a4bb226', '9a4bb226', '9b2a60aa', '9b2a60aa', '9b2a60aa', '9b365c51', '9b365c51'), 'test_accuracy': 0.8136458347580628, 'test_diff_accuracy': 0.09768528600464577, '963f59bc_test_accuracy': 0.9800000190734863, '963f59bc_test_diff_accuracy': 0.0, '96a8c0cd_test_accuracy': 0.9544444680213928, '96a8c0cd_test_diff_accuracy': 0.0, '97239e3d_test_accuracy': 0.800000011920929, '97239e3d_test_diff_accuracy': 0.0, '9772c176_test_accuracy': 0.8266666531562805, '9772c176_test_diff_accuracy': 0.0, '981571dc_test_accuracy': 0.0011111111380159855, '981571dc_test_diff_accuracy': 0.0, '992798f6_test_accuracy': 0.9855555295944214, '992798f6_test_diff_accuracy': 0.0, '99306f82_test_accuracy': 0.8844444155693054, '99306f82_test_diff_accuracy': 0.0, '9a4bb226_test_accuracy': 0.9900000095367432, '9a4bb226_test_diff_accuracy': 0.8, '9b2a60aa_test_accuracy': 0.9644444584846497, '9b2a60aa_test_diff_accuracy': 0.0, '9b365c51_test_accuracy': 0.9744444489479065, '9b365c51_test_diff_accuracy': 0.43902439024390244}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.600387692451477, 'task_ids': ('963f59bc', '963f59bc', '963f59bc', '963f59bc', '96a8c0cd', '96a8c0cd', '96a8c0cd', '96a8c0cd', '97239e3d', '97239e3d', '97239e3d', '9772c176', '9772c176', '981571dc', '981571dc', '981571dc', '981571dc', '992798f6', '992798f6', '992798f6', '992798f6', '99306f82', '99306f82', '99306f82', '9a4bb226', '9a4bb226', '9a4bb226', '9b2a60aa', '9b2a60aa', '9b2a60aa', '9b365c51', '9b365c51'), 'test_accuracy': 0.8136458347580628, 'test_diff_accuracy': 0.09768528600464577, '963f59bc_test_accuracy': 0.9800000190734863, '963f59bc_test_diff_accuracy': 0.0, '96a8c0cd_test_accuracy': 0.9544444680213928, '96a8c0cd_test_diff_accuracy': 0.0, '97239e3d_test_accuracy': 0.800000011920929, '97239e3d_test_diff_accuracy': 0.0, '9772c176_test_accuracy': 0.8266666531562805, '9772c176_test_diff_accuracy': 0.0, '981571dc_test_accuracy': 0.0011111111380159855, '981571dc_test_diff_accuracy': 0.0, '992798f6_test_accuracy': 0.9855555295944214, '992798f6_test_diff_accuracy': 0.0, '99306f82_test_accuracy': 0.8844444155693054, '99306f82_test_diff_accuracy': 0.0, '9a4bb226_test_accuracy': 0.9900000095367432, '9a4bb226_test_diff_accuracy': 0.8, '9b2a60aa_test_accuracy': 0.9644444584846497, '9b2a60aa_test_diff_accuracy': 0.0, '9b365c51_test_accuracy': 0.9744444489479065, '9b365c51_test_diff_accuracy': 0.43902439024390244}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('9b365c51', '9b4c17c4', '9b4c17c4', '9b4c17c4', '9b4c17c4', '9bebae7a', '9bebae7a', '9bebae7a', '9bebae7a', '9bebae7a', '9c1e755f', '9c1e755f', '9c1e755f', '9c1e755f', '9c56f360', '9c56f360', '9c56f360', '9caba7c3', '9caba7c3', '9caba7c3', '9ddd00f0', '9ddd00f0', '9def23fe', '9def23fe', '9def23fe', '9f27f097', '9f27f097', '9f27f097', 'a04b2602', 'a04b2602', 'a04b2602', 'a096bf4d')], batch_idx: 25\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('9b365c51', '9b4c17c4', '9b4c17c4', '9b4c17c4', '9b4c17c4', '9bebae7a', '9bebae7a', '9bebae7a', '9bebae7a', '9bebae7a', '9c1e755f', '9c1e755f', '9c1e755f', '9c1e755f', '9c56f360', '9c56f360', '9c56f360', '9caba7c3', '9caba7c3', '9caba7c3', '9ddd00f0', '9ddd00f0', '9def23fe', '9def23fe', '9def23fe', '9f27f097', '9f27f097', '9f27f097', 'a04b2602', 'a04b2602', 'a04b2602', 'a096bf4d')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5185185185185185\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.14285714285714285\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.35294117647058826\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4166666666666667\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4166666666666667\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.35294117647058826\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.3883328437805176, Avg accuracy: 0.8817361071705818, Avg diff accuracy: 0.11564347961406785\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.3883328437805176, avg_accuracy=0.8817361071705818, diff_accuracy=0.11564347961406785\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.3883328437805176, 'task_ids': ('9b365c51', '9b4c17c4', '9b4c17c4', '9b4c17c4', '9b4c17c4', '9bebae7a', '9bebae7a', '9bebae7a', '9bebae7a', '9bebae7a', '9c1e755f', '9c1e755f', '9c1e755f', '9c1e755f', '9c56f360', '9c56f360', '9c56f360', '9caba7c3', '9caba7c3', '9caba7c3', '9ddd00f0', '9ddd00f0', '9def23fe', '9def23fe', '9def23fe', '9f27f097', '9f27f097', '9f27f097', 'a04b2602', 'a04b2602', 'a04b2602', 'a096bf4d'), 'test_accuracy': 0.8817361071705818, 'test_diff_accuracy': 0.11564347961406785, '9b365c51_test_accuracy': 0.9711111187934875, '9b365c51_test_diff_accuracy': 0.5185185185185185, '9b4c17c4_test_accuracy': 0.8533333539962769, '9b4c17c4_test_diff_accuracy': 0.0, '9bebae7a_test_accuracy': 0.9755555391311646, '9bebae7a_test_diff_accuracy': 0.35294117647058826, '9c1e755f_test_accuracy': 0.9244444370269775, '9c1e755f_test_diff_accuracy': 0.0, '9c56f360_test_accuracy': 0.9611111283302307, '9c56f360_test_diff_accuracy': 0.5, '9caba7c3_test_accuracy': 0.7400000095367432, '9caba7c3_test_diff_accuracy': 0.0, '9ddd00f0_test_accuracy': 0.9866666793823242, '9ddd00f0_test_diff_accuracy': 0.0, '9def23fe_test_accuracy': 0.8388888835906982, '9def23fe_test_diff_accuracy': 0.0, '9f27f097_test_accuracy': 0.8399999737739563, '9f27f097_test_diff_accuracy': 0.0, 'a04b2602_test_accuracy': 0.9333333373069763, 'a04b2602_test_diff_accuracy': 0.0, 'a096bf4d_test_accuracy': 0.7155555486679077, 'a096bf4d_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.3883328437805176, 'task_ids': ('9b365c51', '9b4c17c4', '9b4c17c4', '9b4c17c4', '9b4c17c4', '9bebae7a', '9bebae7a', '9bebae7a', '9bebae7a', '9bebae7a', '9c1e755f', '9c1e755f', '9c1e755f', '9c1e755f', '9c56f360', '9c56f360', '9c56f360', '9caba7c3', '9caba7c3', '9caba7c3', '9ddd00f0', '9ddd00f0', '9def23fe', '9def23fe', '9def23fe', '9f27f097', '9f27f097', '9f27f097', 'a04b2602', 'a04b2602', 'a04b2602', 'a096bf4d'), 'test_accuracy': 0.8817361071705818, 'test_diff_accuracy': 0.11564347961406785, '9b365c51_test_accuracy': 0.9711111187934875, '9b365c51_test_diff_accuracy': 0.5185185185185185, '9b4c17c4_test_accuracy': 0.8533333539962769, '9b4c17c4_test_diff_accuracy': 0.0, '9bebae7a_test_accuracy': 0.9755555391311646, '9bebae7a_test_diff_accuracy': 0.35294117647058826, '9c1e755f_test_accuracy': 0.9244444370269775, '9c1e755f_test_diff_accuracy': 0.0, '9c56f360_test_accuracy': 0.9611111283302307, '9c56f360_test_diff_accuracy': 0.5, '9caba7c3_test_accuracy': 0.7400000095367432, '9caba7c3_test_diff_accuracy': 0.0, '9ddd00f0_test_accuracy': 0.9866666793823242, '9ddd00f0_test_diff_accuracy': 0.0, '9def23fe_test_accuracy': 0.8388888835906982, '9def23fe_test_diff_accuracy': 0.0, '9f27f097_test_accuracy': 0.8399999737739563, '9f27f097_test_diff_accuracy': 0.0, 'a04b2602_test_accuracy': 0.9333333373069763, 'a04b2602_test_diff_accuracy': 0.0, 'a096bf4d_test_accuracy': 0.7155555486679077, 'a096bf4d_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('a096bf4d', 'a096bf4d', 'a3f84088', 'a3f84088', 'a3f84088', 'a3f84088', 'a406ac07', 'a406ac07', 'a406ac07', 'a57f2f04', 'a57f2f04', 'a57f2f04', 'a59b95c0', 'a59b95c0', 'a59b95c0', 'a59b95c0', 'a59b95c0', 'a680ac02', 'a680ac02', 'a680ac02', 'a8610ef7', 'a8610ef7', 'a8610ef7', 'a8610ef7', 'a934301b', 'a934301b', 'a934301b', 'aa18de87', 'aa18de87', 'aa18de87', 'aa18de87', 'aa300dc3')], batch_idx: 26\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('a096bf4d', 'a096bf4d', 'a3f84088', 'a3f84088', 'a3f84088', 'a3f84088', 'a406ac07', 'a406ac07', 'a406ac07', 'a57f2f04', 'a57f2f04', 'a57f2f04', 'a59b95c0', 'a59b95c0', 'a59b95c0', 'a59b95c0', 'a59b95c0', 'a680ac02', 'a680ac02', 'a680ac02', 'a8610ef7', 'a8610ef7', 'a8610ef7', 'a8610ef7', 'a934301b', 'a934301b', 'a934301b', 'aa18de87', 'aa18de87', 'aa18de87', 'aa18de87', 'aa300dc3')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6216216216216216\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6621621621621622\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6666666666666666\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.3979282081127167, Avg accuracy: 0.9047569409012794, Avg diff accuracy: 0.15470157657657657\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.3979282081127167, avg_accuracy=0.9047569409012794, diff_accuracy=0.15470157657657657\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.3979282081127167, 'task_ids': ('a096bf4d', 'a096bf4d', 'a3f84088', 'a3f84088', 'a3f84088', 'a3f84088', 'a406ac07', 'a406ac07', 'a406ac07', 'a57f2f04', 'a57f2f04', 'a57f2f04', 'a59b95c0', 'a59b95c0', 'a59b95c0', 'a59b95c0', 'a59b95c0', 'a680ac02', 'a680ac02', 'a680ac02', 'a8610ef7', 'a8610ef7', 'a8610ef7', 'a8610ef7', 'a934301b', 'a934301b', 'a934301b', 'aa18de87', 'aa18de87', 'aa18de87', 'aa18de87', 'aa300dc3'), 'test_accuracy': 0.9047569409012794, 'test_diff_accuracy': 0.15470157657657657, 'a096bf4d_test_accuracy': 0.8399999737739563, 'a096bf4d_test_diff_accuracy': 0.0, 'a3f84088_test_accuracy': 0.7322221994400024, 'a3f84088_test_diff_accuracy': 0.0, 'a406ac07_test_accuracy': 0.9566666483879089, 'a406ac07_test_diff_accuracy': 0.0, 'a57f2f04_test_accuracy': 0.6822222471237183, 'a57f2f04_test_diff_accuracy': 0.0, 'a59b95c0_test_accuracy': 0.9100000262260437, 'a59b95c0_test_diff_accuracy': 0.0, 'a680ac02_test_accuracy': 0.9555555582046509, 'a680ac02_test_diff_accuracy': 0.6666666666666666, 'a8610ef7_test_accuracy': 0.9766666889190674, 'a8610ef7_test_diff_accuracy': 0.0, 'a934301b_test_accuracy': 0.9599999785423279, 'a934301b_test_diff_accuracy': 1.0, 'aa18de87_test_accuracy': 0.9811111092567444, 'aa18de87_test_diff_accuracy': 0.0, 'aa300dc3_test_accuracy': 0.9300000071525574, 'aa300dc3_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.3979282081127167, 'task_ids': ('a096bf4d', 'a096bf4d', 'a3f84088', 'a3f84088', 'a3f84088', 'a3f84088', 'a406ac07', 'a406ac07', 'a406ac07', 'a57f2f04', 'a57f2f04', 'a57f2f04', 'a59b95c0', 'a59b95c0', 'a59b95c0', 'a59b95c0', 'a59b95c0', 'a680ac02', 'a680ac02', 'a680ac02', 'a8610ef7', 'a8610ef7', 'a8610ef7', 'a8610ef7', 'a934301b', 'a934301b', 'a934301b', 'aa18de87', 'aa18de87', 'aa18de87', 'aa18de87', 'aa300dc3'), 'test_accuracy': 0.9047569409012794, 'test_diff_accuracy': 0.15470157657657657, 'a096bf4d_test_accuracy': 0.8399999737739563, 'a096bf4d_test_diff_accuracy': 0.0, 'a3f84088_test_accuracy': 0.7322221994400024, 'a3f84088_test_diff_accuracy': 0.0, 'a406ac07_test_accuracy': 0.9566666483879089, 'a406ac07_test_diff_accuracy': 0.0, 'a57f2f04_test_accuracy': 0.6822222471237183, 'a57f2f04_test_diff_accuracy': 0.0, 'a59b95c0_test_accuracy': 0.9100000262260437, 'a59b95c0_test_diff_accuracy': 0.0, 'a680ac02_test_accuracy': 0.9555555582046509, 'a680ac02_test_diff_accuracy': 0.6666666666666666, 'a8610ef7_test_accuracy': 0.9766666889190674, 'a8610ef7_test_diff_accuracy': 0.0, 'a934301b_test_accuracy': 0.9599999785423279, 'a934301b_test_diff_accuracy': 1.0, 'aa18de87_test_accuracy': 0.9811111092567444, 'aa18de87_test_diff_accuracy': 0.0, 'aa300dc3_test_accuracy': 0.9300000071525574, 'aa300dc3_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('aa300dc3', 'aa300dc3', 'aa300dc3', 'aa4ec2a5', 'aa4ec2a5', 'aa4ec2a5', 'aab50785', 'aab50785', 'aab50785', 'aab50785', 'aab50785', 'ac0c5833', 'ac0c5833', 'ac0c5833', 'ac2e8ecf', 'ac2e8ecf', 'ac2e8ecf', 'ac3e2b04', 'ac3e2b04', 'ac3e2b04', 'ac3e2b04', 'ac605cbb', 'ac605cbb', 'ac605cbb', 'ac605cbb', 'ac605cbb', 'ac605cbb', 'ad7e01d0', 'ad7e01d0', 'ad7e01d0', 'ad7e01d0', 'ae58858e')], batch_idx: 27\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('aa300dc3', 'aa300dc3', 'aa300dc3', 'aa4ec2a5', 'aa4ec2a5', 'aa4ec2a5', 'aab50785', 'aab50785', 'aab50785', 'aab50785', 'aab50785', 'ac0c5833', 'ac0c5833', 'ac0c5833', 'ac2e8ecf', 'ac2e8ecf', 'ac2e8ecf', 'ac3e2b04', 'ac3e2b04', 'ac3e2b04', 'ac3e2b04', 'ac605cbb', 'ac605cbb', 'ac605cbb', 'ac605cbb', 'ac605cbb', 'ac605cbb', 'ad7e01d0', 'ad7e01d0', 'ad7e01d0', 'ad7e01d0', 'ae58858e')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8760330578512396\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9154929577464789\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.94\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8688524590163934\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9010989010989011\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4507042253521127\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4845360824742268\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.16666666666666666\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0967741935483871\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.07692307692307693\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.36217039823532104, Avg accuracy: 0.9083680585026741, Avg diff accuracy: 0.19615880064617136\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.36217039823532104, avg_accuracy=0.9083680585026741, diff_accuracy=0.19615880064617136\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.36217039823532104, 'task_ids': ('aa300dc3', 'aa300dc3', 'aa300dc3', 'aa4ec2a5', 'aa4ec2a5', 'aa4ec2a5', 'aab50785', 'aab50785', 'aab50785', 'aab50785', 'aab50785', 'ac0c5833', 'ac0c5833', 'ac0c5833', 'ac2e8ecf', 'ac2e8ecf', 'ac2e8ecf', 'ac3e2b04', 'ac3e2b04', 'ac3e2b04', 'ac3e2b04', 'ac605cbb', 'ac605cbb', 'ac605cbb', 'ac605cbb', 'ac605cbb', 'ac605cbb', 'ad7e01d0', 'ad7e01d0', 'ad7e01d0', 'ad7e01d0', 'ae58858e'), 'test_accuracy': 0.9083680585026741, 'test_diff_accuracy': 0.19615880064617136, 'aa300dc3_test_accuracy': 0.9255555272102356, 'aa300dc3_test_diff_accuracy': 0.0, 'aa4ec2a5_test_accuracy': 0.6666666865348816, 'aa4ec2a5_test_diff_accuracy': 0.0, 'aab50785_test_accuracy': 0.9900000095367432, 'aab50785_test_diff_accuracy': 0.9010989010989011, 'ac0c5833_test_accuracy': 0.9599999785423279, 'ac0c5833_test_diff_accuracy': 0.0, 'ac2e8ecf_test_accuracy': 0.9388889074325562, 'ac2e8ecf_test_diff_accuracy': 0.4845360824742268, 'ac3e2b04_test_accuracy': 0.897777795791626, 'ac3e2b04_test_diff_accuracy': 0.0, 'ac605cbb_test_accuracy': 0.992222249507904, 'ac605cbb_test_diff_accuracy': 0.0, 'ad7e01d0_test_accuracy': 0.7866666913032532, 'ad7e01d0_test_diff_accuracy': 0.07692307692307693, 'ae58858e_test_accuracy': 0.9755555391311646, 'ae58858e_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.36217039823532104, 'task_ids': ('aa300dc3', 'aa300dc3', 'aa300dc3', 'aa4ec2a5', 'aa4ec2a5', 'aa4ec2a5', 'aab50785', 'aab50785', 'aab50785', 'aab50785', 'aab50785', 'ac0c5833', 'ac0c5833', 'ac0c5833', 'ac2e8ecf', 'ac2e8ecf', 'ac2e8ecf', 'ac3e2b04', 'ac3e2b04', 'ac3e2b04', 'ac3e2b04', 'ac605cbb', 'ac605cbb', 'ac605cbb', 'ac605cbb', 'ac605cbb', 'ac605cbb', 'ad7e01d0', 'ad7e01d0', 'ad7e01d0', 'ad7e01d0', 'ae58858e'), 'test_accuracy': 0.9083680585026741, 'test_diff_accuracy': 0.19615880064617136, 'aa300dc3_test_accuracy': 0.9255555272102356, 'aa300dc3_test_diff_accuracy': 0.0, 'aa4ec2a5_test_accuracy': 0.6666666865348816, 'aa4ec2a5_test_diff_accuracy': 0.0, 'aab50785_test_accuracy': 0.9900000095367432, 'aab50785_test_diff_accuracy': 0.9010989010989011, 'ac0c5833_test_accuracy': 0.9599999785423279, 'ac0c5833_test_diff_accuracy': 0.0, 'ac2e8ecf_test_accuracy': 0.9388889074325562, 'ac2e8ecf_test_diff_accuracy': 0.4845360824742268, 'ac3e2b04_test_accuracy': 0.897777795791626, 'ac3e2b04_test_diff_accuracy': 0.0, 'ac605cbb_test_accuracy': 0.992222249507904, 'ac605cbb_test_diff_accuracy': 0.0, 'ad7e01d0_test_accuracy': 0.7866666913032532, 'ad7e01d0_test_diff_accuracy': 0.07692307692307693, 'ae58858e_test_accuracy': 0.9755555391311646, 'ae58858e_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('ae58858e', 'ae58858e', 'ae58858e', 'aee291af', 'aee291af', 'aee291af', 'af22c60d', 'af22c60d', 'af22c60d', 'af22c60d', 'af24b4cc', 'af24b4cc', 'af24b4cc', 'b0722778', 'b0722778', 'b0f4d537', 'b0f4d537', 'b0f4d537', 'b0f4d537', 'b15fca0b', 'b15fca0b', 'b15fca0b', 'b15fca0b', 'b15fca0b', 'b1fc8b8e', 'b1fc8b8e', 'b1fc8b8e', 'b1fc8b8e', 'b1fc8b8e', 'b20f7c8b', 'b20f7c8b', 'b20f7c8b')], batch_idx: 28\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('ae58858e', 'ae58858e', 'ae58858e', 'aee291af', 'aee291af', 'aee291af', 'af22c60d', 'af22c60d', 'af22c60d', 'af22c60d', 'af24b4cc', 'af24b4cc', 'af24b4cc', 'b0722778', 'b0722778', 'b0f4d537', 'b0f4d537', 'b0f4d537', 'b0f4d537', 'b15fca0b', 'b15fca0b', 'b15fca0b', 'b15fca0b', 'b15fca0b', 'b1fc8b8e', 'b1fc8b8e', 'b1fc8b8e', 'b1fc8b8e', 'b1fc8b8e', 'b20f7c8b', 'b20f7c8b', 'b20f7c8b')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9448818897637795\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9362549800796812\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.939873417721519\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.85\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8461538461538461\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8717948717948718\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7142857142857143\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7317073170731707\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5961538461538461\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6231884057971014\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6346153846153846\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4375\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.5331350564956665, Avg accuracy: 0.8368402756750584, Avg diff accuracy: 0.3664503022949661\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.5331350564956665, avg_accuracy=0.8368402756750584, diff_accuracy=0.3664503022949661\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.5331350564956665, 'task_ids': ('ae58858e', 'ae58858e', 'ae58858e', 'aee291af', 'aee291af', 'aee291af', 'af22c60d', 'af22c60d', 'af22c60d', 'af22c60d', 'af24b4cc', 'af24b4cc', 'af24b4cc', 'b0722778', 'b0722778', 'b0f4d537', 'b0f4d537', 'b0f4d537', 'b0f4d537', 'b15fca0b', 'b15fca0b', 'b15fca0b', 'b15fca0b', 'b15fca0b', 'b1fc8b8e', 'b1fc8b8e', 'b1fc8b8e', 'b1fc8b8e', 'b1fc8b8e', 'b20f7c8b', 'b20f7c8b', 'b20f7c8b'), 'test_accuracy': 0.8368402756750584, 'test_diff_accuracy': 0.3664503022949661, 'ae58858e_test_accuracy': 0.9855555295944214, 'ae58858e_test_diff_accuracy': 0.0, 'aee291af_test_accuracy': 0.9700000286102295, 'aee291af_test_diff_accuracy': 0.939873417721519, 'af22c60d_test_accuracy': 0.0, 'af22c60d_test_diff_accuracy': 0.0, 'af24b4cc_test_accuracy': 0.9933333396911621, 'af24b4cc_test_diff_accuracy': 0.8717948717948718, 'b0722778_test_accuracy': 0.9866666793823242, 'b0722778_test_diff_accuracy': 0.7317073170731707, 'b0f4d537_test_accuracy': 0.9788888692855835, 'b0f4d537_test_diff_accuracy': 0.6346153846153846, 'b15fca0b_test_accuracy': 0.9399999976158142, 'b15fca0b_test_diff_accuracy': 0.0, 'b1fc8b8e_test_accuracy': 0.9855555295944214, 'b1fc8b8e_test_diff_accuracy': 0.4375, 'b20f7c8b_test_accuracy': 0.7744444608688354, 'b20f7c8b_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.5331350564956665, 'task_ids': ('ae58858e', 'ae58858e', 'ae58858e', 'aee291af', 'aee291af', 'aee291af', 'af22c60d', 'af22c60d', 'af22c60d', 'af22c60d', 'af24b4cc', 'af24b4cc', 'af24b4cc', 'b0722778', 'b0722778', 'b0f4d537', 'b0f4d537', 'b0f4d537', 'b0f4d537', 'b15fca0b', 'b15fca0b', 'b15fca0b', 'b15fca0b', 'b15fca0b', 'b1fc8b8e', 'b1fc8b8e', 'b1fc8b8e', 'b1fc8b8e', 'b1fc8b8e', 'b20f7c8b', 'b20f7c8b', 'b20f7c8b'), 'test_accuracy': 0.8368402756750584, 'test_diff_accuracy': 0.3664503022949661, 'ae58858e_test_accuracy': 0.9855555295944214, 'ae58858e_test_diff_accuracy': 0.0, 'aee291af_test_accuracy': 0.9700000286102295, 'aee291af_test_diff_accuracy': 0.939873417721519, 'af22c60d_test_accuracy': 0.0, 'af22c60d_test_diff_accuracy': 0.0, 'af24b4cc_test_accuracy': 0.9933333396911621, 'af24b4cc_test_diff_accuracy': 0.8717948717948718, 'b0722778_test_accuracy': 0.9866666793823242, 'b0722778_test_diff_accuracy': 0.7317073170731707, 'b0f4d537_test_accuracy': 0.9788888692855835, 'b0f4d537_test_diff_accuracy': 0.6346153846153846, 'b15fca0b_test_accuracy': 0.9399999976158142, 'b15fca0b_test_diff_accuracy': 0.0, 'b1fc8b8e_test_accuracy': 0.9855555295944214, 'b1fc8b8e_test_diff_accuracy': 0.4375, 'b20f7c8b_test_accuracy': 0.7744444608688354, 'b20f7c8b_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('b457fec5', 'b457fec5', 'b457fec5', 'b4a43f3b', 'b4a43f3b', 'b4a43f3b', 'b4a43f3b', 'b7999b51', 'b7999b51', 'b7999b51', 'b7cb93ac', 'b7cb93ac', 'b7cb93ac', 'b7f8a4d8', 'b7f8a4d8', 'b7f8a4d8', 'b7fb29bc', 'b7fb29bc', 'b7fb29bc', 'b942fd60', 'b942fd60', 'b942fd60', 'b942fd60', 'b942fd60', 'b942fd60', 'b9630600', 'b9630600', 'b9630600', 'ba9d41b8', 'ba9d41b8', 'ba9d41b8', 'baf41dbf')], batch_idx: 29\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('b457fec5', 'b457fec5', 'b457fec5', 'b4a43f3b', 'b4a43f3b', 'b4a43f3b', 'b4a43f3b', 'b7999b51', 'b7999b51', 'b7999b51', 'b7cb93ac', 'b7cb93ac', 'b7cb93ac', 'b7f8a4d8', 'b7f8a4d8', 'b7f8a4d8', 'b7fb29bc', 'b7fb29bc', 'b7fb29bc', 'b942fd60', 'b942fd60', 'b942fd60', 'b942fd60', 'b942fd60', 'b942fd60', 'b9630600', 'b9630600', 'b9630600', 'ba9d41b8', 'ba9d41b8', 'ba9d41b8', 'baf41dbf')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.49122807017543857\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4805194805194805\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.44\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4642857142857143\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8732394366197183\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8529411764705882\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.85\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4444444444444444\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.45454545454545453\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.34615384615384615\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.36363636363636365\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.2608695652173913\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.3113536536693573, Avg accuracy: 0.9131249999627471, Avg diff accuracy: 0.32255823600213873\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.3113536536693573, avg_accuracy=0.9131249999627471, diff_accuracy=0.32255823600213873\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.3113536536693573, 'task_ids': ('b457fec5', 'b457fec5', 'b457fec5', 'b4a43f3b', 'b4a43f3b', 'b4a43f3b', 'b4a43f3b', 'b7999b51', 'b7999b51', 'b7999b51', 'b7cb93ac', 'b7cb93ac', 'b7cb93ac', 'b7f8a4d8', 'b7f8a4d8', 'b7f8a4d8', 'b7fb29bc', 'b7fb29bc', 'b7fb29bc', 'b942fd60', 'b942fd60', 'b942fd60', 'b942fd60', 'b942fd60', 'b942fd60', 'b9630600', 'b9630600', 'b9630600', 'ba9d41b8', 'ba9d41b8', 'ba9d41b8', 'baf41dbf'), 'test_accuracy': 0.9131249999627471, 'test_diff_accuracy': 0.32255823600213873, 'b457fec5_test_accuracy': 0.9066666960716248, 'b457fec5_test_diff_accuracy': 0.0, 'b4a43f3b_test_accuracy': 0.9666666388511658, 'b4a43f3b_test_diff_accuracy': 0.4642857142857143, 'b7999b51_test_accuracy': 0.9911110997200012, 'b7999b51_test_diff_accuracy': 0.85, 'b7cb93ac_test_accuracy': 0.9866666793823242, 'b7cb93ac_test_diff_accuracy': 0.5, 'b7f8a4d8_test_accuracy': 0.75, 'b7f8a4d8_test_diff_accuracy': 0.0, 'b7fb29bc_test_accuracy': 0.9100000262260437, 'b7fb29bc_test_diff_accuracy': 0.0, 'b942fd60_test_accuracy': 0.9722222089767456, 'b942fd60_test_diff_accuracy': 0.0, 'b9630600_test_accuracy': 0.8533333539962769, 'b9630600_test_diff_accuracy': 0.36363636363636365, 'ba9d41b8_test_accuracy': 0.8822222352027893, 'ba9d41b8_test_diff_accuracy': 1.0, 'baf41dbf_test_accuracy': 0.9655555486679077, 'baf41dbf_test_diff_accuracy': 0.2608695652173913}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.3113536536693573, 'task_ids': ('b457fec5', 'b457fec5', 'b457fec5', 'b4a43f3b', 'b4a43f3b', 'b4a43f3b', 'b4a43f3b', 'b7999b51', 'b7999b51', 'b7999b51', 'b7cb93ac', 'b7cb93ac', 'b7cb93ac', 'b7f8a4d8', 'b7f8a4d8', 'b7f8a4d8', 'b7fb29bc', 'b7fb29bc', 'b7fb29bc', 'b942fd60', 'b942fd60', 'b942fd60', 'b942fd60', 'b942fd60', 'b942fd60', 'b9630600', 'b9630600', 'b9630600', 'ba9d41b8', 'ba9d41b8', 'ba9d41b8', 'baf41dbf'), 'test_accuracy': 0.9131249999627471, 'test_diff_accuracy': 0.32255823600213873, 'b457fec5_test_accuracy': 0.9066666960716248, 'b457fec5_test_diff_accuracy': 0.0, 'b4a43f3b_test_accuracy': 0.9666666388511658, 'b4a43f3b_test_diff_accuracy': 0.4642857142857143, 'b7999b51_test_accuracy': 0.9911110997200012, 'b7999b51_test_diff_accuracy': 0.85, 'b7cb93ac_test_accuracy': 0.9866666793823242, 'b7cb93ac_test_diff_accuracy': 0.5, 'b7f8a4d8_test_accuracy': 0.75, 'b7f8a4d8_test_diff_accuracy': 0.0, 'b7fb29bc_test_accuracy': 0.9100000262260437, 'b7fb29bc_test_diff_accuracy': 0.0, 'b942fd60_test_accuracy': 0.9722222089767456, 'b942fd60_test_diff_accuracy': 0.0, 'b9630600_test_accuracy': 0.8533333539962769, 'b9630600_test_diff_accuracy': 0.36363636363636365, 'ba9d41b8_test_accuracy': 0.8822222352027893, 'ba9d41b8_test_diff_accuracy': 1.0, 'baf41dbf_test_accuracy': 0.9655555486679077, 'baf41dbf_test_diff_accuracy': 0.2608695652173913}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('baf41dbf', 'baf41dbf', 'bb52a14b', 'bb52a14b', 'bb52a14b', 'bbb1b8b6', 'bbb1b8b6', 'bbb1b8b6', 'bbb1b8b6', 'bbb1b8b6', 'bbb1b8b6', 'bbb1b8b6', 'bc4146bd', 'bc4146bd', 'bc4146bd', 'bc4146bd', 'bcb3040b', 'bcb3040b', 'bcb3040b', 'bd14c3bf', 'bd14c3bf', 'bd14c3bf', 'be03b35f', 'be03b35f', 'be03b35f', 'bf32578f', 'bf32578f', 'bf32578f', 'bf699163', 'bf699163', 'bf89d739', 'bf89d739')], batch_idx: 30\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('baf41dbf', 'baf41dbf', 'bb52a14b', 'bb52a14b', 'bb52a14b', 'bbb1b8b6', 'bbb1b8b6', 'bbb1b8b6', 'bbb1b8b6', 'bbb1b8b6', 'bbb1b8b6', 'bbb1b8b6', 'bc4146bd', 'bc4146bd', 'bc4146bd', 'bc4146bd', 'bcb3040b', 'bcb3040b', 'bcb3040b', 'bd14c3bf', 'bd14c3bf', 'bd14c3bf', 'be03b35f', 'be03b35f', 'be03b35f', 'bf32578f', 'bf32578f', 'bf32578f', 'bf699163', 'bf699163', 'bf89d739', 'bf89d739')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.16666666666666666\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.1875\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.46153846153846156\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6956521739130435\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.46153846153846156\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.45454545454545453\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5789473684210527\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6470588235294118\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4782608695652174\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8333333333333334\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.3333333333333333\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.42857142857142855\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.38461538461538464\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9704797047970479\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9737704918032787\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.1945578008890152, Avg accuracy: 0.9569097217172384, Avg diff accuracy: 0.30174412363036174\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.1945578008890152, avg_accuracy=0.9569097217172384, diff_accuracy=0.30174412363036174\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.1945578008890152, 'task_ids': ('baf41dbf', 'baf41dbf', 'bb52a14b', 'bb52a14b', 'bb52a14b', 'bbb1b8b6', 'bbb1b8b6', 'bbb1b8b6', 'bbb1b8b6', 'bbb1b8b6', 'bbb1b8b6', 'bbb1b8b6', 'bc4146bd', 'bc4146bd', 'bc4146bd', 'bc4146bd', 'bcb3040b', 'bcb3040b', 'bcb3040b', 'bd14c3bf', 'bd14c3bf', 'bd14c3bf', 'be03b35f', 'be03b35f', 'be03b35f', 'bf32578f', 'bf32578f', 'bf32578f', 'bf699163', 'bf699163', 'bf89d739', 'bf89d739'), 'test_accuracy': 0.9569097217172384, 'test_diff_accuracy': 0.30174412363036174, 'baf41dbf_test_accuracy': 0.9366666674613953, 'baf41dbf_test_diff_accuracy': 0.1875, 'bb52a14b_test_accuracy': 0.9177777767181396, 'bb52a14b_test_diff_accuracy': 0.0, 'bbb1b8b6_test_accuracy': 0.9822221994400024, 'bbb1b8b6_test_diff_accuracy': 0.4782608695652174, 'bc4146bd_test_accuracy': 0.9111111164093018, 'bc4146bd_test_diff_accuracy': 0.0, 'bcb3040b_test_accuracy': 0.9399999976158142, 'bcb3040b_test_diff_accuracy': 0.0, 'bd14c3bf_test_accuracy': 0.9144444465637207, 'bd14c3bf_test_diff_accuracy': 0.0, 'be03b35f_test_accuracy': 0.9977777600288391, 'be03b35f_test_diff_accuracy': 0.8333333333333334, 'bf32578f_test_accuracy': 0.9911110997200012, 'bf32578f_test_diff_accuracy': 0.38461538461538464, 'bf699163_test_accuracy': 0.9900000095367432, 'bf699163_test_diff_accuracy': 0.9737704918032787, 'bf89d739_test_accuracy': 0.9755555391311646, 'bf89d739_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.1945578008890152, 'task_ids': ('baf41dbf', 'baf41dbf', 'bb52a14b', 'bb52a14b', 'bb52a14b', 'bbb1b8b6', 'bbb1b8b6', 'bbb1b8b6', 'bbb1b8b6', 'bbb1b8b6', 'bbb1b8b6', 'bbb1b8b6', 'bc4146bd', 'bc4146bd', 'bc4146bd', 'bc4146bd', 'bcb3040b', 'bcb3040b', 'bcb3040b', 'bd14c3bf', 'bd14c3bf', 'bd14c3bf', 'be03b35f', 'be03b35f', 'be03b35f', 'bf32578f', 'bf32578f', 'bf32578f', 'bf699163', 'bf699163', 'bf89d739', 'bf89d739'), 'test_accuracy': 0.9569097217172384, 'test_diff_accuracy': 0.30174412363036174, 'baf41dbf_test_accuracy': 0.9366666674613953, 'baf41dbf_test_diff_accuracy': 0.1875, 'bb52a14b_test_accuracy': 0.9177777767181396, 'bb52a14b_test_diff_accuracy': 0.0, 'bbb1b8b6_test_accuracy': 0.9822221994400024, 'bbb1b8b6_test_diff_accuracy': 0.4782608695652174, 'bc4146bd_test_accuracy': 0.9111111164093018, 'bc4146bd_test_diff_accuracy': 0.0, 'bcb3040b_test_accuracy': 0.9399999976158142, 'bcb3040b_test_diff_accuracy': 0.0, 'bd14c3bf_test_accuracy': 0.9144444465637207, 'bd14c3bf_test_diff_accuracy': 0.0, 'be03b35f_test_accuracy': 0.9977777600288391, 'be03b35f_test_diff_accuracy': 0.8333333333333334, 'bf32578f_test_accuracy': 0.9911110997200012, 'bf32578f_test_diff_accuracy': 0.38461538461538464, 'bf699163_test_accuracy': 0.9900000095367432, 'bf699163_test_diff_accuracy': 0.9737704918032787, 'bf89d739_test_accuracy': 0.9755555391311646, 'bf89d739_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('bf89d739', 'bf89d739', 'c074846d', 'c074846d', 'c074846d', 'c074846d', 'c074846d', 'c1990cce', 'c1990cce', 'c1990cce', 'c3202e5a', 'c3202e5a', 'c3202e5a', 'c35c1b4c', 'c35c1b4c', 'c35c1b4c', 'c48954c1', 'c48954c1', 'c48954c1', 'c62e2108', 'c62e2108', 'c62e2108', 'c64f1187', 'c64f1187', 'c658a4bd', 'c658a4bd', 'c663677b', 'c663677b', 'c663677b', 'c6e1b8da', 'c6e1b8da', 'c6e1b8da')], batch_idx: 31\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('bf89d739', 'bf89d739', 'c074846d', 'c074846d', 'c074846d', 'c074846d', 'c074846d', 'c1990cce', 'c1990cce', 'c1990cce', 'c3202e5a', 'c3202e5a', 'c3202e5a', 'c35c1b4c', 'c35c1b4c', 'c35c1b4c', 'c48954c1', 'c48954c1', 'c48954c1', 'c62e2108', 'c62e2108', 'c62e2108', 'c64f1187', 'c64f1187', 'c658a4bd', 'c658a4bd', 'c663677b', 'c663677b', 'c663677b', 'c6e1b8da', 'c6e1b8da', 'c6e1b8da')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.02564102564102564\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.125\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.07142857142857142\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9642857142857143\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9715639810426541\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9864864864864865\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.02857142857142857\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.024390243902439025\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.07692307692307693\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7272727272727273\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.648936170212766\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.40476190476190477\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.34513274336283184\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.2978723404255319\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4666666666666667\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5869565217391305\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.5282468199729919, Avg accuracy: 0.8724305611103773, Avg diff accuracy: 0.21099655008509235\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.5282468199729919, avg_accuracy=0.8724305611103773, diff_accuracy=0.21099655008509235\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.5282468199729919, 'task_ids': ('bf89d739', 'bf89d739', 'c074846d', 'c074846d', 'c074846d', 'c074846d', 'c074846d', 'c1990cce', 'c1990cce', 'c1990cce', 'c3202e5a', 'c3202e5a', 'c3202e5a', 'c35c1b4c', 'c35c1b4c', 'c35c1b4c', 'c48954c1', 'c48954c1', 'c48954c1', 'c62e2108', 'c62e2108', 'c62e2108', 'c64f1187', 'c64f1187', 'c658a4bd', 'c658a4bd', 'c663677b', 'c663677b', 'c663677b', 'c6e1b8da', 'c6e1b8da', 'c6e1b8da'), 'test_accuracy': 0.8724305611103773, 'test_diff_accuracy': 0.21099655008509235, 'bf89d739_test_accuracy': 0.9700000286102295, 'bf89d739_test_diff_accuracy': 0.0, 'c074846d_test_accuracy': 0.9944444298744202, 'c074846d_test_diff_accuracy': 0.0, 'c1990cce_test_accuracy': 0.9855555295944214, 'c1990cce_test_diff_accuracy': 0.07142857142857142, 'c3202e5a_test_accuracy': 0.995555579662323, 'c3202e5a_test_diff_accuracy': 0.9864864864864865, 'c35c1b4c_test_accuracy': 0.9133333563804626, 'c35c1b4c_test_diff_accuracy': 0.0, 'c48954c1_test_accuracy': 0.9100000262260437, 'c48954c1_test_diff_accuracy': 0.0, 'c62e2108_test_accuracy': 0.8933333158493042, 'c62e2108_test_diff_accuracy': 0.07692307692307693, 'c64f1187_test_accuracy': 0.9622222185134888, 'c64f1187_test_diff_accuracy': 0.648936170212766, 'c658a4bd_test_accuracy': 0.9100000262260437, 'c658a4bd_test_diff_accuracy': 0.34513274336283184, 'c663677b_test_accuracy': 0.1899999976158142, 'c663677b_test_diff_accuracy': 0.0, 'c6e1b8da_test_accuracy': 0.8922222256660461, 'c6e1b8da_test_diff_accuracy': 0.5869565217391305}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.5282468199729919, 'task_ids': ('bf89d739', 'bf89d739', 'c074846d', 'c074846d', 'c074846d', 'c074846d', 'c074846d', 'c1990cce', 'c1990cce', 'c1990cce', 'c3202e5a', 'c3202e5a', 'c3202e5a', 'c35c1b4c', 'c35c1b4c', 'c35c1b4c', 'c48954c1', 'c48954c1', 'c48954c1', 'c62e2108', 'c62e2108', 'c62e2108', 'c64f1187', 'c64f1187', 'c658a4bd', 'c658a4bd', 'c663677b', 'c663677b', 'c663677b', 'c6e1b8da', 'c6e1b8da', 'c6e1b8da'), 'test_accuracy': 0.8724305611103773, 'test_diff_accuracy': 0.21099655008509235, 'bf89d739_test_accuracy': 0.9700000286102295, 'bf89d739_test_diff_accuracy': 0.0, 'c074846d_test_accuracy': 0.9944444298744202, 'c074846d_test_diff_accuracy': 0.0, 'c1990cce_test_accuracy': 0.9855555295944214, 'c1990cce_test_diff_accuracy': 0.07142857142857142, 'c3202e5a_test_accuracy': 0.995555579662323, 'c3202e5a_test_diff_accuracy': 0.9864864864864865, 'c35c1b4c_test_accuracy': 0.9133333563804626, 'c35c1b4c_test_diff_accuracy': 0.0, 'c48954c1_test_accuracy': 0.9100000262260437, 'c48954c1_test_diff_accuracy': 0.0, 'c62e2108_test_accuracy': 0.8933333158493042, 'c62e2108_test_diff_accuracy': 0.07692307692307693, 'c64f1187_test_accuracy': 0.9622222185134888, 'c64f1187_test_diff_accuracy': 0.648936170212766, 'c658a4bd_test_accuracy': 0.9100000262260437, 'c658a4bd_test_diff_accuracy': 0.34513274336283184, 'c663677b_test_accuracy': 0.1899999976158142, 'c663677b_test_diff_accuracy': 0.0, 'c6e1b8da_test_accuracy': 0.8922222256660461, 'c6e1b8da_test_diff_accuracy': 0.5869565217391305}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('c7d4e6ad', 'c7d4e6ad', 'c87289bb', 'c87289bb', 'c87289bb', 'c87289bb', 'c8b7cc0f', 'c8b7cc0f', 'c8b7cc0f', 'c92b942c', 'c92b942c', 'c92b942c', 'c92b942c', 'c97c0139', 'c97c0139', 'ca8de6ea', 'ca8de6ea', 'ca8de6ea', 'ca8f78db', 'ca8f78db', 'ca8f78db', 'cad67732', 'cad67732', 'cad67732', 'cb227835', 'cb227835', 'cb227835', 'ccd554ac', 'ccd554ac', 'ccd554ac', 'ccd554ac', 'ccd554ac')], batch_idx: 32\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('c7d4e6ad', 'c7d4e6ad', 'c87289bb', 'c87289bb', 'c87289bb', 'c87289bb', 'c8b7cc0f', 'c8b7cc0f', 'c8b7cc0f', 'c92b942c', 'c92b942c', 'c92b942c', 'c92b942c', 'c97c0139', 'c97c0139', 'ca8de6ea', 'ca8de6ea', 'ca8de6ea', 'ca8f78db', 'ca8f78db', 'ca8f78db', 'cad67732', 'cad67732', 'cad67732', 'cb227835', 'cb227835', 'cb227835', 'ccd554ac', 'ccd554ac', 'ccd554ac', 'ccd554ac', 'ccd554ac')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9166666666666666\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8620689655172413\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8857142857142857\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.3333333333333333\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.3333333333333333\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.3333333333333333\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.09090909090909091\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.03125\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.4812777638435364, Avg accuracy: 0.8679513931274414, Avg diff accuracy: 0.11833153152522764\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.4812777638435364, avg_accuracy=0.8679513931274414, diff_accuracy=0.11833153152522764\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.4812777638435364, 'task_ids': ('c7d4e6ad', 'c7d4e6ad', 'c87289bb', 'c87289bb', 'c87289bb', 'c87289bb', 'c8b7cc0f', 'c8b7cc0f', 'c8b7cc0f', 'c92b942c', 'c92b942c', 'c92b942c', 'c92b942c', 'c97c0139', 'c97c0139', 'ca8de6ea', 'ca8de6ea', 'ca8de6ea', 'ca8f78db', 'ca8f78db', 'ca8f78db', 'cad67732', 'cad67732', 'cad67732', 'cb227835', 'cb227835', 'cb227835', 'ccd554ac', 'ccd554ac', 'ccd554ac', 'ccd554ac', 'ccd554ac'), 'test_accuracy': 0.8679513931274414, 'test_diff_accuracy': 0.11833153152522764, 'c7d4e6ad_test_accuracy': 0.9766666889190674, 'c7d4e6ad_test_diff_accuracy': 0.0, 'c87289bb_test_accuracy': 0.9355555772781372, 'c87289bb_test_diff_accuracy': 0.0, 'c8b7cc0f_test_accuracy': 0.995555579662323, 'c8b7cc0f_test_diff_accuracy': 0.8857142857142857, 'c92b942c_test_accuracy': 0.9300000071525574, 'c92b942c_test_diff_accuracy': 0.0, 'c97c0139_test_accuracy': 0.9399999976158142, 'c97c0139_test_diff_accuracy': 0.0, 'ca8de6ea_test_accuracy': 0.9900000095367432, 'ca8de6ea_test_diff_accuracy': 0.3333333333333333, 'ca8f78db_test_accuracy': 0.0, 'ca8f78db_test_diff_accuracy': 0.0, 'cad67732_test_accuracy': 0.9822221994400024, 'cad67732_test_diff_accuracy': 0.0, 'cb227835_test_accuracy': 0.9777777791023254, 'cb227835_test_diff_accuracy': 0.0, 'ccd554ac_test_accuracy': 0.8577777743339539, 'ccd554ac_test_diff_accuracy': 0.03125}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.4812777638435364, 'task_ids': ('c7d4e6ad', 'c7d4e6ad', 'c87289bb', 'c87289bb', 'c87289bb', 'c87289bb', 'c8b7cc0f', 'c8b7cc0f', 'c8b7cc0f', 'c92b942c', 'c92b942c', 'c92b942c', 'c92b942c', 'c97c0139', 'c97c0139', 'ca8de6ea', 'ca8de6ea', 'ca8de6ea', 'ca8f78db', 'ca8f78db', 'ca8f78db', 'cad67732', 'cad67732', 'cad67732', 'cb227835', 'cb227835', 'cb227835', 'ccd554ac', 'ccd554ac', 'ccd554ac', 'ccd554ac', 'ccd554ac'), 'test_accuracy': 0.8679513931274414, 'test_diff_accuracy': 0.11833153152522764, 'c7d4e6ad_test_accuracy': 0.9766666889190674, 'c7d4e6ad_test_diff_accuracy': 0.0, 'c87289bb_test_accuracy': 0.9355555772781372, 'c87289bb_test_diff_accuracy': 0.0, 'c8b7cc0f_test_accuracy': 0.995555579662323, 'c8b7cc0f_test_diff_accuracy': 0.8857142857142857, 'c92b942c_test_accuracy': 0.9300000071525574, 'c92b942c_test_diff_accuracy': 0.0, 'c97c0139_test_accuracy': 0.9399999976158142, 'c97c0139_test_diff_accuracy': 0.0, 'ca8de6ea_test_accuracy': 0.9900000095367432, 'ca8de6ea_test_diff_accuracy': 0.3333333333333333, 'ca8f78db_test_accuracy': 0.0, 'ca8f78db_test_diff_accuracy': 0.0, 'cad67732_test_accuracy': 0.9822221994400024, 'cad67732_test_diff_accuracy': 0.0, 'cb227835_test_accuracy': 0.9777777791023254, 'cb227835_test_diff_accuracy': 0.0, 'ccd554ac_test_accuracy': 0.8577777743339539, 'ccd554ac_test_diff_accuracy': 0.03125}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('ccd554ac', 'cd3c21df', 'cd3c21df', 'cd3c21df', 'ce039d91', 'ce039d91', 'ce039d91', 'ce039d91', 'ce8d95cc', 'ce8d95cc', 'ce8d95cc', 'ce8d95cc', 'cf133acc', 'cf133acc', 'cf133acc', 'cfb2ce5a', 'cfb2ce5a', 'cfb2ce5a', 'd017b73f', 'd017b73f', 'd017b73f', 'd017b73f', 'd19f7514', 'd19f7514', 'd19f7514', 'd19f7514', 'd282b262', 'd282b262', 'd282b262', 'd2acf2cb', 'd2acf2cb', 'd2acf2cb')], batch_idx: 33\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('ccd554ac', 'cd3c21df', 'cd3c21df', 'cd3c21df', 'ce039d91', 'ce039d91', 'ce039d91', 'ce039d91', 'ce8d95cc', 'ce8d95cc', 'ce8d95cc', 'ce8d95cc', 'cf133acc', 'cf133acc', 'cf133acc', 'cfb2ce5a', 'cfb2ce5a', 'cfb2ce5a', 'd017b73f', 'd017b73f', 'd017b73f', 'd017b73f', 'd19f7514', 'd19f7514', 'd19f7514', 'd19f7514', 'd282b262', 'd282b262', 'd282b262', 'd2acf2cb', 'd2acf2cb', 'd2acf2cb')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.03125\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8333333333333334\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8181818181818182\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8125\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.68\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.75\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.78125\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6666666666666666\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5714285714285714\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4857142857142857\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.47058823529411764\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4473684210526316\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.47761194029850745\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.45454545454545453\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.2857142857142857\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.18037037551403046, Avg accuracy: 0.9664930570870638, Avg diff accuracy: 0.3458172816321773\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.18037037551403046, avg_accuracy=0.9664930570870638, diff_accuracy=0.3458172816321773\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.18037037551403046, 'task_ids': ('ccd554ac', 'cd3c21df', 'cd3c21df', 'cd3c21df', 'ce039d91', 'ce039d91', 'ce039d91', 'ce039d91', 'ce8d95cc', 'ce8d95cc', 'ce8d95cc', 'ce8d95cc', 'cf133acc', 'cf133acc', 'cf133acc', 'cfb2ce5a', 'cfb2ce5a', 'cfb2ce5a', 'd017b73f', 'd017b73f', 'd017b73f', 'd017b73f', 'd19f7514', 'd19f7514', 'd19f7514', 'd19f7514', 'd282b262', 'd282b262', 'd282b262', 'd2acf2cb', 'd2acf2cb', 'd2acf2cb'), 'test_accuracy': 0.9664930570870638, 'test_diff_accuracy': 0.3458172816321773, 'ccd554ac_test_accuracy': 0.8577777743339539, 'ccd554ac_test_diff_accuracy': 0.03125, 'cd3c21df_test_accuracy': 0.9933333396911621, 'cd3c21df_test_diff_accuracy': 0.8125, 'ce039d91_test_accuracy': 0.9788888692855835, 'ce039d91_test_diff_accuracy': 0.0, 'ce8d95cc_test_accuracy': 0.9744444489479065, 'ce8d95cc_test_diff_accuracy': 0.6666666666666666, 'cf133acc_test_accuracy': 0.9222221970558167, 'cf133acc_test_diff_accuracy': 0.0, 'cfb2ce5a_test_accuracy': 0.9288889169692993, 'cfb2ce5a_test_diff_accuracy': 0.0, 'd017b73f_test_accuracy': 0.9877777695655823, 'd017b73f_test_diff_accuracy': 0.5, 'd19f7514_test_accuracy': 0.9766666889190674, 'd19f7514_test_diff_accuracy': 0.4473684210526316, 'd282b262_test_accuracy': 0.9655555486679077, 'd282b262_test_diff_accuracy': 0.45454545454545453, 'd2acf2cb_test_accuracy': 0.9622222185134888, 'd2acf2cb_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.18037037551403046, 'task_ids': ('ccd554ac', 'cd3c21df', 'cd3c21df', 'cd3c21df', 'ce039d91', 'ce039d91', 'ce039d91', 'ce039d91', 'ce8d95cc', 'ce8d95cc', 'ce8d95cc', 'ce8d95cc', 'cf133acc', 'cf133acc', 'cf133acc', 'cfb2ce5a', 'cfb2ce5a', 'cfb2ce5a', 'd017b73f', 'd017b73f', 'd017b73f', 'd017b73f', 'd19f7514', 'd19f7514', 'd19f7514', 'd19f7514', 'd282b262', 'd282b262', 'd282b262', 'd2acf2cb', 'd2acf2cb', 'd2acf2cb'), 'test_accuracy': 0.9664930570870638, 'test_diff_accuracy': 0.3458172816321773, 'ccd554ac_test_accuracy': 0.8577777743339539, 'ccd554ac_test_diff_accuracy': 0.03125, 'cd3c21df_test_accuracy': 0.9933333396911621, 'cd3c21df_test_diff_accuracy': 0.8125, 'ce039d91_test_accuracy': 0.9788888692855835, 'ce039d91_test_diff_accuracy': 0.0, 'ce8d95cc_test_accuracy': 0.9744444489479065, 'ce8d95cc_test_diff_accuracy': 0.6666666666666666, 'cf133acc_test_accuracy': 0.9222221970558167, 'cf133acc_test_diff_accuracy': 0.0, 'cfb2ce5a_test_accuracy': 0.9288889169692993, 'cfb2ce5a_test_diff_accuracy': 0.0, 'd017b73f_test_accuracy': 0.9877777695655823, 'd017b73f_test_diff_accuracy': 0.5, 'd19f7514_test_accuracy': 0.9766666889190674, 'd19f7514_test_diff_accuracy': 0.4473684210526316, 'd282b262_test_accuracy': 0.9655555486679077, 'd282b262_test_diff_accuracy': 0.45454545454545453, 'd2acf2cb_test_accuracy': 0.9622222185134888, 'd2acf2cb_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('d304284e', 'd304284e', 'd37a1ef5', 'd37a1ef5', 'd37a1ef5', 'd47aa2ff', 'd47aa2ff', 'd47aa2ff', 'd492a647', 'd492a647', 'd4b1c2b1', 'd4b1c2b1', 'd4b1c2b1', 'd4b1c2b1', 'd4b1c2b1', 'd4b1c2b1', 'd4b1c2b1', 'd4c90558', 'd4c90558', 'd4c90558', 'd56f2372', 'd56f2372', 'd56f2372', 'd5c634a2', 'd5c634a2', 'd5c634a2', 'd5c634a2', 'd5c634a2', 'd5c634a2', 'd5c634a2', 'd931c21c', 'd931c21c')], batch_idx: 34\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('d304284e', 'd304284e', 'd37a1ef5', 'd37a1ef5', 'd37a1ef5', 'd47aa2ff', 'd47aa2ff', 'd47aa2ff', 'd492a647', 'd492a647', 'd4b1c2b1', 'd4b1c2b1', 'd4b1c2b1', 'd4b1c2b1', 'd4b1c2b1', 'd4b1c2b1', 'd4b1c2b1', 'd4c90558', 'd4c90558', 'd4c90558', 'd56f2372', 'd56f2372', 'd56f2372', 'd5c634a2', 'd5c634a2', 'd5c634a2', 'd5c634a2', 'd5c634a2', 'd5c634a2', 'd5c634a2', 'd931c21c', 'd931c21c')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7419354838709677\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7142857142857143\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7142857142857143\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8797814207650273\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9306930693069307\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9084967320261438\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8275862068965517\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7571428571428571\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8333333333333334\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7941176470588235\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7857142857142857\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7777777777777778\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7894736842105263\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7727272727272727\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.2449212372303009, Avg accuracy: 0.9594097211956978, Avg diff accuracy: 0.4946047249813102\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.2449212372303009, avg_accuracy=0.9594097211956978, diff_accuracy=0.4946047249813102\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.2449212372303009, 'task_ids': ('d304284e', 'd304284e', 'd37a1ef5', 'd37a1ef5', 'd37a1ef5', 'd47aa2ff', 'd47aa2ff', 'd47aa2ff', 'd492a647', 'd492a647', 'd4b1c2b1', 'd4b1c2b1', 'd4b1c2b1', 'd4b1c2b1', 'd4b1c2b1', 'd4b1c2b1', 'd4b1c2b1', 'd4c90558', 'd4c90558', 'd4c90558', 'd56f2372', 'd56f2372', 'd56f2372', 'd5c634a2', 'd5c634a2', 'd5c634a2', 'd5c634a2', 'd5c634a2', 'd5c634a2', 'd5c634a2', 'd931c21c', 'd931c21c'), 'test_accuracy': 0.9594097211956978, 'test_diff_accuracy': 0.4946047249813102, 'd304284e_test_accuracy': 0.8788889050483704, 'd304284e_test_diff_accuracy': 0.0, 'd37a1ef5_test_accuracy': 0.9200000166893005, 'd37a1ef5_test_diff_accuracy': 0.0, 'd47aa2ff_test_accuracy': 0.9888888597488403, 'd47aa2ff_test_diff_accuracy': 0.7142857142857143, 'd492a647_test_accuracy': 0.8933333158493042, 'd492a647_test_diff_accuracy': 0.0, 'd4b1c2b1_test_accuracy': 0.9599999785423279, 'd4b1c2b1_test_diff_accuracy': 0.0, 'd4c90558_test_accuracy': 0.9811111092567444, 'd4c90558_test_diff_accuracy': 0.9084967320261438, 'd56f2372_test_accuracy': 0.9900000095367432, 'd56f2372_test_diff_accuracy': 0.8333333333333334, 'd5c634a2_test_accuracy': 0.9944444298744202, 'd5c634a2_test_diff_accuracy': 0.7727272727272727, 'd931c21c_test_accuracy': 0.9811111092567444, 'd931c21c_test_diff_accuracy': 1.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.2449212372303009, 'task_ids': ('d304284e', 'd304284e', 'd37a1ef5', 'd37a1ef5', 'd37a1ef5', 'd47aa2ff', 'd47aa2ff', 'd47aa2ff', 'd492a647', 'd492a647', 'd4b1c2b1', 'd4b1c2b1', 'd4b1c2b1', 'd4b1c2b1', 'd4b1c2b1', 'd4b1c2b1', 'd4b1c2b1', 'd4c90558', 'd4c90558', 'd4c90558', 'd56f2372', 'd56f2372', 'd56f2372', 'd5c634a2', 'd5c634a2', 'd5c634a2', 'd5c634a2', 'd5c634a2', 'd5c634a2', 'd5c634a2', 'd931c21c', 'd931c21c'), 'test_accuracy': 0.9594097211956978, 'test_diff_accuracy': 0.4946047249813102, 'd304284e_test_accuracy': 0.8788889050483704, 'd304284e_test_diff_accuracy': 0.0, 'd37a1ef5_test_accuracy': 0.9200000166893005, 'd37a1ef5_test_diff_accuracy': 0.0, 'd47aa2ff_test_accuracy': 0.9888888597488403, 'd47aa2ff_test_diff_accuracy': 0.7142857142857143, 'd492a647_test_accuracy': 0.8933333158493042, 'd492a647_test_diff_accuracy': 0.0, 'd4b1c2b1_test_accuracy': 0.9599999785423279, 'd4b1c2b1_test_diff_accuracy': 0.0, 'd4c90558_test_accuracy': 0.9811111092567444, 'd4c90558_test_diff_accuracy': 0.9084967320261438, 'd56f2372_test_accuracy': 0.9900000095367432, 'd56f2372_test_diff_accuracy': 0.8333333333333334, 'd5c634a2_test_accuracy': 0.9944444298744202, 'd5c634a2_test_diff_accuracy': 0.7727272727272727, 'd931c21c_test_accuracy': 0.9811111092567444, 'd931c21c_test_diff_accuracy': 1.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('d931c21c', 'd931c21c', 'd94c3b52', 'd94c3b52', 'd94c3b52', 'da2b0fe3', 'da2b0fe3', 'da2b0fe3', 'da515329', 'da515329', 'da515329', 'dc2aa30b', 'dc2aa30b', 'dc2aa30b', 'dc2e9a9d', 'dc2e9a9d', 'dc2e9a9d', 'dd2401ed', 'dd2401ed', 'dd2401ed', 'dd2401ed', 'de493100', 'de493100', 'de493100', 'de493100', 'df8cc377', 'df8cc377', 'df8cc377', 'e0fb7511', 'e0fb7511', 'e0fb7511', 'e133d23d')], batch_idx: 35\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('d931c21c', 'd931c21c', 'd94c3b52', 'd94c3b52', 'd94c3b52', 'da2b0fe3', 'da2b0fe3', 'da2b0fe3', 'da515329', 'da515329', 'da515329', 'dc2aa30b', 'dc2aa30b', 'dc2aa30b', 'dc2e9a9d', 'dc2e9a9d', 'dc2e9a9d', 'dd2401ed', 'dd2401ed', 'dd2401ed', 'dd2401ed', 'de493100', 'de493100', 'de493100', 'de493100', 'df8cc377', 'df8cc377', 'df8cc377', 'e0fb7511', 'e0fb7511', 'e0fb7511', 'e133d23d')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4117647058823529\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.3333333333333333\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.22635135135135134\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.43191964285714285\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.19409761634506242\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.15607580824972128\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5714285714285714\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.5498566627502441, Avg accuracy: 0.8259027814492583, Avg diff accuracy: 0.1507803446702355\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.5498566627502441, avg_accuracy=0.8259027814492583, diff_accuracy=0.1507803446702355\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.5498566627502441, 'task_ids': ('d931c21c', 'd931c21c', 'd94c3b52', 'd94c3b52', 'd94c3b52', 'da2b0fe3', 'da2b0fe3', 'da2b0fe3', 'da515329', 'da515329', 'da515329', 'dc2aa30b', 'dc2aa30b', 'dc2aa30b', 'dc2e9a9d', 'dc2e9a9d', 'dc2e9a9d', 'dd2401ed', 'dd2401ed', 'dd2401ed', 'dd2401ed', 'de493100', 'de493100', 'de493100', 'de493100', 'df8cc377', 'df8cc377', 'df8cc377', 'e0fb7511', 'e0fb7511', 'e0fb7511', 'e133d23d'), 'test_accuracy': 0.8259027814492583, 'test_diff_accuracy': 0.1507803446702355, 'd931c21c_test_accuracy': 0.846666693687439, 'd931c21c_test_diff_accuracy': 0.0, 'd94c3b52_test_accuracy': 0.8455555438995361, 'd94c3b52_test_diff_accuracy': 0.0, 'da2b0fe3_test_accuracy': 0.9677777886390686, 'da2b0fe3_test_diff_accuracy': 0.0, 'da515329_test_accuracy': 0.8588888645172119, 'da515329_test_diff_accuracy': 0.0, 'dc2aa30b_test_accuracy': 0.9100000262260437, 'dc2aa30b_test_diff_accuracy': 0.0, 'dc2e9a9d_test_accuracy': 0.9133333563804626, 'dc2e9a9d_test_diff_accuracy': 0.0, 'dd2401ed_test_accuracy': 0.9811111092567444, 'dd2401ed_test_diff_accuracy': 0.5, 'de493100_test_accuracy': 0.15777777135372162, 'de493100_test_diff_accuracy': 0.15607580824972128, 'df8cc377_test_accuracy': 0.9744444489479065, 'df8cc377_test_diff_accuracy': 0.5, 'e0fb7511_test_accuracy': 0.8288888931274414, 'e0fb7511_test_diff_accuracy': 0.0, 'e133d23d_test_accuracy': 0.9933333396911621, 'e133d23d_test_diff_accuracy': 0.5714285714285714}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.5498566627502441, 'task_ids': ('d931c21c', 'd931c21c', 'd94c3b52', 'd94c3b52', 'd94c3b52', 'da2b0fe3', 'da2b0fe3', 'da2b0fe3', 'da515329', 'da515329', 'da515329', 'dc2aa30b', 'dc2aa30b', 'dc2aa30b', 'dc2e9a9d', 'dc2e9a9d', 'dc2e9a9d', 'dd2401ed', 'dd2401ed', 'dd2401ed', 'dd2401ed', 'de493100', 'de493100', 'de493100', 'de493100', 'df8cc377', 'df8cc377', 'df8cc377', 'e0fb7511', 'e0fb7511', 'e0fb7511', 'e133d23d'), 'test_accuracy': 0.8259027814492583, 'test_diff_accuracy': 0.1507803446702355, 'd931c21c_test_accuracy': 0.846666693687439, 'd931c21c_test_diff_accuracy': 0.0, 'd94c3b52_test_accuracy': 0.8455555438995361, 'd94c3b52_test_diff_accuracy': 0.0, 'da2b0fe3_test_accuracy': 0.9677777886390686, 'da2b0fe3_test_diff_accuracy': 0.0, 'da515329_test_accuracy': 0.8588888645172119, 'da515329_test_diff_accuracy': 0.0, 'dc2aa30b_test_accuracy': 0.9100000262260437, 'dc2aa30b_test_diff_accuracy': 0.0, 'dc2e9a9d_test_accuracy': 0.9133333563804626, 'dc2e9a9d_test_diff_accuracy': 0.0, 'dd2401ed_test_accuracy': 0.9811111092567444, 'dd2401ed_test_diff_accuracy': 0.5, 'de493100_test_accuracy': 0.15777777135372162, 'de493100_test_diff_accuracy': 0.15607580824972128, 'df8cc377_test_accuracy': 0.9744444489479065, 'df8cc377_test_diff_accuracy': 0.5, 'e0fb7511_test_accuracy': 0.8288888931274414, 'e0fb7511_test_diff_accuracy': 0.0, 'e133d23d_test_accuracy': 0.9933333396911621, 'e133d23d_test_diff_accuracy': 0.5714285714285714}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('e133d23d', 'e133d23d', 'e133d23d', 'e133d23d', 'e1baa8a4', 'e1baa8a4', 'e1baa8a4', 'e1baa8a4', 'e1d2900e', 'e1d2900e', 'e1d2900e', 'e2092e0c', 'e2092e0c', 'e2092e0c', 'e21a174a', 'e21a174a', 'e21a174a', 'e345f17b', 'e345f17b', 'e345f17b', 'e345f17b', 'e4075551', 'e4075551', 'e4075551', 'e41c6fd3', 'e41c6fd3', 'e41c6fd3', 'e57337a4', 'e57337a4', 'e57337a4', 'e5790162', 'e5790162')], batch_idx: 36\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('e133d23d', 'e133d23d', 'e133d23d', 'e133d23d', 'e1baa8a4', 'e1baa8a4', 'e1baa8a4', 'e1baa8a4', 'e1d2900e', 'e1d2900e', 'e1d2900e', 'e2092e0c', 'e2092e0c', 'e2092e0c', 'e21a174a', 'e21a174a', 'e21a174a', 'e345f17b', 'e345f17b', 'e345f17b', 'e345f17b', 'e4075551', 'e4075551', 'e4075551', 'e41c6fd3', 'e41c6fd3', 'e41c6fd3', 'e57337a4', 'e57337a4', 'e57337a4', 'e5790162', 'e5790162')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.38461538461538464\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.46153846153846156\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9845360824742269\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9700598802395209\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9760765550239234\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9103139013452914\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.24528301886792453\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.2972972972972973\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.2222222222222222\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7058823529411765\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.85\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8421052631578947\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8571428571428571\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.27314814814814814\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.2777777777777778\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.2137870341539383, Avg accuracy: 0.9569791667163372, Avg diff accuracy: 0.4486874750872534\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.2137870341539383, avg_accuracy=0.9569791667163372, diff_accuracy=0.4486874750872534\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.2137870341539383, 'task_ids': ('e133d23d', 'e133d23d', 'e133d23d', 'e133d23d', 'e1baa8a4', 'e1baa8a4', 'e1baa8a4', 'e1baa8a4', 'e1d2900e', 'e1d2900e', 'e1d2900e', 'e2092e0c', 'e2092e0c', 'e2092e0c', 'e21a174a', 'e21a174a', 'e21a174a', 'e345f17b', 'e345f17b', 'e345f17b', 'e345f17b', 'e4075551', 'e4075551', 'e4075551', 'e41c6fd3', 'e41c6fd3', 'e41c6fd3', 'e57337a4', 'e57337a4', 'e57337a4', 'e5790162', 'e5790162'), 'test_accuracy': 0.9569791667163372, 'test_diff_accuracy': 0.4486874750872534, 'e133d23d_test_accuracy': 0.995555579662323, 'e133d23d_test_diff_accuracy': 0.6, 'e1baa8a4_test_accuracy': 0.9755555391311646, 'e1baa8a4_test_diff_accuracy': 0.9103139013452914, 'e1d2900e_test_accuracy': 0.9877777695655823, 'e1d2900e_test_diff_accuracy': 0.5, 'e2092e0c_test_accuracy': 0.8888888955116272, 'e2092e0c_test_diff_accuracy': 0.0, 'e21a174a_test_accuracy': 0.9811111092567444, 'e21a174a_test_diff_accuracy': 0.2222222222222222, 'e345f17b_test_accuracy': 0.996666669845581, 'e345f17b_test_diff_accuracy': 0.8571428571428571, 'e4075551_test_accuracy': 0.9366666674613953, 'e4075551_test_diff_accuracy': 0.0, 'e41c6fd3_test_accuracy': 0.9333333373069763, 'e41c6fd3_test_diff_accuracy': 0.5, 'e57337a4_test_accuracy': 0.9933333396911621, 'e57337a4_test_diff_accuracy': 1.0, 'e5790162_test_accuracy': 0.9888888597488403, 'e5790162_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.2137870341539383, 'task_ids': ('e133d23d', 'e133d23d', 'e133d23d', 'e133d23d', 'e1baa8a4', 'e1baa8a4', 'e1baa8a4', 'e1baa8a4', 'e1d2900e', 'e1d2900e', 'e1d2900e', 'e2092e0c', 'e2092e0c', 'e2092e0c', 'e21a174a', 'e21a174a', 'e21a174a', 'e345f17b', 'e345f17b', 'e345f17b', 'e345f17b', 'e4075551', 'e4075551', 'e4075551', 'e41c6fd3', 'e41c6fd3', 'e41c6fd3', 'e57337a4', 'e57337a4', 'e57337a4', 'e5790162', 'e5790162'), 'test_accuracy': 0.9569791667163372, 'test_diff_accuracy': 0.4486874750872534, 'e133d23d_test_accuracy': 0.995555579662323, 'e133d23d_test_diff_accuracy': 0.6, 'e1baa8a4_test_accuracy': 0.9755555391311646, 'e1baa8a4_test_diff_accuracy': 0.9103139013452914, 'e1d2900e_test_accuracy': 0.9877777695655823, 'e1d2900e_test_diff_accuracy': 0.5, 'e2092e0c_test_accuracy': 0.8888888955116272, 'e2092e0c_test_diff_accuracy': 0.0, 'e21a174a_test_accuracy': 0.9811111092567444, 'e21a174a_test_diff_accuracy': 0.2222222222222222, 'e345f17b_test_accuracy': 0.996666669845581, 'e345f17b_test_diff_accuracy': 0.8571428571428571, 'e4075551_test_accuracy': 0.9366666674613953, 'e4075551_test_diff_accuracy': 0.0, 'e41c6fd3_test_accuracy': 0.9333333373069763, 'e41c6fd3_test_diff_accuracy': 0.5, 'e57337a4_test_accuracy': 0.9933333396911621, 'e57337a4_test_diff_accuracy': 1.0, 'e5790162_test_accuracy': 0.9888888597488403, 'e5790162_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('e5790162', 'e5790162', 'e5790162', 'e5c44e8f', 'e5c44e8f', 'e5c44e8f', 'e619ca6e', 'e619ca6e', 'e619ca6e', 'e633a9e5', 'e633a9e5', 'e633a9e5', 'e66aafb8', 'e66aafb8', 'e66aafb8', 'e66aafb8', 'e66aafb8', 'e681b708', 'e681b708', 'e681b708', 'e69241bd', 'e69241bd', 'e69241bd', 'e6de6e8f', 'e6de6e8f', 'e6de6e8f', 'e74e1818', 'e74e1818', 'e74e1818', 'e760a62e', 'e760a62e', 'e760a62e')], batch_idx: 37\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('e5790162', 'e5790162', 'e5790162', 'e5c44e8f', 'e5c44e8f', 'e5c44e8f', 'e619ca6e', 'e619ca6e', 'e619ca6e', 'e633a9e5', 'e633a9e5', 'e633a9e5', 'e66aafb8', 'e66aafb8', 'e66aafb8', 'e66aafb8', 'e66aafb8', 'e681b708', 'e681b708', 'e681b708', 'e69241bd', 'e69241bd', 'e69241bd', 'e6de6e8f', 'e6de6e8f', 'e6de6e8f', 'e74e1818', 'e74e1818', 'e74e1818', 'e760a62e', 'e760a62e', 'e760a62e')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8949343339587242\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8983957219251337\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9429097605893186\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.967032967032967\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9246704331450094\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5416666666666666\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.55\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5416666666666666\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.4079769551753998, Avg accuracy: 0.9159027803689241, Avg diff accuracy: 0.2425398921870152\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.4079769551753998, avg_accuracy=0.9159027803689241, diff_accuracy=0.2425398921870152\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.4079769551753998, 'task_ids': ('e5790162', 'e5790162', 'e5790162', 'e5c44e8f', 'e5c44e8f', 'e5c44e8f', 'e619ca6e', 'e619ca6e', 'e619ca6e', 'e633a9e5', 'e633a9e5', 'e633a9e5', 'e66aafb8', 'e66aafb8', 'e66aafb8', 'e66aafb8', 'e66aafb8', 'e681b708', 'e681b708', 'e681b708', 'e69241bd', 'e69241bd', 'e69241bd', 'e6de6e8f', 'e6de6e8f', 'e6de6e8f', 'e74e1818', 'e74e1818', 'e74e1818', 'e760a62e', 'e760a62e', 'e760a62e'), 'test_accuracy': 0.9159027803689241, 'test_diff_accuracy': 0.2425398921870152, 'e5790162_test_accuracy': 0.9855555295944214, 'e5790162_test_diff_accuracy': 0.0, 'e5c44e8f_test_accuracy': 0.9644444584846497, 'e5c44e8f_test_diff_accuracy': 0.0, 'e619ca6e_test_accuracy': 0.8777777552604675, 'e619ca6e_test_diff_accuracy': 0.0, 'e633a9e5_test_accuracy': 0.9722222089767456, 'e633a9e5_test_diff_accuracy': 0.0, 'e66aafb8_test_accuracy': 0.9522222280502319, 'e66aafb8_test_diff_accuracy': 0.9246704331450094, 'e681b708_test_accuracy': 0.9111111164093018, 'e681b708_test_diff_accuracy': 0.0, 'e69241bd_test_accuracy': 0.9555555582046509, 'e69241bd_test_diff_accuracy': 0.0, 'e6de6e8f_test_accuracy': 0.9877777695655823, 'e6de6e8f_test_diff_accuracy': 0.5416666666666666, 'e74e1818_test_accuracy': 0.9833333492279053, 'e74e1818_test_diff_accuracy': 0.5, 'e760a62e_test_accuracy': 0.5922222137451172, 'e760a62e_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.4079769551753998, 'task_ids': ('e5790162', 'e5790162', 'e5790162', 'e5c44e8f', 'e5c44e8f', 'e5c44e8f', 'e619ca6e', 'e619ca6e', 'e619ca6e', 'e633a9e5', 'e633a9e5', 'e633a9e5', 'e66aafb8', 'e66aafb8', 'e66aafb8', 'e66aafb8', 'e66aafb8', 'e681b708', 'e681b708', 'e681b708', 'e69241bd', 'e69241bd', 'e69241bd', 'e6de6e8f', 'e6de6e8f', 'e6de6e8f', 'e74e1818', 'e74e1818', 'e74e1818', 'e760a62e', 'e760a62e', 'e760a62e'), 'test_accuracy': 0.9159027803689241, 'test_diff_accuracy': 0.2425398921870152, 'e5790162_test_accuracy': 0.9855555295944214, 'e5790162_test_diff_accuracy': 0.0, 'e5c44e8f_test_accuracy': 0.9644444584846497, 'e5c44e8f_test_diff_accuracy': 0.0, 'e619ca6e_test_accuracy': 0.8777777552604675, 'e619ca6e_test_diff_accuracy': 0.0, 'e633a9e5_test_accuracy': 0.9722222089767456, 'e633a9e5_test_diff_accuracy': 0.0, 'e66aafb8_test_accuracy': 0.9522222280502319, 'e66aafb8_test_diff_accuracy': 0.9246704331450094, 'e681b708_test_accuracy': 0.9111111164093018, 'e681b708_test_diff_accuracy': 0.0, 'e69241bd_test_accuracy': 0.9555555582046509, 'e69241bd_test_diff_accuracy': 0.0, 'e6de6e8f_test_accuracy': 0.9877777695655823, 'e6de6e8f_test_diff_accuracy': 0.5416666666666666, 'e74e1818_test_accuracy': 0.9833333492279053, 'e74e1818_test_diff_accuracy': 0.5, 'e760a62e_test_accuracy': 0.5922222137451172, 'e760a62e_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('e7639916', 'e7639916', 'e7639916', 'e78887d1', 'e78887d1', 'e78887d1', 'e78887d1', 'e7a25a18', 'e7a25a18', 'e7b06bea', 'e7b06bea', 'e7b06bea', 'e7b06bea', 'e7b06bea', 'e7dd8335', 'e7dd8335', 'e7dd8335', 'e872b94a', 'e872b94a', 'e872b94a', 'e872b94a', 'e88171ec', 'e88171ec', 'e88171ec', 'e95e3d8e', 'e95e3d8e', 'e95e3d8e', 'e99362f0', 'e99362f0', 'e99362f0', 'e99362f0', 'e99362f0')], batch_idx: 38\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('e7639916', 'e7639916', 'e7639916', 'e78887d1', 'e78887d1', 'e78887d1', 'e78887d1', 'e7a25a18', 'e7a25a18', 'e7b06bea', 'e7b06bea', 'e7b06bea', 'e7b06bea', 'e7b06bea', 'e7dd8335', 'e7dd8335', 'e7dd8335', 'e872b94a', 'e872b94a', 'e872b94a', 'e872b94a', 'e88171ec', 'e88171ec', 'e88171ec', 'e95e3d8e', 'e95e3d8e', 'e95e3d8e', 'e99362f0', 'e99362f0', 'e99362f0', 'e99362f0', 'e99362f0')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8461538461538461\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7272727272727273\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6779661016949152\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.11627906976744186\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.3181818181818182\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6666666666666666\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6666666666666666\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.75\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6666666666666666\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.75\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 1.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6981132075471698\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7258064516129032\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6818181818181818\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7457627118644068\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7246376811594203\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.3182734549045563, Avg accuracy: 0.9137500021606684, Avg diff accuracy: 0.44568724365852597\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.3182734549045563, avg_accuracy=0.9137500021606684, diff_accuracy=0.44568724365852597\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.3182734549045563, 'task_ids': ('e7639916', 'e7639916', 'e7639916', 'e78887d1', 'e78887d1', 'e78887d1', 'e78887d1', 'e7a25a18', 'e7a25a18', 'e7b06bea', 'e7b06bea', 'e7b06bea', 'e7b06bea', 'e7b06bea', 'e7dd8335', 'e7dd8335', 'e7dd8335', 'e872b94a', 'e872b94a', 'e872b94a', 'e872b94a', 'e88171ec', 'e88171ec', 'e88171ec', 'e95e3d8e', 'e95e3d8e', 'e95e3d8e', 'e99362f0', 'e99362f0', 'e99362f0', 'e99362f0', 'e99362f0'), 'test_accuracy': 0.9137500021606684, 'test_diff_accuracy': 0.44568724365852597, 'e7639916_test_accuracy': 0.9644444584846497, 'e7639916_test_diff_accuracy': 0.0, 'e78887d1_test_accuracy': 0.9766666889190674, 'e78887d1_test_diff_accuracy': 0.6779661016949152, 'e7a25a18_test_accuracy': 0.9599999785423279, 'e7a25a18_test_diff_accuracy': 0.3181818181818182, 'e7b06bea_test_accuracy': 0.9833333492279053, 'e7b06bea_test_diff_accuracy': 0.75, 'e7dd8335_test_accuracy': 0.9777777791023254, 'e7dd8335_test_diff_accuracy': 0.0, 'e872b94a_test_accuracy': 1.0, 'e872b94a_test_diff_accuracy': 1.0, 'e88171ec_test_accuracy': 0.8411111235618591, 'e88171ec_test_diff_accuracy': 0.0, 'e95e3d8e_test_accuracy': 0.46222221851348877, 'e95e3d8e_test_diff_accuracy': 0.0, 'e99362f0_test_accuracy': 0.9766666889190674, 'e99362f0_test_diff_accuracy': 0.7246376811594203}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.3182734549045563, 'task_ids': ('e7639916', 'e7639916', 'e7639916', 'e78887d1', 'e78887d1', 'e78887d1', 'e78887d1', 'e7a25a18', 'e7a25a18', 'e7b06bea', 'e7b06bea', 'e7b06bea', 'e7b06bea', 'e7b06bea', 'e7dd8335', 'e7dd8335', 'e7dd8335', 'e872b94a', 'e872b94a', 'e872b94a', 'e872b94a', 'e88171ec', 'e88171ec', 'e88171ec', 'e95e3d8e', 'e95e3d8e', 'e95e3d8e', 'e99362f0', 'e99362f0', 'e99362f0', 'e99362f0', 'e99362f0'), 'test_accuracy': 0.9137500021606684, 'test_diff_accuracy': 0.44568724365852597, 'e7639916_test_accuracy': 0.9644444584846497, 'e7639916_test_diff_accuracy': 0.0, 'e78887d1_test_accuracy': 0.9766666889190674, 'e78887d1_test_diff_accuracy': 0.6779661016949152, 'e7a25a18_test_accuracy': 0.9599999785423279, 'e7a25a18_test_diff_accuracy': 0.3181818181818182, 'e7b06bea_test_accuracy': 0.9833333492279053, 'e7b06bea_test_diff_accuracy': 0.75, 'e7dd8335_test_accuracy': 0.9777777791023254, 'e7dd8335_test_diff_accuracy': 0.0, 'e872b94a_test_accuracy': 1.0, 'e872b94a_test_diff_accuracy': 1.0, 'e88171ec_test_accuracy': 0.8411111235618591, 'e88171ec_test_diff_accuracy': 0.0, 'e95e3d8e_test_accuracy': 0.46222221851348877, 'e95e3d8e_test_diff_accuracy': 0.0, 'e99362f0_test_accuracy': 0.9766666889190674, 'e99362f0_test_diff_accuracy': 0.7246376811594203}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('e99362f0', 'e9ac8c9e', 'e9ac8c9e', 'e9ac8c9e', 'e9b4f6fc', 'e9b4f6fc', 'e9b4f6fc', 'e9b4f6fc', 'e9bb6954', 'e9bb6954', 'e9bb6954', 'e9bb6954', 'e9c9d9a1', 'e9c9d9a1', 'e9c9d9a1', 'ea959feb', 'ea959feb', 'ea959feb', 'ea9794b1', 'ea9794b1', 'ea9794b1', 'ea9794b1', 'ea9794b1', 'ea9794b1', 'ecaa0ec1', 'ecaa0ec1', 'ecaa0ec1', 'ecaa0ec1', 'ed74f2f2', 'ed74f2f2', 'ed74f2f2', 'ed74f2f2')], batch_idx: 39\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('e99362f0', 'e9ac8c9e', 'e9ac8c9e', 'e9ac8c9e', 'e9b4f6fc', 'e9b4f6fc', 'e9b4f6fc', 'e9b4f6fc', 'e9bb6954', 'e9bb6954', 'e9bb6954', 'e9bb6954', 'e9c9d9a1', 'e9c9d9a1', 'e9c9d9a1', 'ea959feb', 'ea959feb', 'ea959feb', 'ea9794b1', 'ea9794b1', 'ea9794b1', 'ea9794b1', 'ea9794b1', 'ea9794b1', 'ecaa0ec1', 'ecaa0ec1', 'ecaa0ec1', 'ecaa0ec1', 'ed74f2f2', 'ed74f2f2', 'ed74f2f2', 'ed74f2f2')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7121212121212122\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.2\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.1\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.375\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4266666666666667\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.45\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5277777777777778\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.01282051282051282\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6333333333333333\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6271186440677966\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7090909090909091\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6792452830188679\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6274509803921569\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6071428571428571\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5714285714285714\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.36363636363636365\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4444444444444444\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5714285714285714\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5333333333333333\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5714285714285714\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5714285714285714\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5625\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.38374149799346924, Avg accuracy: 0.8990625031292439, Avg diff accuracy: 0.3555436438612662\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.38374149799346924, avg_accuracy=0.8990625031292439, diff_accuracy=0.3555436438612662\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.38374149799346924, 'task_ids': ('e99362f0', 'e9ac8c9e', 'e9ac8c9e', 'e9ac8c9e', 'e9b4f6fc', 'e9b4f6fc', 'e9b4f6fc', 'e9b4f6fc', 'e9bb6954', 'e9bb6954', 'e9bb6954', 'e9bb6954', 'e9c9d9a1', 'e9c9d9a1', 'e9c9d9a1', 'ea959feb', 'ea959feb', 'ea959feb', 'ea9794b1', 'ea9794b1', 'ea9794b1', 'ea9794b1', 'ea9794b1', 'ea9794b1', 'ecaa0ec1', 'ecaa0ec1', 'ecaa0ec1', 'ecaa0ec1', 'ed74f2f2', 'ed74f2f2', 'ed74f2f2', 'ed74f2f2'), 'test_accuracy': 0.8990625031292439, 'test_diff_accuracy': 0.3555436438612662, 'e99362f0_test_accuracy': 0.9777777791023254, 'e99362f0_test_diff_accuracy': 0.7121212121212122, 'e9ac8c9e_test_accuracy': 0.9599999785423279, 'e9ac8c9e_test_diff_accuracy': 0.1, 'e9b4f6fc_test_accuracy': 0.9811111092567444, 'e9b4f6fc_test_diff_accuracy': 0.5277777777777778, 'e9bb6954_test_accuracy': 0.8622221946716309, 'e9bb6954_test_diff_accuracy': 0.01282051282051282, 'e9c9d9a1_test_accuracy': 0.7688888907432556, 'e9c9d9a1_test_diff_accuracy': 0.0, 'ea959feb_test_accuracy': 0.3888888955116272, 'ea959feb_test_diff_accuracy': 0.0, 'ea9794b1_test_accuracy': 0.9688888788223267, 'ea9794b1_test_diff_accuracy': 0.6071428571428571, 'ecaa0ec1_test_accuracy': 0.9900000095367432, 'ecaa0ec1_test_diff_accuracy': 0.5714285714285714, 'ed74f2f2_test_accuracy': 0.992222249507904, 'ed74f2f2_test_diff_accuracy': 0.5625}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.38374149799346924, 'task_ids': ('e99362f0', 'e9ac8c9e', 'e9ac8c9e', 'e9ac8c9e', 'e9b4f6fc', 'e9b4f6fc', 'e9b4f6fc', 'e9b4f6fc', 'e9bb6954', 'e9bb6954', 'e9bb6954', 'e9bb6954', 'e9c9d9a1', 'e9c9d9a1', 'e9c9d9a1', 'ea959feb', 'ea959feb', 'ea959feb', 'ea9794b1', 'ea9794b1', 'ea9794b1', 'ea9794b1', 'ea9794b1', 'ea9794b1', 'ecaa0ec1', 'ecaa0ec1', 'ecaa0ec1', 'ecaa0ec1', 'ed74f2f2', 'ed74f2f2', 'ed74f2f2', 'ed74f2f2'), 'test_accuracy': 0.8990625031292439, 'test_diff_accuracy': 0.3555436438612662, 'e99362f0_test_accuracy': 0.9777777791023254, 'e99362f0_test_diff_accuracy': 0.7121212121212122, 'e9ac8c9e_test_accuracy': 0.9599999785423279, 'e9ac8c9e_test_diff_accuracy': 0.1, 'e9b4f6fc_test_accuracy': 0.9811111092567444, 'e9b4f6fc_test_diff_accuracy': 0.5277777777777778, 'e9bb6954_test_accuracy': 0.8622221946716309, 'e9bb6954_test_diff_accuracy': 0.01282051282051282, 'e9c9d9a1_test_accuracy': 0.7688888907432556, 'e9c9d9a1_test_diff_accuracy': 0.0, 'ea959feb_test_accuracy': 0.3888888955116272, 'ea959feb_test_diff_accuracy': 0.0, 'ea9794b1_test_accuracy': 0.9688888788223267, 'ea9794b1_test_diff_accuracy': 0.6071428571428571, 'ecaa0ec1_test_accuracy': 0.9900000095367432, 'ecaa0ec1_test_diff_accuracy': 0.5714285714285714, 'ed74f2f2_test_accuracy': 0.992222249507904, 'ed74f2f2_test_diff_accuracy': 0.5625}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('ed74f2f2', 'ed74f2f2', 'ed98d772', 'ed98d772', 'ed98d772', 'ed98d772', 'ed98d772', 'ef26cbf6', 'ef26cbf6', 'f0afb749', 'f0afb749', 'f0afb749', 'f0df5ff0', 'f0df5ff0', 'f0df5ff0', 'f21745ec', 'f21745ec', 'f21745ec', 'f3b10344', 'f3b10344', 'f3b10344', 'f3cdc58f', 'f3cdc58f', 'f3cdc58f', 'f3e62deb', 'f3e62deb', 'f3e62deb', 'f3e62deb', 'f3e62deb', 'f3e62deb', 'f4081712', 'f4081712')], batch_idx: 40\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('ed74f2f2', 'ed74f2f2', 'ed98d772', 'ed98d772', 'ed98d772', 'ed98d772', 'ed98d772', 'ef26cbf6', 'ef26cbf6', 'f0afb749', 'f0afb749', 'f0afb749', 'f0df5ff0', 'f0df5ff0', 'f0df5ff0', 'f21745ec', 'f21745ec', 'f21745ec', 'f3b10344', 'f3b10344', 'f3b10344', 'f3cdc58f', 'f3cdc58f', 'f3cdc58f', 'f3e62deb', 'f3e62deb', 'f3e62deb', 'f3e62deb', 'f3e62deb', 'f3e62deb', 'f4081712', 'f4081712')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6666666666666666\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6666666666666666\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.10526315789473684\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.043478260869565216\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.10526315789473684\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.2\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.07142857142857142\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.07407407407407407\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.1111111111111111\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.42105263157894735\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4375\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.6296296296296297\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.43333333333333335\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4318181818181818\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.4782608695652174\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9878048780487805\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.743006993006993\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.2850625216960907, Avg accuracy: 0.9323611035943031, Avg diff accuracy: 0.30019869323710036\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.2850625216960907, avg_accuracy=0.9323611035943031, diff_accuracy=0.30019869323710036\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.2850625216960907, 'task_ids': ('ed74f2f2', 'ed74f2f2', 'ed98d772', 'ed98d772', 'ed98d772', 'ed98d772', 'ed98d772', 'ef26cbf6', 'ef26cbf6', 'f0afb749', 'f0afb749', 'f0afb749', 'f0df5ff0', 'f0df5ff0', 'f0df5ff0', 'f21745ec', 'f21745ec', 'f21745ec', 'f3b10344', 'f3b10344', 'f3b10344', 'f3cdc58f', 'f3cdc58f', 'f3cdc58f', 'f3e62deb', 'f3e62deb', 'f3e62deb', 'f3e62deb', 'f3e62deb', 'f3e62deb', 'f4081712', 'f4081712'), 'test_accuracy': 0.9323611035943031, 'test_diff_accuracy': 0.30019869323710036, 'ed74f2f2_test_accuracy': 0.995555579662323, 'ed74f2f2_test_diff_accuracy': 0.6666666666666666, 'ed98d772_test_accuracy': 0.9822221994400024, 'ed98d772_test_diff_accuracy': 0.07142857142857142, 'ef26cbf6_test_accuracy': 0.95333331823349, 'ef26cbf6_test_diff_accuracy': 0.0, 'f0afb749_test_accuracy': 0.9822221994400024, 'f0afb749_test_diff_accuracy': 0.1111111111111111, 'f0df5ff0_test_accuracy': 0.8455555438995361, 'f0df5ff0_test_diff_accuracy': 0.0, 'f21745ec_test_accuracy': 0.8933333158493042, 'f21745ec_test_diff_accuracy': 0.6296296296296297, 'f3b10344_test_accuracy': 0.7277777791023254, 'f3b10344_test_diff_accuracy': 0.0, 'f3cdc58f_test_accuracy': 0.9855555295944214, 'f3cdc58f_test_diff_accuracy': 0.4782608695652174, 'f3e62deb_test_accuracy': 0.9911110997200012, 'f3e62deb_test_diff_accuracy': 0.5, 'f4081712_test_accuracy': 0.8322222232818604, 'f4081712_test_diff_accuracy': 0.743006993006993}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.2850625216960907, 'task_ids': ('ed74f2f2', 'ed74f2f2', 'ed98d772', 'ed98d772', 'ed98d772', 'ed98d772', 'ed98d772', 'ef26cbf6', 'ef26cbf6', 'f0afb749', 'f0afb749', 'f0afb749', 'f0df5ff0', 'f0df5ff0', 'f0df5ff0', 'f21745ec', 'f21745ec', 'f21745ec', 'f3b10344', 'f3b10344', 'f3b10344', 'f3cdc58f', 'f3cdc58f', 'f3cdc58f', 'f3e62deb', 'f3e62deb', 'f3e62deb', 'f3e62deb', 'f3e62deb', 'f3e62deb', 'f4081712', 'f4081712'), 'test_accuracy': 0.9323611035943031, 'test_diff_accuracy': 0.30019869323710036, 'ed74f2f2_test_accuracy': 0.995555579662323, 'ed74f2f2_test_diff_accuracy': 0.6666666666666666, 'ed98d772_test_accuracy': 0.9822221994400024, 'ed98d772_test_diff_accuracy': 0.07142857142857142, 'ef26cbf6_test_accuracy': 0.95333331823349, 'ef26cbf6_test_diff_accuracy': 0.0, 'f0afb749_test_accuracy': 0.9822221994400024, 'f0afb749_test_diff_accuracy': 0.1111111111111111, 'f0df5ff0_test_accuracy': 0.8455555438995361, 'f0df5ff0_test_diff_accuracy': 0.0, 'f21745ec_test_accuracy': 0.8933333158493042, 'f21745ec_test_diff_accuracy': 0.6296296296296297, 'f3b10344_test_accuracy': 0.7277777791023254, 'f3b10344_test_diff_accuracy': 0.0, 'f3cdc58f_test_accuracy': 0.9855555295944214, 'f3cdc58f_test_diff_accuracy': 0.4782608695652174, 'f3e62deb_test_accuracy': 0.9911110997200012, 'f3e62deb_test_diff_accuracy': 0.5, 'f4081712_test_accuracy': 0.8322222232818604, 'f4081712_test_diff_accuracy': 0.743006993006993}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('f4081712', 'f4081712', 'f4081712', 'f45f5ca7', 'f45f5ca7', 'f45f5ca7', 'f5aa3634', 'f5aa3634', 'f5aa3634', 'f5c89df1', 'f5c89df1', 'f5c89df1', 'f823c43c', 'f823c43c', 'f83cb3f6', 'f83cb3f6', 'f83cb3f6', 'f8be4b64', 'f8be4b64', 'f8be4b64', 'f8be4b64', 'f9a67cb5', 'f9a67cb5', 'f9a67cb5', 'f9d67f8b', 'f9d67f8b', 'f9d67f8b', 'f9d67f8b', 'fafd9572', 'fafd9572', 'fb791726', 'fb791726')], batch_idx: 41\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('f4081712', 'f4081712', 'f4081712', 'f45f5ca7', 'f45f5ca7', 'f45f5ca7', 'f5aa3634', 'f5aa3634', 'f5aa3634', 'f5c89df1', 'f5c89df1', 'f5c89df1', 'f823c43c', 'f823c43c', 'f83cb3f6', 'f83cb3f6', 'f83cb3f6', 'f8be4b64', 'f8be4b64', 'f8be4b64', 'f8be4b64', 'f9a67cb5', 'f9a67cb5', 'f9a67cb5', 'f9d67f8b', 'f9d67f8b', 'f9d67f8b', 'f9d67f8b', 'fafd9572', 'fafd9572', 'fb791726', 'fb791726')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([32, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([32, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([32, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8879159369527145\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9103690685413005\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.9055944055944056\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.775\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8409090909090909\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.8\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.38461538461538464\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.3939393939393939\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5333333333333333\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5217391304347826\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.5789473684210527\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.7142857142857143\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.027777777777777776\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.09722222222222222\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.2549019607843137\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.16129032258064516\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.058823529411764705\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.5629342198371887, Avg accuracy: 0.8458333322778344, Avg diff accuracy: 0.3233332699938718\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.5629342198371887, avg_accuracy=0.8458333322778344, diff_accuracy=0.3233332699938718\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.5629342198371887, 'task_ids': ('f4081712', 'f4081712', 'f4081712', 'f45f5ca7', 'f45f5ca7', 'f45f5ca7', 'f5aa3634', 'f5aa3634', 'f5aa3634', 'f5c89df1', 'f5c89df1', 'f5c89df1', 'f823c43c', 'f823c43c', 'f83cb3f6', 'f83cb3f6', 'f83cb3f6', 'f8be4b64', 'f8be4b64', 'f8be4b64', 'f8be4b64', 'f9a67cb5', 'f9a67cb5', 'f9a67cb5', 'f9d67f8b', 'f9d67f8b', 'f9d67f8b', 'f9d67f8b', 'fafd9572', 'fafd9572', 'fb791726', 'fb791726'), 'test_accuracy': 0.8458333322778344, 'test_diff_accuracy': 0.3233332699938718, 'f4081712_test_accuracy': 0.9355555772781372, 'f4081712_test_diff_accuracy': 0.9055944055944056, 'f45f5ca7_test_accuracy': 0.9911110997200012, 'f45f5ca7_test_diff_accuracy': 0.5, 'f5aa3634_test_accuracy': 0.9911110997200012, 'f5aa3634_test_diff_accuracy': 0.8, 'f5c89df1_test_accuracy': 0.9844444394111633, 'f5c89df1_test_diff_accuracy': 0.5333333333333333, 'f823c43c_test_accuracy': 0.8399999737739563, 'f823c43c_test_diff_accuracy': 0.0, 'f83cb3f6_test_accuracy': 0.9855555295944214, 'f83cb3f6_test_diff_accuracy': 0.7142857142857143, 'f8be4b64_test_accuracy': 0.9688888788223267, 'f8be4b64_test_diff_accuracy': 0.0, 'f9a67cb5_test_accuracy': 0.9433333277702332, 'f9a67cb5_test_diff_accuracy': 0.0, 'f9d67f8b_test_accuracy': 0.1966666728258133, 'f9d67f8b_test_diff_accuracy': 0.16129032258064516, 'fafd9572_test_accuracy': 0.9866666793823242, 'fafd9572_test_diff_accuracy': 0.0, 'fb791726_test_accuracy': 0.9822221994400024, 'fb791726_test_diff_accuracy': 0.058823529411764705}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.5629342198371887, 'task_ids': ('f4081712', 'f4081712', 'f4081712', 'f45f5ca7', 'f45f5ca7', 'f45f5ca7', 'f5aa3634', 'f5aa3634', 'f5aa3634', 'f5c89df1', 'f5c89df1', 'f5c89df1', 'f823c43c', 'f823c43c', 'f83cb3f6', 'f83cb3f6', 'f83cb3f6', 'f8be4b64', 'f8be4b64', 'f8be4b64', 'f8be4b64', 'f9a67cb5', 'f9a67cb5', 'f9a67cb5', 'f9d67f8b', 'f9d67f8b', 'f9d67f8b', 'f9d67f8b', 'fafd9572', 'fafd9572', 'fb791726', 'fb791726'), 'test_accuracy': 0.8458333322778344, 'test_diff_accuracy': 0.3233332699938718, 'f4081712_test_accuracy': 0.9355555772781372, 'f4081712_test_diff_accuracy': 0.9055944055944056, 'f45f5ca7_test_accuracy': 0.9911110997200012, 'f45f5ca7_test_diff_accuracy': 0.5, 'f5aa3634_test_accuracy': 0.9911110997200012, 'f5aa3634_test_diff_accuracy': 0.8, 'f5c89df1_test_accuracy': 0.9844444394111633, 'f5c89df1_test_diff_accuracy': 0.5333333333333333, 'f823c43c_test_accuracy': 0.8399999737739563, 'f823c43c_test_diff_accuracy': 0.0, 'f83cb3f6_test_accuracy': 0.9855555295944214, 'f83cb3f6_test_diff_accuracy': 0.7142857142857143, 'f8be4b64_test_accuracy': 0.9688888788223267, 'f8be4b64_test_diff_accuracy': 0.0, 'f9a67cb5_test_accuracy': 0.9433333277702332, 'f9a67cb5_test_diff_accuracy': 0.0, 'f9d67f8b_test_accuracy': 0.1966666728258133, 'f9d67f8b_test_diff_accuracy': 0.16129032258064516, 'fafd9572_test_accuracy': 0.9866666793823242, 'fafd9572_test_diff_accuracy': 0.0, 'fb791726_test_accuracy': 0.9822221994400024, 'fb791726_test_diff_accuracy': 0.058823529411764705}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step input - batch: [tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0],\n",
            "          [0, 0, 0,  ..., 0, 0, 0]]]]), ('fb791726', 'fc754716', 'fc754716', 'fc754716', 'fc754716', 'fd096ab6', 'fd096ab6', 'fd4b2b02', 'fd4b2b02', 'fd4b2b02', 'fe9372f3', 'fe9372f3', 'fea12743', 'fea12743', 'fea12743', 'ff72ca3e', 'ff72ca3e', 'ff72ca3e', 'ff72ca3e')], batch_idx: 42\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step - Batch type: <class 'list'>, length: 3\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Task IDs in batch: ('fb791726', 'fc754716', 'fc754716', 'fc754716', 'fc754716', 'fd096ab6', 'fd096ab6', 'fd4b2b02', 'fd4b2b02', 'fd4b2b02', 'fe9372f3', 'fe9372f3', 'fea12743', 'fea12743', 'fea12743', 'ff72ca3e', 'ff72ca3e', 'ff72ca3e', 'ff72ca3e')\n",
            "DEBUG:gpt2_arc.src.models.gpt2:GPT2ARC input shape: torch.Size([19, 1, 30, 30]), dtype: torch.float32\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After conv1 shape: torch.Size([19, 256, 30, 30])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Reshaped for transformer blocks: torch.Size([19, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([19, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([19, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([19, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([19, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([19, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([19, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 1 shape: torch.Size([19, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock input shape: torch.Size([19, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention input shape: torch.Size([19, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:Attention output shape: torch.Size([19, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward input shape: torch.Size([19, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:FeedForward output shape: torch.Size([19, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:TransformerBlock output shape: torch.Size([19, 900, 256])\n",
            "DEBUG:gpt2_arc.src.models.gpt2:After block 2 shape: torch.Size([19, 900, 256])\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.058823529411764705\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.1111111111111111\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.07692307692307693\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.047619047619047616\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.058823529411764705\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: diff_accuracy type: <class 'float'>, value: 0.0\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test loss: 0.348099023103714, Avg accuracy: 0.8961403464016161, Avg diff accuracy: 0.01859475234088237\n",
            "/usr/local/python/3.12.1/lib/python3.12/site-packages/pytorch_lightning/utilities/data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 19. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Logged test metrics for epoch 0: loss=0.348099023103714, avg_accuracy=0.8961403464016161, diff_accuracy=0.01859475234088237\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: test_step output - result: {'test_loss': 0.348099023103714, 'task_ids': ('fb791726', 'fc754716', 'fc754716', 'fc754716', 'fc754716', 'fd096ab6', 'fd096ab6', 'fd4b2b02', 'fd4b2b02', 'fd4b2b02', 'fe9372f3', 'fe9372f3', 'fea12743', 'fea12743', 'fea12743', 'ff72ca3e', 'ff72ca3e', 'ff72ca3e', 'ff72ca3e'), 'test_accuracy': 0.8961403464016161, 'test_diff_accuracy': 0.01859475234088237, 'fb791726_test_accuracy': 0.9644444584846497, 'fb791726_test_diff_accuracy': 0.058823529411764705, 'fc754716_test_accuracy': 0.9822221994400024, 'fc754716_test_diff_accuracy': 0.058823529411764705, 'fd096ab6_test_accuracy': 0.36000001430511475, 'fd096ab6_test_diff_accuracy': 0.0, 'fd4b2b02_test_accuracy': 0.8833333253860474, 'fd4b2b02_test_diff_accuracy': 0.0, 'fe9372f3_test_accuracy': 0.9622222185134888, 'fe9372f3_test_diff_accuracy': 0.0, 'fea12743_test_accuracy': 0.9433333277702332, 'fea12743_test_diff_accuracy': 0.0, 'ff72ca3e_test_accuracy': 0.9444444179534912, 'ff72ca3e_test_diff_accuracy': 0.0}\n",
            "DEBUG:gpt2_arc.src.training.trainer:DEBUG: Test step result: {'test_loss': 0.348099023103714, 'task_ids': ('fb791726', 'fc754716', 'fc754716', 'fc754716', 'fc754716', 'fd096ab6', 'fd096ab6', 'fd4b2b02', 'fd4b2b02', 'fd4b2b02', 'fe9372f3', 'fe9372f3', 'fea12743', 'fea12743', 'fea12743', 'ff72ca3e', 'ff72ca3e', 'ff72ca3e', 'ff72ca3e'), 'test_accuracy': 0.8961403464016161, 'test_diff_accuracy': 0.01859475234088237, 'fb791726_test_accuracy': 0.9644444584846497, 'fb791726_test_diff_accuracy': 0.058823529411764705, 'fc754716_test_accuracy': 0.9822221994400024, 'fc754716_test_diff_accuracy': 0.058823529411764705, 'fd096ab6_test_accuracy': 0.36000001430511475, 'fd096ab6_test_diff_accuracy': 0.0, 'fd4b2b02_test_accuracy': 0.8833333253860474, 'fd4b2b02_test_diff_accuracy': 0.0, 'fe9372f3_test_accuracy': 0.9622222185134888, 'fe9372f3_test_diff_accuracy': 0.0, 'fea12743_test_accuracy': 0.9433333277702332, 'fea12743_test_diff_accuracy': 0.0, 'ff72ca3e_test_accuracy': 0.9444444179534912, 'ff72ca3e_test_diff_accuracy': 0.0}\n",
            "DEBUG:__main__:DEBUG: Raw results from test: [{'00576224_test_accuracy': 0.9599999785423279, '00576224_test_diff_accuracy': 0.0, '009d5c81_test_accuracy': 0.9744443893432617, '009d5c81_test_diff_accuracy': 0.21003207564353943, '00dbd492_test_accuracy': 0.929444432258606, '00dbd492_test_diff_accuracy': 0.0, '03560426_test_accuracy': 0.9796295762062073, '03560426_test_diff_accuracy': 0.5188145637512207, '05a7bcf2_test_accuracy': 0.6566666960716248, '05a7bcf2_test_diff_accuracy': 0.0, '0607ce86_test_accuracy': 0.7966666221618652, '0607ce86_test_diff_accuracy': 0.6599085927009583, '0692e18c_test_accuracy': 0.9785184860229492, '0692e18c_test_diff_accuracy': 0.16984127461910248, '070dd51e_test_accuracy': 0.9611111283302307, '070dd51e_test_diff_accuracy': 0.0, '08573cc6_test_accuracy': 0.962592601776123, '08573cc6_test_diff_accuracy': 0.06767676770687103, '0934a4d8_test_accuracy': 0.37638890743255615, '0934a4d8_test_diff_accuracy': 0.37773966789245605, '09c534e7_test_accuracy': 0.7877777218818665, '09c534e7_test_diff_accuracy': 0.0, '0a1d4ef5_test_accuracy': 0.9511110782623291, '0a1d4ef5_test_diff_accuracy': 0.9168465733528137, '0a2355a6_test_accuracy': 0.9394444823265076, '0a2355a6_test_diff_accuracy': 0.0, '0b17323b_test_accuracy': 0.9938889145851135, '0b17323b_test_diff_accuracy': 0.0, '0bb8deee_test_accuracy': 0.9788889288902283, '0bb8deee_test_diff_accuracy': 0.6813034415245056, '0becf7df_test_accuracy': 0.9744444489479065, '0becf7df_test_diff_accuracy': 0.0, '0c786b71_test_accuracy': 0.9466666579246521, '0c786b71_test_diff_accuracy': 0.0, '0c9aba6e_test_accuracy': 0.9916666746139526, '0c9aba6e_test_diff_accuracy': 0.747855007648468, '0d87d2a6_test_accuracy': 0.9055555462837219, '0d87d2a6_test_diff_accuracy': 0.0, '0e671a1a_test_accuracy': 0.9724999666213989, '0e671a1a_test_diff_accuracy': 0.0, '0f63c0b9_test_accuracy': 0.8908333778381348, '0f63c0b9_test_diff_accuracy': 0.0, '103eff5b_test_accuracy': 0.9416666626930237, '103eff5b_test_diff_accuracy': 0.0, '11e1fe23_test_accuracy': 0.992222249507904, '11e1fe23_test_diff_accuracy': 0.0, '12422b43_test_accuracy': 0.9788888692855835, '12422b43_test_diff_accuracy': 0.0, '12997ef3_test_accuracy': 0.9844444394111633, '12997ef3_test_diff_accuracy': 0.3445091247558594, '12eac192_test_accuracy': 0.9725000262260437, '12eac192_test_diff_accuracy': 0.0, '136b0064_test_accuracy': 0.9822222590446472, '136b0064_test_diff_accuracy': 0.711358368396759, '13713586_test_accuracy': 0.859259307384491, '13713586_test_diff_accuracy': 0.0, '137f0df0_test_accuracy': 0.9185185432434082, '137f0df0_test_diff_accuracy': 0.0, '140c817e_test_accuracy': 0.8625926375389099, '140c817e_test_diff_accuracy': 0.0, '14754a24_test_accuracy': 0.8630555272102356, '14754a24_test_diff_accuracy': 0.0, '15113be4_test_accuracy': 0.6255555748939514, '15113be4_test_diff_accuracy': 0.0, '15663ba9_test_accuracy': 0.9422222971916199, '15663ba9_test_diff_accuracy': 0.0, '15696249_test_accuracy': 0.9700000286102295, '15696249_test_diff_accuracy': 0.1875, '16b78196_test_accuracy': 0.7916666865348816, '16b78196_test_diff_accuracy': 0.4842342138290405, '17b80ad2_test_accuracy': 0.9611111283302307, '17b80ad2_test_diff_accuracy': 0.0, '17cae0c1_test_accuracy': 0.9700000286102295, '17cae0c1_test_diff_accuracy': 0.0, '18419cfa_test_accuracy': 0.9344444274902344, '18419cfa_test_diff_accuracy': 0.0, '184a9768_test_accuracy': 0.8522222638130188, '184a9768_test_diff_accuracy': 0.575104296207428, '195ba7dc_test_accuracy': 0.9758332967758179, '195ba7dc_test_diff_accuracy': 0.5054347515106201, '1990f7a8_test_accuracy': 0.9740740656852722, '1990f7a8_test_diff_accuracy': 0.5, '19bb5feb_test_accuracy': 0.9729630351066589, '19bb5feb_test_diff_accuracy': 0.7311635613441467, '1a2e2828_test_accuracy': 0.9986666440963745, '1a2e2828_test_diff_accuracy': 0.9834964871406555, '1a6449f1_test_accuracy': 0.9829629063606262, '1a6449f1_test_diff_accuracy': 0.9130600094795227, '1acc24af_test_accuracy': 0.964722216129303, '1acc24af_test_diff_accuracy': 0.0, '1c02dbbe_test_accuracy': 0.860370397567749, '1c02dbbe_test_diff_accuracy': 0.06207104027271271, '1c0d0a4b_test_accuracy': 0.9825925827026367, '1c0d0a4b_test_diff_accuracy': 0.595678985118866, '1c56ad9f_test_accuracy': 0.9541666507720947, '1c56ad9f_test_diff_accuracy': 0.5, '1d0a4b61_test_accuracy': 0.3055555522441864, '1d0a4b61_test_diff_accuracy': 0.0, '1d398264_test_accuracy': 0.9462962746620178, '1d398264_test_diff_accuracy': 0.0, '1da012fc_test_accuracy': 0.9105556011199951, '1da012fc_test_diff_accuracy': 0.0, '1e81d6f9_test_accuracy': 0.9681481719017029, '1e81d6f9_test_diff_accuracy': 1.0, '1e97544e_test_accuracy': 0.41296300292015076, '1e97544e_test_diff_accuracy': 0.0, '2037f2c7_test_accuracy': 0.9900000095367432, '2037f2c7_test_diff_accuracy': 0.9334214329719543, '2072aba6_test_accuracy': 0.9807407259941101, '2072aba6_test_diff_accuracy': 0.01587301678955555, '20818e16_test_accuracy': 0.9385185241699219, '20818e16_test_diff_accuracy': 0.723113477230072, '20981f0e_test_accuracy': 0.9681481719017029, '20981f0e_test_diff_accuracy': 0.5, '212895b5_test_accuracy': 0.9196296334266663, '212895b5_test_diff_accuracy': 0.0, '21f83797_test_accuracy': 0.9238889217376709, '21f83797_test_diff_accuracy': 0.0, '22a4bbc2_test_accuracy': 0.9433333277702332, '22a4bbc2_test_diff_accuracy': 0.0, '25094a63_test_accuracy': 0.1827777773141861, '25094a63_test_diff_accuracy': 0.0, '2546ccf6_test_accuracy': 0.8550000190734863, '2546ccf6_test_diff_accuracy': 0.0, '256b0a75_test_accuracy': 0.6666666865348816, '256b0a75_test_diff_accuracy': 0.0, '2685904e_test_accuracy': 0.965925931930542, '2685904e_test_diff_accuracy': 0.0, '2697da3f_test_accuracy': 0.9511110782623291, '2697da3f_test_diff_accuracy': 0.16602009534835815, '2753e76c_test_accuracy': 0.9900000095367432, '2753e76c_test_diff_accuracy': 0.899422824382782, '27a77e38_test_accuracy': 0.9807407259941101, '27a77e38_test_diff_accuracy': 0.0, '27f8ce4f_test_accuracy': 0.9650000333786011, '27f8ce4f_test_diff_accuracy': 0.11249999701976776, '281123b4_test_accuracy': 0.9829630255699158, '281123b4_test_diff_accuracy': 0.7146536707878113, '292dd178_test_accuracy': 0.9081481099128723, '292dd178_test_diff_accuracy': 0.0, '29700607_test_accuracy': 0.9618518948554993, '29700607_test_diff_accuracy': 0.0, '2a5f8217_test_accuracy': 0.9774073958396912, '2a5f8217_test_diff_accuracy': 0.0, '2b01abd0_test_accuracy': 0.970740795135498, '2b01abd0_test_diff_accuracy': 0.0, '2c0b0aff_test_accuracy': 0.9119444489479065, '2c0b0aff_test_diff_accuracy': 0.7577368021011353, '2c737e39_test_accuracy': 0.9840741157531738, '2c737e39_test_diff_accuracy': 0.13650794327259064, '2f0c5170_test_accuracy': 0.9674074053764343, '2f0c5170_test_diff_accuracy': 0.9186174869537354, '310f3251_test_accuracy': 0.9700000882148743, '310f3251_test_diff_accuracy': 0.0, '3194b014_test_accuracy': 0.9770370125770569, '3194b014_test_diff_accuracy': 0.9225044250488281, '319f2597_test_accuracy': 0.6277777552604675, '319f2597_test_diff_accuracy': 0.9736223220825195, '31adaf00_test_accuracy': 0.9307407736778259, '31adaf00_test_diff_accuracy': 0.0, '31d5ba1a_test_accuracy': 0.9928889274597168, '31d5ba1a_test_diff_accuracy': 0.6540936231613159, '32e9702f_test_accuracy': 0.9548148512840271, '32e9702f_test_diff_accuracy': 0.0, '332efdb3_test_accuracy': 0.9533333778381348, '332efdb3_test_diff_accuracy': 0.0, '3391f8c0_test_accuracy': 0.9824999570846558, '3391f8c0_test_diff_accuracy': 0.3541666865348816, '33b52de3_test_accuracy': 0.8538888692855835, '33b52de3_test_diff_accuracy': 0.0, '3490cc26_test_accuracy': 0.9061111211776733, '3490cc26_test_diff_accuracy': 0.0, '34b99a2b_test_accuracy': 0.9883333444595337, '34b99a2b_test_diff_accuracy': 0.629668653011322, '351d6448_test_accuracy': 0.9927777647972107, '351d6448_test_diff_accuracy': 0.8858424425125122, '358ba94e_test_accuracy': 0.9744444489479065, '358ba94e_test_diff_accuracy': 0.8644062280654907, '37d3e8b2_test_accuracy': 0.8788889050483704, '37d3e8b2_test_diff_accuracy': 0.0, '3979b1a8_test_accuracy': 0.8888888955116272, '3979b1a8_test_diff_accuracy': 0.0, '3a301edc_test_accuracy': 0.9024444818496704, '3a301edc_test_diff_accuracy': 0.0, '3b4c2228_test_accuracy': 0.9979999661445618, '3b4c2228_test_diff_accuracy': 0.8947456479072571, '3d31c5b3_test_accuracy': 0.9794444441795349, '3d31c5b3_test_diff_accuracy': 0.6079409122467041, '3ed85e70_test_accuracy': 0.6381481885910034, '3ed85e70_test_diff_accuracy': 0.0, '3ee1011a_test_accuracy': 0.9537037014961243, '3ee1011a_test_diff_accuracy': 0.20636117458343506, '3f23242b_test_accuracy': 0.9550000429153442, '3f23242b_test_diff_accuracy': 0.0, '40f6cd08_test_accuracy': 0.6270370483398438, '40f6cd08_test_diff_accuracy': 0.0, '414297c0_test_accuracy': 0.8959259390830994, '414297c0_test_diff_accuracy': 0.4695725440979004, '423a55dc_test_accuracy': 0.9855555295944214, '423a55dc_test_diff_accuracy': 0.5216470956802368, '42918530_test_accuracy': 0.815833330154419, '42918530_test_diff_accuracy': 0.0, '42a15761_test_accuracy': 0.9062963128089905, '42a15761_test_diff_accuracy': 0.5, '4364c1c4_test_accuracy': 0.8177778124809265, '4364c1c4_test_diff_accuracy': 0.0, '456873bc_test_accuracy': 0.9514815211296082, '456873bc_test_diff_accuracy': 0.7703775763511658, '45737921_test_accuracy': 0.9733333587646484, '45737921_test_diff_accuracy': 0.0, '45bbe264_test_accuracy': 0.932962954044342, '45bbe264_test_diff_accuracy': 0.0, '477d2879_test_accuracy': 0.8122222423553467, '477d2879_test_diff_accuracy': 0.0, '47996f11_test_accuracy': 0.13833333551883698, '47996f11_test_diff_accuracy': 0.10620684921741486, '48131b3c_test_accuracy': 0.9733333587646484, '48131b3c_test_diff_accuracy': 0.11290545016527176, '4852f2fa_test_accuracy': 0.9853333234786987, '4852f2fa_test_diff_accuracy': 0.36084944009780884, '48f8583b_test_accuracy': 0.9798148274421692, '48f8583b_test_diff_accuracy': 0.29629629850387573, '4aab4007_test_accuracy': 0.12888889014720917, '4aab4007_test_diff_accuracy': 0.0, '4acc7107_test_accuracy': 0.9758333563804626, '4acc7107_test_diff_accuracy': 0.4823917746543884, '4b6b68e5_test_accuracy': 0.8622221946716309, '4b6b68e5_test_diff_accuracy': 0.03787878900766373, '4c177718_test_accuracy': 0.9872222542762756, '4c177718_test_diff_accuracy': 0.7471552491188049, '4cd1b7b2_test_accuracy': 0.9822222590446472, '4cd1b7b2_test_diff_accuracy': 0.0, '4e45f183_test_accuracy': 0.7507407665252686, '4e45f183_test_diff_accuracy': 0.013888888992369175, '4e469f39_test_accuracy': 0.9662962555885315, '4e469f39_test_diff_accuracy': 0.0, '4f537728_test_accuracy': 0.7972222566604614, '4f537728_test_diff_accuracy': 0.0, '4ff4c9da_test_accuracy': 0.6259259581565857, '4ff4c9da_test_diff_accuracy': 0.0, '505fff84_test_accuracy': 0.9913333654403687, '505fff84_test_diff_accuracy': 0.8910254240036011, '506d28a5_test_accuracy': 0.9822221994400024, '506d28a5_test_diff_accuracy': 0.47752460837364197, '50a16a69_test_accuracy': 0.8159258961677551, '50a16a69_test_diff_accuracy': 0.03999999910593033, '50aad11f_test_accuracy': 0.9785184860229492, '50aad11f_test_diff_accuracy': 0.4671497642993927, '50f325b5_test_accuracy': 0.801944375038147, '50f325b5_test_diff_accuracy': 0.0, '516b51b7_test_accuracy': 0.9188888669013977, '516b51b7_test_diff_accuracy': 0.0, '5207a7b5_test_accuracy': 0.9559259414672852, '5207a7b5_test_diff_accuracy': 0.0, '5289ad53_test_accuracy': 0.9755555391311646, '5289ad53_test_diff_accuracy': 0.8811259269714355, '52fd389e_test_accuracy': 0.7137036323547363, '52fd389e_test_diff_accuracy': 0.0, '54db823b_test_accuracy': 0.9066666960716248, '54db823b_test_diff_accuracy': 1.0, '55059096_test_accuracy': 0.9744443893432617, '55059096_test_diff_accuracy': 0.0, '551d5bf1_test_accuracy': 0.7644444704055786, '551d5bf1_test_diff_accuracy': 0.0, '55783887_test_accuracy': 0.8462222218513489, '55783887_test_diff_accuracy': 0.10000000149011612, '575b1a71_test_accuracy': 0.8888888955116272, '575b1a71_test_diff_accuracy': 0.0, '5783df64_test_accuracy': 0.9900000095367432, '5783df64_test_diff_accuracy': 0.45825162529945374, '5833af48_test_accuracy': 0.8825926184654236, '5833af48_test_diff_accuracy': 0.6010026335716248, '58743b76_test_accuracy': 0.9472222328186035, '58743b76_test_diff_accuracy': 0.0, '58e15b12_test_accuracy': 0.9170370697975159, '58e15b12_test_diff_accuracy': 0.0, '59341089_test_accuracy': 0.960277795791626, '59341089_test_diff_accuracy': 0.0, '5a5a2103_test_accuracy': 0.8194444179534912, '5a5a2103_test_diff_accuracy': 0.04545454680919647, '5af49b42_test_accuracy': 0.9737036824226379, '5af49b42_test_diff_accuracy': 0.0, '5b526a93_test_accuracy': 0.90666663646698, '5b526a93_test_diff_accuracy': 0.0, '5b692c0f_test_accuracy': 0.9133332967758179, '5b692c0f_test_diff_accuracy': 0.23863637447357178, '5b6cbef5_test_accuracy': 0.9197778701782227, '5b6cbef5_test_diff_accuracy': 0.09092767536640167, '5d2a5c43_test_accuracy': 0.9784444570541382, '5d2a5c43_test_diff_accuracy': 0.47774338722229004, '5ffb2104_test_accuracy': 0.987407386302948, '5ffb2104_test_diff_accuracy': 0.4901960790157318, '604001fa_test_accuracy': 0.9819444417953491, '604001fa_test_diff_accuracy': 0.2735389471054077, '60a26a3e_test_accuracy': 0.9718518257141113, '60a26a3e_test_diff_accuracy': 0.0, '60c09cac_test_accuracy': 0.9822221994400024, '60c09cac_test_diff_accuracy': 0.02777777798473835, '626c0bcc_test_accuracy': 0.9825925827026367, '626c0bcc_test_diff_accuracy': 0.0, '62ab2642_test_accuracy': 0.93666672706604, '62ab2642_test_diff_accuracy': 0.0, '62b74c02_test_accuracy': 0.9559259414672852, '62b74c02_test_diff_accuracy': 0.0, '639f5a19_test_accuracy': 0.7777777910232544, '639f5a19_test_diff_accuracy': 0.0, '642248e4_test_accuracy': 0.9570370316505432, '642248e4_test_diff_accuracy': 0.0, '642d658d_test_accuracy': 0.9611111283302307, '642d658d_test_diff_accuracy': 0.9283973574638367, '64a7c07e_test_accuracy': 0.9892592430114746, '64a7c07e_test_diff_accuracy': 0.5, '66e6c45b_test_accuracy': 0.995555579662323, '66e6c45b_test_diff_accuracy': 0.5, '66f2d22f_test_accuracy': 0.991944432258606, '66f2d22f_test_diff_accuracy': 0.7562196850776672, '67636eac_test_accuracy': 0.9862963557243347, '67636eac_test_diff_accuracy': 0.46666666865348816, '67b4a34d_test_accuracy': 0.9696295857429504, '67b4a34d_test_diff_accuracy': 0.9138374328613281, '67c52801_test_accuracy': 0.9786111116409302, '67c52801_test_diff_accuracy': 0.5, '68b67ca3_test_accuracy': 0.9944444298744202, '68b67ca3_test_diff_accuracy': 0.5, '692cd3b6_test_accuracy': 0.9007408022880554, '692cd3b6_test_diff_accuracy': 0.0, '695367ec_test_accuracy': 0.8937036991119385, '695367ec_test_diff_accuracy': 0.05552127584815025, '696d4842_test_accuracy': 0.962592601776123, '696d4842_test_diff_accuracy': 0.0, '69889d6e_test_accuracy': 0.980555534362793, '69889d6e_test_diff_accuracy': 0.0, '6a11f6da_test_accuracy': 0.975777804851532, '6a11f6da_test_diff_accuracy': 0.5782161355018616, '6ad5bdfd_test_accuracy': 0.9814814925193787, '6ad5bdfd_test_diff_accuracy': 0.45766592025756836, '6df30ad6_test_accuracy': 0.991777777671814, '6df30ad6_test_diff_accuracy': 0.5457017421722412, '6ea4a07e_test_accuracy': 0.9937036633491516, '6ea4a07e_test_diff_accuracy': 0.37037038803100586, '6f473927_test_accuracy': 0.9677777886390686, '6f473927_test_diff_accuracy': 0.21378621459007263, '7039b2d7_test_accuracy': 0.9840741157531738, '7039b2d7_test_diff_accuracy': 0.9842607378959656, '705a3229_test_accuracy': 0.9844444394111633, '705a3229_test_diff_accuracy': 0.0, '712bf12e_test_accuracy': 0.9170370101928711, '712bf12e_test_diff_accuracy': 0.0, '72207abc_test_accuracy': 0.9925925731658936, '72207abc_test_diff_accuracy': 0.0, '72a961c9_test_accuracy': 0.9844444990158081, '72a961c9_test_diff_accuracy': 0.0, '73182012_test_accuracy': 0.9881481528282166, '73182012_test_diff_accuracy': 0.8835263848304749, '73c3b0d8_test_accuracy': 0.9869444370269775, '73c3b0d8_test_diff_accuracy': 0.2957516312599182, '73ccf9c2_test_accuracy': 0.9881481528282166, '73ccf9c2_test_diff_accuracy': 0.8363578915596008, '759f3fd3_test_accuracy': 0.8427777886390686, '759f3fd3_test_diff_accuracy': 0.0, '762cd429_test_accuracy': 0.8118519186973572, '762cd429_test_diff_accuracy': 0.0, '770cc55f_test_accuracy': 0.9769444465637207, '770cc55f_test_diff_accuracy': 0.0, '782b5218_test_accuracy': 0.9344444274902344, '782b5218_test_diff_accuracy': 0.4673832952976227, '79369cc6_test_accuracy': 0.8040741086006165, '79369cc6_test_diff_accuracy': 0.0, '7953d61e_test_accuracy': 0.9288889169692993, '7953d61e_test_diff_accuracy': 0.0, '79fb03f4_test_accuracy': 0.93833327293396, '79fb03f4_test_diff_accuracy': 0.0, '7bb29440_test_accuracy': 0.9735555648803711, '7bb29440_test_diff_accuracy': 0.8471860885620117, '7c8af763_test_accuracy': 0.8888888955116272, '7c8af763_test_diff_accuracy': 0.0, '7c9b52a0_test_accuracy': 0.9074074625968933, '7c9b52a0_test_diff_accuracy': 0.6268526911735535, '7d18a6fb_test_accuracy': 0.9770370125770569, '7d18a6fb_test_diff_accuracy': 0.7752125263214111, '7d1f7ee8_test_accuracy': 0.8325925469398499, '7d1f7ee8_test_diff_accuracy': 0.0, '7d419a02_test_accuracy': 0.851111114025116, '7d419a02_test_diff_accuracy': 0.0, '7e02026e_test_accuracy': 0.9000000357627869, '7e02026e_test_diff_accuracy': 0.0, '7ee1c6ea_test_accuracy': 0.9133333563804626, '7ee1c6ea_test_diff_accuracy': 0.0, '817e6c09_test_accuracy': 0.9760000109672546, '817e6c09_test_diff_accuracy': 0.0, '81c0276b_test_accuracy': 0.9933333396911621, '81c0276b_test_diff_accuracy': 0.9544203281402588, '833dafe3_test_accuracy': 0.9644444584846497, '833dafe3_test_diff_accuracy': 0.07334525883197784, '845d6e51_test_accuracy': 0.9477777481079102, '845d6e51_test_diff_accuracy': 0.0, '84db8fc4_test_accuracy': 0.8888888955116272, '84db8fc4_test_diff_accuracy': 0.0, '84f2aca1_test_accuracy': 0.9650000333786011, '84f2aca1_test_diff_accuracy': 0.0, '8597cfd7_test_accuracy': 0.995555579662323, '8597cfd7_test_diff_accuracy': 0.8174242377281189, '85b81ff1_test_accuracy': 0.875, '85b81ff1_test_diff_accuracy': 0.5, '85fa5666_test_accuracy': 0.9622222185134888, '85fa5666_test_diff_accuracy': 0.0, '8719f442_test_accuracy': 0.9422221779823303, '8719f442_test_diff_accuracy': 0.0, '88207623_test_accuracy': 0.9388889074325562, '88207623_test_diff_accuracy': 0.0, '891232d6_test_accuracy': 0.8897222280502319, '891232d6_test_diff_accuracy': 0.0, '896d5239_test_accuracy': 0.8825926184654236, '896d5239_test_diff_accuracy': 0.0, '8a371977_test_accuracy': 0.43888890743255615, '8a371977_test_diff_accuracy': 0.0, '8b28cd80_test_accuracy': 0.948888897895813, '8b28cd80_test_diff_accuracy': 0.017298799008131027, '8ba14f53_test_accuracy': 0.9938888549804688, '8ba14f53_test_diff_accuracy': 0.8179367184638977, '8cb8642d_test_accuracy': 0.9296296238899231, '8cb8642d_test_diff_accuracy': 0.7093300819396973, '8dae5dfc_test_accuracy': 0.8263888359069824, '8dae5dfc_test_diff_accuracy': 0.0, '8e2edd66_test_accuracy': 0.9814814925193787, '8e2edd66_test_diff_accuracy': 0.2586754262447357, '8ee62060_test_accuracy': 0.9788889288902283, '8ee62060_test_diff_accuracy': 0.5, '8fbca751_test_accuracy': 0.9659258723258972, '8fbca751_test_diff_accuracy': 0.0, '90347967_test_accuracy': 0.9933333396911621, '90347967_test_diff_accuracy': 0.5, '903d1b4a_test_accuracy': 0.7155555486679077, '903d1b4a_test_diff_accuracy': 0.0, '9110e3c5_test_accuracy': 0.9960317611694336, '9110e3c5_test_diff_accuracy': 0.8651400804519653, '917bccba_test_accuracy': 0.9644444584846497, '917bccba_test_diff_accuracy': 0.6146110892295837, '929ab4e9_test_accuracy': 0.3613888919353485, '929ab4e9_test_diff_accuracy': 0.0, '92e50de0_test_accuracy': 0.6677777767181396, '92e50de0_test_diff_accuracy': 0.0, '9356391f_test_accuracy': 0.90666663646698, '9356391f_test_diff_accuracy': 0.0, '93b4f4b3_test_accuracy': 0.9233333468437195, '93b4f4b3_test_diff_accuracy': 0.40796583890914917, '93c31fbe_test_accuracy': 0.9399999976158142, '93c31fbe_test_diff_accuracy': 0.3983488082885742, '94133066_test_accuracy': 0.8922222256660461, '94133066_test_diff_accuracy': 0.48462045192718506, '94414823_test_accuracy': 0.9577777981758118, '94414823_test_diff_accuracy': 0.0, '94be5b80_test_accuracy': 0.9411110877990723, '94be5b80_test_diff_accuracy': 0.2946428656578064, '95a58926_test_accuracy': 0.8614814877510071, '95a58926_test_diff_accuracy': 0.5745627284049988, '963f59bc_test_accuracy': 0.9786111116409302, '963f59bc_test_diff_accuracy': 0.0, '96a8c0cd_test_accuracy': 0.9350000023841858, '96a8c0cd_test_diff_accuracy': 0.0, '97239e3d_test_accuracy': 0.7988889217376709, '97239e3d_test_diff_accuracy': 0.0, '9772c176_test_accuracy': 0.7477777600288391, '9772c176_test_diff_accuracy': 0.0, '981571dc_test_accuracy': 0.00027777778450399637, '981571dc_test_diff_accuracy': 0.0, '992798f6_test_accuracy': 0.9863889217376709, '992798f6_test_diff_accuracy': 0.0, '99306f82_test_accuracy': 0.9162963032722473, '99306f82_test_diff_accuracy': 0.0, '9a4bb226_test_accuracy': 0.9888889193534851, '9a4bb226_test_diff_accuracy': 0.7706348896026611, '9b2a60aa_test_accuracy': 0.965925931930542, '9b2a60aa_test_diff_accuracy': 0.0, '9b365c51_test_accuracy': 0.9670370221138, '9b365c51_test_diff_accuracy': 0.444180965423584, '9b4c17c4_test_accuracy': 0.8147222995758057, '9b4c17c4_test_diff_accuracy': 0.0, '9bebae7a_test_accuracy': 0.9786666631698608, '9bebae7a_test_diff_accuracy': 0.33641454577445984, '9c1e755f_test_accuracy': 0.9461110830307007, '9c1e755f_test_diff_accuracy': 0.0, '9c56f360_test_accuracy': 0.9737036824226379, '9c56f360_test_diff_accuracy': 0.5, '9caba7c3_test_accuracy': 0.7659258842468262, '9caba7c3_test_diff_accuracy': 0.0, '9ddd00f0_test_accuracy': 0.9533333778381348, '9ddd00f0_test_diff_accuracy': 0.0, '9def23fe_test_accuracy': 0.8311111330986023, '9def23fe_test_diff_accuracy': 0.0, '9f27f097_test_accuracy': 0.8399999737739563, '9f27f097_test_diff_accuracy': 0.0, 'a04b2602_test_accuracy': 0.8177778124809265, 'a04b2602_test_diff_accuracy': 0.0, 'a096bf4d_test_accuracy': 0.7333333492279053, 'a096bf4d_test_diff_accuracy': 0.0, 'a3f84088_test_accuracy': 0.8686110973358154, 'a3f84088_test_diff_accuracy': 0.0, 'a406ac07_test_accuracy': 0.958148181438446, 'a406ac07_test_diff_accuracy': 0.0, 'a57f2f04_test_accuracy': 0.6633333563804626, 'a57f2f04_test_diff_accuracy': 0.0, 'a59b95c0_test_accuracy': 0.9160000085830688, 'a59b95c0_test_diff_accuracy': 0.0, 'a680ac02_test_accuracy': 0.9644444584846497, 'a680ac02_test_diff_accuracy': 0.6501501202583313, 'a8610ef7_test_accuracy': 0.9766666889190674, 'a8610ef7_test_diff_accuracy': 0.0, 'a934301b_test_accuracy': 0.9674074053764343, 'a934301b_test_diff_accuracy': 1.0, 'aa18de87_test_accuracy': 0.9791666269302368, 'aa18de87_test_diff_accuracy': 0.0, 'aa300dc3_test_accuracy': 0.930555522441864, 'aa300dc3_test_diff_accuracy': 0.0, 'aa4ec2a5_test_accuracy': 0.43740740418434143, 'aa4ec2a5_test_diff_accuracy': 0.0, 'aab50785_test_accuracy': 0.9871110916137695, 'aab50785_test_diff_accuracy': 0.9002954363822937, 'ac0c5833_test_accuracy': 0.9518518447875977, 'ac0c5833_test_diff_accuracy': 0.0, 'ac2e8ecf_test_accuracy': 0.9529629349708557, 'ac2e8ecf_test_diff_accuracy': 0.4784134328365326, 'ac3e2b04_test_accuracy': 0.9386110901832581, 'ac3e2b04_test_diff_accuracy': 0.0, 'ac605cbb_test_accuracy': 0.9875926375389099, 'ac605cbb_test_diff_accuracy': 0.0, 'ad7e01d0_test_accuracy': 0.9144444465637207, 'ad7e01d0_test_diff_accuracy': 0.08509097993373871, 'ae58858e_test_accuracy': 0.9783333539962769, 'ae58858e_test_diff_accuracy': 0.0, 'aee291af_test_accuracy': 0.9762962460517883, 'aee291af_test_diff_accuracy': 0.9403367638587952, 'af22c60d_test_accuracy': 0.0, 'af22c60d_test_diff_accuracy': 0.0, 'af24b4cc_test_accuracy': 0.9929630160331726, 'af24b4cc_test_diff_accuracy': 0.8559829592704773, 'b0722778_test_accuracy': 0.9844444394111633, 'b0722778_test_diff_accuracy': 0.7229965329170227, 'b0f4d537_test_accuracy': 0.9722222089767456, 'b0f4d537_test_diff_accuracy': 0.6134893894195557, 'b15fca0b_test_accuracy': 0.9675555229187012, 'b15fca0b_test_diff_accuracy': 0.0, 'b1fc8b8e_test_accuracy': 0.9851110577583313, 'b1fc8b8e_test_diff_accuracy': 0.48750001192092896, 'b20f7c8b_test_accuracy': 0.7707407474517822, 'b20f7c8b_test_diff_accuracy': 0.0, 'b457fec5_test_accuracy': 0.9137037396430969, 'b457fec5_test_diff_accuracy': 0.0, 'b4a43f3b_test_accuracy': 0.9633333086967468, 'b4a43f3b_test_diff_accuracy': 0.46900829672813416, 'b7999b51_test_accuracy': 0.9900000095367432, 'b7999b51_test_diff_accuracy': 0.8587267994880676, 'b7cb93ac_test_accuracy': 0.9866666793823242, 'b7cb93ac_test_diff_accuracy': 0.4814814627170563, 'b7f8a4d8_test_accuracy': 0.6399999856948853, 'b7f8a4d8_test_diff_accuracy': 0.0, 'b7fb29bc_test_accuracy': 0.9100000262260437, 'b7fb29bc_test_diff_accuracy': 0.0, 'b942fd60_test_accuracy': 0.9666666984558105, 'b942fd60_test_diff_accuracy': 0.0, 'b9630600_test_accuracy': 0.8437037467956543, 'b9630600_test_diff_accuracy': 0.3881119191646576, 'ba9d41b8_test_accuracy': 0.9162963032722473, 'ba9d41b8_test_diff_accuracy': 1.0, 'baf41dbf_test_accuracy': 0.9592592716217041, 'baf41dbf_test_diff_accuracy': 0.20501208305358887, 'bb52a14b_test_accuracy': 0.9188888669013977, 'bb52a14b_test_diff_accuracy': 0.0, 'bbb1b8b6_test_accuracy': 0.9852380156517029, 'bbb1b8b6_test_diff_accuracy': 0.5396488308906555, 'bc4146bd_test_accuracy': 0.9111111164093018, 'bc4146bd_test_diff_accuracy': 0.0, 'bcb3040b_test_accuracy': 0.9196296334266663, 'bcb3040b_test_diff_accuracy': 0.0, 'bd14c3bf_test_accuracy': 0.9211111068725586, 'bd14c3bf_test_diff_accuracy': 0.0, 'be03b35f_test_accuracy': 0.9970369935035706, 'be03b35f_test_diff_accuracy': 0.8111111521720886, 'bf32578f_test_accuracy': 0.9881481528282166, 'bf32578f_test_diff_accuracy': 0.3821733891963959, 'bf699163_test_accuracy': 0.9900000095367432, 'bf699163_test_diff_accuracy': 0.9721251130104065, 'bf89d739_test_accuracy': 0.9780555367469788, 'bf89d739_test_diff_accuracy': 0.0, 'c074846d_test_accuracy': 0.9948889017105103, 'c074846d_test_diff_accuracy': 0.0, 'c1990cce_test_accuracy': 0.9785184860229492, 'c1990cce_test_diff_accuracy': 0.07402319461107254, 'c3202e5a_test_accuracy': 0.9929630160331726, 'c3202e5a_test_diff_accuracy': 0.9741120338439941, 'c35c1b4c_test_accuracy': 0.9144444465637207, 'c35c1b4c_test_diff_accuracy': 0.0, 'c48954c1_test_accuracy': 0.9100000262260437, 'c48954c1_test_diff_accuracy': 0.0, 'c62e2108_test_accuracy': 0.8962963223457336, 'c62e2108_test_diff_accuracy': 0.04329491779208183, 'c64f1187_test_accuracy': 0.9688888788223267, 'c64f1187_test_diff_accuracy': 0.6881044507026672, 'c658a4bd_test_accuracy': 0.9194444417953491, 'c658a4bd_test_diff_accuracy': 0.37494730949401855, 'c663677b_test_accuracy': 0.1899999976158142, 'c663677b_test_diff_accuracy': 0.0, 'c6e1b8da_test_accuracy': 0.8537037372589111, 'c6e1b8da_test_diff_accuracy': 0.45049849152565, 'c7d4e6ad_test_accuracy': 0.9777777791023254, 'c7d4e6ad_test_diff_accuracy': 0.0, 'c87289bb_test_accuracy': 0.9436111450195312, 'c87289bb_test_diff_accuracy': 0.0, 'c8b7cc0f_test_accuracy': 0.995555579662323, 'c8b7cc0f_test_diff_accuracy': 0.8881499767303467, 'c92b942c_test_accuracy': 0.9175000190734863, 'c92b942c_test_diff_accuracy': 0.0, 'c97c0139_test_accuracy': 0.9155555963516235, 'c97c0139_test_diff_accuracy': 0.0, 'ca8de6ea_test_accuracy': 0.9900000095367432, 'ca8de6ea_test_diff_accuracy': 0.3333333432674408, 'ca8f78db_test_accuracy': 0.0, 'ca8f78db_test_diff_accuracy': 0.0, 'cad67732_test_accuracy': 0.9740740656852722, 'cad67732_test_diff_accuracy': 0.0, 'cb227835_test_accuracy': 0.9792592525482178, 'cb227835_test_diff_accuracy': 0.0, 'ccd554ac_test_accuracy': 0.9307406544685364, 'ccd554ac_test_diff_accuracy': 0.02556818164885044, 'cd3c21df_test_accuracy': 0.9948148727416992, 'cd3c21df_test_diff_accuracy': 0.8213383555412292, 'ce039d91_test_accuracy': 0.9774999618530273, 'ce039d91_test_diff_accuracy': 0.0, 'ce8d95cc_test_accuracy': 0.9802777767181396, 'ce8d95cc_test_diff_accuracy': 0.7194792032241821, 'cf133acc_test_accuracy': 0.9370369911193848, 'cf133acc_test_diff_accuracy': 0.0, 'cfb2ce5a_test_accuracy': 0.9325925707817078, 'cfb2ce5a_test_diff_accuracy': 0.0, 'd017b73f_test_accuracy': 0.9883332848548889, 'd017b73f_test_diff_accuracy': 0.5, 'd19f7514_test_accuracy': 0.9808333516120911, 'd19f7514_test_diff_accuracy': 0.4937748610973358, 'd282b262_test_accuracy': 0.9677777290344238, 'd282b262_test_diff_accuracy': 0.4773857891559601, 'd2acf2cb_test_accuracy': 0.9551851749420166, 'd2acf2cb_test_diff_accuracy': 0.095238097012043, 'd304284e_test_accuracy': 0.8761111497879028, 'd304284e_test_diff_accuracy': 0.0, 'd37a1ef5_test_accuracy': 0.9344444274902344, 'd37a1ef5_test_diff_accuracy': 0.0, 'd47aa2ff_test_accuracy': 0.9896295666694641, 'd47aa2ff_test_diff_accuracy': 0.7235023379325867, 'd492a647_test_accuracy': 0.8811111450195312, 'd492a647_test_diff_accuracy': 0.0, 'd4b1c2b1_test_accuracy': 0.9442857503890991, 'd4b1c2b1_test_diff_accuracy': 0.2857142984867096, 'd4c90558_test_accuracy': 0.9829629063606262, 'd4c90558_test_diff_accuracy': 0.9063237309455872, 'd56f2372_test_accuracy': 0.9866666793823242, 'd56f2372_test_diff_accuracy': 0.8060207962989807, 'd5c634a2_test_accuracy': 0.9953967928886414, 'd5c634a2_test_diff_accuracy': 0.7885443568229675, 'd931c21c_test_accuracy': 0.9108333587646484, 'd931c21c_test_diff_accuracy': 0.25, 'd94c3b52_test_accuracy': 0.8414815068244934, 'd94c3b52_test_diff_accuracy': 0.0, 'da2b0fe3_test_accuracy': 0.9707407355308533, 'da2b0fe3_test_diff_accuracy': 0.0, 'da515329_test_accuracy': 0.8374074101448059, 'da515329_test_diff_accuracy': 0.0, 'dc2aa30b_test_accuracy': 0.9100000262260437, 'dc2aa30b_test_diff_accuracy': 0.0, 'dc2e9a9d_test_accuracy': 0.9233333468437195, 'dc2e9a9d_test_diff_accuracy': 0.0, 'dd2401ed_test_accuracy': 0.9811111092567444, 'dd2401ed_test_diff_accuracy': 0.43627452850341797, 'de493100_test_accuracy': 0.25111111998558044, 'de493100_test_diff_accuracy': 0.2521111071109772, 'df8cc377_test_accuracy': 0.9492592811584473, 'df8cc377_test_diff_accuracy': 0.5, 'e0fb7511_test_accuracy': 0.8314814567565918, 'e0fb7511_test_diff_accuracy': 0.0, 'e133d23d_test_accuracy': 0.9926666021347046, 'e133d23d_test_diff_accuracy': 0.5035164952278137, 'e1baa8a4_test_accuracy': 0.9894444942474365, 'e1baa8a4_test_diff_accuracy': 0.9602466225624084, 'e1d2900e_test_accuracy': 0.9777777194976807, 'e1d2900e_test_diff_accuracy': 0.5, 'e2092e0c_test_accuracy': 0.8866667151451111, 'e2092e0c_test_diff_accuracy': 0.0, 'e21a174a_test_accuracy': 0.9562962651252747, 'e21a174a_test_diff_accuracy': 0.254934161901474, 'e345f17b_test_accuracy': 0.9961110949516296, 'e345f17b_test_diff_accuracy': 0.8137826919555664, 'e4075551_test_accuracy': 0.9433333277702332, 'e4075551_test_diff_accuracy': 0.0, 'e41c6fd3_test_accuracy': 0.936296284198761, 'e41c6fd3_test_diff_accuracy': 0.5, 'e57337a4_test_accuracy': 0.8762962818145752, 'e57337a4_test_diff_accuracy': 0.5169753432273865, 'e5790162_test_accuracy': 0.988444447517395, 'e5790162_test_diff_accuracy': 0.0, 'e5c44e8f_test_accuracy': 0.9455555081367493, 'e5c44e8f_test_diff_accuracy': 0.0, 'e619ca6e_test_accuracy': 0.8762962818145752, 'e619ca6e_test_diff_accuracy': 0.0, 'e633a9e5_test_accuracy': 0.9722221493721008, 'e633a9e5_test_diff_accuracy': 0.0, 'e66aafb8_test_accuracy': 0.9508889317512512, 'e66aafb8_test_diff_accuracy': 0.9255886077880859, 'e681b708_test_accuracy': 0.8870370388031006, 'e681b708_test_diff_accuracy': 0.0, 'e69241bd_test_accuracy': 0.9433333277702332, 'e69241bd_test_diff_accuracy': 0.0, 'e6de6e8f_test_accuracy': 0.9877777695655823, 'e6de6e8f_test_diff_accuracy': 0.5444445013999939, 'e74e1818_test_accuracy': 0.9674074053764343, 'e74e1818_test_diff_accuracy': 0.5, 'e760a62e_test_accuracy': 0.618148148059845, 'e760a62e_test_diff_accuracy': 0.0, 'e7639916_test_accuracy': 0.9644444584846497, 'e7639916_test_diff_accuracy': 0.0, 'e78887d1_test_accuracy': 0.9794444441795349, 'e78887d1_test_diff_accuracy': 0.6878482103347778, 'e7a25a18_test_accuracy': 0.9244444370269775, 'e7a25a18_test_diff_accuracy': 0.2172304391860962, 'e7b06bea_test_accuracy': 0.9871110916137695, 'e7b06bea_test_diff_accuracy': 0.7000000476837158, 'e7dd8335_test_accuracy': 0.9785184860229492, 'e7dd8335_test_diff_accuracy': 0.0, 'e872b94a_test_accuracy': 1.0, 'e872b94a_test_diff_accuracy': 1.0, 'e88171ec_test_accuracy': 0.8096296787261963, 'e88171ec_test_diff_accuracy': 0.0, 'e95e3d8e_test_accuracy': 0.46222221851348877, 'e95e3d8e_test_diff_accuracy': 0.0, 'e99362f0_test_accuracy': 0.978518545627594, 'e99362f0_test_diff_accuracy': 0.7147099375724792, 'e9ac8c9e_test_accuracy': 0.9792592525482178, 'e9ac8c9e_test_diff_accuracy': 0.2666666805744171, 'e9b4f6fc_test_accuracy': 0.9619444012641907, 'e9b4f6fc_test_diff_accuracy': 0.44486111402511597, 'e9bb6954_test_accuracy': 0.9030555486679077, 'e9bb6954_test_diff_accuracy': 0.0032051282469183207, 'e9c9d9a1_test_accuracy': 0.8203703761100769, 'e9c9d9a1_test_diff_accuracy': 0.0, 'ea959feb_test_accuracy': 0.3888889253139496, 'ea959feb_test_diff_accuracy': 0.0, 'ea9794b1_test_accuracy': 0.9729629158973694, 'ea9794b1_test_diff_accuracy': 0.647230327129364, 'ecaa0ec1_test_accuracy': 0.9894444346427917, 'ecaa0ec1_test_diff_accuracy': 0.48773449659347534, 'ed74f2f2_test_accuracy': 0.9935185313224792, 'ed74f2f2_test_diff_accuracy': 0.5953373312950134, 'ed98d772_test_accuracy': 0.9777777791023254, 'ed98d772_test_diff_accuracy': 0.10508663952350616, 'ef26cbf6_test_accuracy': 0.95333331823349, 'ef26cbf6_test_diff_accuracy': 0.0, 'f0afb749_test_accuracy': 0.9822222590446472, 'f0afb749_test_diff_accuracy': 0.061728399246931076, 'f0df5ff0_test_accuracy': 0.8670370578765869, 'f0df5ff0_test_diff_accuracy': 0.0, 'f21745ec_test_accuracy': 0.8877778053283691, 'f21745ec_test_diff_accuracy': 0.4960607588291168, 'f3b10344_test_accuracy': 0.711481511592865, 'f3b10344_test_diff_accuracy': 0.0, 'f3cdc58f_test_accuracy': 0.9785184860229492, 'f3cdc58f_test_diff_accuracy': 0.44780412316322327, 'f3e62deb_test_accuracy': 0.9911110997200012, 'f3e62deb_test_diff_accuracy': 0.5, 'f4081712_test_accuracy': 0.9235555529594421, 'f4081712_test_diff_accuracy': 0.8869382739067078, 'f45f5ca7_test_accuracy': 0.9918518662452698, 'f45f5ca7_test_diff_accuracy': 0.5, 'f5aa3634_test_accuracy': 0.9911110997200012, 'f5aa3634_test_diff_accuracy': 0.8053030371665955, 'f5c89df1_test_accuracy': 0.9829629063606262, 'f5c89df1_test_diff_accuracy': 0.437296062707901, 'f823c43c_test_accuracy': 0.7616666555404663, 'f823c43c_test_diff_accuracy': 0.0, 'f83cb3f6_test_accuracy': 0.9807407259941101, 'f83cb3f6_test_diff_accuracy': 0.6049907803535461, 'f8be4b64_test_accuracy': 0.9094444513320923, 'f8be4b64_test_diff_accuracy': 0.0, 'f9a67cb5_test_accuracy': 0.9262962937355042, 'f9a67cb5_test_diff_accuracy': 0.0, 'f9d67f8b_test_accuracy': 0.15777777135372162, 'f9d67f8b_test_diff_accuracy': 0.13529807329177856, 'fafd9572_test_accuracy': 0.9700000286102295, 'fafd9572_test_diff_accuracy': 0.0, 'fb791726_test_accuracy': 0.961017370223999, 'fb791726_test_diff_accuracy': 0.03614457696676254, 'fc754716_test_accuracy': 0.9844443798065186, 'fc754716_test_diff_accuracy': 0.07361919432878494, 'fd096ab6_test_accuracy': 0.41111111640930176, 'fd096ab6_test_diff_accuracy': 0.0, 'fd4b2b02_test_accuracy': 0.9122222065925598, 'fd4b2b02_test_diff_accuracy': 0.0, 'fe9372f3_test_accuracy': 0.9600000977516174, 'fe9372f3_test_diff_accuracy': 0.0, 'fea12743_test_accuracy': 0.9288887977600098, 'fea12743_test_diff_accuracy': 0.0, 'ff72ca3e_test_accuracy': 0.9647221565246582, 'ff72ca3e_test_diff_accuracy': 0.0, 'avg_test_loss': 0.3664872646331787, 'avg_test_accuracy': 0.904828667640686, 'avg_test_diff_accuracy': 0.2692205607891083}]\n",
            "DEBUG:__main__:DEBUG: Evaluation results: {'test_loss': 0.3664872646331787, 'test_accuracy': 0.904828667640686, 'test_diff_accuracy': 0.2692205607891083, 'complete_task_accuracy': 0.2344139650872818}\n",
            "DEBUG:__main__:DEBUG: Individual metrics: {'00576224': {'test_accuracy': 0.9599999785423279, 'test_diff_accuracy': 0.0}, '009d5c81': {'test_accuracy': 0.9744443893432617, 'test_diff_accuracy': 0.21003207564353943}, '00dbd492': {'test_accuracy': 0.929444432258606, 'test_diff_accuracy': 0.0}, '03560426': {'test_accuracy': 0.9796295762062073, 'test_diff_accuracy': 0.5188145637512207}, '05a7bcf2': {'test_accuracy': 0.6566666960716248, 'test_diff_accuracy': 0.0}, '0607ce86': {'test_accuracy': 0.7966666221618652, 'test_diff_accuracy': 0.6599085927009583}, '0692e18c': {'test_accuracy': 0.9785184860229492, 'test_diff_accuracy': 0.16984127461910248}, '070dd51e': {'test_accuracy': 0.9611111283302307, 'test_diff_accuracy': 0.0}, '08573cc6': {'test_accuracy': 0.962592601776123, 'test_diff_accuracy': 0.06767676770687103}, '0934a4d8': {'test_accuracy': 0.37638890743255615, 'test_diff_accuracy': 0.37773966789245605}, '09c534e7': {'test_accuracy': 0.7877777218818665, 'test_diff_accuracy': 0.0}, '0a1d4ef5': {'test_accuracy': 0.9511110782623291, 'test_diff_accuracy': 0.9168465733528137}, '0a2355a6': {'test_accuracy': 0.9394444823265076, 'test_diff_accuracy': 0.0}, '0b17323b': {'test_accuracy': 0.9938889145851135, 'test_diff_accuracy': 0.0}, '0bb8deee': {'test_accuracy': 0.9788889288902283, 'test_diff_accuracy': 0.6813034415245056}, '0becf7df': {'test_accuracy': 0.9744444489479065, 'test_diff_accuracy': 0.0}, '0c786b71': {'test_accuracy': 0.9466666579246521, 'test_diff_accuracy': 0.0}, '0c9aba6e': {'test_accuracy': 0.9916666746139526, 'test_diff_accuracy': 0.747855007648468}, '0d87d2a6': {'test_accuracy': 0.9055555462837219, 'test_diff_accuracy': 0.0}, '0e671a1a': {'test_accuracy': 0.9724999666213989, 'test_diff_accuracy': 0.0}, '0f63c0b9': {'test_accuracy': 0.8908333778381348, 'test_diff_accuracy': 0.0}, '103eff5b': {'test_accuracy': 0.9416666626930237, 'test_diff_accuracy': 0.0}, '11e1fe23': {'test_accuracy': 0.992222249507904, 'test_diff_accuracy': 0.0}, '12422b43': {'test_accuracy': 0.9788888692855835, 'test_diff_accuracy': 0.0}, '12997ef3': {'test_accuracy': 0.9844444394111633, 'test_diff_accuracy': 0.3445091247558594}, '12eac192': {'test_accuracy': 0.9725000262260437, 'test_diff_accuracy': 0.0}, '136b0064': {'test_accuracy': 0.9822222590446472, 'test_diff_accuracy': 0.711358368396759}, '13713586': {'test_accuracy': 0.859259307384491, 'test_diff_accuracy': 0.0}, '137f0df0': {'test_accuracy': 0.9185185432434082, 'test_diff_accuracy': 0.0}, '140c817e': {'test_accuracy': 0.8625926375389099, 'test_diff_accuracy': 0.0}, '14754a24': {'test_accuracy': 0.8630555272102356, 'test_diff_accuracy': 0.0}, '15113be4': {'test_accuracy': 0.6255555748939514, 'test_diff_accuracy': 0.0}, '15663ba9': {'test_accuracy': 0.9422222971916199, 'test_diff_accuracy': 0.0}, '15696249': {'test_accuracy': 0.9700000286102295, 'test_diff_accuracy': 0.1875}, '16b78196': {'test_accuracy': 0.7916666865348816, 'test_diff_accuracy': 0.4842342138290405}, '17b80ad2': {'test_accuracy': 0.9611111283302307, 'test_diff_accuracy': 0.0}, '17cae0c1': {'test_accuracy': 0.9700000286102295, 'test_diff_accuracy': 0.0}, '18419cfa': {'test_accuracy': 0.9344444274902344, 'test_diff_accuracy': 0.0}, '184a9768': {'test_accuracy': 0.8522222638130188, 'test_diff_accuracy': 0.575104296207428}, '195ba7dc': {'test_accuracy': 0.9758332967758179, 'test_diff_accuracy': 0.5054347515106201}, '1990f7a8': {'test_accuracy': 0.9740740656852722, 'test_diff_accuracy': 0.5}, '19bb5feb': {'test_accuracy': 0.9729630351066589, 'test_diff_accuracy': 0.7311635613441467}, '1a2e2828': {'test_accuracy': 0.9986666440963745, 'test_diff_accuracy': 0.9834964871406555}, '1a6449f1': {'test_accuracy': 0.9829629063606262, 'test_diff_accuracy': 0.9130600094795227}, '1acc24af': {'test_accuracy': 0.964722216129303, 'test_diff_accuracy': 0.0}, '1c02dbbe': {'test_accuracy': 0.860370397567749, 'test_diff_accuracy': 0.06207104027271271}, '1c0d0a4b': {'test_accuracy': 0.9825925827026367, 'test_diff_accuracy': 0.595678985118866}, '1c56ad9f': {'test_accuracy': 0.9541666507720947, 'test_diff_accuracy': 0.5}, '1d0a4b61': {'test_accuracy': 0.3055555522441864, 'test_diff_accuracy': 0.0}, '1d398264': {'test_accuracy': 0.9462962746620178, 'test_diff_accuracy': 0.0}, '1da012fc': {'test_accuracy': 0.9105556011199951, 'test_diff_accuracy': 0.0}, '1e81d6f9': {'test_accuracy': 0.9681481719017029, 'test_diff_accuracy': 1.0}, '1e97544e': {'test_accuracy': 0.41296300292015076, 'test_diff_accuracy': 0.0}, '2037f2c7': {'test_accuracy': 0.9900000095367432, 'test_diff_accuracy': 0.9334214329719543}, '2072aba6': {'test_accuracy': 0.9807407259941101, 'test_diff_accuracy': 0.01587301678955555}, '20818e16': {'test_accuracy': 0.9385185241699219, 'test_diff_accuracy': 0.723113477230072}, '20981f0e': {'test_accuracy': 0.9681481719017029, 'test_diff_accuracy': 0.5}, '212895b5': {'test_accuracy': 0.9196296334266663, 'test_diff_accuracy': 0.0}, '21f83797': {'test_accuracy': 0.9238889217376709, 'test_diff_accuracy': 0.0}, '22a4bbc2': {'test_accuracy': 0.9433333277702332, 'test_diff_accuracy': 0.0}, '25094a63': {'test_accuracy': 0.1827777773141861, 'test_diff_accuracy': 0.0}, '2546ccf6': {'test_accuracy': 0.8550000190734863, 'test_diff_accuracy': 0.0}, '256b0a75': {'test_accuracy': 0.6666666865348816, 'test_diff_accuracy': 0.0}, '2685904e': {'test_accuracy': 0.965925931930542, 'test_diff_accuracy': 0.0}, '2697da3f': {'test_accuracy': 0.9511110782623291, 'test_diff_accuracy': 0.16602009534835815}, '2753e76c': {'test_accuracy': 0.9900000095367432, 'test_diff_accuracy': 0.899422824382782}, '27a77e38': {'test_accuracy': 0.9807407259941101, 'test_diff_accuracy': 0.0}, '27f8ce4f': {'test_accuracy': 0.9650000333786011, 'test_diff_accuracy': 0.11249999701976776}, '281123b4': {'test_accuracy': 0.9829630255699158, 'test_diff_accuracy': 0.7146536707878113}, '292dd178': {'test_accuracy': 0.9081481099128723, 'test_diff_accuracy': 0.0}, '29700607': {'test_accuracy': 0.9618518948554993, 'test_diff_accuracy': 0.0}, '2a5f8217': {'test_accuracy': 0.9774073958396912, 'test_diff_accuracy': 0.0}, '2b01abd0': {'test_accuracy': 0.970740795135498, 'test_diff_accuracy': 0.0}, '2c0b0aff': {'test_accuracy': 0.9119444489479065, 'test_diff_accuracy': 0.7577368021011353}, '2c737e39': {'test_accuracy': 0.9840741157531738, 'test_diff_accuracy': 0.13650794327259064}, '2f0c5170': {'test_accuracy': 0.9674074053764343, 'test_diff_accuracy': 0.9186174869537354}, '310f3251': {'test_accuracy': 0.9700000882148743, 'test_diff_accuracy': 0.0}, '3194b014': {'test_accuracy': 0.9770370125770569, 'test_diff_accuracy': 0.9225044250488281}, '319f2597': {'test_accuracy': 0.6277777552604675, 'test_diff_accuracy': 0.9736223220825195}, '31adaf00': {'test_accuracy': 0.9307407736778259, 'test_diff_accuracy': 0.0}, '31d5ba1a': {'test_accuracy': 0.9928889274597168, 'test_diff_accuracy': 0.6540936231613159}, '32e9702f': {'test_accuracy': 0.9548148512840271, 'test_diff_accuracy': 0.0}, '332efdb3': {'test_accuracy': 0.9533333778381348, 'test_diff_accuracy': 0.0}, '3391f8c0': {'test_accuracy': 0.9824999570846558, 'test_diff_accuracy': 0.3541666865348816}, '33b52de3': {'test_accuracy': 0.8538888692855835, 'test_diff_accuracy': 0.0}, '3490cc26': {'test_accuracy': 0.9061111211776733, 'test_diff_accuracy': 0.0}, '34b99a2b': {'test_accuracy': 0.9883333444595337, 'test_diff_accuracy': 0.629668653011322}, '351d6448': {'test_accuracy': 0.9927777647972107, 'test_diff_accuracy': 0.8858424425125122}, '358ba94e': {'test_accuracy': 0.9744444489479065, 'test_diff_accuracy': 0.8644062280654907}, '37d3e8b2': {'test_accuracy': 0.8788889050483704, 'test_diff_accuracy': 0.0}, '3979b1a8': {'test_accuracy': 0.8888888955116272, 'test_diff_accuracy': 0.0}, '3a301edc': {'test_accuracy': 0.9024444818496704, 'test_diff_accuracy': 0.0}, '3b4c2228': {'test_accuracy': 0.9979999661445618, 'test_diff_accuracy': 0.8947456479072571}, '3d31c5b3': {'test_accuracy': 0.9794444441795349, 'test_diff_accuracy': 0.6079409122467041}, '3ed85e70': {'test_accuracy': 0.6381481885910034, 'test_diff_accuracy': 0.0}, '3ee1011a': {'test_accuracy': 0.9537037014961243, 'test_diff_accuracy': 0.20636117458343506}, '3f23242b': {'test_accuracy': 0.9550000429153442, 'test_diff_accuracy': 0.0}, '40f6cd08': {'test_accuracy': 0.6270370483398438, 'test_diff_accuracy': 0.0}, '414297c0': {'test_accuracy': 0.8959259390830994, 'test_diff_accuracy': 0.4695725440979004}, '423a55dc': {'test_accuracy': 0.9855555295944214, 'test_diff_accuracy': 0.5216470956802368}, '42918530': {'test_accuracy': 0.815833330154419, 'test_diff_accuracy': 0.0}, '42a15761': {'test_accuracy': 0.9062963128089905, 'test_diff_accuracy': 0.5}, '4364c1c4': {'test_accuracy': 0.8177778124809265, 'test_diff_accuracy': 0.0}, '456873bc': {'test_accuracy': 0.9514815211296082, 'test_diff_accuracy': 0.7703775763511658}, '45737921': {'test_accuracy': 0.9733333587646484, 'test_diff_accuracy': 0.0}, '45bbe264': {'test_accuracy': 0.932962954044342, 'test_diff_accuracy': 0.0}, '477d2879': {'test_accuracy': 0.8122222423553467, 'test_diff_accuracy': 0.0}, '47996f11': {'test_accuracy': 0.13833333551883698, 'test_diff_accuracy': 0.10620684921741486}, '48131b3c': {'test_accuracy': 0.9733333587646484, 'test_diff_accuracy': 0.11290545016527176}, '4852f2fa': {'test_accuracy': 0.9853333234786987, 'test_diff_accuracy': 0.36084944009780884}, '48f8583b': {'test_accuracy': 0.9798148274421692, 'test_diff_accuracy': 0.29629629850387573}, '4aab4007': {'test_accuracy': 0.12888889014720917, 'test_diff_accuracy': 0.0}, '4acc7107': {'test_accuracy': 0.9758333563804626, 'test_diff_accuracy': 0.4823917746543884}, '4b6b68e5': {'test_accuracy': 0.8622221946716309, 'test_diff_accuracy': 0.03787878900766373}, '4c177718': {'test_accuracy': 0.9872222542762756, 'test_diff_accuracy': 0.7471552491188049}, '4cd1b7b2': {'test_accuracy': 0.9822222590446472, 'test_diff_accuracy': 0.0}, '4e45f183': {'test_accuracy': 0.7507407665252686, 'test_diff_accuracy': 0.013888888992369175}, '4e469f39': {'test_accuracy': 0.9662962555885315, 'test_diff_accuracy': 0.0}, '4f537728': {'test_accuracy': 0.7972222566604614, 'test_diff_accuracy': 0.0}, '4ff4c9da': {'test_accuracy': 0.6259259581565857, 'test_diff_accuracy': 0.0}, '505fff84': {'test_accuracy': 0.9913333654403687, 'test_diff_accuracy': 0.8910254240036011}, '506d28a5': {'test_accuracy': 0.9822221994400024, 'test_diff_accuracy': 0.47752460837364197}, '50a16a69': {'test_accuracy': 0.8159258961677551, 'test_diff_accuracy': 0.03999999910593033}, '50aad11f': {'test_accuracy': 0.9785184860229492, 'test_diff_accuracy': 0.4671497642993927}, '50f325b5': {'test_accuracy': 0.801944375038147, 'test_diff_accuracy': 0.0}, '516b51b7': {'test_accuracy': 0.9188888669013977, 'test_diff_accuracy': 0.0}, '5207a7b5': {'test_accuracy': 0.9559259414672852, 'test_diff_accuracy': 0.0}, '5289ad53': {'test_accuracy': 0.9755555391311646, 'test_diff_accuracy': 0.8811259269714355}, '52fd389e': {'test_accuracy': 0.7137036323547363, 'test_diff_accuracy': 0.0}, '54db823b': {'test_accuracy': 0.9066666960716248, 'test_diff_accuracy': 1.0}, '55059096': {'test_accuracy': 0.9744443893432617, 'test_diff_accuracy': 0.0}, '551d5bf1': {'test_accuracy': 0.7644444704055786, 'test_diff_accuracy': 0.0}, '55783887': {'test_accuracy': 0.8462222218513489, 'test_diff_accuracy': 0.10000000149011612}, '575b1a71': {'test_accuracy': 0.8888888955116272, 'test_diff_accuracy': 0.0}, '5783df64': {'test_accuracy': 0.9900000095367432, 'test_diff_accuracy': 0.45825162529945374}, '5833af48': {'test_accuracy': 0.8825926184654236, 'test_diff_accuracy': 0.6010026335716248}, '58743b76': {'test_accuracy': 0.9472222328186035, 'test_diff_accuracy': 0.0}, '58e15b12': {'test_accuracy': 0.9170370697975159, 'test_diff_accuracy': 0.0}, '59341089': {'test_accuracy': 0.960277795791626, 'test_diff_accuracy': 0.0}, '5a5a2103': {'test_accuracy': 0.8194444179534912, 'test_diff_accuracy': 0.04545454680919647}, '5af49b42': {'test_accuracy': 0.9737036824226379, 'test_diff_accuracy': 0.0}, '5b526a93': {'test_accuracy': 0.90666663646698, 'test_diff_accuracy': 0.0}, '5b692c0f': {'test_accuracy': 0.9133332967758179, 'test_diff_accuracy': 0.23863637447357178}, '5b6cbef5': {'test_accuracy': 0.9197778701782227, 'test_diff_accuracy': 0.09092767536640167}, '5d2a5c43': {'test_accuracy': 0.9784444570541382, 'test_diff_accuracy': 0.47774338722229004}, '5ffb2104': {'test_accuracy': 0.987407386302948, 'test_diff_accuracy': 0.4901960790157318}, '604001fa': {'test_accuracy': 0.9819444417953491, 'test_diff_accuracy': 0.2735389471054077}, '60a26a3e': {'test_accuracy': 0.9718518257141113, 'test_diff_accuracy': 0.0}, '60c09cac': {'test_accuracy': 0.9822221994400024, 'test_diff_accuracy': 0.02777777798473835}, '626c0bcc': {'test_accuracy': 0.9825925827026367, 'test_diff_accuracy': 0.0}, '62ab2642': {'test_accuracy': 0.93666672706604, 'test_diff_accuracy': 0.0}, '62b74c02': {'test_accuracy': 0.9559259414672852, 'test_diff_accuracy': 0.0}, '639f5a19': {'test_accuracy': 0.7777777910232544, 'test_diff_accuracy': 0.0}, '642248e4': {'test_accuracy': 0.9570370316505432, 'test_diff_accuracy': 0.0}, '642d658d': {'test_accuracy': 0.9611111283302307, 'test_diff_accuracy': 0.9283973574638367}, '64a7c07e': {'test_accuracy': 0.9892592430114746, 'test_diff_accuracy': 0.5}, '66e6c45b': {'test_accuracy': 0.995555579662323, 'test_diff_accuracy': 0.5}, '66f2d22f': {'test_accuracy': 0.991944432258606, 'test_diff_accuracy': 0.7562196850776672}, '67636eac': {'test_accuracy': 0.9862963557243347, 'test_diff_accuracy': 0.46666666865348816}, '67b4a34d': {'test_accuracy': 0.9696295857429504, 'test_diff_accuracy': 0.9138374328613281}, '67c52801': {'test_accuracy': 0.9786111116409302, 'test_diff_accuracy': 0.5}, '68b67ca3': {'test_accuracy': 0.9944444298744202, 'test_diff_accuracy': 0.5}, '692cd3b6': {'test_accuracy': 0.9007408022880554, 'test_diff_accuracy': 0.0}, '695367ec': {'test_accuracy': 0.8937036991119385, 'test_diff_accuracy': 0.05552127584815025}, '696d4842': {'test_accuracy': 0.962592601776123, 'test_diff_accuracy': 0.0}, '69889d6e': {'test_accuracy': 0.980555534362793, 'test_diff_accuracy': 0.0}, '6a11f6da': {'test_accuracy': 0.975777804851532, 'test_diff_accuracy': 0.5782161355018616}, '6ad5bdfd': {'test_accuracy': 0.9814814925193787, 'test_diff_accuracy': 0.45766592025756836}, '6df30ad6': {'test_accuracy': 0.991777777671814, 'test_diff_accuracy': 0.5457017421722412}, '6ea4a07e': {'test_accuracy': 0.9937036633491516, 'test_diff_accuracy': 0.37037038803100586}, '6f473927': {'test_accuracy': 0.9677777886390686, 'test_diff_accuracy': 0.21378621459007263}, '7039b2d7': {'test_accuracy': 0.9840741157531738, 'test_diff_accuracy': 0.9842607378959656}, '705a3229': {'test_accuracy': 0.9844444394111633, 'test_diff_accuracy': 0.0}, '712bf12e': {'test_accuracy': 0.9170370101928711, 'test_diff_accuracy': 0.0}, '72207abc': {'test_accuracy': 0.9925925731658936, 'test_diff_accuracy': 0.0}, '72a961c9': {'test_accuracy': 0.9844444990158081, 'test_diff_accuracy': 0.0}, '73182012': {'test_accuracy': 0.9881481528282166, 'test_diff_accuracy': 0.8835263848304749}, '73c3b0d8': {'test_accuracy': 0.9869444370269775, 'test_diff_accuracy': 0.2957516312599182}, '73ccf9c2': {'test_accuracy': 0.9881481528282166, 'test_diff_accuracy': 0.8363578915596008}, '759f3fd3': {'test_accuracy': 0.8427777886390686, 'test_diff_accuracy': 0.0}, '762cd429': {'test_accuracy': 0.8118519186973572, 'test_diff_accuracy': 0.0}, '770cc55f': {'test_accuracy': 0.9769444465637207, 'test_diff_accuracy': 0.0}, '782b5218': {'test_accuracy': 0.9344444274902344, 'test_diff_accuracy': 0.4673832952976227}, '79369cc6': {'test_accuracy': 0.8040741086006165, 'test_diff_accuracy': 0.0}, '7953d61e': {'test_accuracy': 0.9288889169692993, 'test_diff_accuracy': 0.0}, '79fb03f4': {'test_accuracy': 0.93833327293396, 'test_diff_accuracy': 0.0}, '7bb29440': {'test_accuracy': 0.9735555648803711, 'test_diff_accuracy': 0.8471860885620117}, '7c8af763': {'test_accuracy': 0.8888888955116272, 'test_diff_accuracy': 0.0}, '7c9b52a0': {'test_accuracy': 0.9074074625968933, 'test_diff_accuracy': 0.6268526911735535}, '7d18a6fb': {'test_accuracy': 0.9770370125770569, 'test_diff_accuracy': 0.7752125263214111}, '7d1f7ee8': {'test_accuracy': 0.8325925469398499, 'test_diff_accuracy': 0.0}, '7d419a02': {'test_accuracy': 0.851111114025116, 'test_diff_accuracy': 0.0}, '7e02026e': {'test_accuracy': 0.9000000357627869, 'test_diff_accuracy': 0.0}, '7ee1c6ea': {'test_accuracy': 0.9133333563804626, 'test_diff_accuracy': 0.0}, '817e6c09': {'test_accuracy': 0.9760000109672546, 'test_diff_accuracy': 0.0}, '81c0276b': {'test_accuracy': 0.9933333396911621, 'test_diff_accuracy': 0.9544203281402588}, '833dafe3': {'test_accuracy': 0.9644444584846497, 'test_diff_accuracy': 0.07334525883197784}, '845d6e51': {'test_accuracy': 0.9477777481079102, 'test_diff_accuracy': 0.0}, '84db8fc4': {'test_accuracy': 0.8888888955116272, 'test_diff_accuracy': 0.0}, '84f2aca1': {'test_accuracy': 0.9650000333786011, 'test_diff_accuracy': 0.0}, '8597cfd7': {'test_accuracy': 0.995555579662323, 'test_diff_accuracy': 0.8174242377281189}, '85b81ff1': {'test_accuracy': 0.875, 'test_diff_accuracy': 0.5}, '85fa5666': {'test_accuracy': 0.9622222185134888, 'test_diff_accuracy': 0.0}, '8719f442': {'test_accuracy': 0.9422221779823303, 'test_diff_accuracy': 0.0}, '88207623': {'test_accuracy': 0.9388889074325562, 'test_diff_accuracy': 0.0}, '891232d6': {'test_accuracy': 0.8897222280502319, 'test_diff_accuracy': 0.0}, '896d5239': {'test_accuracy': 0.8825926184654236, 'test_diff_accuracy': 0.0}, '8a371977': {'test_accuracy': 0.43888890743255615, 'test_diff_accuracy': 0.0}, '8b28cd80': {'test_accuracy': 0.948888897895813, 'test_diff_accuracy': 0.017298799008131027}, '8ba14f53': {'test_accuracy': 0.9938888549804688, 'test_diff_accuracy': 0.8179367184638977}, '8cb8642d': {'test_accuracy': 0.9296296238899231, 'test_diff_accuracy': 0.7093300819396973}, '8dae5dfc': {'test_accuracy': 0.8263888359069824, 'test_diff_accuracy': 0.0}, '8e2edd66': {'test_accuracy': 0.9814814925193787, 'test_diff_accuracy': 0.2586754262447357}, '8ee62060': {'test_accuracy': 0.9788889288902283, 'test_diff_accuracy': 0.5}, '8fbca751': {'test_accuracy': 0.9659258723258972, 'test_diff_accuracy': 0.0}, '90347967': {'test_accuracy': 0.9933333396911621, 'test_diff_accuracy': 0.5}, '903d1b4a': {'test_accuracy': 0.7155555486679077, 'test_diff_accuracy': 0.0}, '9110e3c5': {'test_accuracy': 0.9960317611694336, 'test_diff_accuracy': 0.8651400804519653}, '917bccba': {'test_accuracy': 0.9644444584846497, 'test_diff_accuracy': 0.6146110892295837}, '929ab4e9': {'test_accuracy': 0.3613888919353485, 'test_diff_accuracy': 0.0}, '92e50de0': {'test_accuracy': 0.6677777767181396, 'test_diff_accuracy': 0.0}, '9356391f': {'test_accuracy': 0.90666663646698, 'test_diff_accuracy': 0.0}, '93b4f4b3': {'test_accuracy': 0.9233333468437195, 'test_diff_accuracy': 0.40796583890914917}, '93c31fbe': {'test_accuracy': 0.9399999976158142, 'test_diff_accuracy': 0.3983488082885742}, '94133066': {'test_accuracy': 0.8922222256660461, 'test_diff_accuracy': 0.48462045192718506}, '94414823': {'test_accuracy': 0.9577777981758118, 'test_diff_accuracy': 0.0}, '94be5b80': {'test_accuracy': 0.9411110877990723, 'test_diff_accuracy': 0.2946428656578064}, '95a58926': {'test_accuracy': 0.8614814877510071, 'test_diff_accuracy': 0.5745627284049988}, '963f59bc': {'test_accuracy': 0.9786111116409302, 'test_diff_accuracy': 0.0}, '96a8c0cd': {'test_accuracy': 0.9350000023841858, 'test_diff_accuracy': 0.0}, '97239e3d': {'test_accuracy': 0.7988889217376709, 'test_diff_accuracy': 0.0}, '9772c176': {'test_accuracy': 0.7477777600288391, 'test_diff_accuracy': 0.0}, '981571dc': {'test_accuracy': 0.00027777778450399637, 'test_diff_accuracy': 0.0}, '992798f6': {'test_accuracy': 0.9863889217376709, 'test_diff_accuracy': 0.0}, '99306f82': {'test_accuracy': 0.9162963032722473, 'test_diff_accuracy': 0.0}, '9a4bb226': {'test_accuracy': 0.9888889193534851, 'test_diff_accuracy': 0.7706348896026611}, '9b2a60aa': {'test_accuracy': 0.965925931930542, 'test_diff_accuracy': 0.0}, '9b365c51': {'test_accuracy': 0.9670370221138, 'test_diff_accuracy': 0.444180965423584}, '9b4c17c4': {'test_accuracy': 0.8147222995758057, 'test_diff_accuracy': 0.0}, '9bebae7a': {'test_accuracy': 0.9786666631698608, 'test_diff_accuracy': 0.33641454577445984}, '9c1e755f': {'test_accuracy': 0.9461110830307007, 'test_diff_accuracy': 0.0}, '9c56f360': {'test_accuracy': 0.9737036824226379, 'test_diff_accuracy': 0.5}, '9caba7c3': {'test_accuracy': 0.7659258842468262, 'test_diff_accuracy': 0.0}, '9ddd00f0': {'test_accuracy': 0.9533333778381348, 'test_diff_accuracy': 0.0}, '9def23fe': {'test_accuracy': 0.8311111330986023, 'test_diff_accuracy': 0.0}, '9f27f097': {'test_accuracy': 0.8399999737739563, 'test_diff_accuracy': 0.0}, 'a04b2602': {'test_accuracy': 0.8177778124809265, 'test_diff_accuracy': 0.0}, 'a096bf4d': {'test_accuracy': 0.7333333492279053, 'test_diff_accuracy': 0.0}, 'a3f84088': {'test_accuracy': 0.8686110973358154, 'test_diff_accuracy': 0.0}, 'a406ac07': {'test_accuracy': 0.958148181438446, 'test_diff_accuracy': 0.0}, 'a57f2f04': {'test_accuracy': 0.6633333563804626, 'test_diff_accuracy': 0.0}, 'a59b95c0': {'test_accuracy': 0.9160000085830688, 'test_diff_accuracy': 0.0}, 'a680ac02': {'test_accuracy': 0.9644444584846497, 'test_diff_accuracy': 0.6501501202583313}, 'a8610ef7': {'test_accuracy': 0.9766666889190674, 'test_diff_accuracy': 0.0}, 'a934301b': {'test_accuracy': 0.9674074053764343, 'test_diff_accuracy': 1.0}, 'aa18de87': {'test_accuracy': 0.9791666269302368, 'test_diff_accuracy': 0.0}, 'aa300dc3': {'test_accuracy': 0.930555522441864, 'test_diff_accuracy': 0.0}, 'aa4ec2a5': {'test_accuracy': 0.43740740418434143, 'test_diff_accuracy': 0.0}, 'aab50785': {'test_accuracy': 0.9871110916137695, 'test_diff_accuracy': 0.9002954363822937}, 'ac0c5833': {'test_accuracy': 0.9518518447875977, 'test_diff_accuracy': 0.0}, 'ac2e8ecf': {'test_accuracy': 0.9529629349708557, 'test_diff_accuracy': 0.4784134328365326}, 'ac3e2b04': {'test_accuracy': 0.9386110901832581, 'test_diff_accuracy': 0.0}, 'ac605cbb': {'test_accuracy': 0.9875926375389099, 'test_diff_accuracy': 0.0}, 'ad7e01d0': {'test_accuracy': 0.9144444465637207, 'test_diff_accuracy': 0.08509097993373871}, 'ae58858e': {'test_accuracy': 0.9783333539962769, 'test_diff_accuracy': 0.0}, 'aee291af': {'test_accuracy': 0.9762962460517883, 'test_diff_accuracy': 0.9403367638587952}, 'af22c60d': {'test_accuracy': 0.0, 'test_diff_accuracy': 0.0}, 'af24b4cc': {'test_accuracy': 0.9929630160331726, 'test_diff_accuracy': 0.8559829592704773}, 'b0722778': {'test_accuracy': 0.9844444394111633, 'test_diff_accuracy': 0.7229965329170227}, 'b0f4d537': {'test_accuracy': 0.9722222089767456, 'test_diff_accuracy': 0.6134893894195557}, 'b15fca0b': {'test_accuracy': 0.9675555229187012, 'test_diff_accuracy': 0.0}, 'b1fc8b8e': {'test_accuracy': 0.9851110577583313, 'test_diff_accuracy': 0.48750001192092896}, 'b20f7c8b': {'test_accuracy': 0.7707407474517822, 'test_diff_accuracy': 0.0}, 'b457fec5': {'test_accuracy': 0.9137037396430969, 'test_diff_accuracy': 0.0}, 'b4a43f3b': {'test_accuracy': 0.9633333086967468, 'test_diff_accuracy': 0.46900829672813416}, 'b7999b51': {'test_accuracy': 0.9900000095367432, 'test_diff_accuracy': 0.8587267994880676}, 'b7cb93ac': {'test_accuracy': 0.9866666793823242, 'test_diff_accuracy': 0.4814814627170563}, 'b7f8a4d8': {'test_accuracy': 0.6399999856948853, 'test_diff_accuracy': 0.0}, 'b7fb29bc': {'test_accuracy': 0.9100000262260437, 'test_diff_accuracy': 0.0}, 'b942fd60': {'test_accuracy': 0.9666666984558105, 'test_diff_accuracy': 0.0}, 'b9630600': {'test_accuracy': 0.8437037467956543, 'test_diff_accuracy': 0.3881119191646576}, 'ba9d41b8': {'test_accuracy': 0.9162963032722473, 'test_diff_accuracy': 1.0}, 'baf41dbf': {'test_accuracy': 0.9592592716217041, 'test_diff_accuracy': 0.20501208305358887}, 'bb52a14b': {'test_accuracy': 0.9188888669013977, 'test_diff_accuracy': 0.0}, 'bbb1b8b6': {'test_accuracy': 0.9852380156517029, 'test_diff_accuracy': 0.5396488308906555}, 'bc4146bd': {'test_accuracy': 0.9111111164093018, 'test_diff_accuracy': 0.0}, 'bcb3040b': {'test_accuracy': 0.9196296334266663, 'test_diff_accuracy': 0.0}, 'bd14c3bf': {'test_accuracy': 0.9211111068725586, 'test_diff_accuracy': 0.0}, 'be03b35f': {'test_accuracy': 0.9970369935035706, 'test_diff_accuracy': 0.8111111521720886}, 'bf32578f': {'test_accuracy': 0.9881481528282166, 'test_diff_accuracy': 0.3821733891963959}, 'bf699163': {'test_accuracy': 0.9900000095367432, 'test_diff_accuracy': 0.9721251130104065}, 'bf89d739': {'test_accuracy': 0.9780555367469788, 'test_diff_accuracy': 0.0}, 'c074846d': {'test_accuracy': 0.9948889017105103, 'test_diff_accuracy': 0.0}, 'c1990cce': {'test_accuracy': 0.9785184860229492, 'test_diff_accuracy': 0.07402319461107254}, 'c3202e5a': {'test_accuracy': 0.9929630160331726, 'test_diff_accuracy': 0.9741120338439941}, 'c35c1b4c': {'test_accuracy': 0.9144444465637207, 'test_diff_accuracy': 0.0}, 'c48954c1': {'test_accuracy': 0.9100000262260437, 'test_diff_accuracy': 0.0}, 'c62e2108': {'test_accuracy': 0.8962963223457336, 'test_diff_accuracy': 0.04329491779208183}, 'c64f1187': {'test_accuracy': 0.9688888788223267, 'test_diff_accuracy': 0.6881044507026672}, 'c658a4bd': {'test_accuracy': 0.9194444417953491, 'test_diff_accuracy': 0.37494730949401855}, 'c663677b': {'test_accuracy': 0.1899999976158142, 'test_diff_accuracy': 0.0}, 'c6e1b8da': {'test_accuracy': 0.8537037372589111, 'test_diff_accuracy': 0.45049849152565}, 'c7d4e6ad': {'test_accuracy': 0.9777777791023254, 'test_diff_accuracy': 0.0}, 'c87289bb': {'test_accuracy': 0.9436111450195312, 'test_diff_accuracy': 0.0}, 'c8b7cc0f': {'test_accuracy': 0.995555579662323, 'test_diff_accuracy': 0.8881499767303467}, 'c92b942c': {'test_accuracy': 0.9175000190734863, 'test_diff_accuracy': 0.0}, 'c97c0139': {'test_accuracy': 0.9155555963516235, 'test_diff_accuracy': 0.0}, 'ca8de6ea': {'test_accuracy': 0.9900000095367432, 'test_diff_accuracy': 0.3333333432674408}, 'ca8f78db': {'test_accuracy': 0.0, 'test_diff_accuracy': 0.0}, 'cad67732': {'test_accuracy': 0.9740740656852722, 'test_diff_accuracy': 0.0}, 'cb227835': {'test_accuracy': 0.9792592525482178, 'test_diff_accuracy': 0.0}, 'ccd554ac': {'test_accuracy': 0.9307406544685364, 'test_diff_accuracy': 0.02556818164885044}, 'cd3c21df': {'test_accuracy': 0.9948148727416992, 'test_diff_accuracy': 0.8213383555412292}, 'ce039d91': {'test_accuracy': 0.9774999618530273, 'test_diff_accuracy': 0.0}, 'ce8d95cc': {'test_accuracy': 0.9802777767181396, 'test_diff_accuracy': 0.7194792032241821}, 'cf133acc': {'test_accuracy': 0.9370369911193848, 'test_diff_accuracy': 0.0}, 'cfb2ce5a': {'test_accuracy': 0.9325925707817078, 'test_diff_accuracy': 0.0}, 'd017b73f': {'test_accuracy': 0.9883332848548889, 'test_diff_accuracy': 0.5}, 'd19f7514': {'test_accuracy': 0.9808333516120911, 'test_diff_accuracy': 0.4937748610973358}, 'd282b262': {'test_accuracy': 0.9677777290344238, 'test_diff_accuracy': 0.4773857891559601}, 'd2acf2cb': {'test_accuracy': 0.9551851749420166, 'test_diff_accuracy': 0.095238097012043}, 'd304284e': {'test_accuracy': 0.8761111497879028, 'test_diff_accuracy': 0.0}, 'd37a1ef5': {'test_accuracy': 0.9344444274902344, 'test_diff_accuracy': 0.0}, 'd47aa2ff': {'test_accuracy': 0.9896295666694641, 'test_diff_accuracy': 0.7235023379325867}, 'd492a647': {'test_accuracy': 0.8811111450195312, 'test_diff_accuracy': 0.0}, 'd4b1c2b1': {'test_accuracy': 0.9442857503890991, 'test_diff_accuracy': 0.2857142984867096}, 'd4c90558': {'test_accuracy': 0.9829629063606262, 'test_diff_accuracy': 0.9063237309455872}, 'd56f2372': {'test_accuracy': 0.9866666793823242, 'test_diff_accuracy': 0.8060207962989807}, 'd5c634a2': {'test_accuracy': 0.9953967928886414, 'test_diff_accuracy': 0.7885443568229675}, 'd931c21c': {'test_accuracy': 0.9108333587646484, 'test_diff_accuracy': 0.25}, 'd94c3b52': {'test_accuracy': 0.8414815068244934, 'test_diff_accuracy': 0.0}, 'da2b0fe3': {'test_accuracy': 0.9707407355308533, 'test_diff_accuracy': 0.0}, 'da515329': {'test_accuracy': 0.8374074101448059, 'test_diff_accuracy': 0.0}, 'dc2aa30b': {'test_accuracy': 0.9100000262260437, 'test_diff_accuracy': 0.0}, 'dc2e9a9d': {'test_accuracy': 0.9233333468437195, 'test_diff_accuracy': 0.0}, 'dd2401ed': {'test_accuracy': 0.9811111092567444, 'test_diff_accuracy': 0.43627452850341797}, 'de493100': {'test_accuracy': 0.25111111998558044, 'test_diff_accuracy': 0.2521111071109772}, 'df8cc377': {'test_accuracy': 0.9492592811584473, 'test_diff_accuracy': 0.5}, 'e0fb7511': {'test_accuracy': 0.8314814567565918, 'test_diff_accuracy': 0.0}, 'e133d23d': {'test_accuracy': 0.9926666021347046, 'test_diff_accuracy': 0.5035164952278137}, 'e1baa8a4': {'test_accuracy': 0.9894444942474365, 'test_diff_accuracy': 0.9602466225624084}, 'e1d2900e': {'test_accuracy': 0.9777777194976807, 'test_diff_accuracy': 0.5}, 'e2092e0c': {'test_accuracy': 0.8866667151451111, 'test_diff_accuracy': 0.0}, 'e21a174a': {'test_accuracy': 0.9562962651252747, 'test_diff_accuracy': 0.254934161901474}, 'e345f17b': {'test_accuracy': 0.9961110949516296, 'test_diff_accuracy': 0.8137826919555664}, 'e4075551': {'test_accuracy': 0.9433333277702332, 'test_diff_accuracy': 0.0}, 'e41c6fd3': {'test_accuracy': 0.936296284198761, 'test_diff_accuracy': 0.5}, 'e57337a4': {'test_accuracy': 0.8762962818145752, 'test_diff_accuracy': 0.5169753432273865}, 'e5790162': {'test_accuracy': 0.988444447517395, 'test_diff_accuracy': 0.0}, 'e5c44e8f': {'test_accuracy': 0.9455555081367493, 'test_diff_accuracy': 0.0}, 'e619ca6e': {'test_accuracy': 0.8762962818145752, 'test_diff_accuracy': 0.0}, 'e633a9e5': {'test_accuracy': 0.9722221493721008, 'test_diff_accuracy': 0.0}, 'e66aafb8': {'test_accuracy': 0.9508889317512512, 'test_diff_accuracy': 0.9255886077880859}, 'e681b708': {'test_accuracy': 0.8870370388031006, 'test_diff_accuracy': 0.0}, 'e69241bd': {'test_accuracy': 0.9433333277702332, 'test_diff_accuracy': 0.0}, 'e6de6e8f': {'test_accuracy': 0.9877777695655823, 'test_diff_accuracy': 0.5444445013999939}, 'e74e1818': {'test_accuracy': 0.9674074053764343, 'test_diff_accuracy': 0.5}, 'e760a62e': {'test_accuracy': 0.618148148059845, 'test_diff_accuracy': 0.0}, 'e7639916': {'test_accuracy': 0.9644444584846497, 'test_diff_accuracy': 0.0}, 'e78887d1': {'test_accuracy': 0.9794444441795349, 'test_diff_accuracy': 0.6878482103347778}, 'e7a25a18': {'test_accuracy': 0.9244444370269775, 'test_diff_accuracy': 0.2172304391860962}, 'e7b06bea': {'test_accuracy': 0.9871110916137695, 'test_diff_accuracy': 0.7000000476837158}, 'e7dd8335': {'test_accuracy': 0.9785184860229492, 'test_diff_accuracy': 0.0}, 'e872b94a': {'test_accuracy': 1.0, 'test_diff_accuracy': 1.0}, 'e88171ec': {'test_accuracy': 0.8096296787261963, 'test_diff_accuracy': 0.0}, 'e95e3d8e': {'test_accuracy': 0.46222221851348877, 'test_diff_accuracy': 0.0}, 'e99362f0': {'test_accuracy': 0.978518545627594, 'test_diff_accuracy': 0.7147099375724792}, 'e9ac8c9e': {'test_accuracy': 0.9792592525482178, 'test_diff_accuracy': 0.2666666805744171}, 'e9b4f6fc': {'test_accuracy': 0.9619444012641907, 'test_diff_accuracy': 0.44486111402511597}, 'e9bb6954': {'test_accuracy': 0.9030555486679077, 'test_diff_accuracy': 0.0032051282469183207}, 'e9c9d9a1': {'test_accuracy': 0.8203703761100769, 'test_diff_accuracy': 0.0}, 'ea959feb': {'test_accuracy': 0.3888889253139496, 'test_diff_accuracy': 0.0}, 'ea9794b1': {'test_accuracy': 0.9729629158973694, 'test_diff_accuracy': 0.647230327129364}, 'ecaa0ec1': {'test_accuracy': 0.9894444346427917, 'test_diff_accuracy': 0.48773449659347534}, 'ed74f2f2': {'test_accuracy': 0.9935185313224792, 'test_diff_accuracy': 0.5953373312950134}, 'ed98d772': {'test_accuracy': 0.9777777791023254, 'test_diff_accuracy': 0.10508663952350616}, 'ef26cbf6': {'test_accuracy': 0.95333331823349, 'test_diff_accuracy': 0.0}, 'f0afb749': {'test_accuracy': 0.9822222590446472, 'test_diff_accuracy': 0.061728399246931076}, 'f0df5ff0': {'test_accuracy': 0.8670370578765869, 'test_diff_accuracy': 0.0}, 'f21745ec': {'test_accuracy': 0.8877778053283691, 'test_diff_accuracy': 0.4960607588291168}, 'f3b10344': {'test_accuracy': 0.711481511592865, 'test_diff_accuracy': 0.0}, 'f3cdc58f': {'test_accuracy': 0.9785184860229492, 'test_diff_accuracy': 0.44780412316322327}, 'f3e62deb': {'test_accuracy': 0.9911110997200012, 'test_diff_accuracy': 0.5}, 'f4081712': {'test_accuracy': 0.9235555529594421, 'test_diff_accuracy': 0.8869382739067078}, 'f45f5ca7': {'test_accuracy': 0.9918518662452698, 'test_diff_accuracy': 0.5}, 'f5aa3634': {'test_accuracy': 0.9911110997200012, 'test_diff_accuracy': 0.8053030371665955}, 'f5c89df1': {'test_accuracy': 0.9829629063606262, 'test_diff_accuracy': 0.437296062707901}, 'f823c43c': {'test_accuracy': 0.7616666555404663, 'test_diff_accuracy': 0.0}, 'f83cb3f6': {'test_accuracy': 0.9807407259941101, 'test_diff_accuracy': 0.6049907803535461}, 'f8be4b64': {'test_accuracy': 0.9094444513320923, 'test_diff_accuracy': 0.0}, 'f9a67cb5': {'test_accuracy': 0.9262962937355042, 'test_diff_accuracy': 0.0}, 'f9d67f8b': {'test_accuracy': 0.15777777135372162, 'test_diff_accuracy': 0.13529807329177856}, 'fafd9572': {'test_accuracy': 0.9700000286102295, 'test_diff_accuracy': 0.0}, 'fb791726': {'test_accuracy': 0.961017370223999, 'test_diff_accuracy': 0.03614457696676254}, 'fc754716': {'test_accuracy': 0.9844443798065186, 'test_diff_accuracy': 0.07361919432878494}, 'fd096ab6': {'test_accuracy': 0.41111111640930176, 'test_diff_accuracy': 0.0}, 'fd4b2b02': {'test_accuracy': 0.9122222065925598, 'test_diff_accuracy': 0.0}, 'fe9372f3': {'test_accuracy': 0.9600000977516174, 'test_diff_accuracy': 0.0}, 'fea12743': {'test_accuracy': 0.9288887977600098, 'test_diff_accuracy': 0.0}, 'ff72ca3e': {'test_accuracy': 0.9647221565246582, 'test_diff_accuracy': 0.0}, 'avg': {'test_accuracy': 0.904828667640686, 'test_diff_accuracy': 0.2692205607891083}}\n",
            "INFO:__main__:Evaluation Results:\n",
            "INFO:__main__:Task 00576224: Accuracy = 0.9600, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 009d5c81: Accuracy = 0.9744, Diff Accuracy = 0.2100\n",
            "INFO:__main__:Task 00dbd492: Accuracy = 0.9294, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 03560426: Accuracy = 0.9796, Diff Accuracy = 0.5188\n",
            "INFO:__main__:Task 05a7bcf2: Accuracy = 0.6567, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 0607ce86: Accuracy = 0.7967, Diff Accuracy = 0.6599\n",
            "INFO:__main__:Task 0692e18c: Accuracy = 0.9785, Diff Accuracy = 0.1698\n",
            "INFO:__main__:Task 070dd51e: Accuracy = 0.9611, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 08573cc6: Accuracy = 0.9626, Diff Accuracy = 0.0677\n",
            "INFO:__main__:Task 0934a4d8: Accuracy = 0.3764, Diff Accuracy = 0.3777\n",
            "INFO:__main__:Task 09c534e7: Accuracy = 0.7878, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 0a1d4ef5: Accuracy = 0.9511, Diff Accuracy = 0.9168\n",
            "INFO:__main__:Task 0a2355a6: Accuracy = 0.9394, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 0b17323b: Accuracy = 0.9939, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 0bb8deee: Accuracy = 0.9789, Diff Accuracy = 0.6813\n",
            "INFO:__main__:Task 0becf7df: Accuracy = 0.9744, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 0c786b71: Accuracy = 0.9467, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 0c9aba6e: Accuracy = 0.9917, Diff Accuracy = 0.7479\n",
            "INFO:__main__:Task 0d87d2a6: Accuracy = 0.9056, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 0e671a1a: Accuracy = 0.9725, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 0f63c0b9: Accuracy = 0.8908, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 103eff5b: Accuracy = 0.9417, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 11e1fe23: Accuracy = 0.9922, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 12422b43: Accuracy = 0.9789, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 12997ef3: Accuracy = 0.9844, Diff Accuracy = 0.3445\n",
            "INFO:__main__:Task 12eac192: Accuracy = 0.9725, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 136b0064: Accuracy = 0.9822, Diff Accuracy = 0.7114\n",
            "INFO:__main__:Task 13713586: Accuracy = 0.8593, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 137f0df0: Accuracy = 0.9185, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 140c817e: Accuracy = 0.8626, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 14754a24: Accuracy = 0.8631, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 15113be4: Accuracy = 0.6256, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 15663ba9: Accuracy = 0.9422, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 15696249: Accuracy = 0.9700, Diff Accuracy = 0.1875\n",
            "INFO:__main__:Task 16b78196: Accuracy = 0.7917, Diff Accuracy = 0.4842\n",
            "INFO:__main__:Task 17b80ad2: Accuracy = 0.9611, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 17cae0c1: Accuracy = 0.9700, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 18419cfa: Accuracy = 0.9344, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 184a9768: Accuracy = 0.8522, Diff Accuracy = 0.5751\n",
            "INFO:__main__:Task 195ba7dc: Accuracy = 0.9758, Diff Accuracy = 0.5054\n",
            "INFO:__main__:Task 1990f7a8: Accuracy = 0.9741, Diff Accuracy = 0.5000\n",
            "INFO:__main__:Task 19bb5feb: Accuracy = 0.9730, Diff Accuracy = 0.7312\n",
            "INFO:__main__:Task 1a2e2828: Accuracy = 0.9987, Diff Accuracy = 0.9835\n",
            "INFO:__main__:Task 1a6449f1: Accuracy = 0.9830, Diff Accuracy = 0.9131\n",
            "INFO:__main__:Task 1acc24af: Accuracy = 0.9647, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 1c02dbbe: Accuracy = 0.8604, Diff Accuracy = 0.0621\n",
            "INFO:__main__:Task 1c0d0a4b: Accuracy = 0.9826, Diff Accuracy = 0.5957\n",
            "INFO:__main__:Task 1c56ad9f: Accuracy = 0.9542, Diff Accuracy = 0.5000\n",
            "INFO:__main__:Task 1d0a4b61: Accuracy = 0.3056, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 1d398264: Accuracy = 0.9463, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 1da012fc: Accuracy = 0.9106, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 1e81d6f9: Accuracy = 0.9681, Diff Accuracy = 1.0000\n",
            "INFO:__main__:Task 1e97544e: Accuracy = 0.4130, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 2037f2c7: Accuracy = 0.9900, Diff Accuracy = 0.9334\n",
            "INFO:__main__:Task 2072aba6: Accuracy = 0.9807, Diff Accuracy = 0.0159\n",
            "INFO:__main__:Task 20818e16: Accuracy = 0.9385, Diff Accuracy = 0.7231\n",
            "INFO:__main__:Task 20981f0e: Accuracy = 0.9681, Diff Accuracy = 0.5000\n",
            "INFO:__main__:Task 212895b5: Accuracy = 0.9196, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 21f83797: Accuracy = 0.9239, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 22a4bbc2: Accuracy = 0.9433, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 25094a63: Accuracy = 0.1828, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 2546ccf6: Accuracy = 0.8550, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 256b0a75: Accuracy = 0.6667, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 2685904e: Accuracy = 0.9659, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 2697da3f: Accuracy = 0.9511, Diff Accuracy = 0.1660\n",
            "INFO:__main__:Task 2753e76c: Accuracy = 0.9900, Diff Accuracy = 0.8994\n",
            "INFO:__main__:Task 27a77e38: Accuracy = 0.9807, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 27f8ce4f: Accuracy = 0.9650, Diff Accuracy = 0.1125\n",
            "INFO:__main__:Task 281123b4: Accuracy = 0.9830, Diff Accuracy = 0.7147\n",
            "INFO:__main__:Task 292dd178: Accuracy = 0.9081, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 29700607: Accuracy = 0.9619, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 2a5f8217: Accuracy = 0.9774, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 2b01abd0: Accuracy = 0.9707, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 2c0b0aff: Accuracy = 0.9119, Diff Accuracy = 0.7577\n",
            "INFO:__main__:Task 2c737e39: Accuracy = 0.9841, Diff Accuracy = 0.1365\n",
            "INFO:__main__:Task 2f0c5170: Accuracy = 0.9674, Diff Accuracy = 0.9186\n",
            "INFO:__main__:Task 310f3251: Accuracy = 0.9700, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 3194b014: Accuracy = 0.9770, Diff Accuracy = 0.9225\n",
            "INFO:__main__:Task 319f2597: Accuracy = 0.6278, Diff Accuracy = 0.9736\n",
            "INFO:__main__:Task 31adaf00: Accuracy = 0.9307, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 31d5ba1a: Accuracy = 0.9929, Diff Accuracy = 0.6541\n",
            "INFO:__main__:Task 32e9702f: Accuracy = 0.9548, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 332efdb3: Accuracy = 0.9533, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 3391f8c0: Accuracy = 0.9825, Diff Accuracy = 0.3542\n",
            "INFO:__main__:Task 33b52de3: Accuracy = 0.8539, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 3490cc26: Accuracy = 0.9061, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 34b99a2b: Accuracy = 0.9883, Diff Accuracy = 0.6297\n",
            "INFO:__main__:Task 351d6448: Accuracy = 0.9928, Diff Accuracy = 0.8858\n",
            "INFO:__main__:Task 358ba94e: Accuracy = 0.9744, Diff Accuracy = 0.8644\n",
            "INFO:__main__:Task 37d3e8b2: Accuracy = 0.8789, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 3979b1a8: Accuracy = 0.8889, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 3a301edc: Accuracy = 0.9024, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 3b4c2228: Accuracy = 0.9980, Diff Accuracy = 0.8947\n",
            "INFO:__main__:Task 3d31c5b3: Accuracy = 0.9794, Diff Accuracy = 0.6079\n",
            "INFO:__main__:Task 3ed85e70: Accuracy = 0.6381, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 3ee1011a: Accuracy = 0.9537, Diff Accuracy = 0.2064\n",
            "INFO:__main__:Task 3f23242b: Accuracy = 0.9550, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 40f6cd08: Accuracy = 0.6270, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 414297c0: Accuracy = 0.8959, Diff Accuracy = 0.4696\n",
            "INFO:__main__:Task 423a55dc: Accuracy = 0.9856, Diff Accuracy = 0.5216\n",
            "INFO:__main__:Task 42918530: Accuracy = 0.8158, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 42a15761: Accuracy = 0.9063, Diff Accuracy = 0.5000\n",
            "INFO:__main__:Task 4364c1c4: Accuracy = 0.8178, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 456873bc: Accuracy = 0.9515, Diff Accuracy = 0.7704\n",
            "INFO:__main__:Task 45737921: Accuracy = 0.9733, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 45bbe264: Accuracy = 0.9330, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 477d2879: Accuracy = 0.8122, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 47996f11: Accuracy = 0.1383, Diff Accuracy = 0.1062\n",
            "INFO:__main__:Task 48131b3c: Accuracy = 0.9733, Diff Accuracy = 0.1129\n",
            "INFO:__main__:Task 4852f2fa: Accuracy = 0.9853, Diff Accuracy = 0.3608\n",
            "INFO:__main__:Task 48f8583b: Accuracy = 0.9798, Diff Accuracy = 0.2963\n",
            "INFO:__main__:Task 4aab4007: Accuracy = 0.1289, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 4acc7107: Accuracy = 0.9758, Diff Accuracy = 0.4824\n",
            "INFO:__main__:Task 4b6b68e5: Accuracy = 0.8622, Diff Accuracy = 0.0379\n",
            "INFO:__main__:Task 4c177718: Accuracy = 0.9872, Diff Accuracy = 0.7472\n",
            "INFO:__main__:Task 4cd1b7b2: Accuracy = 0.9822, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 4e45f183: Accuracy = 0.7507, Diff Accuracy = 0.0139\n",
            "INFO:__main__:Task 4e469f39: Accuracy = 0.9663, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 4f537728: Accuracy = 0.7972, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 4ff4c9da: Accuracy = 0.6259, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 505fff84: Accuracy = 0.9913, Diff Accuracy = 0.8910\n",
            "INFO:__main__:Task 506d28a5: Accuracy = 0.9822, Diff Accuracy = 0.4775\n",
            "INFO:__main__:Task 50a16a69: Accuracy = 0.8159, Diff Accuracy = 0.0400\n",
            "INFO:__main__:Task 50aad11f: Accuracy = 0.9785, Diff Accuracy = 0.4671\n",
            "INFO:__main__:Task 50f325b5: Accuracy = 0.8019, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 516b51b7: Accuracy = 0.9189, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 5207a7b5: Accuracy = 0.9559, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 5289ad53: Accuracy = 0.9756, Diff Accuracy = 0.8811\n",
            "INFO:__main__:Task 52fd389e: Accuracy = 0.7137, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 54db823b: Accuracy = 0.9067, Diff Accuracy = 1.0000\n",
            "INFO:__main__:Task 55059096: Accuracy = 0.9744, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 551d5bf1: Accuracy = 0.7644, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 55783887: Accuracy = 0.8462, Diff Accuracy = 0.1000\n",
            "INFO:__main__:Task 575b1a71: Accuracy = 0.8889, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 5783df64: Accuracy = 0.9900, Diff Accuracy = 0.4583\n",
            "INFO:__main__:Task 5833af48: Accuracy = 0.8826, Diff Accuracy = 0.6010\n",
            "INFO:__main__:Task 58743b76: Accuracy = 0.9472, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 58e15b12: Accuracy = 0.9170, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 59341089: Accuracy = 0.9603, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 5a5a2103: Accuracy = 0.8194, Diff Accuracy = 0.0455\n",
            "INFO:__main__:Task 5af49b42: Accuracy = 0.9737, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 5b526a93: Accuracy = 0.9067, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 5b692c0f: Accuracy = 0.9133, Diff Accuracy = 0.2386\n",
            "INFO:__main__:Task 5b6cbef5: Accuracy = 0.9198, Diff Accuracy = 0.0909\n",
            "INFO:__main__:Task 5d2a5c43: Accuracy = 0.9784, Diff Accuracy = 0.4777\n",
            "INFO:__main__:Task 5ffb2104: Accuracy = 0.9874, Diff Accuracy = 0.4902\n",
            "INFO:__main__:Task 604001fa: Accuracy = 0.9819, Diff Accuracy = 0.2735\n",
            "INFO:__main__:Task 60a26a3e: Accuracy = 0.9719, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 60c09cac: Accuracy = 0.9822, Diff Accuracy = 0.0278\n",
            "INFO:__main__:Task 626c0bcc: Accuracy = 0.9826, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 62ab2642: Accuracy = 0.9367, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 62b74c02: Accuracy = 0.9559, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 639f5a19: Accuracy = 0.7778, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 642248e4: Accuracy = 0.9570, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 642d658d: Accuracy = 0.9611, Diff Accuracy = 0.9284\n",
            "INFO:__main__:Task 64a7c07e: Accuracy = 0.9893, Diff Accuracy = 0.5000\n",
            "INFO:__main__:Task 66e6c45b: Accuracy = 0.9956, Diff Accuracy = 0.5000\n",
            "INFO:__main__:Task 66f2d22f: Accuracy = 0.9919, Diff Accuracy = 0.7562\n",
            "INFO:__main__:Task 67636eac: Accuracy = 0.9863, Diff Accuracy = 0.4667\n",
            "INFO:__main__:Task 67b4a34d: Accuracy = 0.9696, Diff Accuracy = 0.9138\n",
            "INFO:__main__:Task 67c52801: Accuracy = 0.9786, Diff Accuracy = 0.5000\n",
            "INFO:__main__:Task 68b67ca3: Accuracy = 0.9944, Diff Accuracy = 0.5000\n",
            "INFO:__main__:Task 692cd3b6: Accuracy = 0.9007, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 695367ec: Accuracy = 0.8937, Diff Accuracy = 0.0555\n",
            "INFO:__main__:Task 696d4842: Accuracy = 0.9626, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 69889d6e: Accuracy = 0.9806, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 6a11f6da: Accuracy = 0.9758, Diff Accuracy = 0.5782\n",
            "INFO:__main__:Task 6ad5bdfd: Accuracy = 0.9815, Diff Accuracy = 0.4577\n",
            "INFO:__main__:Task 6df30ad6: Accuracy = 0.9918, Diff Accuracy = 0.5457\n",
            "INFO:__main__:Task 6ea4a07e: Accuracy = 0.9937, Diff Accuracy = 0.3704\n",
            "INFO:__main__:Task 6f473927: Accuracy = 0.9678, Diff Accuracy = 0.2138\n",
            "INFO:__main__:Task 7039b2d7: Accuracy = 0.9841, Diff Accuracy = 0.9843\n",
            "INFO:__main__:Task 705a3229: Accuracy = 0.9844, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 712bf12e: Accuracy = 0.9170, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 72207abc: Accuracy = 0.9926, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 72a961c9: Accuracy = 0.9844, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 73182012: Accuracy = 0.9881, Diff Accuracy = 0.8835\n",
            "INFO:__main__:Task 73c3b0d8: Accuracy = 0.9869, Diff Accuracy = 0.2958\n",
            "INFO:__main__:Task 73ccf9c2: Accuracy = 0.9881, Diff Accuracy = 0.8364\n",
            "INFO:__main__:Task 759f3fd3: Accuracy = 0.8428, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 762cd429: Accuracy = 0.8119, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 770cc55f: Accuracy = 0.9769, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 782b5218: Accuracy = 0.9344, Diff Accuracy = 0.4674\n",
            "INFO:__main__:Task 79369cc6: Accuracy = 0.8041, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 7953d61e: Accuracy = 0.9289, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 79fb03f4: Accuracy = 0.9383, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 7bb29440: Accuracy = 0.9736, Diff Accuracy = 0.8472\n",
            "INFO:__main__:Task 7c8af763: Accuracy = 0.8889, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 7c9b52a0: Accuracy = 0.9074, Diff Accuracy = 0.6269\n",
            "INFO:__main__:Task 7d18a6fb: Accuracy = 0.9770, Diff Accuracy = 0.7752\n",
            "INFO:__main__:Task 7d1f7ee8: Accuracy = 0.8326, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 7d419a02: Accuracy = 0.8511, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 7e02026e: Accuracy = 0.9000, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 7ee1c6ea: Accuracy = 0.9133, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 817e6c09: Accuracy = 0.9760, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 81c0276b: Accuracy = 0.9933, Diff Accuracy = 0.9544\n",
            "INFO:__main__:Task 833dafe3: Accuracy = 0.9644, Diff Accuracy = 0.0733\n",
            "INFO:__main__:Task 845d6e51: Accuracy = 0.9478, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 84db8fc4: Accuracy = 0.8889, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 84f2aca1: Accuracy = 0.9650, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 8597cfd7: Accuracy = 0.9956, Diff Accuracy = 0.8174\n",
            "INFO:__main__:Task 85b81ff1: Accuracy = 0.8750, Diff Accuracy = 0.5000\n",
            "INFO:__main__:Task 85fa5666: Accuracy = 0.9622, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 8719f442: Accuracy = 0.9422, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 88207623: Accuracy = 0.9389, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 891232d6: Accuracy = 0.8897, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 896d5239: Accuracy = 0.8826, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 8a371977: Accuracy = 0.4389, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 8b28cd80: Accuracy = 0.9489, Diff Accuracy = 0.0173\n",
            "INFO:__main__:Task 8ba14f53: Accuracy = 0.9939, Diff Accuracy = 0.8179\n",
            "INFO:__main__:Task 8cb8642d: Accuracy = 0.9296, Diff Accuracy = 0.7093\n",
            "INFO:__main__:Task 8dae5dfc: Accuracy = 0.8264, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 8e2edd66: Accuracy = 0.9815, Diff Accuracy = 0.2587\n",
            "INFO:__main__:Task 8ee62060: Accuracy = 0.9789, Diff Accuracy = 0.5000\n",
            "INFO:__main__:Task 8fbca751: Accuracy = 0.9659, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 90347967: Accuracy = 0.9933, Diff Accuracy = 0.5000\n",
            "INFO:__main__:Task 903d1b4a: Accuracy = 0.7156, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 9110e3c5: Accuracy = 0.9960, Diff Accuracy = 0.8651\n",
            "INFO:__main__:Task 917bccba: Accuracy = 0.9644, Diff Accuracy = 0.6146\n",
            "INFO:__main__:Task 929ab4e9: Accuracy = 0.3614, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 92e50de0: Accuracy = 0.6678, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 9356391f: Accuracy = 0.9067, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 93b4f4b3: Accuracy = 0.9233, Diff Accuracy = 0.4080\n",
            "INFO:__main__:Task 93c31fbe: Accuracy = 0.9400, Diff Accuracy = 0.3983\n",
            "INFO:__main__:Task 94133066: Accuracy = 0.8922, Diff Accuracy = 0.4846\n",
            "INFO:__main__:Task 94414823: Accuracy = 0.9578, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 94be5b80: Accuracy = 0.9411, Diff Accuracy = 0.2946\n",
            "INFO:__main__:Task 95a58926: Accuracy = 0.8615, Diff Accuracy = 0.5746\n",
            "INFO:__main__:Task 963f59bc: Accuracy = 0.9786, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 96a8c0cd: Accuracy = 0.9350, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 97239e3d: Accuracy = 0.7989, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 9772c176: Accuracy = 0.7478, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 981571dc: Accuracy = 0.0003, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 992798f6: Accuracy = 0.9864, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 99306f82: Accuracy = 0.9163, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 9a4bb226: Accuracy = 0.9889, Diff Accuracy = 0.7706\n",
            "INFO:__main__:Task 9b2a60aa: Accuracy = 0.9659, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 9b365c51: Accuracy = 0.9670, Diff Accuracy = 0.4442\n",
            "INFO:__main__:Task 9b4c17c4: Accuracy = 0.8147, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 9bebae7a: Accuracy = 0.9787, Diff Accuracy = 0.3364\n",
            "INFO:__main__:Task 9c1e755f: Accuracy = 0.9461, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 9c56f360: Accuracy = 0.9737, Diff Accuracy = 0.5000\n",
            "INFO:__main__:Task 9caba7c3: Accuracy = 0.7659, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 9ddd00f0: Accuracy = 0.9533, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 9def23fe: Accuracy = 0.8311, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task 9f27f097: Accuracy = 0.8400, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task a04b2602: Accuracy = 0.8178, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task a096bf4d: Accuracy = 0.7333, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task a3f84088: Accuracy = 0.8686, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task a406ac07: Accuracy = 0.9581, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task a57f2f04: Accuracy = 0.6633, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task a59b95c0: Accuracy = 0.9160, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task a680ac02: Accuracy = 0.9644, Diff Accuracy = 0.6502\n",
            "INFO:__main__:Task a8610ef7: Accuracy = 0.9767, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task a934301b: Accuracy = 0.9674, Diff Accuracy = 1.0000\n",
            "INFO:__main__:Task aa18de87: Accuracy = 0.9792, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task aa300dc3: Accuracy = 0.9306, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task aa4ec2a5: Accuracy = 0.4374, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task aab50785: Accuracy = 0.9871, Diff Accuracy = 0.9003\n",
            "INFO:__main__:Task ac0c5833: Accuracy = 0.9519, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task ac2e8ecf: Accuracy = 0.9530, Diff Accuracy = 0.4784\n",
            "INFO:__main__:Task ac3e2b04: Accuracy = 0.9386, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task ac605cbb: Accuracy = 0.9876, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task ad7e01d0: Accuracy = 0.9144, Diff Accuracy = 0.0851\n",
            "INFO:__main__:Task ae58858e: Accuracy = 0.9783, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task aee291af: Accuracy = 0.9763, Diff Accuracy = 0.9403\n",
            "INFO:__main__:Task af22c60d: Accuracy = 0.0000, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task af24b4cc: Accuracy = 0.9930, Diff Accuracy = 0.8560\n",
            "INFO:__main__:Task b0722778: Accuracy = 0.9844, Diff Accuracy = 0.7230\n",
            "INFO:__main__:Task b0f4d537: Accuracy = 0.9722, Diff Accuracy = 0.6135\n",
            "INFO:__main__:Task b15fca0b: Accuracy = 0.9676, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task b1fc8b8e: Accuracy = 0.9851, Diff Accuracy = 0.4875\n",
            "INFO:__main__:Task b20f7c8b: Accuracy = 0.7707, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task b457fec5: Accuracy = 0.9137, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task b4a43f3b: Accuracy = 0.9633, Diff Accuracy = 0.4690\n",
            "INFO:__main__:Task b7999b51: Accuracy = 0.9900, Diff Accuracy = 0.8587\n",
            "INFO:__main__:Task b7cb93ac: Accuracy = 0.9867, Diff Accuracy = 0.4815\n",
            "INFO:__main__:Task b7f8a4d8: Accuracy = 0.6400, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task b7fb29bc: Accuracy = 0.9100, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task b942fd60: Accuracy = 0.9667, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task b9630600: Accuracy = 0.8437, Diff Accuracy = 0.3881\n",
            "INFO:__main__:Task ba9d41b8: Accuracy = 0.9163, Diff Accuracy = 1.0000\n",
            "INFO:__main__:Task baf41dbf: Accuracy = 0.9593, Diff Accuracy = 0.2050\n",
            "INFO:__main__:Task bb52a14b: Accuracy = 0.9189, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task bbb1b8b6: Accuracy = 0.9852, Diff Accuracy = 0.5396\n",
            "INFO:__main__:Task bc4146bd: Accuracy = 0.9111, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task bcb3040b: Accuracy = 0.9196, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task bd14c3bf: Accuracy = 0.9211, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task be03b35f: Accuracy = 0.9970, Diff Accuracy = 0.8111\n",
            "INFO:__main__:Task bf32578f: Accuracy = 0.9881, Diff Accuracy = 0.3822\n",
            "INFO:__main__:Task bf699163: Accuracy = 0.9900, Diff Accuracy = 0.9721\n",
            "INFO:__main__:Task bf89d739: Accuracy = 0.9781, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task c074846d: Accuracy = 0.9949, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task c1990cce: Accuracy = 0.9785, Diff Accuracy = 0.0740\n",
            "INFO:__main__:Task c3202e5a: Accuracy = 0.9930, Diff Accuracy = 0.9741\n",
            "INFO:__main__:Task c35c1b4c: Accuracy = 0.9144, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task c48954c1: Accuracy = 0.9100, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task c62e2108: Accuracy = 0.8963, Diff Accuracy = 0.0433\n",
            "INFO:__main__:Task c64f1187: Accuracy = 0.9689, Diff Accuracy = 0.6881\n",
            "INFO:__main__:Task c658a4bd: Accuracy = 0.9194, Diff Accuracy = 0.3749\n",
            "INFO:__main__:Task c663677b: Accuracy = 0.1900, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task c6e1b8da: Accuracy = 0.8537, Diff Accuracy = 0.4505\n",
            "INFO:__main__:Task c7d4e6ad: Accuracy = 0.9778, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task c87289bb: Accuracy = 0.9436, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task c8b7cc0f: Accuracy = 0.9956, Diff Accuracy = 0.8881\n",
            "INFO:__main__:Task c92b942c: Accuracy = 0.9175, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task c97c0139: Accuracy = 0.9156, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task ca8de6ea: Accuracy = 0.9900, Diff Accuracy = 0.3333\n",
            "INFO:__main__:Task ca8f78db: Accuracy = 0.0000, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task cad67732: Accuracy = 0.9741, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task cb227835: Accuracy = 0.9793, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task ccd554ac: Accuracy = 0.9307, Diff Accuracy = 0.0256\n",
            "INFO:__main__:Task cd3c21df: Accuracy = 0.9948, Diff Accuracy = 0.8213\n",
            "INFO:__main__:Task ce039d91: Accuracy = 0.9775, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task ce8d95cc: Accuracy = 0.9803, Diff Accuracy = 0.7195\n",
            "INFO:__main__:Task cf133acc: Accuracy = 0.9370, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task cfb2ce5a: Accuracy = 0.9326, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task d017b73f: Accuracy = 0.9883, Diff Accuracy = 0.5000\n",
            "INFO:__main__:Task d19f7514: Accuracy = 0.9808, Diff Accuracy = 0.4938\n",
            "INFO:__main__:Task d282b262: Accuracy = 0.9678, Diff Accuracy = 0.4774\n",
            "INFO:__main__:Task d2acf2cb: Accuracy = 0.9552, Diff Accuracy = 0.0952\n",
            "INFO:__main__:Task d304284e: Accuracy = 0.8761, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task d37a1ef5: Accuracy = 0.9344, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task d47aa2ff: Accuracy = 0.9896, Diff Accuracy = 0.7235\n",
            "INFO:__main__:Task d492a647: Accuracy = 0.8811, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task d4b1c2b1: Accuracy = 0.9443, Diff Accuracy = 0.2857\n",
            "INFO:__main__:Task d4c90558: Accuracy = 0.9830, Diff Accuracy = 0.9063\n",
            "INFO:__main__:Task d56f2372: Accuracy = 0.9867, Diff Accuracy = 0.8060\n",
            "INFO:__main__:Task d5c634a2: Accuracy = 0.9954, Diff Accuracy = 0.7885\n",
            "INFO:__main__:Task d931c21c: Accuracy = 0.9108, Diff Accuracy = 0.2500\n",
            "INFO:__main__:Task d94c3b52: Accuracy = 0.8415, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task da2b0fe3: Accuracy = 0.9707, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task da515329: Accuracy = 0.8374, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task dc2aa30b: Accuracy = 0.9100, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task dc2e9a9d: Accuracy = 0.9233, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task dd2401ed: Accuracy = 0.9811, Diff Accuracy = 0.4363\n",
            "INFO:__main__:Task de493100: Accuracy = 0.2511, Diff Accuracy = 0.2521\n",
            "INFO:__main__:Task df8cc377: Accuracy = 0.9493, Diff Accuracy = 0.5000\n",
            "INFO:__main__:Task e0fb7511: Accuracy = 0.8315, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task e133d23d: Accuracy = 0.9927, Diff Accuracy = 0.5035\n",
            "INFO:__main__:Task e1baa8a4: Accuracy = 0.9894, Diff Accuracy = 0.9602\n",
            "INFO:__main__:Task e1d2900e: Accuracy = 0.9778, Diff Accuracy = 0.5000\n",
            "INFO:__main__:Task e2092e0c: Accuracy = 0.8867, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task e21a174a: Accuracy = 0.9563, Diff Accuracy = 0.2549\n",
            "INFO:__main__:Task e345f17b: Accuracy = 0.9961, Diff Accuracy = 0.8138\n",
            "INFO:__main__:Task e4075551: Accuracy = 0.9433, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task e41c6fd3: Accuracy = 0.9363, Diff Accuracy = 0.5000\n",
            "INFO:__main__:Task e57337a4: Accuracy = 0.8763, Diff Accuracy = 0.5170\n",
            "INFO:__main__:Task e5790162: Accuracy = 0.9884, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task e5c44e8f: Accuracy = 0.9456, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task e619ca6e: Accuracy = 0.8763, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task e633a9e5: Accuracy = 0.9722, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task e66aafb8: Accuracy = 0.9509, Diff Accuracy = 0.9256\n",
            "INFO:__main__:Task e681b708: Accuracy = 0.8870, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task e69241bd: Accuracy = 0.9433, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task e6de6e8f: Accuracy = 0.9878, Diff Accuracy = 0.5444\n",
            "INFO:__main__:Task e74e1818: Accuracy = 0.9674, Diff Accuracy = 0.5000\n",
            "INFO:__main__:Task e760a62e: Accuracy = 0.6181, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task e7639916: Accuracy = 0.9644, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task e78887d1: Accuracy = 0.9794, Diff Accuracy = 0.6878\n",
            "INFO:__main__:Task e7a25a18: Accuracy = 0.9244, Diff Accuracy = 0.2172\n",
            "INFO:__main__:Task e7b06bea: Accuracy = 0.9871, Diff Accuracy = 0.7000\n",
            "INFO:__main__:Task e7dd8335: Accuracy = 0.9785, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task e872b94a: Accuracy = 1.0000, Diff Accuracy = 1.0000\n",
            "INFO:__main__:Task e88171ec: Accuracy = 0.8096, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task e95e3d8e: Accuracy = 0.4622, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task e99362f0: Accuracy = 0.9785, Diff Accuracy = 0.7147\n",
            "INFO:__main__:Task e9ac8c9e: Accuracy = 0.9793, Diff Accuracy = 0.2667\n",
            "INFO:__main__:Task e9b4f6fc: Accuracy = 0.9619, Diff Accuracy = 0.4449\n",
            "INFO:__main__:Task e9bb6954: Accuracy = 0.9031, Diff Accuracy = 0.0032\n",
            "INFO:__main__:Task e9c9d9a1: Accuracy = 0.8204, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task ea959feb: Accuracy = 0.3889, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task ea9794b1: Accuracy = 0.9730, Diff Accuracy = 0.6472\n",
            "INFO:__main__:Task ecaa0ec1: Accuracy = 0.9894, Diff Accuracy = 0.4877\n",
            "INFO:__main__:Task ed74f2f2: Accuracy = 0.9935, Diff Accuracy = 0.5953\n",
            "INFO:__main__:Task ed98d772: Accuracy = 0.9778, Diff Accuracy = 0.1051\n",
            "INFO:__main__:Task ef26cbf6: Accuracy = 0.9533, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task f0afb749: Accuracy = 0.9822, Diff Accuracy = 0.0617\n",
            "INFO:__main__:Task f0df5ff0: Accuracy = 0.8670, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task f21745ec: Accuracy = 0.8878, Diff Accuracy = 0.4961\n",
            "INFO:__main__:Task f3b10344: Accuracy = 0.7115, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task f3cdc58f: Accuracy = 0.9785, Diff Accuracy = 0.4478\n",
            "INFO:__main__:Task f3e62deb: Accuracy = 0.9911, Diff Accuracy = 0.5000\n",
            "INFO:__main__:Task f4081712: Accuracy = 0.9236, Diff Accuracy = 0.8869\n",
            "INFO:__main__:Task f45f5ca7: Accuracy = 0.9919, Diff Accuracy = 0.5000\n",
            "INFO:__main__:Task f5aa3634: Accuracy = 0.9911, Diff Accuracy = 0.8053\n",
            "INFO:__main__:Task f5c89df1: Accuracy = 0.9830, Diff Accuracy = 0.4373\n",
            "INFO:__main__:Task f823c43c: Accuracy = 0.7617, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task f83cb3f6: Accuracy = 0.9807, Diff Accuracy = 0.6050\n",
            "INFO:__main__:Task f8be4b64: Accuracy = 0.9094, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task f9a67cb5: Accuracy = 0.9263, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task f9d67f8b: Accuracy = 0.1578, Diff Accuracy = 0.1353\n",
            "INFO:__main__:Task fafd9572: Accuracy = 0.9700, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task fb791726: Accuracy = 0.9610, Diff Accuracy = 0.0361\n",
            "INFO:__main__:Task fc754716: Accuracy = 0.9844, Diff Accuracy = 0.0736\n",
            "INFO:__main__:Task fd096ab6: Accuracy = 0.4111, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task fd4b2b02: Accuracy = 0.9122, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task fe9372f3: Accuracy = 0.9600, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task fea12743: Accuracy = 0.9289, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task ff72ca3e: Accuracy = 0.9647, Diff Accuracy = 0.0000\n",
            "INFO:__main__:Task avg: Accuracy = 0.9048, Diff Accuracy = 0.2692\n",
            "DEBUG:__main__:DEBUG: Data to be saved: {'aggregate_results': {'test_loss': 0.3664872646331787, 'test_accuracy': 0.904828667640686, 'test_diff_accuracy': 0.2692205607891083, 'complete_task_accuracy': 0.2344139650872818}, 'individual_metrics': {'00576224': {'test_accuracy': 0.9599999785423279, 'test_diff_accuracy': 0.0}, '009d5c81': {'test_accuracy': 0.9744443893432617, 'test_diff_accuracy': 0.21003207564353943}, '00dbd492': {'test_accuracy': 0.929444432258606, 'test_diff_accuracy': 0.0}, '03560426': {'test_accuracy': 0.9796295762062073, 'test_diff_accuracy': 0.5188145637512207}, '05a7bcf2': {'test_accuracy': 0.6566666960716248, 'test_diff_accuracy': 0.0}, '0607ce86': {'test_accuracy': 0.7966666221618652, 'test_diff_accuracy': 0.6599085927009583}, '0692e18c': {'test_accuracy': 0.9785184860229492, 'test_diff_accuracy': 0.16984127461910248}, '070dd51e': {'test_accuracy': 0.9611111283302307, 'test_diff_accuracy': 0.0}, '08573cc6': {'test_accuracy': 0.962592601776123, 'test_diff_accuracy': 0.06767676770687103}, '0934a4d8': {'test_accuracy': 0.37638890743255615, 'test_diff_accuracy': 0.37773966789245605}, '09c534e7': {'test_accuracy': 0.7877777218818665, 'test_diff_accuracy': 0.0}, '0a1d4ef5': {'test_accuracy': 0.9511110782623291, 'test_diff_accuracy': 0.9168465733528137}, '0a2355a6': {'test_accuracy': 0.9394444823265076, 'test_diff_accuracy': 0.0}, '0b17323b': {'test_accuracy': 0.9938889145851135, 'test_diff_accuracy': 0.0}, '0bb8deee': {'test_accuracy': 0.9788889288902283, 'test_diff_accuracy': 0.6813034415245056}, '0becf7df': {'test_accuracy': 0.9744444489479065, 'test_diff_accuracy': 0.0}, '0c786b71': {'test_accuracy': 0.9466666579246521, 'test_diff_accuracy': 0.0}, '0c9aba6e': {'test_accuracy': 0.9916666746139526, 'test_diff_accuracy': 0.747855007648468}, '0d87d2a6': {'test_accuracy': 0.9055555462837219, 'test_diff_accuracy': 0.0}, '0e671a1a': {'test_accuracy': 0.9724999666213989, 'test_diff_accuracy': 0.0}, '0f63c0b9': {'test_accuracy': 0.8908333778381348, 'test_diff_accuracy': 0.0}, '103eff5b': {'test_accuracy': 0.9416666626930237, 'test_diff_accuracy': 0.0}, '11e1fe23': {'test_accuracy': 0.992222249507904, 'test_diff_accuracy': 0.0}, '12422b43': {'test_accuracy': 0.9788888692855835, 'test_diff_accuracy': 0.0}, '12997ef3': {'test_accuracy': 0.9844444394111633, 'test_diff_accuracy': 0.3445091247558594}, '12eac192': {'test_accuracy': 0.9725000262260437, 'test_diff_accuracy': 0.0}, '136b0064': {'test_accuracy': 0.9822222590446472, 'test_diff_accuracy': 0.711358368396759}, '13713586': {'test_accuracy': 0.859259307384491, 'test_diff_accuracy': 0.0}, '137f0df0': {'test_accuracy': 0.9185185432434082, 'test_diff_accuracy': 0.0}, '140c817e': {'test_accuracy': 0.8625926375389099, 'test_diff_accuracy': 0.0}, '14754a24': {'test_accuracy': 0.8630555272102356, 'test_diff_accuracy': 0.0}, '15113be4': {'test_accuracy': 0.6255555748939514, 'test_diff_accuracy': 0.0}, '15663ba9': {'test_accuracy': 0.9422222971916199, 'test_diff_accuracy': 0.0}, '15696249': {'test_accuracy': 0.9700000286102295, 'test_diff_accuracy': 0.1875}, '16b78196': {'test_accuracy': 0.7916666865348816, 'test_diff_accuracy': 0.4842342138290405}, '17b80ad2': {'test_accuracy': 0.9611111283302307, 'test_diff_accuracy': 0.0}, '17cae0c1': {'test_accuracy': 0.9700000286102295, 'test_diff_accuracy': 0.0}, '18419cfa': {'test_accuracy': 0.9344444274902344, 'test_diff_accuracy': 0.0}, '184a9768': {'test_accuracy': 0.8522222638130188, 'test_diff_accuracy': 0.575104296207428}, '195ba7dc': {'test_accuracy': 0.9758332967758179, 'test_diff_accuracy': 0.5054347515106201}, '1990f7a8': {'test_accuracy': 0.9740740656852722, 'test_diff_accuracy': 0.5}, '19bb5feb': {'test_accuracy': 0.9729630351066589, 'test_diff_accuracy': 0.7311635613441467}, '1a2e2828': {'test_accuracy': 0.9986666440963745, 'test_diff_accuracy': 0.9834964871406555}, '1a6449f1': {'test_accuracy': 0.9829629063606262, 'test_diff_accuracy': 0.9130600094795227}, '1acc24af': {'test_accuracy': 0.964722216129303, 'test_diff_accuracy': 0.0}, '1c02dbbe': {'test_accuracy': 0.860370397567749, 'test_diff_accuracy': 0.06207104027271271}, '1c0d0a4b': {'test_accuracy': 0.9825925827026367, 'test_diff_accuracy': 0.595678985118866}, '1c56ad9f': {'test_accuracy': 0.9541666507720947, 'test_diff_accuracy': 0.5}, '1d0a4b61': {'test_accuracy': 0.3055555522441864, 'test_diff_accuracy': 0.0}, '1d398264': {'test_accuracy': 0.9462962746620178, 'test_diff_accuracy': 0.0}, '1da012fc': {'test_accuracy': 0.9105556011199951, 'test_diff_accuracy': 0.0}, '1e81d6f9': {'test_accuracy': 0.9681481719017029, 'test_diff_accuracy': 1.0}, '1e97544e': {'test_accuracy': 0.41296300292015076, 'test_diff_accuracy': 0.0}, '2037f2c7': {'test_accuracy': 0.9900000095367432, 'test_diff_accuracy': 0.9334214329719543}, '2072aba6': {'test_accuracy': 0.9807407259941101, 'test_diff_accuracy': 0.01587301678955555}, '20818e16': {'test_accuracy': 0.9385185241699219, 'test_diff_accuracy': 0.723113477230072}, '20981f0e': {'test_accuracy': 0.9681481719017029, 'test_diff_accuracy': 0.5}, '212895b5': {'test_accuracy': 0.9196296334266663, 'test_diff_accuracy': 0.0}, '21f83797': {'test_accuracy': 0.9238889217376709, 'test_diff_accuracy': 0.0}, '22a4bbc2': {'test_accuracy': 0.9433333277702332, 'test_diff_accuracy': 0.0}, '25094a63': {'test_accuracy': 0.1827777773141861, 'test_diff_accuracy': 0.0}, '2546ccf6': {'test_accuracy': 0.8550000190734863, 'test_diff_accuracy': 0.0}, '256b0a75': {'test_accuracy': 0.6666666865348816, 'test_diff_accuracy': 0.0}, '2685904e': {'test_accuracy': 0.965925931930542, 'test_diff_accuracy': 0.0}, '2697da3f': {'test_accuracy': 0.9511110782623291, 'test_diff_accuracy': 0.16602009534835815}, '2753e76c': {'test_accuracy': 0.9900000095367432, 'test_diff_accuracy': 0.899422824382782}, '27a77e38': {'test_accuracy': 0.9807407259941101, 'test_diff_accuracy': 0.0}, '27f8ce4f': {'test_accuracy': 0.9650000333786011, 'test_diff_accuracy': 0.11249999701976776}, '281123b4': {'test_accuracy': 0.9829630255699158, 'test_diff_accuracy': 0.7146536707878113}, '292dd178': {'test_accuracy': 0.9081481099128723, 'test_diff_accuracy': 0.0}, '29700607': {'test_accuracy': 0.9618518948554993, 'test_diff_accuracy': 0.0}, '2a5f8217': {'test_accuracy': 0.9774073958396912, 'test_diff_accuracy': 0.0}, '2b01abd0': {'test_accuracy': 0.970740795135498, 'test_diff_accuracy': 0.0}, '2c0b0aff': {'test_accuracy': 0.9119444489479065, 'test_diff_accuracy': 0.7577368021011353}, '2c737e39': {'test_accuracy': 0.9840741157531738, 'test_diff_accuracy': 0.13650794327259064}, '2f0c5170': {'test_accuracy': 0.9674074053764343, 'test_diff_accuracy': 0.9186174869537354}, '310f3251': {'test_accuracy': 0.9700000882148743, 'test_diff_accuracy': 0.0}, '3194b014': {'test_accuracy': 0.9770370125770569, 'test_diff_accuracy': 0.9225044250488281}, '319f2597': {'test_accuracy': 0.6277777552604675, 'test_diff_accuracy': 0.9736223220825195}, '31adaf00': {'test_accuracy': 0.9307407736778259, 'test_diff_accuracy': 0.0}, '31d5ba1a': {'test_accuracy': 0.9928889274597168, 'test_diff_accuracy': 0.6540936231613159}, '32e9702f': {'test_accuracy': 0.9548148512840271, 'test_diff_accuracy': 0.0}, '332efdb3': {'test_accuracy': 0.9533333778381348, 'test_diff_accuracy': 0.0}, '3391f8c0': {'test_accuracy': 0.9824999570846558, 'test_diff_accuracy': 0.3541666865348816}, '33b52de3': {'test_accuracy': 0.8538888692855835, 'test_diff_accuracy': 0.0}, '3490cc26': {'test_accuracy': 0.9061111211776733, 'test_diff_accuracy': 0.0}, '34b99a2b': {'test_accuracy': 0.9883333444595337, 'test_diff_accuracy': 0.629668653011322}, '351d6448': {'test_accuracy': 0.9927777647972107, 'test_diff_accuracy': 0.8858424425125122}, '358ba94e': {'test_accuracy': 0.9744444489479065, 'test_diff_accuracy': 0.8644062280654907}, '37d3e8b2': {'test_accuracy': 0.8788889050483704, 'test_diff_accuracy': 0.0}, '3979b1a8': {'test_accuracy': 0.8888888955116272, 'test_diff_accuracy': 0.0}, '3a301edc': {'test_accuracy': 0.9024444818496704, 'test_diff_accuracy': 0.0}, '3b4c2228': {'test_accuracy': 0.9979999661445618, 'test_diff_accuracy': 0.8947456479072571}, '3d31c5b3': {'test_accuracy': 0.9794444441795349, 'test_diff_accuracy': 0.6079409122467041}, '3ed85e70': {'test_accuracy': 0.6381481885910034, 'test_diff_accuracy': 0.0}, '3ee1011a': {'test_accuracy': 0.9537037014961243, 'test_diff_accuracy': 0.20636117458343506}, '3f23242b': {'test_accuracy': 0.9550000429153442, 'test_diff_accuracy': 0.0}, '40f6cd08': {'test_accuracy': 0.6270370483398438, 'test_diff_accuracy': 0.0}, '414297c0': {'test_accuracy': 0.8959259390830994, 'test_diff_accuracy': 0.4695725440979004}, '423a55dc': {'test_accuracy': 0.9855555295944214, 'test_diff_accuracy': 0.5216470956802368}, '42918530': {'test_accuracy': 0.815833330154419, 'test_diff_accuracy': 0.0}, '42a15761': {'test_accuracy': 0.9062963128089905, 'test_diff_accuracy': 0.5}, '4364c1c4': {'test_accuracy': 0.8177778124809265, 'test_diff_accuracy': 0.0}, '456873bc': {'test_accuracy': 0.9514815211296082, 'test_diff_accuracy': 0.7703775763511658}, '45737921': {'test_accuracy': 0.9733333587646484, 'test_diff_accuracy': 0.0}, '45bbe264': {'test_accuracy': 0.932962954044342, 'test_diff_accuracy': 0.0}, '477d2879': {'test_accuracy': 0.8122222423553467, 'test_diff_accuracy': 0.0}, '47996f11': {'test_accuracy': 0.13833333551883698, 'test_diff_accuracy': 0.10620684921741486}, '48131b3c': {'test_accuracy': 0.9733333587646484, 'test_diff_accuracy': 0.11290545016527176}, '4852f2fa': {'test_accuracy': 0.9853333234786987, 'test_diff_accuracy': 0.36084944009780884}, '48f8583b': {'test_accuracy': 0.9798148274421692, 'test_diff_accuracy': 0.29629629850387573}, '4aab4007': {'test_accuracy': 0.12888889014720917, 'test_diff_accuracy': 0.0}, '4acc7107': {'test_accuracy': 0.9758333563804626, 'test_diff_accuracy': 0.4823917746543884}, '4b6b68e5': {'test_accuracy': 0.8622221946716309, 'test_diff_accuracy': 0.03787878900766373}, '4c177718': {'test_accuracy': 0.9872222542762756, 'test_diff_accuracy': 0.7471552491188049}, '4cd1b7b2': {'test_accuracy': 0.9822222590446472, 'test_diff_accuracy': 0.0}, '4e45f183': {'test_accuracy': 0.7507407665252686, 'test_diff_accuracy': 0.013888888992369175}, '4e469f39': {'test_accuracy': 0.9662962555885315, 'test_diff_accuracy': 0.0}, '4f537728': {'test_accuracy': 0.7972222566604614, 'test_diff_accuracy': 0.0}, '4ff4c9da': {'test_accuracy': 0.6259259581565857, 'test_diff_accuracy': 0.0}, '505fff84': {'test_accuracy': 0.9913333654403687, 'test_diff_accuracy': 0.8910254240036011}, '506d28a5': {'test_accuracy': 0.9822221994400024, 'test_diff_accuracy': 0.47752460837364197}, '50a16a69': {'test_accuracy': 0.8159258961677551, 'test_diff_accuracy': 0.03999999910593033}, '50aad11f': {'test_accuracy': 0.9785184860229492, 'test_diff_accuracy': 0.4671497642993927}, '50f325b5': {'test_accuracy': 0.801944375038147, 'test_diff_accuracy': 0.0}, '516b51b7': {'test_accuracy': 0.9188888669013977, 'test_diff_accuracy': 0.0}, '5207a7b5': {'test_accuracy': 0.9559259414672852, 'test_diff_accuracy': 0.0}, '5289ad53': {'test_accuracy': 0.9755555391311646, 'test_diff_accuracy': 0.8811259269714355}, '52fd389e': {'test_accuracy': 0.7137036323547363, 'test_diff_accuracy': 0.0}, '54db823b': {'test_accuracy': 0.9066666960716248, 'test_diff_accuracy': 1.0}, '55059096': {'test_accuracy': 0.9744443893432617, 'test_diff_accuracy': 0.0}, '551d5bf1': {'test_accuracy': 0.7644444704055786, 'test_diff_accuracy': 0.0}, '55783887': {'test_accuracy': 0.8462222218513489, 'test_diff_accuracy': 0.10000000149011612}, '575b1a71': {'test_accuracy': 0.8888888955116272, 'test_diff_accuracy': 0.0}, '5783df64': {'test_accuracy': 0.9900000095367432, 'test_diff_accuracy': 0.45825162529945374}, '5833af48': {'test_accuracy': 0.8825926184654236, 'test_diff_accuracy': 0.6010026335716248}, '58743b76': {'test_accuracy': 0.9472222328186035, 'test_diff_accuracy': 0.0}, '58e15b12': {'test_accuracy': 0.9170370697975159, 'test_diff_accuracy': 0.0}, '59341089': {'test_accuracy': 0.960277795791626, 'test_diff_accuracy': 0.0}, '5a5a2103': {'test_accuracy': 0.8194444179534912, 'test_diff_accuracy': 0.04545454680919647}, '5af49b42': {'test_accuracy': 0.9737036824226379, 'test_diff_accuracy': 0.0}, '5b526a93': {'test_accuracy': 0.90666663646698, 'test_diff_accuracy': 0.0}, '5b692c0f': {'test_accuracy': 0.9133332967758179, 'test_diff_accuracy': 0.23863637447357178}, '5b6cbef5': {'test_accuracy': 0.9197778701782227, 'test_diff_accuracy': 0.09092767536640167}, '5d2a5c43': {'test_accuracy': 0.9784444570541382, 'test_diff_accuracy': 0.47774338722229004}, '5ffb2104': {'test_accuracy': 0.987407386302948, 'test_diff_accuracy': 0.4901960790157318}, '604001fa': {'test_accuracy': 0.9819444417953491, 'test_diff_accuracy': 0.2735389471054077}, '60a26a3e': {'test_accuracy': 0.9718518257141113, 'test_diff_accuracy': 0.0}, '60c09cac': {'test_accuracy': 0.9822221994400024, 'test_diff_accuracy': 0.02777777798473835}, '626c0bcc': {'test_accuracy': 0.9825925827026367, 'test_diff_accuracy': 0.0}, '62ab2642': {'test_accuracy': 0.93666672706604, 'test_diff_accuracy': 0.0}, '62b74c02': {'test_accuracy': 0.9559259414672852, 'test_diff_accuracy': 0.0}, '639f5a19': {'test_accuracy': 0.7777777910232544, 'test_diff_accuracy': 0.0}, '642248e4': {'test_accuracy': 0.9570370316505432, 'test_diff_accuracy': 0.0}, '642d658d': {'test_accuracy': 0.9611111283302307, 'test_diff_accuracy': 0.9283973574638367}, '64a7c07e': {'test_accuracy': 0.9892592430114746, 'test_diff_accuracy': 0.5}, '66e6c45b': {'test_accuracy': 0.995555579662323, 'test_diff_accuracy': 0.5}, '66f2d22f': {'test_accuracy': 0.991944432258606, 'test_diff_accuracy': 0.7562196850776672}, '67636eac': {'test_accuracy': 0.9862963557243347, 'test_diff_accuracy': 0.46666666865348816}, '67b4a34d': {'test_accuracy': 0.9696295857429504, 'test_diff_accuracy': 0.9138374328613281}, '67c52801': {'test_accuracy': 0.9786111116409302, 'test_diff_accuracy': 0.5}, '68b67ca3': {'test_accuracy': 0.9944444298744202, 'test_diff_accuracy': 0.5}, '692cd3b6': {'test_accuracy': 0.9007408022880554, 'test_diff_accuracy': 0.0}, '695367ec': {'test_accuracy': 0.8937036991119385, 'test_diff_accuracy': 0.05552127584815025}, '696d4842': {'test_accuracy': 0.962592601776123, 'test_diff_accuracy': 0.0}, '69889d6e': {'test_accuracy': 0.980555534362793, 'test_diff_accuracy': 0.0}, '6a11f6da': {'test_accuracy': 0.975777804851532, 'test_diff_accuracy': 0.5782161355018616}, '6ad5bdfd': {'test_accuracy': 0.9814814925193787, 'test_diff_accuracy': 0.45766592025756836}, '6df30ad6': {'test_accuracy': 0.991777777671814, 'test_diff_accuracy': 0.5457017421722412}, '6ea4a07e': {'test_accuracy': 0.9937036633491516, 'test_diff_accuracy': 0.37037038803100586}, '6f473927': {'test_accuracy': 0.9677777886390686, 'test_diff_accuracy': 0.21378621459007263}, '7039b2d7': {'test_accuracy': 0.9840741157531738, 'test_diff_accuracy': 0.9842607378959656}, '705a3229': {'test_accuracy': 0.9844444394111633, 'test_diff_accuracy': 0.0}, '712bf12e': {'test_accuracy': 0.9170370101928711, 'test_diff_accuracy': 0.0}, '72207abc': {'test_accuracy': 0.9925925731658936, 'test_diff_accuracy': 0.0}, '72a961c9': {'test_accuracy': 0.9844444990158081, 'test_diff_accuracy': 0.0}, '73182012': {'test_accuracy': 0.9881481528282166, 'test_diff_accuracy': 0.8835263848304749}, '73c3b0d8': {'test_accuracy': 0.9869444370269775, 'test_diff_accuracy': 0.2957516312599182}, '73ccf9c2': {'test_accuracy': 0.9881481528282166, 'test_diff_accuracy': 0.8363578915596008}, '759f3fd3': {'test_accuracy': 0.8427777886390686, 'test_diff_accuracy': 0.0}, '762cd429': {'test_accuracy': 0.8118519186973572, 'test_diff_accuracy': 0.0}, '770cc55f': {'test_accuracy': 0.9769444465637207, 'test_diff_accuracy': 0.0}, '782b5218': {'test_accuracy': 0.9344444274902344, 'test_diff_accuracy': 0.4673832952976227}, '79369cc6': {'test_accuracy': 0.8040741086006165, 'test_diff_accuracy': 0.0}, '7953d61e': {'test_accuracy': 0.9288889169692993, 'test_diff_accuracy': 0.0}, '79fb03f4': {'test_accuracy': 0.93833327293396, 'test_diff_accuracy': 0.0}, '7bb29440': {'test_accuracy': 0.9735555648803711, 'test_diff_accuracy': 0.8471860885620117}, '7c8af763': {'test_accuracy': 0.8888888955116272, 'test_diff_accuracy': 0.0}, '7c9b52a0': {'test_accuracy': 0.9074074625968933, 'test_diff_accuracy': 0.6268526911735535}, '7d18a6fb': {'test_accuracy': 0.9770370125770569, 'test_diff_accuracy': 0.7752125263214111}, '7d1f7ee8': {'test_accuracy': 0.8325925469398499, 'test_diff_accuracy': 0.0}, '7d419a02': {'test_accuracy': 0.851111114025116, 'test_diff_accuracy': 0.0}, '7e02026e': {'test_accuracy': 0.9000000357627869, 'test_diff_accuracy': 0.0}, '7ee1c6ea': {'test_accuracy': 0.9133333563804626, 'test_diff_accuracy': 0.0}, '817e6c09': {'test_accuracy': 0.9760000109672546, 'test_diff_accuracy': 0.0}, '81c0276b': {'test_accuracy': 0.9933333396911621, 'test_diff_accuracy': 0.9544203281402588}, '833dafe3': {'test_accuracy': 0.9644444584846497, 'test_diff_accuracy': 0.07334525883197784}, '845d6e51': {'test_accuracy': 0.9477777481079102, 'test_diff_accuracy': 0.0}, '84db8fc4': {'test_accuracy': 0.8888888955116272, 'test_diff_accuracy': 0.0}, '84f2aca1': {'test_accuracy': 0.9650000333786011, 'test_diff_accuracy': 0.0}, '8597cfd7': {'test_accuracy': 0.995555579662323, 'test_diff_accuracy': 0.8174242377281189}, '85b81ff1': {'test_accuracy': 0.875, 'test_diff_accuracy': 0.5}, '85fa5666': {'test_accuracy': 0.9622222185134888, 'test_diff_accuracy': 0.0}, '8719f442': {'test_accuracy': 0.9422221779823303, 'test_diff_accuracy': 0.0}, '88207623': {'test_accuracy': 0.9388889074325562, 'test_diff_accuracy': 0.0}, '891232d6': {'test_accuracy': 0.8897222280502319, 'test_diff_accuracy': 0.0}, '896d5239': {'test_accuracy': 0.8825926184654236, 'test_diff_accuracy': 0.0}, '8a371977': {'test_accuracy': 0.43888890743255615, 'test_diff_accuracy': 0.0}, '8b28cd80': {'test_accuracy': 0.948888897895813, 'test_diff_accuracy': 0.017298799008131027}, '8ba14f53': {'test_accuracy': 0.9938888549804688, 'test_diff_accuracy': 0.8179367184638977}, '8cb8642d': {'test_accuracy': 0.9296296238899231, 'test_diff_accuracy': 0.7093300819396973}, '8dae5dfc': {'test_accuracy': 0.8263888359069824, 'test_diff_accuracy': 0.0}, '8e2edd66': {'test_accuracy': 0.9814814925193787, 'test_diff_accuracy': 0.2586754262447357}, '8ee62060': {'test_accuracy': 0.9788889288902283, 'test_diff_accuracy': 0.5}, '8fbca751': {'test_accuracy': 0.9659258723258972, 'test_diff_accuracy': 0.0}, '90347967': {'test_accuracy': 0.9933333396911621, 'test_diff_accuracy': 0.5}, '903d1b4a': {'test_accuracy': 0.7155555486679077, 'test_diff_accuracy': 0.0}, '9110e3c5': {'test_accuracy': 0.9960317611694336, 'test_diff_accuracy': 0.8651400804519653}, '917bccba': {'test_accuracy': 0.9644444584846497, 'test_diff_accuracy': 0.6146110892295837}, '929ab4e9': {'test_accuracy': 0.3613888919353485, 'test_diff_accuracy': 0.0}, '92e50de0': {'test_accuracy': 0.6677777767181396, 'test_diff_accuracy': 0.0}, '9356391f': {'test_accuracy': 0.90666663646698, 'test_diff_accuracy': 0.0}, '93b4f4b3': {'test_accuracy': 0.9233333468437195, 'test_diff_accuracy': 0.40796583890914917}, '93c31fbe': {'test_accuracy': 0.9399999976158142, 'test_diff_accuracy': 0.3983488082885742}, '94133066': {'test_accuracy': 0.8922222256660461, 'test_diff_accuracy': 0.48462045192718506}, '94414823': {'test_accuracy': 0.9577777981758118, 'test_diff_accuracy': 0.0}, '94be5b80': {'test_accuracy': 0.9411110877990723, 'test_diff_accuracy': 0.2946428656578064}, '95a58926': {'test_accuracy': 0.8614814877510071, 'test_diff_accuracy': 0.5745627284049988}, '963f59bc': {'test_accuracy': 0.9786111116409302, 'test_diff_accuracy': 0.0}, '96a8c0cd': {'test_accuracy': 0.9350000023841858, 'test_diff_accuracy': 0.0}, '97239e3d': {'test_accuracy': 0.7988889217376709, 'test_diff_accuracy': 0.0}, '9772c176': {'test_accuracy': 0.7477777600288391, 'test_diff_accuracy': 0.0}, '981571dc': {'test_accuracy': 0.00027777778450399637, 'test_diff_accuracy': 0.0}, '992798f6': {'test_accuracy': 0.9863889217376709, 'test_diff_accuracy': 0.0}, '99306f82': {'test_accuracy': 0.9162963032722473, 'test_diff_accuracy': 0.0}, '9a4bb226': {'test_accuracy': 0.9888889193534851, 'test_diff_accuracy': 0.7706348896026611}, '9b2a60aa': {'test_accuracy': 0.965925931930542, 'test_diff_accuracy': 0.0}, '9b365c51': {'test_accuracy': 0.9670370221138, 'test_diff_accuracy': 0.444180965423584}, '9b4c17c4': {'test_accuracy': 0.8147222995758057, 'test_diff_accuracy': 0.0}, '9bebae7a': {'test_accuracy': 0.9786666631698608, 'test_diff_accuracy': 0.33641454577445984}, '9c1e755f': {'test_accuracy': 0.9461110830307007, 'test_diff_accuracy': 0.0}, '9c56f360': {'test_accuracy': 0.9737036824226379, 'test_diff_accuracy': 0.5}, '9caba7c3': {'test_accuracy': 0.7659258842468262, 'test_diff_accuracy': 0.0}, '9ddd00f0': {'test_accuracy': 0.9533333778381348, 'test_diff_accuracy': 0.0}, '9def23fe': {'test_accuracy': 0.8311111330986023, 'test_diff_accuracy': 0.0}, '9f27f097': {'test_accuracy': 0.8399999737739563, 'test_diff_accuracy': 0.0}, 'a04b2602': {'test_accuracy': 0.8177778124809265, 'test_diff_accuracy': 0.0}, 'a096bf4d': {'test_accuracy': 0.7333333492279053, 'test_diff_accuracy': 0.0}, 'a3f84088': {'test_accuracy': 0.8686110973358154, 'test_diff_accuracy': 0.0}, 'a406ac07': {'test_accuracy': 0.958148181438446, 'test_diff_accuracy': 0.0}, 'a57f2f04': {'test_accuracy': 0.6633333563804626, 'test_diff_accuracy': 0.0}, 'a59b95c0': {'test_accuracy': 0.9160000085830688, 'test_diff_accuracy': 0.0}, 'a680ac02': {'test_accuracy': 0.9644444584846497, 'test_diff_accuracy': 0.6501501202583313}, 'a8610ef7': {'test_accuracy': 0.9766666889190674, 'test_diff_accuracy': 0.0}, 'a934301b': {'test_accuracy': 0.9674074053764343, 'test_diff_accuracy': 1.0}, 'aa18de87': {'test_accuracy': 0.9791666269302368, 'test_diff_accuracy': 0.0}, 'aa300dc3': {'test_accuracy': 0.930555522441864, 'test_diff_accuracy': 0.0}, 'aa4ec2a5': {'test_accuracy': 0.43740740418434143, 'test_diff_accuracy': 0.0}, 'aab50785': {'test_accuracy': 0.9871110916137695, 'test_diff_accuracy': 0.9002954363822937}, 'ac0c5833': {'test_accuracy': 0.9518518447875977, 'test_diff_accuracy': 0.0}, 'ac2e8ecf': {'test_accuracy': 0.9529629349708557, 'test_diff_accuracy': 0.4784134328365326}, 'ac3e2b04': {'test_accuracy': 0.9386110901832581, 'test_diff_accuracy': 0.0}, 'ac605cbb': {'test_accuracy': 0.9875926375389099, 'test_diff_accuracy': 0.0}, 'ad7e01d0': {'test_accuracy': 0.9144444465637207, 'test_diff_accuracy': 0.08509097993373871}, 'ae58858e': {'test_accuracy': 0.9783333539962769, 'test_diff_accuracy': 0.0}, 'aee291af': {'test_accuracy': 0.9762962460517883, 'test_diff_accuracy': 0.9403367638587952}, 'af22c60d': {'test_accuracy': 0.0, 'test_diff_accuracy': 0.0}, 'af24b4cc': {'test_accuracy': 0.9929630160331726, 'test_diff_accuracy': 0.8559829592704773}, 'b0722778': {'test_accuracy': 0.9844444394111633, 'test_diff_accuracy': 0.7229965329170227}, 'b0f4d537': {'test_accuracy': 0.9722222089767456, 'test_diff_accuracy': 0.6134893894195557}, 'b15fca0b': {'test_accuracy': 0.9675555229187012, 'test_diff_accuracy': 0.0}, 'b1fc8b8e': {'test_accuracy': 0.9851110577583313, 'test_diff_accuracy': 0.48750001192092896}, 'b20f7c8b': {'test_accuracy': 0.7707407474517822, 'test_diff_accuracy': 0.0}, 'b457fec5': {'test_accuracy': 0.9137037396430969, 'test_diff_accuracy': 0.0}, 'b4a43f3b': {'test_accuracy': 0.9633333086967468, 'test_diff_accuracy': 0.46900829672813416}, 'b7999b51': {'test_accuracy': 0.9900000095367432, 'test_diff_accuracy': 0.8587267994880676}, 'b7cb93ac': {'test_accuracy': 0.9866666793823242, 'test_diff_accuracy': 0.4814814627170563}, 'b7f8a4d8': {'test_accuracy': 0.6399999856948853, 'test_diff_accuracy': 0.0}, 'b7fb29bc': {'test_accuracy': 0.9100000262260437, 'test_diff_accuracy': 0.0}, 'b942fd60': {'test_accuracy': 0.9666666984558105, 'test_diff_accuracy': 0.0}, 'b9630600': {'test_accuracy': 0.8437037467956543, 'test_diff_accuracy': 0.3881119191646576}, 'ba9d41b8': {'test_accuracy': 0.9162963032722473, 'test_diff_accuracy': 1.0}, 'baf41dbf': {'test_accuracy': 0.9592592716217041, 'test_diff_accuracy': 0.20501208305358887}, 'bb52a14b': {'test_accuracy': 0.9188888669013977, 'test_diff_accuracy': 0.0}, 'bbb1b8b6': {'test_accuracy': 0.9852380156517029, 'test_diff_accuracy': 0.5396488308906555}, 'bc4146bd': {'test_accuracy': 0.9111111164093018, 'test_diff_accuracy': 0.0}, 'bcb3040b': {'test_accuracy': 0.9196296334266663, 'test_diff_accuracy': 0.0}, 'bd14c3bf': {'test_accuracy': 0.9211111068725586, 'test_diff_accuracy': 0.0}, 'be03b35f': {'test_accuracy': 0.9970369935035706, 'test_diff_accuracy': 0.8111111521720886}, 'bf32578f': {'test_accuracy': 0.9881481528282166, 'test_diff_accuracy': 0.3821733891963959}, 'bf699163': {'test_accuracy': 0.9900000095367432, 'test_diff_accuracy': 0.9721251130104065}, 'bf89d739': {'test_accuracy': 0.9780555367469788, 'test_diff_accuracy': 0.0}, 'c074846d': {'test_accuracy': 0.9948889017105103, 'test_diff_accuracy': 0.0}, 'c1990cce': {'test_accuracy': 0.9785184860229492, 'test_diff_accuracy': 0.07402319461107254}, 'c3202e5a': {'test_accuracy': 0.9929630160331726, 'test_diff_accuracy': 0.9741120338439941}, 'c35c1b4c': {'test_accuracy': 0.9144444465637207, 'test_diff_accuracy': 0.0}, 'c48954c1': {'test_accuracy': 0.9100000262260437, 'test_diff_accuracy': 0.0}, 'c62e2108': {'test_accuracy': 0.8962963223457336, 'test_diff_accuracy': 0.04329491779208183}, 'c64f1187': {'test_accuracy': 0.9688888788223267, 'test_diff_accuracy': 0.6881044507026672}, 'c658a4bd': {'test_accuracy': 0.9194444417953491, 'test_diff_accuracy': 0.37494730949401855}, 'c663677b': {'test_accuracy': 0.1899999976158142, 'test_diff_accuracy': 0.0}, 'c6e1b8da': {'test_accuracy': 0.8537037372589111, 'test_diff_accuracy': 0.45049849152565}, 'c7d4e6ad': {'test_accuracy': 0.9777777791023254, 'test_diff_accuracy': 0.0}, 'c87289bb': {'test_accuracy': 0.9436111450195312, 'test_diff_accuracy': 0.0}, 'c8b7cc0f': {'test_accuracy': 0.995555579662323, 'test_diff_accuracy': 0.8881499767303467}, 'c92b942c': {'test_accuracy': 0.9175000190734863, 'test_diff_accuracy': 0.0}, 'c97c0139': {'test_accuracy': 0.9155555963516235, 'test_diff_accuracy': 0.0}, 'ca8de6ea': {'test_accuracy': 0.9900000095367432, 'test_diff_accuracy': 0.3333333432674408}, 'ca8f78db': {'test_accuracy': 0.0, 'test_diff_accuracy': 0.0}, 'cad67732': {'test_accuracy': 0.9740740656852722, 'test_diff_accuracy': 0.0}, 'cb227835': {'test_accuracy': 0.9792592525482178, 'test_diff_accuracy': 0.0}, 'ccd554ac': {'test_accuracy': 0.9307406544685364, 'test_diff_accuracy': 0.02556818164885044}, 'cd3c21df': {'test_accuracy': 0.9948148727416992, 'test_diff_accuracy': 0.8213383555412292}, 'ce039d91': {'test_accuracy': 0.9774999618530273, 'test_diff_accuracy': 0.0}, 'ce8d95cc': {'test_accuracy': 0.9802777767181396, 'test_diff_accuracy': 0.7194792032241821}, 'cf133acc': {'test_accuracy': 0.9370369911193848, 'test_diff_accuracy': 0.0}, 'cfb2ce5a': {'test_accuracy': 0.9325925707817078, 'test_diff_accuracy': 0.0}, 'd017b73f': {'test_accuracy': 0.9883332848548889, 'test_diff_accuracy': 0.5}, 'd19f7514': {'test_accuracy': 0.9808333516120911, 'test_diff_accuracy': 0.4937748610973358}, 'd282b262': {'test_accuracy': 0.9677777290344238, 'test_diff_accuracy': 0.4773857891559601}, 'd2acf2cb': {'test_accuracy': 0.9551851749420166, 'test_diff_accuracy': 0.095238097012043}, 'd304284e': {'test_accuracy': 0.8761111497879028, 'test_diff_accuracy': 0.0}, 'd37a1ef5': {'test_accuracy': 0.9344444274902344, 'test_diff_accuracy': 0.0}, 'd47aa2ff': {'test_accuracy': 0.9896295666694641, 'test_diff_accuracy': 0.7235023379325867}, 'd492a647': {'test_accuracy': 0.8811111450195312, 'test_diff_accuracy': 0.0}, 'd4b1c2b1': {'test_accuracy': 0.9442857503890991, 'test_diff_accuracy': 0.2857142984867096}, 'd4c90558': {'test_accuracy': 0.9829629063606262, 'test_diff_accuracy': 0.9063237309455872}, 'd56f2372': {'test_accuracy': 0.9866666793823242, 'test_diff_accuracy': 0.8060207962989807}, 'd5c634a2': {'test_accuracy': 0.9953967928886414, 'test_diff_accuracy': 0.7885443568229675}, 'd931c21c': {'test_accuracy': 0.9108333587646484, 'test_diff_accuracy': 0.25}, 'd94c3b52': {'test_accuracy': 0.8414815068244934, 'test_diff_accuracy': 0.0}, 'da2b0fe3': {'test_accuracy': 0.9707407355308533, 'test_diff_accuracy': 0.0}, 'da515329': {'test_accuracy': 0.8374074101448059, 'test_diff_accuracy': 0.0}, 'dc2aa30b': {'test_accuracy': 0.9100000262260437, 'test_diff_accuracy': 0.0}, 'dc2e9a9d': {'test_accuracy': 0.9233333468437195, 'test_diff_accuracy': 0.0}, 'dd2401ed': {'test_accuracy': 0.9811111092567444, 'test_diff_accuracy': 0.43627452850341797}, 'de493100': {'test_accuracy': 0.25111111998558044, 'test_diff_accuracy': 0.2521111071109772}, 'df8cc377': {'test_accuracy': 0.9492592811584473, 'test_diff_accuracy': 0.5}, 'e0fb7511': {'test_accuracy': 0.8314814567565918, 'test_diff_accuracy': 0.0}, 'e133d23d': {'test_accuracy': 0.9926666021347046, 'test_diff_accuracy': 0.5035164952278137}, 'e1baa8a4': {'test_accuracy': 0.9894444942474365, 'test_diff_accuracy': 0.9602466225624084}, 'e1d2900e': {'test_accuracy': 0.9777777194976807, 'test_diff_accuracy': 0.5}, 'e2092e0c': {'test_accuracy': 0.8866667151451111, 'test_diff_accuracy': 0.0}, 'e21a174a': {'test_accuracy': 0.9562962651252747, 'test_diff_accuracy': 0.254934161901474}, 'e345f17b': {'test_accuracy': 0.9961110949516296, 'test_diff_accuracy': 0.8137826919555664}, 'e4075551': {'test_accuracy': 0.9433333277702332, 'test_diff_accuracy': 0.0}, 'e41c6fd3': {'test_accuracy': 0.936296284198761, 'test_diff_accuracy': 0.5}, 'e57337a4': {'test_accuracy': 0.8762962818145752, 'test_diff_accuracy': 0.5169753432273865}, 'e5790162': {'test_accuracy': 0.988444447517395, 'test_diff_accuracy': 0.0}, 'e5c44e8f': {'test_accuracy': 0.9455555081367493, 'test_diff_accuracy': 0.0}, 'e619ca6e': {'test_accuracy': 0.8762962818145752, 'test_diff_accuracy': 0.0}, 'e633a9e5': {'test_accuracy': 0.9722221493721008, 'test_diff_accuracy': 0.0}, 'e66aafb8': {'test_accuracy': 0.9508889317512512, 'test_diff_accuracy': 0.9255886077880859}, 'e681b708': {'test_accuracy': 0.8870370388031006, 'test_diff_accuracy': 0.0}, 'e69241bd': {'test_accuracy': 0.9433333277702332, 'test_diff_accuracy': 0.0}, 'e6de6e8f': {'test_accuracy': 0.9877777695655823, 'test_diff_accuracy': 0.5444445013999939}, 'e74e1818': {'test_accuracy': 0.9674074053764343, 'test_diff_accuracy': 0.5}, 'e760a62e': {'test_accuracy': 0.618148148059845, 'test_diff_accuracy': 0.0}, 'e7639916': {'test_accuracy': 0.9644444584846497, 'test_diff_accuracy': 0.0}, 'e78887d1': {'test_accuracy': 0.9794444441795349, 'test_diff_accuracy': 0.6878482103347778}, 'e7a25a18': {'test_accuracy': 0.9244444370269775, 'test_diff_accuracy': 0.2172304391860962}, 'e7b06bea': {'test_accuracy': 0.9871110916137695, 'test_diff_accuracy': 0.7000000476837158}, 'e7dd8335': {'test_accuracy': 0.9785184860229492, 'test_diff_accuracy': 0.0}, 'e872b94a': {'test_accuracy': 1.0, 'test_diff_accuracy': 1.0}, 'e88171ec': {'test_accuracy': 0.8096296787261963, 'test_diff_accuracy': 0.0}, 'e95e3d8e': {'test_accuracy': 0.46222221851348877, 'test_diff_accuracy': 0.0}, 'e99362f0': {'test_accuracy': 0.978518545627594, 'test_diff_accuracy': 0.7147099375724792}, 'e9ac8c9e': {'test_accuracy': 0.9792592525482178, 'test_diff_accuracy': 0.2666666805744171}, 'e9b4f6fc': {'test_accuracy': 0.9619444012641907, 'test_diff_accuracy': 0.44486111402511597}, 'e9bb6954': {'test_accuracy': 0.9030555486679077, 'test_diff_accuracy': 0.0032051282469183207}, 'e9c9d9a1': {'test_accuracy': 0.8203703761100769, 'test_diff_accuracy': 0.0}, 'ea959feb': {'test_accuracy': 0.3888889253139496, 'test_diff_accuracy': 0.0}, 'ea9794b1': {'test_accuracy': 0.9729629158973694, 'test_diff_accuracy': 0.647230327129364}, 'ecaa0ec1': {'test_accuracy': 0.9894444346427917, 'test_diff_accuracy': 0.48773449659347534}, 'ed74f2f2': {'test_accuracy': 0.9935185313224792, 'test_diff_accuracy': 0.5953373312950134}, 'ed98d772': {'test_accuracy': 0.9777777791023254, 'test_diff_accuracy': 0.10508663952350616}, 'ef26cbf6': {'test_accuracy': 0.95333331823349, 'test_diff_accuracy': 0.0}, 'f0afb749': {'test_accuracy': 0.9822222590446472, 'test_diff_accuracy': 0.061728399246931076}, 'f0df5ff0': {'test_accuracy': 0.8670370578765869, 'test_diff_accuracy': 0.0}, 'f21745ec': {'test_accuracy': 0.8877778053283691, 'test_diff_accuracy': 0.4960607588291168}, 'f3b10344': {'test_accuracy': 0.711481511592865, 'test_diff_accuracy': 0.0}, 'f3cdc58f': {'test_accuracy': 0.9785184860229492, 'test_diff_accuracy': 0.44780412316322327}, 'f3e62deb': {'test_accuracy': 0.9911110997200012, 'test_diff_accuracy': 0.5}, 'f4081712': {'test_accuracy': 0.9235555529594421, 'test_diff_accuracy': 0.8869382739067078}, 'f45f5ca7': {'test_accuracy': 0.9918518662452698, 'test_diff_accuracy': 0.5}, 'f5aa3634': {'test_accuracy': 0.9911110997200012, 'test_diff_accuracy': 0.8053030371665955}, 'f5c89df1': {'test_accuracy': 0.9829629063606262, 'test_diff_accuracy': 0.437296062707901}, 'f823c43c': {'test_accuracy': 0.7616666555404663, 'test_diff_accuracy': 0.0}, 'f83cb3f6': {'test_accuracy': 0.9807407259941101, 'test_diff_accuracy': 0.6049907803535461}, 'f8be4b64': {'test_accuracy': 0.9094444513320923, 'test_diff_accuracy': 0.0}, 'f9a67cb5': {'test_accuracy': 0.9262962937355042, 'test_diff_accuracy': 0.0}, 'f9d67f8b': {'test_accuracy': 0.15777777135372162, 'test_diff_accuracy': 0.13529807329177856}, 'fafd9572': {'test_accuracy': 0.9700000286102295, 'test_diff_accuracy': 0.0}, 'fb791726': {'test_accuracy': 0.961017370223999, 'test_diff_accuracy': 0.03614457696676254}, 'fc754716': {'test_accuracy': 0.9844443798065186, 'test_diff_accuracy': 0.07361919432878494}, 'fd096ab6': {'test_accuracy': 0.41111111640930176, 'test_diff_accuracy': 0.0}, 'fd4b2b02': {'test_accuracy': 0.9122222065925598, 'test_diff_accuracy': 0.0}, 'fe9372f3': {'test_accuracy': 0.9600000977516174, 'test_diff_accuracy': 0.0}, 'fea12743': {'test_accuracy': 0.9288887977600098, 'test_diff_accuracy': 0.0}, 'ff72ca3e': {'test_accuracy': 0.9647221565246582, 'test_diff_accuracy': 0.0}, 'avg': {'test_accuracy': 0.904828667640686, 'test_diff_accuracy': 0.2692205607891083}}, 'model_summary': '   | Name                        | Type             | Params | Mode\\n-------------------------------------------------------------------------\\n0  | conv1                       | Conv2d           | 2.6 K  | eval\\n1  | blocks                      | ModuleList       | 1.6 M  | eval\\n2  | blocks.0                    | TransformerBlock | 789 K  | eval\\n3  | blocks.0.attention          | Attention        | 263 K  | eval\\n4  | blocks.0.attention.key      | Linear           | 65.8 K | eval\\n5  | blocks.0.attention.query    | Linear           | 65.8 K | eval\\n6  | blocks.0.attention.value    | Linear           | 65.8 K | eval\\n7  | blocks.0.attention.proj     | Linear           | 65.8 K | eval\\n8  | blocks.0.feed_forward       | FeedForward      | 525 K  | eval\\n9  | blocks.0.feed_forward.net   | Sequential       | 525 K  | eval\\n10 | blocks.0.feed_forward.net.0 | Linear           | 263 K  | eval\\n11 | blocks.0.feed_forward.net.1 | ReLU             | 0      | eval\\n12 | blocks.0.feed_forward.net.2 | Linear           | 262 K  | eval\\n13 | blocks.0.ln1                | LayerNorm        | 512    | eval\\n14 | blocks.0.ln2                | LayerNorm        | 512    | eval\\n15 | blocks.1                    | TransformerBlock | 789 K  | eval\\n16 | blocks.1.attention          | Attention        | 263 K  | eval\\n17 | blocks.1.attention.key      | Linear           | 65.8 K | eval\\n18 | blocks.1.attention.query    | Linear           | 65.8 K | eval\\n19 | blocks.1.attention.value    | Linear           | 65.8 K | eval\\n20 | blocks.1.attention.proj     | Linear           | 65.8 K | eval\\n21 | blocks.1.feed_forward       | FeedForward      | 525 K  | eval\\n22 | blocks.1.feed_forward.net   | Sequential       | 525 K  | eval\\n23 | blocks.1.feed_forward.net.0 | Linear           | 263 K  | eval\\n24 | blocks.1.feed_forward.net.1 | ReLU             | 0      | eval\\n25 | blocks.1.feed_forward.net.2 | Linear           | 262 K  | eval\\n26 | blocks.1.ln1                | LayerNorm        | 512    | eval\\n27 | blocks.1.ln2                | LayerNorm        | 512    | eval\\n28 | ln_f                        | LayerNorm        | 512    | eval\\n29 | fc_out                      | Linear           | 2.6 K  | eval\\n-------------------------------------------------------------------------\\n1.6 M     Trainable params\\n0         Non-trainable params\\n1.6 M     Total params\\n6.341     Total estimated model params size (MB)\\n0         Modules in train mode\\n30        Modules in eval mode'}\n",
            "INFO:__main__:Results saved to evaluation_results/arc_model-epoch_00-val_loss_0_eval_results_20240928_231927.json\n",
            "DEBUG:__main__:Creating wandb Artifact with name: arc_model-epoch_00-val_loss_0\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
            "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/11\" 200 None\n",
            "DEBUG:__main__:Artifact created and logged successfully.\n",
            "wandb: - 0.049 MB of 0.049 MB uploaded\n",
            "wandb: \\ 1.217 MB of 1.217 MB uploaded\n",
            "wandb: | 1.218 MB of 1.218 MB uploaded\n",
            "wandb: / 1.218 MB of 1.218 MB uploaded\n",
            "wandb: - 1.218 MB of 1.218 MB uploaded\n",
            "wandb:                                                                                \n",
            "wandb: \n",
            "wandb: Run history:\n",
            "wandb: eval/complete_task_accuracy ▁\n",
            "wandb:          eval/test_accuracy ▁\n",
            "wandb:     eval/test_diff_accuracy ▁\n",
            "wandb:              eval/test_loss ▁\n",
            "wandb: \n",
            "wandb: Run summary:\n",
            "wandb: eval/complete_task_accuracy 0.23441\n",
            "wandb:          eval/test_accuracy 0.90483\n",
            "wandb:     eval/test_diff_accuracy 0.26922\n",
            "wandb:              eval/test_loss 0.36649\n",
            "wandb: \n",
            "wandb: 🚀 View run scaling-test-evaluation-epoch00-val_loss0.37 at: https://wandb.ai/arc-abolition/arc-evaluation/runs/rn92ouio\n",
            "wandb: ⭐️ View project at: https://wandb.ai/arc-abolition/arc-evaluation\n",
            "wandb: Synced 4 W&B file(s), 0 media file(s), 5 artifact file(s) and 0 other file(s)\n",
            "wandb: Find logs at: ./wandb/run-20240928_231726-rn92ouio/logs\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): o151352.ingest.sentry.io:443\n",
            "DEBUG:urllib3.connectionpool:https://o151352.ingest.sentry.io:443 \"POST /api/4504800232407040/envelope/ HTTP/11\" 200 0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Build the arguments for the training command\n",
        "train_args = [\n",
        "    \"python\", os.path.join(arc_model_dir, \"gpt2_arc/src/training/train.py\"),\n",
        "    \"--n-embd\", str(params[\"n_embd\"]),\n",
        "    \"--n-head\", str(params[\"n_head\"]),\n",
        "    \"--n-layer\", str(params[\"n_layer\"]),\n",
        "    \"--batch-size\", str(params[\"batch_size\"]),\n",
        "    \"--learning-rate\", str(params[\"learning_rate\"]),\n",
        "    \"--max-epochs\", str(params[\"max_epochs\"]),\n",
        "    \"--use-gpu\",\n",
        "    \"--project\", \"arc-scaling-test\"\n",
        "]\n",
        "\n",
        "# Notify the user that training is starting\n",
        "print(\"Starting training process...\")\n",
        "\n",
        "# Start the training process and stream output to the notebook cell\n",
        "process = subprocess.Popen(\n",
        "    train_args,\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.STDOUT,\n",
        "    text=True  # Ensures that the output is treated as text\n",
        ")\n",
        "\n",
        "# Stream the output in real-time\n",
        "try:\n",
        "    for line in process.stdout:\n",
        "        print(line, end='')  # Print each line as it's received\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\nTraining interrupted by user.\")\n",
        "    process.terminate()\n",
        "    process.wait()\n",
        "\n",
        "# Wait for the process to complete and get the return code\n",
        "return_code = process.wait()\n",
        "if return_code == 0:\n",
        "    print(\"Training completed successfully.\")\n",
        "else:\n",
        "    print(f\"Training failed with return code {return_code}.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "L25zvW0ig8K1",
      "metadata": {
        "id": "L25zvW0ig8K1"
      },
      "source": [
        "### 6. Analyze the results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "mJhLC5Ttg8K1",
      "metadata": {
        "id": "mJhLC5Ttg8K1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2 JSON files.\n",
            "Compiled 2 records.\n",
            "Aggregate Results DataFrame:\n",
            "            timestamp  test_loss  test_accuracy  test_diff_accuracy  \\\n",
            "0 2024-09-28 23:19:27   0.366487       0.904829            0.269221   \n",
            "1 2024-09-28 23:19:28   0.366487       0.904829            0.269221   \n",
            "\n",
            "   complete_task_accuracy  \n",
            "0                0.234414  \n",
            "1                0.234414  \n",
            "Individual Metrics DataFrame:\n",
            "            timestamp metric_id  test_accuracy  test_diff_accuracy\n",
            "0 2024-09-28 23:19:27  00576224       0.960000            0.000000\n",
            "1 2024-09-28 23:19:27  009d5c81       0.974444            0.210032\n",
            "2 2024-09-28 23:19:27  00dbd492       0.929444            0.000000\n",
            "3 2024-09-28 23:19:27  03560426       0.979630            0.518815\n",
            "4 2024-09-28 23:19:27  05a7bcf2       0.656667            0.000000\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x1000 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import glob\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 1. Define the directory containing evaluation results\n",
        "results_dir = Path(\"./evaluation_results/\")\n",
        "\n",
        "# 2. Retrieve all JSON files\n",
        "json_files = list(results_dir.glob(\"*.json\"))\n",
        "print(f\"Found {len(json_files)} JSON files.\")\n",
        "\n",
        "# 3. Function to extract timestamp from filename\n",
        "def extract_timestamp(filename):\n",
        "    \"\"\"\n",
        "    Extracts the timestamp from the filename.\n",
        "    Expected format: ..._YYYYMMDD_HHMMSS.json\n",
        "    \"\"\"\n",
        "    pattern = r\"_(\\d{8}_\\d{6})\\.json$\"\n",
        "    match = re.search(pattern, filename)\n",
        "    if match:\n",
        "        return pd.to_datetime(match.group(1), format=\"%Y%m%d_%H%M%S\")\n",
        "    else:\n",
        "        return pd.NaT  # Not a Time if pattern doesn't match\n",
        "\n",
        "# 4. Load and compile aggregate results\n",
        "data = []\n",
        "\n",
        "for file in json_files:\n",
        "    with open(file, \"r\") as f:\n",
        "        results = json.load(f)\n",
        "\n",
        "    # Extract aggregate results\n",
        "    aggregate = results.get(\"aggregate_results\", {})\n",
        "\n",
        "    # Extract timestamp from filename\n",
        "    timestamp = extract_timestamp(file.name)\n",
        "\n",
        "    # Combine data\n",
        "    record = {\n",
        "        \"timestamp\": timestamp,\n",
        "        \"test_loss\": aggregate.get(\"test_loss\"),\n",
        "        \"test_accuracy\": aggregate.get(\"test_accuracy\"),\n",
        "        \"test_diff_accuracy\": aggregate.get(\"test_diff_accuracy\"),\n",
        "        \"complete_task_accuracy\": aggregate.get(\"complete_task_accuracy\")\n",
        "    }\n",
        "\n",
        "    data.append(record)\n",
        "\n",
        "print(f\"Compiled {len(data)} records.\")\n",
        "\n",
        "# 5. Create DataFrame for aggregate results\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Drop records with missing timestamps\n",
        "df = df.dropna(subset=[\"timestamp\"])\n",
        "\n",
        "# Sort by timestamp\n",
        "df = df.sort_values(\"timestamp\").reset_index(drop=True)\n",
        "\n",
        "print(\"Aggregate Results DataFrame:\")\n",
        "print(df.head())\n",
        "\n",
        "# 6. (Optional) Handle individual metrics\n",
        "individual_data = []\n",
        "\n",
        "for file in json_files:\n",
        "    with open(file, \"r\") as f:\n",
        "        results = json.load(f)\n",
        "\n",
        "    # Extract individual metrics\n",
        "    individual = results.get(\"individual_metrics\", {})\n",
        "\n",
        "    # Extract timestamp from filename\n",
        "    timestamp = extract_timestamp(file.name)\n",
        "\n",
        "    for metric_id, metrics in individual.items():\n",
        "        record = {\n",
        "            \"timestamp\": timestamp,\n",
        "            \"metric_id\": metric_id,\n",
        "            \"test_accuracy\": metrics.get(\"test_accuracy\"),\n",
        "            \"test_diff_accuracy\": metrics.get(\"test_diff_accuracy\")\n",
        "        }\n",
        "        individual_data.append(record)\n",
        "\n",
        "individual_df = pd.DataFrame(individual_data)\n",
        "\n",
        "# Drop records with missing timestamps\n",
        "individual_df = individual_df.dropna(subset=[\"timestamp\"])\n",
        "\n",
        "# Convert timestamp to datetime if not already\n",
        "if individual_df[\"timestamp\"].dtype == object:\n",
        "    individual_df[\"timestamp\"] = pd.to_datetime(individual_df[\"timestamp\"])\n",
        "\n",
        "print(\"Individual Metrics DataFrame:\")\n",
        "print(individual_df.head())\n",
        "\n",
        "# 7. Save DataFrames to CSV (Optional)\n",
        "df.to_csv(\"aggregate_evaluation_results.csv\", index=False)\n",
        "individual_df.to_csv(\"individual_evaluation_metrics.csv\", index=False)\n",
        "\n",
        "# 8. Plot Test Accuracy Over Time\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(df['timestamp'], df['test_accuracy'], marker='o', linestyle='-', label='Test Accuracy')\n",
        "plt.title('Test Accuracy Over Time')\n",
        "plt.xlabel('Timestamp')\n",
        "plt.ylabel('Test Accuracy')\n",
        "plt.grid(True)\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot Test Diff Accuracy Over Time\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(df['timestamp'], df['test_diff_accuracy'], marker='o', linestyle='-', color='green', label='Test Diff Accuracy')\n",
        "plt.title('Test Diff Accuracy Over Time')\n",
        "plt.xlabel('Timestamp')\n",
        "plt.ylabel('Test Diff Accuracy')\n",
        "plt.grid(True)\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot Complete Task Accuracy Over Time\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(df['timestamp'], df['complete_task_accuracy'], marker='o', linestyle='-', color='red', label='Complete Task Accuracy')\n",
        "plt.title('Complete Task Accuracy Over Time')\n",
        "plt.xlabel('Timestamp')\n",
        "plt.ylabel('Complete Task Accuracy')\n",
        "plt.grid(True)\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Heatmap: Task Accuracy Over Time\n",
        "\n",
        "# Pivot the individual_df to have 'metric_id' as rows and 'timestamp' as columns, with 'test_accuracy' as values\n",
        "heatmap_data = individual_df.pivot_table(index='metric_id', columns='timestamp', values='test_accuracy')\n",
        "\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(heatmap_data, cmap=\"coolwarm\", cbar_kws={'label': 'Test Accuracy'}, annot=False)\n",
        "plt.title('Task Accuracy Over Time')\n",
        "plt.xlabel('Timestamp')\n",
        "plt.ylabel('Task (Metric ID)')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LOEvyN3LCVdV",
      "metadata": {
        "id": "LOEvyN3LCVdV"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "5062c297"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
